{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from main import get_preprocessed_data\n",
    "from indicator_and_strategy.indicators import Indicator\n",
    "from indicator_and_strategy.momentumstrategy import MomentumStrategy\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import talib\n",
    "import datetime as dt\n",
    "\n",
    "from finrl.meta.preprocessor.yahoodownloader import  YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl import config_tickers\n",
    "from finrl.config import INDICATORS\n",
    "import itertools\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dollar PnL calculation\n",
    "\n",
    "pnls = []\n",
    "dates = []\n",
    "entry = None\n",
    "for i in range(len(df)):\n",
    "    if df['emas'].iloc[i] > df['emal'].iloc[i] and df['emas'].iloc[i-1] < df['emal'].iloc[i-1]:\n",
    "        if entry:\n",
    "            pnl = entry - df['close'].iloc[i]\n",
    "            pnls.append(pnl)\n",
    "            dates.append(df.index[i])\n",
    "            print(f'Buy on {df.index[i]} and at {df.close.iloc[i]}: {pnl}')\n",
    "        entry = df['close'].iloc[i]\n",
    "\n",
    "    elif df['emas'].iloc[i] < df['emal'].iloc[i] and df['emas'].iloc[i-1] > df['emal'].iloc[i-1]:\n",
    "        if entry:\n",
    "            pnl = df['close'].iloc[i] - entry\n",
    "            pnls.append(pnl)\n",
    "            dates.append(df.index[i])\n",
    "            print(f'Sell on {df.index[i]} at {df.close.iloc[i]}: {pnl}')\n",
    "        entry = df['close'].iloc[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentage PnL calculation\n",
    "pnls = []\n",
    "dates = []\n",
    "entry = None\n",
    "for i in range(len(df)):\n",
    "    if df['emas'].iloc[i] > df['emal'].iloc[i] and df['emas'].iloc[i-1] < df['emal'].iloc[i-1]:\n",
    "        if entry:\n",
    "            pnl = (entry - df['close'].iloc[i]) / entry\n",
    "            pnls.append(pnl)\n",
    "            dates.append(df.index[i])\n",
    "            print(f'Buy on {df.index[i]} and at {df.close.iloc[i]}: {pnl}')\n",
    "        entry = df['close'].iloc[i]\n",
    "\n",
    "\n",
    "    elif df['emas'].iloc[i] < df['emal'].iloc[i] and df['emas'].iloc[i-1] > df['emal'].iloc[i-1]:\n",
    "        if entry:\n",
    "            pnl = (df['close'].iloc[i] - entry) / entry\n",
    "            pnls.append(pnl)\n",
    "            dates.append(df.index[i])\n",
    "            print(f'Sell on {df.index[i]} at {df.close.iloc[i]}: {pnl}')\n",
    "        entry = df['close'].iloc[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Unrealized PnL \n",
    "\n",
    "entry = None\n",
    "pnls = []\n",
    "dates = []\n",
    "inpos = 0\n",
    "unrlzd = []\n",
    "urlzd_dates = []\n",
    "hold_time = []\n",
    "for i in range(len(df)):\n",
    "    unr = (spy.iloc[i] -spy.iloc[i - 1]) * inpos\n",
    "    unrlzd.append(unr)\n",
    "    urlzd_dates.append(df.index[i])\n",
    "    hold_time.append((df['close'].index[i] - start).days)\n",
    "    if df['emas'].iloc[i] > df['emal'].iloc[i] and df['emas'].iloc[i-1] < df['emal'].iloc[i-1]:\n",
    "        if entry:\n",
    "            pnl = entry - spy.iloc[i]\n",
    "            pnls.append(pnl)\n",
    "            dates.append(df.index[i])\n",
    "            print(f'Buy on {df.index[i]} and at {df.close.iloc[i]}: {pnl}')\n",
    "        entry = df['close'].index[i]\n",
    "        inpos = 1\n",
    "        start = df.index[i]\n",
    "\n",
    "    elif df['emas'].iloc[i] < df['emal'].iloc[i] and df['emas'].iloc[i-1] > df['emal'].iloc[i-1]:\n",
    "        if entry:\n",
    "            pnl = spy.iloc[i] - entry\n",
    "            pnls.append(pnl)\n",
    "            dates.append(df.index[i])\n",
    "            print(f'Sell on {df.index[i]} at {df.close.iloc[i]}: {pnl}')\n",
    "        entry = df['close'].iloc[i]\n",
    "        inpos = -1\n",
    "        start = df['close'].index[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Unrealized PnL vs Realized PnL')\n",
    "plt.plot(urlzd_dates, np.cumsum(unrlzd))\n",
    "plt.plot(dates, np.cumsum(pnls), '-o')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantifying the strategy: How good is it?\n",
    "\n",
    "sharp_ratio = np.mean(unrlzd) / np.std(unrlzd) * np.sqrt(252)\n",
    "print(f'Annualized Sharpe Ratio: {sharp_ratio}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sharp_ratio = np.mean(unrlzd) / np.std(unrlzd) * 16\n",
    "print(f'Annualized Sharpe Ratio: {sharp_ratio}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_START_DATE = '2009-01-01'\n",
    "TRAIN_END_DATE = '2020-07-01'\n",
    "TRADE_START_DATE = '2020-07-01'\n",
    "TRADE_END_DATE = '2023-05-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = [\n",
    "    'aapl', \n",
    "    'msft',\n",
    "    'meta',\n",
    "    'ibm'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (13569, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw = YahooDownloader(start_date = TRAIN_START_DATE,\n",
    "                     end_date = TRADE_END_DATE,\n",
    "                     ticker_list = symbols\n",
    "                     ).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>3.067143</td>\n",
       "      <td>3.251429</td>\n",
       "      <td>3.041429</td>\n",
       "      <td>2.740173</td>\n",
       "      <td>746015200</td>\n",
       "      <td>aapl</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>80.200768</td>\n",
       "      <td>83.738052</td>\n",
       "      <td>80.200768</td>\n",
       "      <td>49.160149</td>\n",
       "      <td>7905877</td>\n",
       "      <td>ibm</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>19.530001</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>19.370001</td>\n",
       "      <td>15.011639</td>\n",
       "      <td>50084000</td>\n",
       "      <td>msft</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>3.327500</td>\n",
       "      <td>3.435000</td>\n",
       "      <td>3.311071</td>\n",
       "      <td>2.855819</td>\n",
       "      <td>1181608400</td>\n",
       "      <td>aapl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>82.619499</td>\n",
       "      <td>83.814529</td>\n",
       "      <td>82.390060</td>\n",
       "      <td>48.850681</td>\n",
       "      <td>8698222</td>\n",
       "      <td>ibm</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>20.200001</td>\n",
       "      <td>20.670000</td>\n",
       "      <td>20.059999</td>\n",
       "      <td>15.151946</td>\n",
       "      <td>61475200</td>\n",
       "      <td>msft</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2009-01-06</td>\n",
       "      <td>3.426786</td>\n",
       "      <td>3.470357</td>\n",
       "      <td>3.299643</td>\n",
       "      <td>2.808713</td>\n",
       "      <td>1289310400</td>\n",
       "      <td>aapl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2009-01-06</td>\n",
       "      <td>83.279160</td>\n",
       "      <td>86.434036</td>\n",
       "      <td>82.571701</td>\n",
       "      <td>50.206703</td>\n",
       "      <td>10093377</td>\n",
       "      <td>ibm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2009-01-06</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>20.610001</td>\n",
       "      <td>15.329155</td>\n",
       "      <td>58083400</td>\n",
       "      <td>msft</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2009-01-07</td>\n",
       "      <td>3.278929</td>\n",
       "      <td>3.303571</td>\n",
       "      <td>3.223571</td>\n",
       "      <td>2.748023</td>\n",
       "      <td>753048800</td>\n",
       "      <td>aapl</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       open       high        low      close      volume   tic  \\\n",
       "0  2009-01-02   3.067143   3.251429   3.041429   2.740173   746015200  aapl   \n",
       "1  2009-01-02  80.200768  83.738052  80.200768  49.160149     7905877   ibm   \n",
       "2  2009-01-02  19.530001  20.400000  19.370001  15.011639    50084000  msft   \n",
       "3  2009-01-05   3.327500   3.435000   3.311071   2.855819  1181608400  aapl   \n",
       "4  2009-01-05  82.619499  83.814529  82.390060  48.850681     8698222   ibm   \n",
       "5  2009-01-05  20.200001  20.670000  20.059999  15.151946    61475200  msft   \n",
       "6  2009-01-06   3.426786   3.470357   3.299643   2.808713  1289310400  aapl   \n",
       "7  2009-01-06  83.279160  86.434036  82.571701  50.206703    10093377   ibm   \n",
       "8  2009-01-06  20.750000  21.000000  20.610001  15.329155    58083400  msft   \n",
       "9  2009-01-07   3.278929   3.303571   3.223571   2.748023   753048800  aapl   \n",
       "\n",
       "   day  \n",
       "0    4  \n",
       "1    4  \n",
       "2    4  \n",
       "3    0  \n",
       "4    0  \n",
       "5    0  \n",
       "6    1  \n",
       "7    1  \n",
       "8    1  \n",
       "9    2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (3604, 8)\n",
      "Successfully added vix\n",
      "Successfully added turbulence index\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>3.067143</td>\n",
       "      <td>3.251429</td>\n",
       "      <td>3.041429</td>\n",
       "      <td>2.740173</td>\n",
       "      <td>746015200</td>\n",
       "      <td>aapl</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.961544</td>\n",
       "      <td>2.634448</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.740173</td>\n",
       "      <td>2.740173</td>\n",
       "      <td>39.189999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>80.200768</td>\n",
       "      <td>83.738052</td>\n",
       "      <td>80.200768</td>\n",
       "      <td>49.160149</td>\n",
       "      <td>7905877</td>\n",
       "      <td>ibm</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.961544</td>\n",
       "      <td>2.634448</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>49.160149</td>\n",
       "      <td>49.160149</td>\n",
       "      <td>39.189999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>19.530001</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>19.370001</td>\n",
       "      <td>15.011639</td>\n",
       "      <td>50084000</td>\n",
       "      <td>msft</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.961544</td>\n",
       "      <td>2.634448</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>15.011639</td>\n",
       "      <td>15.011639</td>\n",
       "      <td>39.189999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>3.327500</td>\n",
       "      <td>3.435000</td>\n",
       "      <td>3.311071</td>\n",
       "      <td>2.855819</td>\n",
       "      <td>1181608400</td>\n",
       "      <td>aapl</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002595</td>\n",
       "      <td>2.961544</td>\n",
       "      <td>2.634448</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.797996</td>\n",
       "      <td>2.797996</td>\n",
       "      <td>39.080002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>82.619499</td>\n",
       "      <td>83.814529</td>\n",
       "      <td>82.390060</td>\n",
       "      <td>48.850681</td>\n",
       "      <td>8698222</td>\n",
       "      <td>ibm</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006943</td>\n",
       "      <td>49.443068</td>\n",
       "      <td>48.567762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>49.005415</td>\n",
       "      <td>49.005415</td>\n",
       "      <td>39.080002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       open       high        low      close      volume   tic  \\\n",
       "0  2009-01-02   3.067143   3.251429   3.041429   2.740173   746015200  aapl   \n",
       "1  2009-01-02  80.200768  83.738052  80.200768  49.160149     7905877   ibm   \n",
       "2  2009-01-02  19.530001  20.400000  19.370001  15.011639    50084000  msft   \n",
       "3  2009-01-05   3.327500   3.435000   3.311071   2.855819  1181608400  aapl   \n",
       "4  2009-01-05  82.619499  83.814529  82.390060  48.850681     8698222   ibm   \n",
       "\n",
       "   day      macd    boll_ub    boll_lb  rsi_30     cci_30  dx_30  \\\n",
       "0    4  0.000000   2.961544   2.634448   100.0  66.666667  100.0   \n",
       "1    4  0.000000   2.961544   2.634448   100.0  66.666667  100.0   \n",
       "2    4  0.000000   2.961544   2.634448   100.0  66.666667  100.0   \n",
       "3    0  0.002595   2.961544   2.634448   100.0  66.666667  100.0   \n",
       "4    0 -0.006943  49.443068  48.567762     0.0  66.666667  100.0   \n",
       "\n",
       "   close_30_sma  close_60_sma        vix  turbulence  \n",
       "0      2.740173      2.740173  39.189999         0.0  \n",
       "1     49.160149     49.160149  39.189999         0.0  \n",
       "2     15.011639     15.011639  39.189999         0.0  \n",
       "3      2.797996      2.797996  39.080002         0.0  \n",
       "4     49.005415     49.005415  39.080002         0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe = FeatureEngineer(use_technical_indicator=True,\n",
    "                     tech_indicator_list = INDICATORS,\n",
    "                     use_vix=True,\n",
    "                     use_turbulence=True,\n",
    "                     user_defined_feature = False)\n",
    "df = fe.preprocess_data(df_raw)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ticker = df['tic'].unique().tolist()\n",
    "list_date = list(pd.date_range(df['date'].min(), df['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date, list_ticker))\n",
    "\n",
    "procesed_df = pd.DataFrame(combination, columns=['date', 'tic']).merge(df, on=['date', 'tic'], how='left')\n",
    "procesed_df = procesed_df[procesed_df['date'].isin(df['date'])]\n",
    "procesed_df = procesed_df.sort_values(['date', 'tic'])\n",
    "procesed_df = procesed_df.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>aapl</td>\n",
       "      <td>3.067143</td>\n",
       "      <td>3.251429</td>\n",
       "      <td>3.041429</td>\n",
       "      <td>2.740173</td>\n",
       "      <td>7.460152e+08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.961544</td>\n",
       "      <td>2.634448</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.740173</td>\n",
       "      <td>2.740173</td>\n",
       "      <td>39.189999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>ibm</td>\n",
       "      <td>80.200768</td>\n",
       "      <td>83.738052</td>\n",
       "      <td>80.200768</td>\n",
       "      <td>49.160149</td>\n",
       "      <td>7.905877e+06</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.961544</td>\n",
       "      <td>2.634448</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>49.160149</td>\n",
       "      <td>49.160149</td>\n",
       "      <td>39.189999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>msft</td>\n",
       "      <td>19.530001</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>19.370001</td>\n",
       "      <td>15.011639</td>\n",
       "      <td>5.008400e+07</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.961544</td>\n",
       "      <td>2.634448</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>15.011639</td>\n",
       "      <td>15.011639</td>\n",
       "      <td>39.189999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>aapl</td>\n",
       "      <td>3.327500</td>\n",
       "      <td>3.435000</td>\n",
       "      <td>3.311071</td>\n",
       "      <td>2.855819</td>\n",
       "      <td>1.181608e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002595</td>\n",
       "      <td>2.961544</td>\n",
       "      <td>2.634448</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.797996</td>\n",
       "      <td>2.797996</td>\n",
       "      <td>39.080002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>ibm</td>\n",
       "      <td>82.619499</td>\n",
       "      <td>83.814529</td>\n",
       "      <td>82.390060</td>\n",
       "      <td>48.850681</td>\n",
       "      <td>8.698222e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.006943</td>\n",
       "      <td>49.443068</td>\n",
       "      <td>48.567762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>49.005415</td>\n",
       "      <td>49.005415</td>\n",
       "      <td>39.080002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date   tic       open       high        low      close  \\\n",
       "0   2009-01-02  aapl   3.067143   3.251429   3.041429   2.740173   \n",
       "1   2009-01-02   ibm  80.200768  83.738052  80.200768  49.160149   \n",
       "2   2009-01-02  msft  19.530001  20.400000  19.370001  15.011639   \n",
       "9   2009-01-05  aapl   3.327500   3.435000   3.311071   2.855819   \n",
       "10  2009-01-05   ibm  82.619499  83.814529  82.390060  48.850681   \n",
       "\n",
       "          volume  day      macd    boll_ub    boll_lb  rsi_30     cci_30  \\\n",
       "0   7.460152e+08  4.0  0.000000   2.961544   2.634448   100.0  66.666667   \n",
       "1   7.905877e+06  4.0  0.000000   2.961544   2.634448   100.0  66.666667   \n",
       "2   5.008400e+07  4.0  0.000000   2.961544   2.634448   100.0  66.666667   \n",
       "9   1.181608e+09  0.0  0.002595   2.961544   2.634448   100.0  66.666667   \n",
       "10  8.698222e+06  0.0 -0.006943  49.443068  48.567762     0.0  66.666667   \n",
       "\n",
       "    dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
       "0   100.0      2.740173      2.740173  39.189999         0.0  \n",
       "1   100.0     49.160149     49.160149  39.189999         0.0  \n",
       "2   100.0     15.011639     15.011639  39.189999         0.0  \n",
       "9   100.0      2.797996      2.797996  39.080002         0.0  \n",
       "10  100.0     49.005415     49.005415  39.080002         0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "procesed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8679\n",
      "2133\n"
     ]
    }
   ],
   "source": [
    "train = data_split(procesed_df, TRAIN_START_DATE, TRAIN_END_DATE)\n",
    "trade = data_split(procesed_df, TRADE_START_DATE, TRADE_END_DATE)\n",
    "\n",
    "print(len(train))\n",
    "print(len(trade))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(Path.cwd() / 'train.csv')\n",
    "trade.to_csv(Path.cwd() / 'trade.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traing part of Finrl:\n",
    "\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from stable_baselines3.common.logger import configure\n",
    "from finrl import config_tickers\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import INDICATORS, TRAINED_MODEL_DIR, RESULTS_DIR\n",
    "\n",
    "check_and_make_directories([TRAINED_MODEL_DIR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Stock: 3 || State Space: 31\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2 * stock_dimension + len(INDICATORS) * stock_dimension\n",
    "print(f'Number of Stock: {stock_dimension} || State Space: {state_space}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    'hmax': 100,    # the maximum number of shares that can be purchased at each step\n",
    "    'initial_amount': 1000000, \n",
    "    'num_stock_shares': num_stock_shares,\n",
    "    'buy_cost_pct': buy_cost_list,\n",
    "    'sell_cost_pct': sell_cost_list,\n",
    "    'state_space': state_space,\n",
    "    'stock_dim': stock_dimension,\n",
    "    'tech_indicator_list': INDICATORS,\n",
    "    'action_space': stock_dimension,\n",
    "    'reward_scaling': 1e-4\n",
    "}\n",
    "\n",
    "e_train_gym = StockTradingEnv(df=train, **env_kwargs)   # This is state-space representation of the env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "if_using_a2c = False\n",
    "if_using_ddpg = False\n",
    "if_using_ppo = False\n",
    "if_using_td3 = False\n",
    "if_using_sac = False\n",
    "if_using_ddpg = False\n",
    "if_using_dqn = False\n",
    "if_using_a2c = False\n",
    "if_using_ddpg = False\n",
    "if_using_ppo = True\n",
    "if_using_td3 = False\n",
    "if_using_sac = False\n",
    "if_using_dqn = False\n",
    "if_using_a2c = True\n",
    "if_using_ddpg = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to trained_modelsa2c\n"
     ]
    }
   ],
   "source": [
    "model_a2c = agent.get_model(\"a2c\")\n",
    "model_ppo = agent.get_model(\"ppo\")\n",
    "\n",
    "if if_using_a2c:\n",
    "    tmp_path = TRAINED_MODEL_DIR + 'a2c'\n",
    "    new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "    model_a2c.set_logger(new_logger_a2c)\n",
    "\n",
    "if if_using_dqn:\n",
    "    tmp_path = TRAINED_MODEL_DIR + 'ppo'\n",
    "    new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "    model_a2c.set_logger(new_logger_ppo)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 587         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 0           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.5        |\n",
      "|    explained_variance | 0.209       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10099       |\n",
      "|    policy_loss        | -2.43       |\n",
      "|    reward             | 0.075249605 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.399       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 578       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.48     |\n",
      "|    explained_variance | 0.185     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10199     |\n",
      "|    policy_loss        | -10.2     |\n",
      "|    reward             | -1.356469 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 5.41      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 500       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.49     |\n",
      "|    explained_variance | -0.0483   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10299     |\n",
      "|    policy_loss        | -27.9     |\n",
      "|    reward             | 2.8598154 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 57.7      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 519         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 3           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.49       |\n",
      "|    explained_variance | -0.0313     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10399       |\n",
      "|    policy_loss        | -13.4       |\n",
      "|    reward             | -0.24219681 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 23.8        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 530        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 4          |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.48      |\n",
      "|    explained_variance | 0.0149     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10499      |\n",
      "|    policy_loss        | 76.2       |\n",
      "|    reward             | -19.739641 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 375        |\n",
      "--------------------------------------\n",
      "day: 2892, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8386382.61\n",
      "total_reward: 7386382.61\n",
      "total_cost: 33312.37\n",
      "total_trades: 8169\n",
      "Sharpe: 0.976\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 542         |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.47       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10599       |\n",
      "|    policy_loss        | 12.7        |\n",
      "|    reward             | 0.026155284 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 7.26        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 553        |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.46      |\n",
      "|    explained_variance | -0.102     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10699      |\n",
      "|    policy_loss        | -12.8      |\n",
      "|    reward             | -2.5582747 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 10.5       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 556        |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.44      |\n",
      "|    explained_variance | -0.0986    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10799      |\n",
      "|    policy_loss        | 9.21       |\n",
      "|    reward             | 0.09491101 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 9.16       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 556        |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 8          |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.45      |\n",
      "|    explained_variance | -0.301     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10899      |\n",
      "|    policy_loss        | -0.236     |\n",
      "|    reward             | -1.2913368 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 2.53       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 558       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.45     |\n",
      "|    explained_variance | -0.151    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10999     |\n",
      "|    policy_loss        | -13.2     |\n",
      "|    reward             | -3.902351 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 15.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 557      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.46    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | -21.9    |\n",
      "|    reward             | 2.956093 |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 21.9     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 555        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 10         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.45      |\n",
      "|    explained_variance | -0.014     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11199      |\n",
      "|    policy_loss        | -8.1       |\n",
      "|    reward             | 0.78671443 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 3.48       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 556       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.46     |\n",
      "|    explained_variance | 0.00223   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11299     |\n",
      "|    policy_loss        | 0.56      |\n",
      "|    reward             | -3.470238 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 3.26      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 555       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.46     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | -17.2     |\n",
      "|    reward             | 4.855009  |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 54        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 553        |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 13         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.47      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11499      |\n",
      "|    policy_loss        | -3.2       |\n",
      "|    reward             | 0.67765206 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 2.08       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 556       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.49     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11599     |\n",
      "|    policy_loss        | 2.23      |\n",
      "|    reward             | 16.069164 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.919     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 556      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.49    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | -26      |\n",
      "|    reward             | 1.298461 |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 31.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 557       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.48     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11799     |\n",
      "|    policy_loss        | -2.27     |\n",
      "|    reward             | 2.2888033 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.427     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 556        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.48      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11899      |\n",
      "|    policy_loss        | 6.65       |\n",
      "|    reward             | -0.6322151 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 3.02       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.47       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11999       |\n",
      "|    policy_loss        | 0.579       |\n",
      "|    reward             | -0.97319233 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 12.8        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 558        |\n",
      "|    iterations         | 2100       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 10500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.49      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12099      |\n",
      "|    policy_loss        | 8.86       |\n",
      "|    reward             | -1.1064858 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 9.82       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 557       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.52     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12199     |\n",
      "|    policy_loss        | 3.87      |\n",
      "|    reward             | -4.148563 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 1.86      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 559       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.53     |\n",
      "|    explained_variance | 0.128     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12299     |\n",
      "|    policy_loss        | -138      |\n",
      "|    reward             | -4.506291 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 912       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 557       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.54     |\n",
      "|    explained_variance | 0.532     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12399     |\n",
      "|    policy_loss        | -3.1      |\n",
      "|    reward             | 0.6144477 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 1.41      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 559        |\n",
      "|    iterations         | 2500       |\n",
      "|    time_elapsed       | 22         |\n",
      "|    total_timesteps    | 12500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.54      |\n",
      "|    explained_variance | -0.0141    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12499      |\n",
      "|    policy_loss        | -8.19      |\n",
      "|    reward             | 0.25058657 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 4.29       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 561        |\n",
      "|    iterations         | 2600       |\n",
      "|    time_elapsed       | 23         |\n",
      "|    total_timesteps    | 13000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.54      |\n",
      "|    explained_variance | -0.197     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12599      |\n",
      "|    policy_loss        | -0.59      |\n",
      "|    reward             | 0.95214826 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 0.788      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 2700        |\n",
      "|    time_elapsed       | 23          |\n",
      "|    total_timesteps    | 13500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.56       |\n",
      "|    explained_variance | 0.264       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12699       |\n",
      "|    policy_loss        | -1.41       |\n",
      "|    reward             | -0.52228075 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 0.4         |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.55     |\n",
      "|    explained_variance | 0.424     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | 7.79      |\n",
      "|    reward             | 1.5636917 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 3.17      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 566        |\n",
      "|    iterations         | 2900       |\n",
      "|    time_elapsed       | 25         |\n",
      "|    total_timesteps    | 14500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.56      |\n",
      "|    explained_variance | 0.189      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12899      |\n",
      "|    policy_loss        | -4.58      |\n",
      "|    reward             | 0.38767543 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 0.766      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 569       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.55     |\n",
      "|    explained_variance | -0.245    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12999     |\n",
      "|    policy_loss        | -1.09     |\n",
      "|    reward             | 0.5243589 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 1.42      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 567        |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 27         |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.55      |\n",
      "|    explained_variance | -0.0487    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13099      |\n",
      "|    policy_loss        | -12.4      |\n",
      "|    reward             | 0.17553276 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 5.05       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 567        |\n",
      "|    iterations         | 3200       |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 16000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.55      |\n",
      "|    explained_variance | -0.233     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13199      |\n",
      "|    policy_loss        | 0.479      |\n",
      "|    reward             | -1.0245433 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 8.97       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 566        |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 29         |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.56      |\n",
      "|    explained_variance | -0.0371    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13299      |\n",
      "|    policy_loss        | 26.2       |\n",
      "|    reward             | 0.14117254 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 68.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 30        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.55     |\n",
      "|    explained_variance | -0.14     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13399     |\n",
      "|    policy_loss        | 50.9      |\n",
      "|    reward             | 2.0188243 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 142       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 3500       |\n",
      "|    time_elapsed       | 30         |\n",
      "|    total_timesteps    | 17500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.54      |\n",
      "|    explained_variance | -0.0592    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13499      |\n",
      "|    policy_loss        | 22.1       |\n",
      "|    reward             | 0.09313928 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 48.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.55     |\n",
      "|    explained_variance | 0.0142    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13599     |\n",
      "|    policy_loss        | -7.49     |\n",
      "|    reward             | 1.1198509 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 4.98      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.56     |\n",
      "|    explained_variance | 0.0846    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13699     |\n",
      "|    policy_loss        | -0.727    |\n",
      "|    reward             | 2.8707101 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 1.73      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 3800       |\n",
      "|    time_elapsed       | 33         |\n",
      "|    total_timesteps    | 19000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.56      |\n",
      "|    explained_variance | -0.107     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13799      |\n",
      "|    policy_loss        | 3.63       |\n",
      "|    reward             | -0.6661759 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 1.78       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.58     |\n",
      "|    explained_variance | -0.0587   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13899     |\n",
      "|    policy_loss        | -13.2     |\n",
      "|    reward             | 1.5498006 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 7.87      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 569       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.59     |\n",
      "|    explained_variance | 0.038     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13999     |\n",
      "|    policy_loss        | -18       |\n",
      "|    reward             | 2.3608718 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 18.5      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 570         |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 35          |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.6        |\n",
      "|    explained_variance | -0.305      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14099       |\n",
      "|    policy_loss        | -1.07       |\n",
      "|    reward             | -0.13518086 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 1.34        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 569        |\n",
      "|    iterations         | 4200       |\n",
      "|    time_elapsed       | 36         |\n",
      "|    total_timesteps    | 21000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.61      |\n",
      "|    explained_variance | -0.0575    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 14199      |\n",
      "|    policy_loss        | -16.7      |\n",
      "|    reward             | -4.7983303 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 13.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 569       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.61     |\n",
      "|    explained_variance | 0.0299    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14299     |\n",
      "|    policy_loss        | -12.7     |\n",
      "|    reward             | 2.3319438 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 11.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 568      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.64    |\n",
      "|    explained_variance | -0.117   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | 7.53     |\n",
      "|    reward             | 3.478586 |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 6.43     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 569        |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 39         |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.63      |\n",
      "|    explained_variance | -0.0974    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 14499      |\n",
      "|    policy_loss        | 9.26       |\n",
      "|    reward             | -1.1144376 |\n",
      "|    std                | 1.13       |\n",
      "|    value_loss         | 6.63       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 569       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.63     |\n",
      "|    explained_variance | -0.243    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14599     |\n",
      "|    policy_loss        | 20.9      |\n",
      "|    reward             | 0.8873846 |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 27.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.62     |\n",
      "|    explained_variance | 0.0471    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14699     |\n",
      "|    policy_loss        | -14.1     |\n",
      "|    reward             | 0.7995146 |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 15.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 570        |\n",
      "|    iterations         | 4800       |\n",
      "|    time_elapsed       | 42         |\n",
      "|    total_timesteps    | 24000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.6       |\n",
      "|    explained_variance | -0.0996    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 14799      |\n",
      "|    policy_loss        | -28.1      |\n",
      "|    reward             | -1.5367855 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 31.6       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 569        |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 42         |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.62      |\n",
      "|    explained_variance | -0.0241    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 14899      |\n",
      "|    policy_loss        | -9.68      |\n",
      "|    reward             | 0.46711382 |\n",
      "|    std                | 1.13       |\n",
      "|    value_loss         | 9.8        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 570       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.61     |\n",
      "|    explained_variance | 0.0594    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14999     |\n",
      "|    policy_loss        | 8.69      |\n",
      "|    reward             | 1.0103874 |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 8.05      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 571       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.59     |\n",
      "|    explained_variance | -0.0313   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15099     |\n",
      "|    policy_loss        | 52.5      |\n",
      "|    reward             | 0.7468605 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 227       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 571       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.61     |\n",
      "|    explained_variance | -0.00183  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15199     |\n",
      "|    policy_loss        | 1.31      |\n",
      "|    reward             | 10.280145 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 213       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 571         |\n",
      "|    iterations         | 5300        |\n",
      "|    time_elapsed       | 46          |\n",
      "|    total_timesteps    | 26500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.59       |\n",
      "|    explained_variance | -0.733      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15299       |\n",
      "|    policy_loss        | 5.27        |\n",
      "|    reward             | -0.14126843 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 1.83        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 571        |\n",
      "|    iterations         | 5400       |\n",
      "|    time_elapsed       | 47         |\n",
      "|    total_timesteps    | 27000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.6       |\n",
      "|    explained_variance | -0.000774  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15399      |\n",
      "|    policy_loss        | -41.9      |\n",
      "|    reward             | 0.80181396 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 105        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 571       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.61     |\n",
      "|    explained_variance | 0.0106    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15499     |\n",
      "|    policy_loss        | -14.3     |\n",
      "|    reward             | 3.6484876 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 17        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 570        |\n",
      "|    iterations         | 5600       |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 28000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.62      |\n",
      "|    explained_variance | 0.00974    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15599      |\n",
      "|    policy_loss        | 2.44       |\n",
      "|    reward             | -0.5705773 |\n",
      "|    std                | 1.13       |\n",
      "|    value_loss         | 1.88       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 570        |\n",
      "|    iterations         | 5700       |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 28500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.62      |\n",
      "|    explained_variance | -7.18e-05  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15699      |\n",
      "|    policy_loss        | -83.9      |\n",
      "|    reward             | -12.660566 |\n",
      "|    std                | 1.13       |\n",
      "|    value_loss         | 340        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 569         |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.63       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15799       |\n",
      "|    policy_loss        | -2.98       |\n",
      "|    reward             | -0.43785322 |\n",
      "|    std                | 1.13        |\n",
      "|    value_loss         | 0.982       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 569       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 51        |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.64     |\n",
      "|    explained_variance | 0.0266    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15899     |\n",
      "|    policy_loss        | -0.783    |\n",
      "|    reward             | 0.2731493 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 0.306     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 570        |\n",
      "|    iterations         | 6000       |\n",
      "|    time_elapsed       | 52         |\n",
      "|    total_timesteps    | 30000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.64      |\n",
      "|    explained_variance | -0.0555    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15999      |\n",
      "|    policy_loss        | -3.88      |\n",
      "|    reward             | -1.0019428 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 0.988      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 570       |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 53        |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.65     |\n",
      "|    explained_variance | -0.00498  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16099     |\n",
      "|    policy_loss        | 1.88      |\n",
      "|    reward             | -3.430594 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 2.15      |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 571          |\n",
      "|    iterations         | 6200         |\n",
      "|    time_elapsed       | 54           |\n",
      "|    total_timesteps    | 31000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.64        |\n",
      "|    explained_variance | -0.000812    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16199        |\n",
      "|    policy_loss        | 1.78         |\n",
      "|    reward             | -0.051043905 |\n",
      "|    std                | 1.14         |\n",
      "|    value_loss         | 1.26         |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 570      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.66    |\n",
      "|    explained_variance | 0.000484 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | 82.6     |\n",
      "|    reward             | 19.20318 |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 368      |\n",
      "------------------------------------\n",
      "day: 2892, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 12222226.54\n",
      "total_reward: 11222226.54\n",
      "total_cost: 34044.17\n",
      "total_trades: 8277\n",
      "Sharpe: 1.129\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 570       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.63     |\n",
      "|    explained_variance | 0.582     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | -1.72     |\n",
      "|    reward             | 2.0094411 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 0.363     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 570        |\n",
      "|    iterations         | 6500       |\n",
      "|    time_elapsed       | 56         |\n",
      "|    total_timesteps    | 32500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.64      |\n",
      "|    explained_variance | 0.015      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16499      |\n",
      "|    policy_loss        | -2.74      |\n",
      "|    reward             | -3.6428678 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 8.15       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 569         |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 57          |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.63       |\n",
      "|    explained_variance | 0.0852      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16599       |\n",
      "|    policy_loss        | -8.06       |\n",
      "|    reward             | -0.62618786 |\n",
      "|    std                | 1.14        |\n",
      "|    value_loss         | 8.35        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 569       |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 58        |\n",
      "|    total_timesteps    | 33500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.62     |\n",
      "|    explained_variance | -0.019    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16699     |\n",
      "|    policy_loss        | -78.8     |\n",
      "|    reward             | -9.833089 |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 531       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 569      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.62    |\n",
      "|    explained_variance | -0.037   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | -19.6    |\n",
      "|    reward             | 1.016658 |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 31.4     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 568        |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.63      |\n",
      "|    explained_variance | 0.0511     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16899      |\n",
      "|    policy_loss        | -45.1      |\n",
      "|    reward             | -3.6620352 |\n",
      "|    std                | 1.13       |\n",
      "|    value_loss         | 200        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 567        |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 61         |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.64      |\n",
      "|    explained_variance | 0.167      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16999      |\n",
      "|    policy_loss        | 2.23       |\n",
      "|    reward             | -0.7439898 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 0.471      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 567        |\n",
      "|    iterations         | 7100       |\n",
      "|    time_elapsed       | 62         |\n",
      "|    total_timesteps    | 35500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.64      |\n",
      "|    explained_variance | 0.152      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17099      |\n",
      "|    policy_loss        | 1.67       |\n",
      "|    reward             | 0.49905995 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 0.497      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 568        |\n",
      "|    iterations         | 7200       |\n",
      "|    time_elapsed       | 63         |\n",
      "|    total_timesteps    | 36000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.65      |\n",
      "|    explained_variance | 0.163      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17199      |\n",
      "|    policy_loss        | -15        |\n",
      "|    reward             | 0.78508586 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 14.6       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 568         |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.64       |\n",
      "|    explained_variance | 0.105       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17299       |\n",
      "|    policy_loss        | 2.21        |\n",
      "|    reward             | 0.041088037 |\n",
      "|    std                | 1.14        |\n",
      "|    value_loss         | 9.51        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 568        |\n",
      "|    iterations         | 7400       |\n",
      "|    time_elapsed       | 65         |\n",
      "|    total_timesteps    | 37000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.63      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17399      |\n",
      "|    policy_loss        | 34.3       |\n",
      "|    reward             | -5.6790147 |\n",
      "|    std                | 1.13       |\n",
      "|    value_loss         | 63.1       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 568        |\n",
      "|    iterations         | 7500       |\n",
      "|    time_elapsed       | 65         |\n",
      "|    total_timesteps    | 37500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.65      |\n",
      "|    explained_variance | 0.00693    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17499      |\n",
      "|    policy_loss        | 82.7       |\n",
      "|    reward             | -16.632088 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 421        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.66     |\n",
      "|    explained_variance | 0.00167   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17599     |\n",
      "|    policy_loss        | -11.8     |\n",
      "|    reward             | 0.5352998 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 4.89      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 568        |\n",
      "|    iterations         | 7700       |\n",
      "|    time_elapsed       | 67         |\n",
      "|    total_timesteps    | 38500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.64      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17699      |\n",
      "|    policy_loss        | -25.6      |\n",
      "|    reward             | 0.12738858 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 34         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 568        |\n",
      "|    iterations         | 7800       |\n",
      "|    time_elapsed       | 68         |\n",
      "|    total_timesteps    | 39000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.66      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17799      |\n",
      "|    policy_loss        | -0.196     |\n",
      "|    reward             | 0.20537591 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 1.38       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.66     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17899     |\n",
      "|    policy_loss        | 27.4      |\n",
      "|    reward             | 4.5920367 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 79.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 70        |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.67     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17999     |\n",
      "|    policy_loss        | -36.2     |\n",
      "|    reward             | -4.824061 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 102       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 567       |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 71        |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.68     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18099     |\n",
      "|    policy_loss        | 107       |\n",
      "|    reward             | 12.1717   |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 816       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 567        |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 72         |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.67      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18199      |\n",
      "|    policy_loss        | -6.57      |\n",
      "|    reward             | 0.07681858 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 2.79       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 567       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.66     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18299     |\n",
      "|    policy_loss        | 5.81      |\n",
      "|    reward             | -0.960015 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 3.68      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 567       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.66     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18399     |\n",
      "|    policy_loss        | -18.1     |\n",
      "|    reward             | -2.366109 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 13.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 567        |\n",
      "|    iterations         | 8500       |\n",
      "|    time_elapsed       | 74         |\n",
      "|    total_timesteps    | 42500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.67      |\n",
      "|    explained_variance | -0.0257    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18499      |\n",
      "|    policy_loss        | -27        |\n",
      "|    reward             | -0.5863359 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 41.1       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 568        |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 75         |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.65      |\n",
      "|    explained_variance | 0.0311     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18599      |\n",
      "|    policy_loss        | 56.7       |\n",
      "|    reward             | -16.715414 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 149        |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 568          |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 76           |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.66        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18699        |\n",
      "|    policy_loss        | 3.35         |\n",
      "|    reward             | -0.029326674 |\n",
      "|    std                | 1.14         |\n",
      "|    value_loss         | 1.18         |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 77        |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.67     |\n",
      "|    explained_variance | 0.113     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18799     |\n",
      "|    policy_loss        | -4.1      |\n",
      "|    reward             | 0.5511062 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 1.4       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 78        |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.68     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18899     |\n",
      "|    policy_loss        | 26.3      |\n",
      "|    reward             | 0.8269791 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 46.7      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 567         |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 79          |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.7        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18999       |\n",
      "|    policy_loss        | 10.6        |\n",
      "|    reward             | -0.00499845 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 14.8        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 567         |\n",
      "|    iterations         | 9100        |\n",
      "|    time_elapsed       | 80          |\n",
      "|    total_timesteps    | 45500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.71       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19099       |\n",
      "|    policy_loss        | 3.33        |\n",
      "|    reward             | 0.093860865 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 3.2         |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 567      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.68    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | 31.3     |\n",
      "|    reward             | 8.785064 |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 82.4     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 566        |\n",
      "|    iterations         | 9300       |\n",
      "|    time_elapsed       | 82         |\n",
      "|    total_timesteps    | 46500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.68      |\n",
      "|    explained_variance | -0.818     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 19299      |\n",
      "|    policy_loss        | -4.11      |\n",
      "|    reward             | 0.60803515 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 0.797      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 82        |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.68     |\n",
      "|    explained_variance | -0.0622   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19399     |\n",
      "|    policy_loss        | -10.3     |\n",
      "|    reward             | 0.6616416 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 24.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.67    |\n",
      "|    explained_variance | -0.205   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | -24.4    |\n",
      "|    reward             | 2.120314 |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 38.8     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 9600        |\n",
      "|    time_elapsed       | 84          |\n",
      "|    total_timesteps    | 48000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.68       |\n",
      "|    explained_variance | -0.22       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19599       |\n",
      "|    policy_loss        | -13.6       |\n",
      "|    reward             | -0.61209637 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 6.7         |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 85        |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.68     |\n",
      "|    explained_variance | -2.66     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19699     |\n",
      "|    policy_loss        | 13.3      |\n",
      "|    reward             | 1.6151903 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 22.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.68    |\n",
      "|    explained_variance | 0.034    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | 16.5     |\n",
      "|    reward             | 4.769755 |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 39.6     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 87          |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.67       |\n",
      "|    explained_variance | -0.164      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19899       |\n",
      "|    policy_loss        | -1.68       |\n",
      "|    reward             | -0.30597982 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 0.754       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 10000       |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 50000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.66       |\n",
      "|    explained_variance | -0.118      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19999       |\n",
      "|    policy_loss        | 5.51        |\n",
      "|    reward             | -0.10763607 |\n",
      "|    std                | 1.14        |\n",
      "|    value_loss         | 2.86        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 10100     |\n",
      "|    time_elapsed       | 89        |\n",
      "|    total_timesteps    | 50500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.67     |\n",
      "|    explained_variance | 0.183     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 20099     |\n",
      "|    policy_loss        | 28.2      |\n",
      "|    reward             | 2.2306583 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 42.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 10200      |\n",
      "|    time_elapsed       | 90         |\n",
      "|    total_timesteps    | 51000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.69      |\n",
      "|    explained_variance | 0.145      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 20199      |\n",
      "|    policy_loss        | 3.5        |\n",
      "|    reward             | -1.6635041 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 5.87       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 10300      |\n",
      "|    time_elapsed       | 91         |\n",
      "|    total_timesteps    | 51500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.69      |\n",
      "|    explained_variance | 0.0176     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 20299      |\n",
      "|    policy_loss        | -24.8      |\n",
      "|    reward             | -3.9625204 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 67.7       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.67    |\n",
      "|    explained_variance | 0.0102   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20399    |\n",
      "|    policy_loss        | -30.8    |\n",
      "|    reward             | 49.7099  |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 1.02e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 10500     |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 52500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.67     |\n",
      "|    explained_variance | -0.0625   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 20499     |\n",
      "|    policy_loss        | 10.5      |\n",
      "|    reward             | 3.3274822 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 7.83      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 10600       |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 53000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.68       |\n",
      "|    explained_variance | -0.0491     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 20599       |\n",
      "|    policy_loss        | 1.19        |\n",
      "|    reward             | -0.31906897 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 10700     |\n",
      "|    time_elapsed       | 94        |\n",
      "|    total_timesteps    | 53500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.68     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 20699     |\n",
      "|    policy_loss        | -7.23     |\n",
      "|    reward             | -1.913269 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 3.66      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 10800      |\n",
      "|    time_elapsed       | 95         |\n",
      "|    total_timesteps    | 54000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.68      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 20799      |\n",
      "|    policy_loss        | -2.7       |\n",
      "|    reward             | -1.0325166 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 1.03       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.7     |\n",
      "|    explained_variance | 0.0245   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20899    |\n",
      "|    policy_loss        | -27.5    |\n",
      "|    reward             | 7.366134 |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 71.7     |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 564          |\n",
      "|    iterations         | 11000        |\n",
      "|    time_elapsed       | 97           |\n",
      "|    total_timesteps    | 55000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.7         |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 20999        |\n",
      "|    policy_loss        | -0.521       |\n",
      "|    reward             | -0.005553014 |\n",
      "|    std                | 1.16         |\n",
      "|    value_loss         | 0.11         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 11100       |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 55500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.71       |\n",
      "|    explained_variance | -1.44       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 21099       |\n",
      "|    policy_loss        | 6.55        |\n",
      "|    reward             | -0.24764678 |\n",
      "|    std                | 1.17        |\n",
      "|    value_loss         | 2.46        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.7     |\n",
      "|    explained_variance | -0.219   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21199    |\n",
      "|    policy_loss        | -18.5    |\n",
      "|    reward             | 1.803041 |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 14       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.71    |\n",
      "|    explained_variance | -0.00267 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21299    |\n",
      "|    policy_loss        | -61.7    |\n",
      "|    reward             | 3.841261 |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 535      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 11400      |\n",
      "|    time_elapsed       | 101        |\n",
      "|    total_timesteps    | 57000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.7       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 21399      |\n",
      "|    policy_loss        | 25.8       |\n",
      "|    reward             | -3.3061628 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 30.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 11500      |\n",
      "|    time_elapsed       | 102        |\n",
      "|    total_timesteps    | 57500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.69      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 21499      |\n",
      "|    policy_loss        | 96.4       |\n",
      "|    reward             | -14.968709 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 661        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 11600       |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 58000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.69       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 21599       |\n",
      "|    policy_loss        | 40.2        |\n",
      "|    reward             | -0.32871145 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 70.1        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 11700     |\n",
      "|    time_elapsed       | 103       |\n",
      "|    total_timesteps    | 58500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.7      |\n",
      "|    explained_variance | -0.232    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 21699     |\n",
      "|    policy_loss        | -9.54     |\n",
      "|    reward             | 5.8243184 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 4         |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 11800      |\n",
      "|    time_elapsed       | 104        |\n",
      "|    total_timesteps    | 59000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.7       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 21799      |\n",
      "|    policy_loss        | 1.12       |\n",
      "|    reward             | 0.63203335 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 1.1        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 11900      |\n",
      "|    time_elapsed       | 105        |\n",
      "|    total_timesteps    | 59500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.73      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 21899      |\n",
      "|    policy_loss        | -14        |\n",
      "|    reward             | 0.59178436 |\n",
      "|    std                | 1.17       |\n",
      "|    value_loss         | 28.1       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.72    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21999    |\n",
      "|    policy_loss        | -35.6    |\n",
      "|    reward             | 6.303136 |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 92       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 12100     |\n",
      "|    time_elapsed       | 106       |\n",
      "|    total_timesteps    | 60500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.71     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 22099     |\n",
      "|    policy_loss        | 77        |\n",
      "|    reward             | 12.33942  |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 334       |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 14779533.19\n",
      "total_reward: 13779533.19\n",
      "total_cost: 9526.71\n",
      "total_trades: 6323\n",
      "Sharpe: 1.113\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 12200      |\n",
      "|    time_elapsed       | 107        |\n",
      "|    total_timesteps    | 61000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.7       |\n",
      "|    explained_variance | -0.0368    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 22199      |\n",
      "|    policy_loss        | -10.9      |\n",
      "|    reward             | 0.61583745 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 5.51       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 12300      |\n",
      "|    time_elapsed       | 108        |\n",
      "|    total_timesteps    | 61500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.69      |\n",
      "|    explained_variance | -0.00136   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 22299      |\n",
      "|    policy_loss        | -6.76      |\n",
      "|    reward             | -1.9098634 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 2.4        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 12400     |\n",
      "|    time_elapsed       | 109       |\n",
      "|    total_timesteps    | 62000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.66     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 22399     |\n",
      "|    policy_loss        | 4.05      |\n",
      "|    reward             | 1.2613647 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 3.75      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 12500     |\n",
      "|    time_elapsed       | 110       |\n",
      "|    total_timesteps    | 62500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.66     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 22499     |\n",
      "|    policy_loss        | -9.25     |\n",
      "|    reward             | 1.9584376 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 22.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 12600     |\n",
      "|    time_elapsed       | 111       |\n",
      "|    total_timesteps    | 63000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.67     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 22599     |\n",
      "|    policy_loss        | 55.3      |\n",
      "|    reward             | 3.6179109 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 112       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 12700      |\n",
      "|    time_elapsed       | 112        |\n",
      "|    total_timesteps    | 63500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.67      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 22699      |\n",
      "|    policy_loss        | -6.09      |\n",
      "|    reward             | -13.401053 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 4.01       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 12800       |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 64000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.67       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 22799       |\n",
      "|    policy_loss        | -23.6       |\n",
      "|    reward             | -0.12353435 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 34.7        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 12900      |\n",
      "|    time_elapsed       | 114        |\n",
      "|    total_timesteps    | 64500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.68      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 22899      |\n",
      "|    policy_loss        | -31.1      |\n",
      "|    reward             | -0.8228285 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 41.3       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.69    |\n",
      "|    explained_variance | 0.0433   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 22999    |\n",
      "|    policy_loss        | 16.5     |\n",
      "|    reward             | 3.779299 |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 14.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 13100     |\n",
      "|    time_elapsed       | 115       |\n",
      "|    total_timesteps    | 65500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.69     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 23099     |\n",
      "|    policy_loss        | -5.21     |\n",
      "|    reward             | 5.7556734 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 6.5       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 13200     |\n",
      "|    time_elapsed       | 116       |\n",
      "|    total_timesteps    | 66000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.7      |\n",
      "|    explained_variance | -0.000309 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 23199     |\n",
      "|    policy_loss        | -15.7     |\n",
      "|    reward             | 7.144569  |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 57.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.69    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 23299    |\n",
      "|    policy_loss        | 138      |\n",
      "|    reward             | 13.5215  |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 1.38e+03 |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 13400      |\n",
      "|    time_elapsed       | 118        |\n",
      "|    total_timesteps    | 67000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.69      |\n",
      "|    explained_variance | -0.769     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 23399      |\n",
      "|    policy_loss        | -16.1      |\n",
      "|    reward             | 0.66010255 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 15.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 13500     |\n",
      "|    time_elapsed       | 119       |\n",
      "|    total_timesteps    | 67500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.69     |\n",
      "|    explained_variance | 0.131     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 23499     |\n",
      "|    policy_loss        | -7.24     |\n",
      "|    reward             | 0.2270615 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 6.41      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 13600       |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 68000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.7        |\n",
      "|    explained_variance | 0.0043      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 23599       |\n",
      "|    policy_loss        | -45         |\n",
      "|    reward             | -0.36846882 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 90.2        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 13700       |\n",
      "|    time_elapsed       | 121         |\n",
      "|    total_timesteps    | 68500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.7        |\n",
      "|    explained_variance | -0.0186     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 23699       |\n",
      "|    policy_loss        | 26.5        |\n",
      "|    reward             | -0.43521625 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 29          |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 13800     |\n",
      "|    time_elapsed       | 122       |\n",
      "|    total_timesteps    | 69000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.7      |\n",
      "|    explained_variance | -0.0143   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 23799     |\n",
      "|    policy_loss        | -7.08     |\n",
      "|    reward             | -5.383511 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 44.5      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 13900       |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 69500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.7        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 23899       |\n",
      "|    policy_loss        | 8.81        |\n",
      "|    reward             | -0.68030965 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 4.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 14000       |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 70000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.69       |\n",
      "|    explained_variance | -0.0707     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 23999       |\n",
      "|    policy_loss        | 13.5        |\n",
      "|    reward             | -0.49202877 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 6.96        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 14100      |\n",
      "|    time_elapsed       | 125        |\n",
      "|    total_timesteps    | 70500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.7       |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 24099      |\n",
      "|    policy_loss        | -0.47      |\n",
      "|    reward             | -0.9052035 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 0.788      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 14200      |\n",
      "|    time_elapsed       | 125        |\n",
      "|    total_timesteps    | 71000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.69      |\n",
      "|    explained_variance | -0.221     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 24199      |\n",
      "|    policy_loss        | 0.509      |\n",
      "|    reward             | -1.7585455 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 17.1       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.68    |\n",
      "|    explained_variance | 0.0215   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24299    |\n",
      "|    policy_loss        | 4.87     |\n",
      "|    reward             | 3.311647 |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 2.16     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 14400      |\n",
      "|    time_elapsed       | 127        |\n",
      "|    total_timesteps    | 72000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.67      |\n",
      "|    explained_variance | 0.0689     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 24399      |\n",
      "|    policy_loss        | 50         |\n",
      "|    reward             | -2.6498184 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 141        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 14500      |\n",
      "|    time_elapsed       | 128        |\n",
      "|    total_timesteps    | 72500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.65      |\n",
      "|    explained_variance | 0.338      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 24499      |\n",
      "|    policy_loss        | 0.205      |\n",
      "|    reward             | 0.84367085 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 1.1        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 14600     |\n",
      "|    time_elapsed       | 129       |\n",
      "|    total_timesteps    | 73000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.63     |\n",
      "|    explained_variance | 0.0221    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 24599     |\n",
      "|    policy_loss        | 15.7      |\n",
      "|    reward             | 2.4082246 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 27.3      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 14700       |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 73500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.64       |\n",
      "|    explained_variance | -0.794      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 24699       |\n",
      "|    policy_loss        | -14.2       |\n",
      "|    reward             | -0.22127312 |\n",
      "|    std                | 1.14        |\n",
      "|    value_loss         | 15.6        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 14800       |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 74000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.63       |\n",
      "|    explained_variance | 0.107       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 24799       |\n",
      "|    policy_loss        | -47.2       |\n",
      "|    reward             | -0.32021686 |\n",
      "|    std                | 1.14        |\n",
      "|    value_loss         | 163         |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 14900     |\n",
      "|    time_elapsed       | 132       |\n",
      "|    total_timesteps    | 74500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.64     |\n",
      "|    explained_variance | 0.522     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 24899     |\n",
      "|    policy_loss        | 2.55      |\n",
      "|    reward             | 1.3438425 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 1.12      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 15000     |\n",
      "|    time_elapsed       | 133       |\n",
      "|    total_timesteps    | 75000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.64     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 24999     |\n",
      "|    policy_loss        | 6.73      |\n",
      "|    reward             | -2.777277 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 14        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 15100     |\n",
      "|    time_elapsed       | 134       |\n",
      "|    total_timesteps    | 75500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.65     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 25099     |\n",
      "|    policy_loss        | -2.89     |\n",
      "|    reward             | 1.0259106 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 3.29      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 15200      |\n",
      "|    time_elapsed       | 135        |\n",
      "|    total_timesteps    | 76000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.65      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 25199      |\n",
      "|    policy_loss        | -2.82      |\n",
      "|    reward             | 0.74256957 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 1.29       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 15300     |\n",
      "|    time_elapsed       | 136       |\n",
      "|    total_timesteps    | 76500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.66     |\n",
      "|    explained_variance | -0.0126   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 25299     |\n",
      "|    policy_loss        | -16.6     |\n",
      "|    reward             | 1.5864868 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 25.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 15400      |\n",
      "|    time_elapsed       | 136        |\n",
      "|    total_timesteps    | 77000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.66      |\n",
      "|    explained_variance | -0.0448    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 25399      |\n",
      "|    policy_loss        | -5.17      |\n",
      "|    reward             | -2.6098864 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 10.4       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.65    |\n",
      "|    explained_variance | 0.0383   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25499    |\n",
      "|    policy_loss        | -12.6    |\n",
      "|    reward             | 2.936791 |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 20.7     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 15600      |\n",
      "|    time_elapsed       | 138        |\n",
      "|    total_timesteps    | 78000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.64      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 25599      |\n",
      "|    policy_loss        | 1.44       |\n",
      "|    reward             | -1.8335121 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 1.07       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 15700      |\n",
      "|    time_elapsed       | 139        |\n",
      "|    total_timesteps    | 78500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.65      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 25699      |\n",
      "|    policy_loss        | 8.84       |\n",
      "|    reward             | -1.3104577 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 4.73       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.66    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25799    |\n",
      "|    policy_loss        | -21.8    |\n",
      "|    reward             | 3.18708  |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 19.5     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 561        |\n",
      "|    iterations         | 15900      |\n",
      "|    time_elapsed       | 141        |\n",
      "|    total_timesteps    | 79500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.65      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 25899      |\n",
      "|    policy_loss        | 22.1       |\n",
      "|    reward             | 0.34052238 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 37.6       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 561        |\n",
      "|    iterations         | 16000      |\n",
      "|    time_elapsed       | 142        |\n",
      "|    total_timesteps    | 80000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.66      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 25999      |\n",
      "|    policy_loss        | -31.3      |\n",
      "|    reward             | 0.83539206 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 69.1       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 16100       |\n",
      "|    time_elapsed       | 143         |\n",
      "|    total_timesteps    | 80500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.67       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 26099       |\n",
      "|    policy_loss        | -14.7       |\n",
      "|    reward             | -0.44438142 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 13.8        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 16200     |\n",
      "|    time_elapsed       | 144       |\n",
      "|    total_timesteps    | 81000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.68     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26199     |\n",
      "|    policy_loss        | 10.3      |\n",
      "|    reward             | 3.7473693 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 18.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 16300     |\n",
      "|    time_elapsed       | 144       |\n",
      "|    total_timesteps    | 81500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.66     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26299     |\n",
      "|    policy_loss        | 4.57      |\n",
      "|    reward             | 1.3199434 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 1.16      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 145       |\n",
      "|    total_timesteps    | 82000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.68     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26399     |\n",
      "|    policy_loss        | 13.5      |\n",
      "|    reward             | 2.0836918 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 9.33      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 16500     |\n",
      "|    time_elapsed       | 146       |\n",
      "|    total_timesteps    | 82500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.68     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26499     |\n",
      "|    policy_loss        | 6.82      |\n",
      "|    reward             | 0.6551323 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 3.45      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 16600      |\n",
      "|    time_elapsed       | 147        |\n",
      "|    total_timesteps    | 83000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.7       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 26599      |\n",
      "|    policy_loss        | 1.62       |\n",
      "|    reward             | 0.64183766 |\n",
      "|    std                | 1.17       |\n",
      "|    value_loss         | 1.11       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 16700     |\n",
      "|    time_elapsed       | 148       |\n",
      "|    total_timesteps    | 83500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.68     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26699     |\n",
      "|    policy_loss        | -16.7     |\n",
      "|    reward             | 3.8102338 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 19.9      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 16800      |\n",
      "|    time_elapsed       | 149        |\n",
      "|    total_timesteps    | 84000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.69      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 26799      |\n",
      "|    policy_loss        | 3.39       |\n",
      "|    reward             | -0.8988993 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 1.47       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 16900      |\n",
      "|    time_elapsed       | 150        |\n",
      "|    total_timesteps    | 84500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.69      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 26899      |\n",
      "|    policy_loss        | 0.113      |\n",
      "|    reward             | -0.1973459 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 1.69       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 17000      |\n",
      "|    time_elapsed       | 150        |\n",
      "|    total_timesteps    | 85000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.69      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 26999      |\n",
      "|    policy_loss        | -3.13      |\n",
      "|    reward             | -1.8546537 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 1.64       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 17100       |\n",
      "|    time_elapsed       | 151         |\n",
      "|    total_timesteps    | 85500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.67       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 27099       |\n",
      "|    policy_loss        | -3.98       |\n",
      "|    reward             | -0.23465718 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 2.26        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 17200      |\n",
      "|    time_elapsed       | 152        |\n",
      "|    total_timesteps    | 86000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.68      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 27199      |\n",
      "|    policy_loss        | -2.47      |\n",
      "|    reward             | -0.7569465 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 1.49       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 17300      |\n",
      "|    time_elapsed       | 153        |\n",
      "|    total_timesteps    | 86500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.68      |\n",
      "|    explained_variance | 0.0564     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 27299      |\n",
      "|    policy_loss        | 3.18       |\n",
      "|    reward             | 0.48970282 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 0.971      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 17400       |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 87000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.7        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 27399       |\n",
      "|    policy_loss        | -7.08       |\n",
      "|    reward             | 0.022740629 |\n",
      "|    std                | 1.17        |\n",
      "|    value_loss         | 2.74        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 17500     |\n",
      "|    time_elapsed       | 155       |\n",
      "|    total_timesteps    | 87500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.69     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 27499     |\n",
      "|    policy_loss        | -33.8     |\n",
      "|    reward             | 1.7248269 |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 99.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.69    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 27599    |\n",
      "|    policy_loss        | 8.18     |\n",
      "|    reward             | 0.887127 |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 8.23     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 17700      |\n",
      "|    time_elapsed       | 157        |\n",
      "|    total_timesteps    | 88500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.7       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 27699      |\n",
      "|    policy_loss        | 1.35       |\n",
      "|    reward             | -1.3669854 |\n",
      "|    std                | 1.17       |\n",
      "|    value_loss         | 3.26       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 17800     |\n",
      "|    time_elapsed       | 158       |\n",
      "|    total_timesteps    | 89000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.72     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 27799     |\n",
      "|    policy_loss        | 2.26      |\n",
      "|    reward             | -0.742957 |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 0.891     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 17900     |\n",
      "|    time_elapsed       | 158       |\n",
      "|    total_timesteps    | 89500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.71     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 27899     |\n",
      "|    policy_loss        | -12.8     |\n",
      "|    reward             | 1.7875401 |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 10.5      |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1723818.79\n",
      "total_reward: 723818.79\n",
      "total_cost: 2288.19\n",
      "total_trades: 7297\n",
      "Sharpe: 0.328\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 18000      |\n",
      "|    time_elapsed       | 159        |\n",
      "|    total_timesteps    | 90000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.73      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 27999      |\n",
      "|    policy_loss        | -4.41      |\n",
      "|    reward             | -0.5712011 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 1.15       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 18100      |\n",
      "|    time_elapsed       | 160        |\n",
      "|    total_timesteps    | 90500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.73      |\n",
      "|    explained_variance | -0.552     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 28099      |\n",
      "|    policy_loss        | -0.922     |\n",
      "|    reward             | 0.46563858 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 1.39       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 18200     |\n",
      "|    time_elapsed       | 161       |\n",
      "|    total_timesteps    | 91000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.74     |\n",
      "|    explained_variance | -0.0156   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28199     |\n",
      "|    policy_loss        | 2.11      |\n",
      "|    reward             | 1.8182673 |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 8.22      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 18300      |\n",
      "|    time_elapsed       | 162        |\n",
      "|    total_timesteps    | 91500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.75      |\n",
      "|    explained_variance | 0.026      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 28299      |\n",
      "|    policy_loss        | 24.1       |\n",
      "|    reward             | -0.5974337 |\n",
      "|    std                | 1.19       |\n",
      "|    value_loss         | 34         |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 18400     |\n",
      "|    time_elapsed       | 163       |\n",
      "|    total_timesteps    | 92000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.76     |\n",
      "|    explained_variance | -0.535    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28399     |\n",
      "|    policy_loss        | 43.4      |\n",
      "|    reward             | -8.004193 |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 141       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.76    |\n",
      "|    explained_variance | -0.034   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 28499    |\n",
      "|    policy_loss        | -118     |\n",
      "|    reward             | 95.4496  |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 1.1e+03  |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 18600      |\n",
      "|    time_elapsed       | 165        |\n",
      "|    total_timesteps    | 93000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.77      |\n",
      "|    explained_variance | 0.1        |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 28599      |\n",
      "|    policy_loss        | -3.19      |\n",
      "|    reward             | 0.31982046 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 1.61       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 166       |\n",
      "|    total_timesteps    | 93500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.77     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28699     |\n",
      "|    policy_loss        | -5.31     |\n",
      "|    reward             | 2.7426734 |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 3.28      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.77    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 28799    |\n",
      "|    policy_loss        | 1.81     |\n",
      "|    reward             | 3.668219 |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 2.82     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 18900      |\n",
      "|    time_elapsed       | 167        |\n",
      "|    total_timesteps    | 94500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.75      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 28899      |\n",
      "|    policy_loss        | -12.8      |\n",
      "|    reward             | 0.42220044 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 5.01       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 19000     |\n",
      "|    time_elapsed       | 168       |\n",
      "|    total_timesteps    | 95000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.74     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28999     |\n",
      "|    policy_loss        | -41.7     |\n",
      "|    reward             | -5.208156 |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 59.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 19100     |\n",
      "|    time_elapsed       | 169       |\n",
      "|    total_timesteps    | 95500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.71     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 29099     |\n",
      "|    policy_loss        | -1.49     |\n",
      "|    reward             | 0.1484376 |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 0.176     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 19200     |\n",
      "|    time_elapsed       | 170       |\n",
      "|    total_timesteps    | 96000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.71     |\n",
      "|    explained_variance | -0.366    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 29199     |\n",
      "|    policy_loss        | -5        |\n",
      "|    reward             | -1.526906 |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 3.48      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 19300      |\n",
      "|    time_elapsed       | 171        |\n",
      "|    total_timesteps    | 96500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.71      |\n",
      "|    explained_variance | -1.26      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 29299      |\n",
      "|    policy_loss        | 9.71       |\n",
      "|    reward             | 0.66267616 |\n",
      "|    std                | 1.17       |\n",
      "|    value_loss         | 6.68       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 19400     |\n",
      "|    time_elapsed       | 172       |\n",
      "|    total_timesteps    | 97000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.72     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 29399     |\n",
      "|    policy_loss        | -146      |\n",
      "|    reward             | 2.1411996 |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 771       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 19500     |\n",
      "|    time_elapsed       | 173       |\n",
      "|    total_timesteps    | 97500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.73     |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 29499     |\n",
      "|    policy_loss        | 2.04      |\n",
      "|    reward             | 10.649992 |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 2.12      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 19600      |\n",
      "|    time_elapsed       | 174        |\n",
      "|    total_timesteps    | 98000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.73      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 29599      |\n",
      "|    policy_loss        | 50.3       |\n",
      "|    reward             | -3.7418542 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 210        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 19700       |\n",
      "|    time_elapsed       | 174         |\n",
      "|    total_timesteps    | 98500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.73       |\n",
      "|    explained_variance | -10.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 29699       |\n",
      "|    policy_loss        | 23.8        |\n",
      "|    reward             | -0.94392216 |\n",
      "|    std                | 1.18        |\n",
      "|    value_loss         | 35.2        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 19800     |\n",
      "|    time_elapsed       | 175       |\n",
      "|    total_timesteps    | 99000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.72     |\n",
      "|    explained_variance | -0.106    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 29799     |\n",
      "|    policy_loss        | 7.75      |\n",
      "|    reward             | 1.5183295 |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 5.85      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 19900       |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 99500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.73       |\n",
      "|    explained_variance | -0.24       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 29899       |\n",
      "|    policy_loss        | -2.93       |\n",
      "|    reward             | -0.13099998 |\n",
      "|    std                | 1.18        |\n",
      "|    value_loss         | 5.44        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 20000      |\n",
      "|    time_elapsed       | 177        |\n",
      "|    total_timesteps    | 100000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.74      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 29999      |\n",
      "|    policy_loss        | -37.4      |\n",
      "|    reward             | -0.4155498 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 95.7       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 20100     |\n",
      "|    time_elapsed       | 178       |\n",
      "|    total_timesteps    | 100500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.75     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30099     |\n",
      "|    policy_loss        | 23        |\n",
      "|    reward             | 3.1841137 |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 43        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 20200     |\n",
      "|    time_elapsed       | 179       |\n",
      "|    total_timesteps    | 101000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.77     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30199     |\n",
      "|    policy_loss        | 106       |\n",
      "|    reward             | 1.6435757 |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 645       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 20300     |\n",
      "|    time_elapsed       | 179       |\n",
      "|    total_timesteps    | 101500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.78     |\n",
      "|    explained_variance | -0.237    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30299     |\n",
      "|    policy_loss        | -0.197    |\n",
      "|    reward             | 1.3305043 |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 1.25      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 20400      |\n",
      "|    time_elapsed       | 180        |\n",
      "|    total_timesteps    | 102000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.8       |\n",
      "|    explained_variance | -0.0908    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 30399      |\n",
      "|    policy_loss        | -3.74      |\n",
      "|    reward             | -1.0209773 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 2.43       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 20500      |\n",
      "|    time_elapsed       | 181        |\n",
      "|    total_timesteps    | 102500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.79      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 30499      |\n",
      "|    policy_loss        | -8.6       |\n",
      "|    reward             | -2.1246881 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 5.34       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 20600      |\n",
      "|    time_elapsed       | 182        |\n",
      "|    total_timesteps    | 103000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.8       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 30599      |\n",
      "|    policy_loss        | 15.6       |\n",
      "|    reward             | -1.3012444 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 14.9       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 20700    |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 103500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.81    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 30699    |\n",
      "|    policy_loss        | 6.33     |\n",
      "|    reward             | 0.915522 |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 4.68     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 20800     |\n",
      "|    time_elapsed       | 184       |\n",
      "|    total_timesteps    | 104000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.78     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30799     |\n",
      "|    policy_loss        | -1.08     |\n",
      "|    reward             | -0.865531 |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 4.8       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 20900     |\n",
      "|    time_elapsed       | 185       |\n",
      "|    total_timesteps    | 104500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.78     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30899     |\n",
      "|    policy_loss        | -34       |\n",
      "|    reward             | 3.4460795 |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 51.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 21000     |\n",
      "|    time_elapsed       | 186       |\n",
      "|    total_timesteps    | 105000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.77     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30999     |\n",
      "|    policy_loss        | -9.17     |\n",
      "|    reward             | 2.0868108 |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 6.4       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 21100       |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 105500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.79       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 31099       |\n",
      "|    policy_loss        | 12.8        |\n",
      "|    reward             | -0.10441415 |\n",
      "|    std                | 1.2         |\n",
      "|    value_loss         | 9.21        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 21200      |\n",
      "|    time_elapsed       | 187        |\n",
      "|    total_timesteps    | 106000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.81      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 31199      |\n",
      "|    policy_loss        | 4.33       |\n",
      "|    reward             | 0.06883655 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 2.75       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 21300       |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 106500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.82       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 31299       |\n",
      "|    policy_loss        | -3.55       |\n",
      "|    reward             | -0.47031984 |\n",
      "|    std                | 1.21        |\n",
      "|    value_loss         | 1.93        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 21400     |\n",
      "|    time_elapsed       | 189       |\n",
      "|    total_timesteps    | 107000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.82     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 31399     |\n",
      "|    policy_loss        | 28.3      |\n",
      "|    reward             | 2.9751887 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 59.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 21500      |\n",
      "|    time_elapsed       | 190        |\n",
      "|    total_timesteps    | 107500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.82      |\n",
      "|    explained_variance | -0.00457   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 31499      |\n",
      "|    policy_loss        | -5.83      |\n",
      "|    reward             | -0.5714341 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 4.55       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 21600     |\n",
      "|    time_elapsed       | 191       |\n",
      "|    total_timesteps    | 108000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.82     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 31599     |\n",
      "|    policy_loss        | 5.82      |\n",
      "|    reward             | 0.6152923 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 4.75      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 21700      |\n",
      "|    time_elapsed       | 192        |\n",
      "|    total_timesteps    | 108500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.84      |\n",
      "|    explained_variance | 0.0176     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 31699      |\n",
      "|    policy_loss        | -25.3      |\n",
      "|    reward             | -11.705679 |\n",
      "|    std                | 1.22       |\n",
      "|    value_loss         | 47.1       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 21800      |\n",
      "|    time_elapsed       | 193        |\n",
      "|    total_timesteps    | 109000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.84      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 31799      |\n",
      "|    policy_loss        | -3.74      |\n",
      "|    reward             | -0.8237433 |\n",
      "|    std                | 1.22       |\n",
      "|    value_loss         | 2.19       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 21900       |\n",
      "|    time_elapsed       | 194         |\n",
      "|    total_timesteps    | 109500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.85       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 31899       |\n",
      "|    policy_loss        | 14.5        |\n",
      "|    reward             | 0.004817628 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 13.6        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 22000      |\n",
      "|    time_elapsed       | 194        |\n",
      "|    total_timesteps    | 110000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.83      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 31999      |\n",
      "|    policy_loss        | 1.13       |\n",
      "|    reward             | 0.94962895 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 0.565      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 22100     |\n",
      "|    time_elapsed       | 195       |\n",
      "|    total_timesteps    | 110500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.81     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32099     |\n",
      "|    policy_loss        | 15.4      |\n",
      "|    reward             | 1.0611125 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 16        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 22200     |\n",
      "|    time_elapsed       | 196       |\n",
      "|    total_timesteps    | 111000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.81     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32199     |\n",
      "|    policy_loss        | -10.9     |\n",
      "|    reward             | -1.055371 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 5.21      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 22300      |\n",
      "|    time_elapsed       | 197        |\n",
      "|    total_timesteps    | 111500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.82      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 32299      |\n",
      "|    policy_loss        | 15.2       |\n",
      "|    reward             | -4.8422484 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 14.1       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 22400      |\n",
      "|    time_elapsed       | 198        |\n",
      "|    total_timesteps    | 112000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.82      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 32399      |\n",
      "|    policy_loss        | -13.3      |\n",
      "|    reward             | 0.08926102 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 13.8       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 22500     |\n",
      "|    time_elapsed       | 199       |\n",
      "|    total_timesteps    | 112500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.81     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32499     |\n",
      "|    policy_loss        | -21.3     |\n",
      "|    reward             | 1.4039721 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 21.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 22600     |\n",
      "|    time_elapsed       | 200       |\n",
      "|    total_timesteps    | 113000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.82     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32599     |\n",
      "|    policy_loss        | -12.4     |\n",
      "|    reward             | 0.9218965 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 8.31      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 22700      |\n",
      "|    time_elapsed       | 201        |\n",
      "|    total_timesteps    | 113500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.83      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 32699      |\n",
      "|    policy_loss        | 27         |\n",
      "|    reward             | -3.5110807 |\n",
      "|    std                | 1.22       |\n",
      "|    value_loss         | 54.7       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 22800       |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 114000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.82       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 32799       |\n",
      "|    policy_loss        | 15.8        |\n",
      "|    reward             | -0.50171196 |\n",
      "|    std                | 1.21        |\n",
      "|    value_loss         | 9.26        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 22900    |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 114500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.82    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 32899    |\n",
      "|    policy_loss        | -10.4    |\n",
      "|    reward             | 8.272052 |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 6.3      |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 23000       |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 115000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.8        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 32999       |\n",
      "|    policy_loss        | 9.48        |\n",
      "|    reward             | 0.016323797 |\n",
      "|    std                | 1.2         |\n",
      "|    value_loss         | 4.65        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 23100     |\n",
      "|    time_elapsed       | 204       |\n",
      "|    total_timesteps    | 115500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.81     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 33099     |\n",
      "|    policy_loss        | -5.21     |\n",
      "|    reward             | 6.1214323 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 31.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 23200      |\n",
      "|    time_elapsed       | 205        |\n",
      "|    total_timesteps    | 116000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.82      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 33199      |\n",
      "|    policy_loss        | -6.23      |\n",
      "|    reward             | 0.21223594 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 3.18       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 23300     |\n",
      "|    time_elapsed       | 206       |\n",
      "|    total_timesteps    | 116500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.82     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 33299     |\n",
      "|    policy_loss        | 4.38      |\n",
      "|    reward             | 0.6437203 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 0.989     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 23400       |\n",
      "|    time_elapsed       | 207         |\n",
      "|    total_timesteps    | 117000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.84       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 33399       |\n",
      "|    policy_loss        | -25.4       |\n",
      "|    reward             | -0.20571694 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 37.9        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 23500     |\n",
      "|    time_elapsed       | 207       |\n",
      "|    total_timesteps    | 117500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.84     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 33499     |\n",
      "|    policy_loss        | -21.2     |\n",
      "|    reward             | 6.2206345 |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 39.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 23600      |\n",
      "|    time_elapsed       | 208        |\n",
      "|    total_timesteps    | 118000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.86      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 33599      |\n",
      "|    policy_loss        | 31.5       |\n",
      "|    reward             | -0.9428614 |\n",
      "|    std                | 1.23       |\n",
      "|    value_loss         | 44         |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 23700       |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 118500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.84       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 33699       |\n",
      "|    policy_loss        | 25.9        |\n",
      "|    reward             | -0.23695904 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 50.8        |\n",
      "---------------------------------------\n",
      "day: 2892, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4695860.62\n",
      "total_reward: 3695860.62\n",
      "total_cost: 2090.89\n",
      "total_trades: 8241\n",
      "Sharpe: 0.763\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 23800     |\n",
      "|    time_elapsed       | 210       |\n",
      "|    total_timesteps    | 119000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.83     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 33799     |\n",
      "|    policy_loss        | 20.9      |\n",
      "|    reward             | 1.6168485 |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 13.4      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 23900      |\n",
      "|    time_elapsed       | 211        |\n",
      "|    total_timesteps    | 119500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.82      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 33899      |\n",
      "|    policy_loss        | 13.2       |\n",
      "|    reward             | -1.5489888 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 7.31       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 24000     |\n",
      "|    time_elapsed       | 212       |\n",
      "|    total_timesteps    | 120000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.84     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 33999     |\n",
      "|    policy_loss        | 12.6      |\n",
      "|    reward             | 0.5156945 |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 8.93      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 24100    |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 120500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.83    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 34099    |\n",
      "|    policy_loss        | -35.2    |\n",
      "|    reward             | 0.305985 |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 64       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 24200     |\n",
      "|    time_elapsed       | 214       |\n",
      "|    total_timesteps    | 121000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.84     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34199     |\n",
      "|    policy_loss        | 17.1      |\n",
      "|    reward             | -6.564025 |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 12.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 24300     |\n",
      "|    time_elapsed       | 214       |\n",
      "|    total_timesteps    | 121500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.85     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34299     |\n",
      "|    policy_loss        | 74.8      |\n",
      "|    reward             | 5.9327145 |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 492       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 24400       |\n",
      "|    time_elapsed       | 215         |\n",
      "|    total_timesteps    | 122000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.84       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 34399       |\n",
      "|    policy_loss        | 0.755       |\n",
      "|    reward             | 0.085210495 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 0.361       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 24500      |\n",
      "|    time_elapsed       | 216        |\n",
      "|    total_timesteps    | 122500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.85      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 34499      |\n",
      "|    policy_loss        | -0.985     |\n",
      "|    reward             | -0.8913134 |\n",
      "|    std                | 1.22       |\n",
      "|    value_loss         | 1.65       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 24600      |\n",
      "|    time_elapsed       | 217        |\n",
      "|    total_timesteps    | 123000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.86      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 34599      |\n",
      "|    policy_loss        | 6.83       |\n",
      "|    reward             | 0.16854373 |\n",
      "|    std                | 1.23       |\n",
      "|    value_loss         | 3.44       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 24700      |\n",
      "|    time_elapsed       | 218        |\n",
      "|    total_timesteps    | 123500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.83      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 34699      |\n",
      "|    policy_loss        | -2.89      |\n",
      "|    reward             | 0.28617465 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 2.35       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 24800    |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 124000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.82    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 34799    |\n",
      "|    policy_loss        | -101     |\n",
      "|    reward             | 17.45193 |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 464      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 24900     |\n",
      "|    time_elapsed       | 219       |\n",
      "|    total_timesteps    | 124500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.82     |\n",
      "|    explained_variance | -0.267    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34899     |\n",
      "|    policy_loss        | -1.71     |\n",
      "|    reward             | 1.1794027 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 1.55      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 566        |\n",
      "|    iterations         | 25000      |\n",
      "|    time_elapsed       | 220        |\n",
      "|    total_timesteps    | 125000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.82      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 34999      |\n",
      "|    policy_loss        | -15.1      |\n",
      "|    reward             | -1.9138523 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 8.39       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 25100       |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 125500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.81       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 35099       |\n",
      "|    policy_loss        | -7.99       |\n",
      "|    reward             | -0.31749734 |\n",
      "|    std                | 1.21        |\n",
      "|    value_loss         | 2.01        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 25200     |\n",
      "|    time_elapsed       | 222       |\n",
      "|    total_timesteps    | 126000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.82     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35199     |\n",
      "|    policy_loss        | -16.3     |\n",
      "|    reward             | 3.2849157 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 12.4      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 25300       |\n",
      "|    time_elapsed       | 223         |\n",
      "|    total_timesteps    | 126500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.83       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 35299       |\n",
      "|    policy_loss        | 1.89        |\n",
      "|    reward             | -0.63086414 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 0.37        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 25400      |\n",
      "|    time_elapsed       | 224        |\n",
      "|    total_timesteps    | 127000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.82      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 35399      |\n",
      "|    policy_loss        | 25.3       |\n",
      "|    reward             | -1.2609321 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 40.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 25500     |\n",
      "|    time_elapsed       | 225       |\n",
      "|    total_timesteps    | 127500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.82     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35499     |\n",
      "|    policy_loss        | -3.23     |\n",
      "|    reward             | 1.341549  |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 5.37      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 25600     |\n",
      "|    time_elapsed       | 226       |\n",
      "|    total_timesteps    | 128000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.82     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35599     |\n",
      "|    policy_loss        | -3.51     |\n",
      "|    reward             | 0.5449002 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 3.11      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 25700       |\n",
      "|    time_elapsed       | 227         |\n",
      "|    total_timesteps    | 128500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.82       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 35699       |\n",
      "|    policy_loss        | 18.9        |\n",
      "|    reward             | -0.73837435 |\n",
      "|    std                | 1.21        |\n",
      "|    value_loss         | 26.8        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 25800     |\n",
      "|    time_elapsed       | 227       |\n",
      "|    total_timesteps    | 129000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.84     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35799     |\n",
      "|    policy_loss        | 26.5      |\n",
      "|    reward             | 0.5386896 |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 45.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 25900     |\n",
      "|    time_elapsed       | 228       |\n",
      "|    total_timesteps    | 129500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.84     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35899     |\n",
      "|    policy_loss        | 3.88      |\n",
      "|    reward             | 1.0666208 |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 0.994     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 566        |\n",
      "|    iterations         | 26000      |\n",
      "|    time_elapsed       | 229        |\n",
      "|    total_timesteps    | 130000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.84      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 35999      |\n",
      "|    policy_loss        | 11.8       |\n",
      "|    reward             | -3.3350966 |\n",
      "|    std                | 1.22       |\n",
      "|    value_loss         | 11.8       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 26100       |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 130500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.83       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 36099       |\n",
      "|    policy_loss        | -4.44       |\n",
      "|    reward             | -0.27094236 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 26200       |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 131000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.85       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 36199       |\n",
      "|    policy_loss        | -7.08       |\n",
      "|    reward             | -0.34023142 |\n",
      "|    std                | 1.23        |\n",
      "|    value_loss         | 4.07        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 566        |\n",
      "|    iterations         | 26300      |\n",
      "|    time_elapsed       | 232        |\n",
      "|    total_timesteps    | 131500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.86      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 36299      |\n",
      "|    policy_loss        | 3.53       |\n",
      "|    reward             | -2.8255954 |\n",
      "|    std                | 1.23       |\n",
      "|    value_loss         | 5.05       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 26400     |\n",
      "|    time_elapsed       | 233       |\n",
      "|    total_timesteps    | 132000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.84     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 36399     |\n",
      "|    policy_loss        | 21.2      |\n",
      "|    reward             | 1.9364188 |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 12.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 26500     |\n",
      "|    time_elapsed       | 234       |\n",
      "|    total_timesteps    | 132500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.84     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 36499     |\n",
      "|    policy_loss        | 8.34      |\n",
      "|    reward             | 1.9560816 |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 6.35      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 26600      |\n",
      "|    time_elapsed       | 235        |\n",
      "|    total_timesteps    | 133000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.85      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 36599      |\n",
      "|    policy_loss        | 45.5       |\n",
      "|    reward             | -18.945978 |\n",
      "|    std                | 1.22       |\n",
      "|    value_loss         | 201        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 26700      |\n",
      "|    time_elapsed       | 235        |\n",
      "|    total_timesteps    | 133500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.85      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 36699      |\n",
      "|    policy_loss        | -10.2      |\n",
      "|    reward             | -1.7205213 |\n",
      "|    std                | 1.22       |\n",
      "|    value_loss         | 6.16       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 26800     |\n",
      "|    time_elapsed       | 236       |\n",
      "|    total_timesteps    | 134000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.85     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 36799     |\n",
      "|    policy_loss        | -13.5     |\n",
      "|    reward             | 0.1995225 |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 9.56      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 26900       |\n",
      "|    time_elapsed       | 237         |\n",
      "|    total_timesteps    | 134500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.85       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 36899       |\n",
      "|    policy_loss        | 7.36        |\n",
      "|    reward             | -0.83796793 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 4.35        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 566        |\n",
      "|    iterations         | 27000      |\n",
      "|    time_elapsed       | 238        |\n",
      "|    total_timesteps    | 135000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.87      |\n",
      "|    explained_variance | -0.0801    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 36999      |\n",
      "|    policy_loss        | -2.25      |\n",
      "|    reward             | 0.07709232 |\n",
      "|    std                | 1.23       |\n",
      "|    value_loss         | 0.943      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 27100     |\n",
      "|    time_elapsed       | 239       |\n",
      "|    total_timesteps    | 135500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.86     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37099     |\n",
      "|    policy_loss        | 14.3      |\n",
      "|    reward             | 0.8606953 |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 12.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 566        |\n",
      "|    iterations         | 27200      |\n",
      "|    time_elapsed       | 240        |\n",
      "|    total_timesteps    | 136000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.86      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 37199      |\n",
      "|    policy_loss        | 3.21       |\n",
      "|    reward             | -0.2381595 |\n",
      "|    std                | 1.23       |\n",
      "|    value_loss         | 0.438      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 27300     |\n",
      "|    time_elapsed       | 241       |\n",
      "|    total_timesteps    | 136500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.86     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37299     |\n",
      "|    policy_loss        | 4.93      |\n",
      "|    reward             | 1.5720356 |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 2.65      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 27400       |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 137000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.87       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 37399       |\n",
      "|    policy_loss        | 5.87        |\n",
      "|    reward             | -0.70865613 |\n",
      "|    std                | 1.23        |\n",
      "|    value_loss         | 9.59        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 27500     |\n",
      "|    time_elapsed       | 242       |\n",
      "|    total_timesteps    | 137500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.9      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37499     |\n",
      "|    policy_loss        | 8.17      |\n",
      "|    reward             | -4.381416 |\n",
      "|    std                | 1.25      |\n",
      "|    value_loss         | 6.52      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 27600     |\n",
      "|    time_elapsed       | 243       |\n",
      "|    total_timesteps    | 138000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.9      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37599     |\n",
      "|    policy_loss        | -6.32     |\n",
      "|    reward             | 2.3936477 |\n",
      "|    std                | 1.24      |\n",
      "|    value_loss         | 2.4       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 27700      |\n",
      "|    time_elapsed       | 244        |\n",
      "|    total_timesteps    | 138500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.9       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 37699      |\n",
      "|    policy_loss        | -10.9      |\n",
      "|    reward             | -4.8687057 |\n",
      "|    std                | 1.24       |\n",
      "|    value_loss         | 10.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 27800     |\n",
      "|    time_elapsed       | 245       |\n",
      "|    total_timesteps    | 139000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.89     |\n",
      "|    explained_variance | -0.756    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37799     |\n",
      "|    policy_loss        | 17.4      |\n",
      "|    reward             | 1.0522265 |\n",
      "|    std                | 1.24      |\n",
      "|    value_loss         | 12.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 27900      |\n",
      "|    time_elapsed       | 246        |\n",
      "|    total_timesteps    | 139500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.89      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 37899      |\n",
      "|    policy_loss        | 18.1       |\n",
      "|    reward             | 0.33887726 |\n",
      "|    std                | 1.24       |\n",
      "|    value_loss         | 20.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 28000     |\n",
      "|    time_elapsed       | 247       |\n",
      "|    total_timesteps    | 140000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.88     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37999     |\n",
      "|    policy_loss        | -12.8     |\n",
      "|    reward             | 1.3632307 |\n",
      "|    std                | 1.24      |\n",
      "|    value_loss         | 9.65      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 28100       |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 140500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.88       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 38099       |\n",
      "|    policy_loss        | -12.8       |\n",
      "|    reward             | -0.30028638 |\n",
      "|    std                | 1.24        |\n",
      "|    value_loss         | 11          |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 28200     |\n",
      "|    time_elapsed       | 249       |\n",
      "|    total_timesteps    | 141000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.89     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38199     |\n",
      "|    policy_loss        | -5.02     |\n",
      "|    reward             | 1.7889097 |\n",
      "|    std                | 1.24      |\n",
      "|    value_loss         | 1.62      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 28300     |\n",
      "|    time_elapsed       | 250       |\n",
      "|    total_timesteps    | 141500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.89     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38299     |\n",
      "|    policy_loss        | 37.4      |\n",
      "|    reward             | -11.12972 |\n",
      "|    std                | 1.24      |\n",
      "|    value_loss         | 52.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 28400     |\n",
      "|    time_elapsed       | 251       |\n",
      "|    total_timesteps    | 142000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.87     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38399     |\n",
      "|    policy_loss        | 5.89      |\n",
      "|    reward             | 1.3021044 |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 1.72      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 28500       |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 142500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.87       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 38499       |\n",
      "|    policy_loss        | 18.3        |\n",
      "|    reward             | -0.54287606 |\n",
      "|    std                | 1.23        |\n",
      "|    value_loss         | 26.4        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 28600      |\n",
      "|    time_elapsed       | 253        |\n",
      "|    total_timesteps    | 143000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.86      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 38599      |\n",
      "|    policy_loss        | -7.51      |\n",
      "|    reward             | -1.0761545 |\n",
      "|    std                | 1.23       |\n",
      "|    value_loss         | 4.32       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 28700     |\n",
      "|    time_elapsed       | 254       |\n",
      "|    total_timesteps    | 143500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.88     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38699     |\n",
      "|    policy_loss        | -1.27     |\n",
      "|    reward             | 3.7288156 |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 0.68      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 28800      |\n",
      "|    time_elapsed       | 254        |\n",
      "|    total_timesteps    | 144000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.88      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 38799      |\n",
      "|    policy_loss        | 22.6       |\n",
      "|    reward             | -1.1769534 |\n",
      "|    std                | 1.24       |\n",
      "|    value_loss         | 14         |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 28900    |\n",
      "|    time_elapsed       | 255      |\n",
      "|    total_timesteps    | 144500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.89    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 38899    |\n",
      "|    policy_loss        | 13.9     |\n",
      "|    reward             | 4.199649 |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 10.4     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 29000       |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 145000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.89       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 38999       |\n",
      "|    policy_loss        | -6.67       |\n",
      "|    reward             | -0.19788606 |\n",
      "|    std                | 1.24        |\n",
      "|    value_loss         | 4.81        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 29100      |\n",
      "|    time_elapsed       | 257        |\n",
      "|    total_timesteps    | 145500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.9       |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 39099      |\n",
      "|    policy_loss        | -13.5      |\n",
      "|    reward             | -1.7537483 |\n",
      "|    std                | 1.25       |\n",
      "|    value_loss         | 13.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 29200      |\n",
      "|    time_elapsed       | 258        |\n",
      "|    total_timesteps    | 146000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.91      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 39199      |\n",
      "|    policy_loss        | -6.87      |\n",
      "|    reward             | -2.8389542 |\n",
      "|    std                | 1.25       |\n",
      "|    value_loss         | 4.56       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 29300     |\n",
      "|    time_elapsed       | 259       |\n",
      "|    total_timesteps    | 146500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.91     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 39299     |\n",
      "|    policy_loss        | -25.5     |\n",
      "|    reward             | 3.8084347 |\n",
      "|    std                | 1.25      |\n",
      "|    value_loss         | 28        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 29400     |\n",
      "|    time_elapsed       | 260       |\n",
      "|    total_timesteps    | 147000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.93     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 39399     |\n",
      "|    policy_loss        | 14.6      |\n",
      "|    reward             | 3.5631793 |\n",
      "|    std                | 1.26      |\n",
      "|    value_loss         | 12.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 29500      |\n",
      "|    time_elapsed       | 261        |\n",
      "|    total_timesteps    | 147500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.92      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 39499      |\n",
      "|    policy_loss        | -13.9      |\n",
      "|    reward             | -0.5056667 |\n",
      "|    std                | 1.25       |\n",
      "|    value_loss         | 53.8       |\n",
      "--------------------------------------\n",
      "day: 2892, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4569736.68\n",
      "total_reward: 3569736.68\n",
      "total_cost: 1145.08\n",
      "total_trades: 6709\n",
      "Sharpe: 0.753\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 29600     |\n",
      "|    time_elapsed       | 262       |\n",
      "|    total_timesteps    | 148000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.95     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 39599     |\n",
      "|    policy_loss        | -16.1     |\n",
      "|    reward             | 1.5735931 |\n",
      "|    std                | 1.27      |\n",
      "|    value_loss         | 11.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 29700      |\n",
      "|    time_elapsed       | 263        |\n",
      "|    total_timesteps    | 148500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.96      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 39699      |\n",
      "|    policy_loss        | -17.9      |\n",
      "|    reward             | -4.8121834 |\n",
      "|    std                | 1.27       |\n",
      "|    value_loss         | 20         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 29800      |\n",
      "|    time_elapsed       | 263        |\n",
      "|    total_timesteps    | 149000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.95      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 39799      |\n",
      "|    policy_loss        | -8.26      |\n",
      "|    reward             | -2.3328571 |\n",
      "|    std                | 1.27       |\n",
      "|    value_loss         | 7.01       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 29900      |\n",
      "|    time_elapsed       | 264        |\n",
      "|    total_timesteps    | 149500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.97      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 39899      |\n",
      "|    policy_loss        | -13        |\n",
      "|    reward             | -3.3387504 |\n",
      "|    std                | 1.28       |\n",
      "|    value_loss         | 6.31       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 30000      |\n",
      "|    time_elapsed       | 265        |\n",
      "|    total_timesteps    | 150000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.95      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 39999      |\n",
      "|    policy_loss        | 0.409      |\n",
      "|    reward             | -3.3123846 |\n",
      "|    std                | 1.27       |\n",
      "|    value_loss         | 0.753      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 30100       |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 150500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.95       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 40099       |\n",
      "|    policy_loss        | -8.27       |\n",
      "|    reward             | -0.19156349 |\n",
      "|    std                | 1.27        |\n",
      "|    value_loss         | 2.88        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 30200     |\n",
      "|    time_elapsed       | 267       |\n",
      "|    total_timesteps    | 151000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.97     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 40199     |\n",
      "|    policy_loss        | 14.7      |\n",
      "|    reward             | 0.7359695 |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 12.5      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 30300      |\n",
      "|    time_elapsed       | 268        |\n",
      "|    total_timesteps    | 151500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.97      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 40299      |\n",
      "|    policy_loss        | 3.51       |\n",
      "|    reward             | -0.9143304 |\n",
      "|    std                | 1.28       |\n",
      "|    value_loss         | 1.99       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 30400     |\n",
      "|    time_elapsed       | 269       |\n",
      "|    total_timesteps    | 152000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.97     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 40399     |\n",
      "|    policy_loss        | -5.27     |\n",
      "|    reward             | 1.4720254 |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 9.33      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 30500     |\n",
      "|    time_elapsed       | 270       |\n",
      "|    total_timesteps    | 152500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.98     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 40499     |\n",
      "|    policy_loss        | -12       |\n",
      "|    reward             | 1.1151961 |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 6.56      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 30600     |\n",
      "|    time_elapsed       | 270       |\n",
      "|    total_timesteps    | 153000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.98     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 40599     |\n",
      "|    policy_loss        | -12.7     |\n",
      "|    reward             | 1.8302482 |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 7.95      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 30700       |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 153500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.99       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 40699       |\n",
      "|    policy_loss        | -5.13       |\n",
      "|    reward             | 0.045053057 |\n",
      "|    std                | 1.29        |\n",
      "|    value_loss         | 1.35        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 30800      |\n",
      "|    time_elapsed       | 272        |\n",
      "|    total_timesteps    | 154000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.01      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 40799      |\n",
      "|    policy_loss        | 11.6       |\n",
      "|    reward             | 0.04214717 |\n",
      "|    std                | 1.29       |\n",
      "|    value_loss         | 29.5       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 30900      |\n",
      "|    time_elapsed       | 273        |\n",
      "|    total_timesteps    | 154500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5         |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 40899      |\n",
      "|    policy_loss        | -5.5       |\n",
      "|    reward             | -0.8354715 |\n",
      "|    std                | 1.29       |\n",
      "|    value_loss         | 4.11       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 31000      |\n",
      "|    time_elapsed       | 274        |\n",
      "|    total_timesteps    | 155000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.01      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 40999      |\n",
      "|    policy_loss        | 3.43       |\n",
      "|    reward             | -6.8403244 |\n",
      "|    std                | 1.29       |\n",
      "|    value_loss         | 1.81       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 31100     |\n",
      "|    time_elapsed       | 275       |\n",
      "|    total_timesteps    | 155500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5        |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41099     |\n",
      "|    policy_loss        | -18.4     |\n",
      "|    reward             | -4.155699 |\n",
      "|    std                | 1.29      |\n",
      "|    value_loss         | 11.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 31200     |\n",
      "|    time_elapsed       | 276       |\n",
      "|    total_timesteps    | 156000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5        |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41199     |\n",
      "|    policy_loss        | -32.3     |\n",
      "|    reward             | -13.36883 |\n",
      "|    std                | 1.29      |\n",
      "|    value_loss         | 103       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 31300       |\n",
      "|    time_elapsed       | 276         |\n",
      "|    total_timesteps    | 156500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5          |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 41299       |\n",
      "|    policy_loss        | 0.194       |\n",
      "|    reward             | -0.33183333 |\n",
      "|    std                | 1.28        |\n",
      "|    value_loss         | 3.03        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 31400    |\n",
      "|    time_elapsed       | 277      |\n",
      "|    total_timesteps    | 157000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.99    |\n",
      "|    explained_variance | -0.627   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41399    |\n",
      "|    policy_loss        | -6.71    |\n",
      "|    reward             | 2.053454 |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 2.27     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 31500     |\n",
      "|    time_elapsed       | 278       |\n",
      "|    total_timesteps    | 157500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.98     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41499     |\n",
      "|    policy_loss        | -20.3     |\n",
      "|    reward             | 1.3733749 |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 30.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 31600     |\n",
      "|    time_elapsed       | 279       |\n",
      "|    total_timesteps    | 158000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5        |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41599     |\n",
      "|    policy_loss        | -46.6     |\n",
      "|    reward             | -3.265002 |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 104       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 31700     |\n",
      "|    time_elapsed       | 280       |\n",
      "|    total_timesteps    | 158500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5        |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41699     |\n",
      "|    policy_loss        | 14.4      |\n",
      "|    reward             | 3.876054  |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 6.31      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 31800    |\n",
      "|    time_elapsed       | 281      |\n",
      "|    total_timesteps    | 159000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.01    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41799    |\n",
      "|    policy_loss        | 37       |\n",
      "|    reward             | 8.314627 |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 72.2     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 31900      |\n",
      "|    time_elapsed       | 282        |\n",
      "|    total_timesteps    | 159500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5         |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 41899      |\n",
      "|    policy_loss        | 20.7       |\n",
      "|    reward             | 0.09078616 |\n",
      "|    std                | 1.28       |\n",
      "|    value_loss         | 18.1       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 32000      |\n",
      "|    time_elapsed       | 282        |\n",
      "|    total_timesteps    | 160000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.01      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 41999      |\n",
      "|    policy_loss        | 10.3       |\n",
      "|    reward             | -1.6762846 |\n",
      "|    std                | 1.29       |\n",
      "|    value_loss         | 7.72       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 32100       |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 160500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.01       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 42099       |\n",
      "|    policy_loss        | 3.06        |\n",
      "|    reward             | -0.11266205 |\n",
      "|    std                | 1.29        |\n",
      "|    value_loss         | 1.04        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 32200     |\n",
      "|    time_elapsed       | 284       |\n",
      "|    total_timesteps    | 161000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5        |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42199     |\n",
      "|    policy_loss        | 5.07      |\n",
      "|    reward             | 4.4601912 |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 3.57      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 32300     |\n",
      "|    time_elapsed       | 285       |\n",
      "|    total_timesteps    | 161500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5        |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42299     |\n",
      "|    policy_loss        | -10.9     |\n",
      "|    reward             | -6.971006 |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 7.51      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 32400     |\n",
      "|    time_elapsed       | 286       |\n",
      "|    total_timesteps    | 162000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5        |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42399     |\n",
      "|    policy_loss        | -58       |\n",
      "|    reward             | -4.36307  |\n",
      "|    std                | 1.29      |\n",
      "|    value_loss         | 272       |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 565          |\n",
      "|    iterations         | 32500        |\n",
      "|    time_elapsed       | 287          |\n",
      "|    total_timesteps    | 162500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5           |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 42499        |\n",
      "|    policy_loss        | -9.84        |\n",
      "|    reward             | -0.095857404 |\n",
      "|    std                | 1.29         |\n",
      "|    value_loss         | 6.58         |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 32600     |\n",
      "|    time_elapsed       | 288       |\n",
      "|    total_timesteps    | 163000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.02     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42599     |\n",
      "|    policy_loss        | -14.3     |\n",
      "|    reward             | 1.9133866 |\n",
      "|    std                | 1.29      |\n",
      "|    value_loss         | 13.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 32700      |\n",
      "|    time_elapsed       | 288        |\n",
      "|    total_timesteps    | 163500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.03      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 42699      |\n",
      "|    policy_loss        | -3.68      |\n",
      "|    reward             | -1.6703734 |\n",
      "|    std                | 1.3        |\n",
      "|    value_loss         | 2.27       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 32800      |\n",
      "|    time_elapsed       | 289        |\n",
      "|    total_timesteps    | 164000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.04      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 42799      |\n",
      "|    policy_loss        | 20.5       |\n",
      "|    reward             | -3.3489482 |\n",
      "|    std                | 1.3        |\n",
      "|    value_loss         | 22.6       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 32900     |\n",
      "|    time_elapsed       | 290       |\n",
      "|    total_timesteps    | 164500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.05     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42899     |\n",
      "|    policy_loss        | 26.9      |\n",
      "|    reward             | 12.392672 |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 42.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 33000      |\n",
      "|    time_elapsed       | 291        |\n",
      "|    total_timesteps    | 165000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.06      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 42999      |\n",
      "|    policy_loss        | 8.29       |\n",
      "|    reward             | -1.2598584 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 3.18       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 33100     |\n",
      "|    time_elapsed       | 292       |\n",
      "|    total_timesteps    | 165500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.06     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43099     |\n",
      "|    policy_loss        | -1.13     |\n",
      "|    reward             | 0.1578381 |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 0.61      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 33200     |\n",
      "|    time_elapsed       | 293       |\n",
      "|    total_timesteps    | 166000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.06     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43199     |\n",
      "|    policy_loss        | -14.3     |\n",
      "|    reward             | 1.3870882 |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 7.78      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 33300       |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 166500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.05       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 43299       |\n",
      "|    policy_loss        | -27.5       |\n",
      "|    reward             | -0.34848472 |\n",
      "|    std                | 1.31        |\n",
      "|    value_loss         | 26.1        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 566        |\n",
      "|    iterations         | 33400      |\n",
      "|    time_elapsed       | 294        |\n",
      "|    total_timesteps    | 167000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.06      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 43399      |\n",
      "|    policy_loss        | 14.4       |\n",
      "|    reward             | -1.3451093 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 9.56       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 33500     |\n",
      "|    time_elapsed       | 295       |\n",
      "|    total_timesteps    | 167500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.06     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43499     |\n",
      "|    policy_loss        | 118       |\n",
      "|    reward             | -6.835462 |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 356       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 33600     |\n",
      "|    time_elapsed       | 296       |\n",
      "|    total_timesteps    | 168000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.08     |\n",
      "|    explained_variance | -0.0239   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43599     |\n",
      "|    policy_loss        | -12.2     |\n",
      "|    reward             | 0.2014803 |\n",
      "|    std                | 1.32      |\n",
      "|    value_loss         | 9.88      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 33700       |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 168500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.06       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 43699       |\n",
      "|    policy_loss        | 7.66        |\n",
      "|    reward             | -0.29455608 |\n",
      "|    std                | 1.31        |\n",
      "|    value_loss         | 6.89        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 33800     |\n",
      "|    time_elapsed       | 298       |\n",
      "|    total_timesteps    | 169000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.05     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43799     |\n",
      "|    policy_loss        | 8.15      |\n",
      "|    reward             | -6.561422 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 9.33      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 566        |\n",
      "|    iterations         | 33900      |\n",
      "|    time_elapsed       | 299        |\n",
      "|    total_timesteps    | 169500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.04      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 43899      |\n",
      "|    policy_loss        | 32.4       |\n",
      "|    reward             | -1.2583965 |\n",
      "|    std                | 1.3        |\n",
      "|    value_loss         | 62.6       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 567          |\n",
      "|    iterations         | 34000        |\n",
      "|    time_elapsed       | 299          |\n",
      "|    total_timesteps    | 170000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.02        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 43999        |\n",
      "|    policy_loss        | 5.53         |\n",
      "|    reward             | -0.077096775 |\n",
      "|    std                | 1.29         |\n",
      "|    value_loss         | 2.51         |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 567      |\n",
      "|    iterations         | 34100    |\n",
      "|    time_elapsed       | 300      |\n",
      "|    total_timesteps    | 170500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.03    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44099    |\n",
      "|    policy_loss        | 5.26     |\n",
      "|    reward             | 5.032139 |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 16.7     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 567         |\n",
      "|    iterations         | 34200       |\n",
      "|    time_elapsed       | 301         |\n",
      "|    total_timesteps    | 171000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.02       |\n",
      "|    explained_variance | -1.72       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 44199       |\n",
      "|    policy_loss        | 3.82        |\n",
      "|    reward             | -0.24471138 |\n",
      "|    std                | 1.3         |\n",
      "|    value_loss         | 1.37        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 567       |\n",
      "|    iterations         | 34300     |\n",
      "|    time_elapsed       | 302       |\n",
      "|    total_timesteps    | 171500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.01     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 44299     |\n",
      "|    policy_loss        | -1.52     |\n",
      "|    reward             | 2.7392704 |\n",
      "|    std                | 1.29      |\n",
      "|    value_loss         | 2.66      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 567       |\n",
      "|    iterations         | 34400     |\n",
      "|    time_elapsed       | 303       |\n",
      "|    total_timesteps    | 172000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.01     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 44399     |\n",
      "|    policy_loss        | 1.51      |\n",
      "|    reward             | 1.8347001 |\n",
      "|    std                | 1.29      |\n",
      "|    value_loss         | 2.81      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 567       |\n",
      "|    iterations         | 34500     |\n",
      "|    time_elapsed       | 303       |\n",
      "|    total_timesteps    | 172500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5        |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 44499     |\n",
      "|    policy_loss        | 3.77      |\n",
      "|    reward             | 2.3163886 |\n",
      "|    std                | 1.29      |\n",
      "|    value_loss         | 2.76      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 567        |\n",
      "|    iterations         | 34600      |\n",
      "|    time_elapsed       | 304        |\n",
      "|    total_timesteps    | 173000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.02      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 44599      |\n",
      "|    policy_loss        | -2.4       |\n",
      "|    reward             | -7.0903263 |\n",
      "|    std                | 1.29       |\n",
      "|    value_loss         | 5.67       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 567        |\n",
      "|    iterations         | 34700      |\n",
      "|    time_elapsed       | 305        |\n",
      "|    total_timesteps    | 173500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.01      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 44699      |\n",
      "|    policy_loss        | 74.7       |\n",
      "|    reward             | -38.520298 |\n",
      "|    std                | 1.29       |\n",
      "|    value_loss         | 574        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 567         |\n",
      "|    iterations         | 34800       |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 174000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.02       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 44799       |\n",
      "|    policy_loss        | -18.7       |\n",
      "|    reward             | -0.35426733 |\n",
      "|    std                | 1.3         |\n",
      "|    value_loss         | 15.3        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 568        |\n",
      "|    iterations         | 34900      |\n",
      "|    time_elapsed       | 307        |\n",
      "|    total_timesteps    | 174500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.04      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 44899      |\n",
      "|    policy_loss        | 4.48       |\n",
      "|    reward             | -0.9875106 |\n",
      "|    std                | 1.3        |\n",
      "|    value_loss         | 2.43       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 35000     |\n",
      "|    time_elapsed       | 308       |\n",
      "|    total_timesteps    | 175000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.03     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 44999     |\n",
      "|    policy_loss        | 19.1      |\n",
      "|    reward             | 0.5312148 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 13        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 35100     |\n",
      "|    time_elapsed       | 308       |\n",
      "|    total_timesteps    | 175500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.04     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45099     |\n",
      "|    policy_loss        | 9.9       |\n",
      "|    reward             | 0.7367167 |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 4.27      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 35200     |\n",
      "|    time_elapsed       | 309       |\n",
      "|    total_timesteps    | 176000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.03     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45199     |\n",
      "|    policy_loss        | 28.6      |\n",
      "|    reward             | 4.1202946 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 37.7      |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6616430.34\n",
      "total_reward: 5616430.34\n",
      "total_cost: 1969.72\n",
      "total_trades: 6099\n",
      "Sharpe: 0.896\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 35300     |\n",
      "|    time_elapsed       | 310       |\n",
      "|    total_timesteps    | 176500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.04     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45299     |\n",
      "|    policy_loss        | -0.434    |\n",
      "|    reward             | 0.3603484 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 0.0571    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 35400     |\n",
      "|    time_elapsed       | 311       |\n",
      "|    total_timesteps    | 177000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.06     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45399     |\n",
      "|    policy_loss        | -11.5     |\n",
      "|    reward             | 0.5453879 |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 8.47      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 35500     |\n",
      "|    time_elapsed       | 312       |\n",
      "|    total_timesteps    | 177500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.07     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45499     |\n",
      "|    policy_loss        | 25.7      |\n",
      "|    reward             | 2.4719408 |\n",
      "|    std                | 1.32      |\n",
      "|    value_loss         | 32.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 568        |\n",
      "|    iterations         | 35600      |\n",
      "|    time_elapsed       | 313        |\n",
      "|    total_timesteps    | 178000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.06      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 45599      |\n",
      "|    policy_loss        | -18.5      |\n",
      "|    reward             | -4.9666348 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 15.8       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 35700     |\n",
      "|    time_elapsed       | 313       |\n",
      "|    total_timesteps    | 178500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.04     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45699     |\n",
      "|    policy_loss        | -3.75     |\n",
      "|    reward             | 0.9080987 |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 2.55      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 35800     |\n",
      "|    time_elapsed       | 314       |\n",
      "|    total_timesteps    | 179000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.04     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45799     |\n",
      "|    policy_loss        | 34        |\n",
      "|    reward             | 2.3951116 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 121       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 569       |\n",
      "|    iterations         | 35900     |\n",
      "|    time_elapsed       | 315       |\n",
      "|    total_timesteps    | 179500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.04     |\n",
      "|    explained_variance | 0.312     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45899     |\n",
      "|    policy_loss        | 12.3      |\n",
      "|    reward             | 2.9365394 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 6.95      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 569       |\n",
      "|    iterations         | 36000     |\n",
      "|    time_elapsed       | 316       |\n",
      "|    total_timesteps    | 180000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.05     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45999     |\n",
      "|    policy_loss        | 20.5      |\n",
      "|    reward             | -1.580535 |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 27.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 569        |\n",
      "|    iterations         | 36100      |\n",
      "|    time_elapsed       | 317        |\n",
      "|    total_timesteps    | 180500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.05      |\n",
      "|    explained_variance | 0.508      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 46099      |\n",
      "|    policy_loss        | -10.2      |\n",
      "|    reward             | 0.26686272 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 6.57       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 569       |\n",
      "|    iterations         | 36200     |\n",
      "|    time_elapsed       | 317       |\n",
      "|    total_timesteps    | 181000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.06     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 46199     |\n",
      "|    policy_loss        | -9.38     |\n",
      "|    reward             | 2.0174942 |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 5.31      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 569         |\n",
      "|    iterations         | 36300       |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 181500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.05       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 46299       |\n",
      "|    policy_loss        | 7.75        |\n",
      "|    reward             | -0.54615027 |\n",
      "|    std                | 1.31        |\n",
      "|    value_loss         | 2.31        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 569        |\n",
      "|    iterations         | 36400      |\n",
      "|    time_elapsed       | 319        |\n",
      "|    total_timesteps    | 182000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.04      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 46399      |\n",
      "|    policy_loss        | 3.18       |\n",
      "|    reward             | 0.35853842 |\n",
      "|    std                | 1.3        |\n",
      "|    value_loss         | 3.12       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 569        |\n",
      "|    iterations         | 36500      |\n",
      "|    time_elapsed       | 320        |\n",
      "|    total_timesteps    | 182500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.06      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 46499      |\n",
      "|    policy_loss        | 1.96       |\n",
      "|    reward             | 0.27026635 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 0.427      |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 570      |\n",
      "|    iterations         | 36600    |\n",
      "|    time_elapsed       | 321      |\n",
      "|    total_timesteps    | 183000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.04    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46599    |\n",
      "|    policy_loss        | 20.9     |\n",
      "|    reward             | 2.843458 |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 40.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 570       |\n",
      "|    iterations         | 36700     |\n",
      "|    time_elapsed       | 321       |\n",
      "|    total_timesteps    | 183500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.04     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 46699     |\n",
      "|    policy_loss        | -0.432    |\n",
      "|    reward             | 1.8379475 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 4.9       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 570        |\n",
      "|    iterations         | 36800      |\n",
      "|    time_elapsed       | 322        |\n",
      "|    total_timesteps    | 184000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.03      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 46799      |\n",
      "|    policy_loss        | 9.05       |\n",
      "|    reward             | -1.4563167 |\n",
      "|    std                | 1.3        |\n",
      "|    value_loss         | 7.6        |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 570      |\n",
      "|    iterations         | 36900    |\n",
      "|    time_elapsed       | 323      |\n",
      "|    total_timesteps    | 184500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.04    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46899    |\n",
      "|    policy_loss        | -7.66    |\n",
      "|    reward             | 1.049987 |\n",
      "|    std                | 1.31     |\n",
      "|    value_loss         | 3.18     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 570       |\n",
      "|    iterations         | 37000     |\n",
      "|    time_elapsed       | 324       |\n",
      "|    total_timesteps    | 185000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.03     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 46999     |\n",
      "|    policy_loss        | 0.949     |\n",
      "|    reward             | 0.4537979 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 0.891     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 570       |\n",
      "|    iterations         | 37100     |\n",
      "|    time_elapsed       | 325       |\n",
      "|    total_timesteps    | 185500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.03     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 47099     |\n",
      "|    policy_loss        | 9.15      |\n",
      "|    reward             | 0.9889557 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 16.3      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 570         |\n",
      "|    iterations         | 37200       |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 186000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.03       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 47199       |\n",
      "|    policy_loss        | -26.6       |\n",
      "|    reward             | -0.66928506 |\n",
      "|    std                | 1.3         |\n",
      "|    value_loss         | 29.3        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 570       |\n",
      "|    iterations         | 37300     |\n",
      "|    time_elapsed       | 326       |\n",
      "|    total_timesteps    | 186500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.03     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 47299     |\n",
      "|    policy_loss        | -19.6     |\n",
      "|    reward             | 0.6312937 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 27.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 571      |\n",
      "|    iterations         | 37400    |\n",
      "|    time_elapsed       | 327      |\n",
      "|    total_timesteps    | 187000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.04    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47399    |\n",
      "|    policy_loss        | -23.1    |\n",
      "|    reward             | 2.677736 |\n",
      "|    std                | 1.31     |\n",
      "|    value_loss         | 26.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 571       |\n",
      "|    iterations         | 37500     |\n",
      "|    time_elapsed       | 328       |\n",
      "|    total_timesteps    | 187500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.04     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 47499     |\n",
      "|    policy_loss        | -25.2     |\n",
      "|    reward             | -4.684973 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 36.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 571       |\n",
      "|    iterations         | 37600     |\n",
      "|    time_elapsed       | 329       |\n",
      "|    total_timesteps    | 188000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.01     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 47599     |\n",
      "|    policy_loss        | -74.8     |\n",
      "|    reward             | -7.031432 |\n",
      "|    std                | 1.29      |\n",
      "|    value_loss         | 266       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 571         |\n",
      "|    iterations         | 37700       |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 188500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.02       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 47699       |\n",
      "|    policy_loss        | 6.59        |\n",
      "|    reward             | -0.18030421 |\n",
      "|    std                | 1.29        |\n",
      "|    value_loss         | 2.82        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 571       |\n",
      "|    iterations         | 37800     |\n",
      "|    time_elapsed       | 330       |\n",
      "|    total_timesteps    | 189000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.03     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 47799     |\n",
      "|    policy_loss        | -14.3     |\n",
      "|    reward             | 1.4992532 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 9.52      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 571        |\n",
      "|    iterations         | 37900      |\n",
      "|    time_elapsed       | 331        |\n",
      "|    total_timesteps    | 189500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.03      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 47899      |\n",
      "|    policy_loss        | -16        |\n",
      "|    reward             | 0.36412975 |\n",
      "|    std                | 1.3        |\n",
      "|    value_loss         | 12.7       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 571         |\n",
      "|    iterations         | 38000       |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 190000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.05       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 47999       |\n",
      "|    policy_loss        | 9.03        |\n",
      "|    reward             | -0.88210106 |\n",
      "|    std                | 1.31        |\n",
      "|    value_loss         | 6.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 572         |\n",
      "|    iterations         | 38100       |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 190500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.03       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 48099       |\n",
      "|    policy_loss        | 8.3         |\n",
      "|    reward             | -0.43274504 |\n",
      "|    std                | 1.3         |\n",
      "|    value_loss         | 8.2         |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 572       |\n",
      "|    iterations         | 38200     |\n",
      "|    time_elapsed       | 333       |\n",
      "|    total_timesteps    | 191000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.05     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48199     |\n",
      "|    policy_loss        | 7.38      |\n",
      "|    reward             | 1.1814845 |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 2.45      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 572         |\n",
      "|    iterations         | 38300       |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 191500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.04       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 48299       |\n",
      "|    policy_loss        | 1.91        |\n",
      "|    reward             | -0.92090213 |\n",
      "|    std                | 1.31        |\n",
      "|    value_loss         | 10.5        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 572      |\n",
      "|    iterations         | 38400    |\n",
      "|    time_elapsed       | 335      |\n",
      "|    total_timesteps    | 192000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.04    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 48399    |\n",
      "|    policy_loss        | -0.436   |\n",
      "|    reward             | -1.24302 |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 3.37     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 572        |\n",
      "|    iterations         | 38500      |\n",
      "|    time_elapsed       | 336        |\n",
      "|    total_timesteps    | 192500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.04      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 48499      |\n",
      "|    policy_loss        | -15.8      |\n",
      "|    reward             | -0.2958855 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 16.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 572        |\n",
      "|    iterations         | 38600      |\n",
      "|    time_elapsed       | 336        |\n",
      "|    total_timesteps    | 193000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.04      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 48599      |\n",
      "|    policy_loss        | -1.86      |\n",
      "|    reward             | -1.1424316 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 1.69       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 573      |\n",
      "|    iterations         | 38700    |\n",
      "|    time_elapsed       | 337      |\n",
      "|    total_timesteps    | 193500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.04    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 48699    |\n",
      "|    policy_loss        | -6.12    |\n",
      "|    reward             | 6.265475 |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 1.61     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 573        |\n",
      "|    iterations         | 38800      |\n",
      "|    time_elapsed       | 338        |\n",
      "|    total_timesteps    | 194000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.04      |\n",
      "|    explained_variance | 0.41       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 48799      |\n",
      "|    policy_loss        | -0.872     |\n",
      "|    reward             | 0.47365102 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 0.148      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 573       |\n",
      "|    iterations         | 38900     |\n",
      "|    time_elapsed       | 339       |\n",
      "|    total_timesteps    | 194500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.03     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48899     |\n",
      "|    policy_loss        | -36.2     |\n",
      "|    reward             | 3.6054273 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 107       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 573        |\n",
      "|    iterations         | 39000      |\n",
      "|    time_elapsed       | 340        |\n",
      "|    total_timesteps    | 195000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.01      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 48999      |\n",
      "|    policy_loss        | -21.1      |\n",
      "|    reward             | -1.2862055 |\n",
      "|    std                | 1.29       |\n",
      "|    value_loss         | 18.7       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 573       |\n",
      "|    iterations         | 39100     |\n",
      "|    time_elapsed       | 340       |\n",
      "|    total_timesteps    | 195500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.03     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 49099     |\n",
      "|    policy_loss        | -5.84     |\n",
      "|    reward             | -2.267981 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 2.39      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 573         |\n",
      "|    iterations         | 39200       |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 196000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.05       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 49199       |\n",
      "|    policy_loss        | -6.36       |\n",
      "|    reward             | -0.25472462 |\n",
      "|    std                | 1.31        |\n",
      "|    value_loss         | 2.2         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 573        |\n",
      "|    iterations         | 39300      |\n",
      "|    time_elapsed       | 342        |\n",
      "|    total_timesteps    | 196500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.06      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 49299      |\n",
      "|    policy_loss        | -81.7      |\n",
      "|    reward             | -4.8670883 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 285        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 573        |\n",
      "|    iterations         | 39400      |\n",
      "|    time_elapsed       | 343        |\n",
      "|    total_timesteps    | 197000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.04      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 49399      |\n",
      "|    policy_loss        | -8.07      |\n",
      "|    reward             | -1.2192187 |\n",
      "|    std                | 1.3        |\n",
      "|    value_loss         | 5.86       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 574        |\n",
      "|    iterations         | 39500      |\n",
      "|    time_elapsed       | 344        |\n",
      "|    total_timesteps    | 197500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.06      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 49499      |\n",
      "|    policy_loss        | 20.3       |\n",
      "|    reward             | 0.40294948 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 42.1       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 574          |\n",
      "|    iterations         | 39600        |\n",
      "|    time_elapsed       | 344          |\n",
      "|    total_timesteps    | 198000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.06        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 49599        |\n",
      "|    policy_loss        | -27.1        |\n",
      "|    reward             | 0.0036362854 |\n",
      "|    std                | 1.31         |\n",
      "|    value_loss         | 39.8         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 574         |\n",
      "|    iterations         | 39700       |\n",
      "|    time_elapsed       | 345         |\n",
      "|    total_timesteps    | 198500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.07       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 49699       |\n",
      "|    policy_loss        | -18.2       |\n",
      "|    reward             | -0.87041295 |\n",
      "|    std                | 1.32        |\n",
      "|    value_loss         | 17.4        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 574        |\n",
      "|    iterations         | 39800      |\n",
      "|    time_elapsed       | 346        |\n",
      "|    total_timesteps    | 199000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.06      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 49799      |\n",
      "|    policy_loss        | 12.3       |\n",
      "|    reward             | 0.60910064 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 14.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 574        |\n",
      "|    iterations         | 39900      |\n",
      "|    time_elapsed       | 347        |\n",
      "|    total_timesteps    | 199500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.09      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 49899      |\n",
      "|    policy_loss        | -1.88      |\n",
      "|    reward             | -1.6103864 |\n",
      "|    std                | 1.33       |\n",
      "|    value_loss         | 2.9        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 574       |\n",
      "|    iterations         | 40000     |\n",
      "|    time_elapsed       | 348       |\n",
      "|    total_timesteps    | 200000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.09     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 49999     |\n",
      "|    policy_loss        | -3.97     |\n",
      "|    reward             | 1.8457631 |\n",
      "|    std                | 1.33      |\n",
      "|    value_loss         | 8.43      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 574        |\n",
      "|    iterations         | 40100      |\n",
      "|    time_elapsed       | 348        |\n",
      "|    total_timesteps    | 200500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.09      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 50099      |\n",
      "|    policy_loss        | -7.81      |\n",
      "|    reward             | -0.6560743 |\n",
      "|    std                | 1.33       |\n",
      "|    value_loss         | 9.49       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 574       |\n",
      "|    iterations         | 40200     |\n",
      "|    time_elapsed       | 349       |\n",
      "|    total_timesteps    | 201000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.08     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50199     |\n",
      "|    policy_loss        | -9.04     |\n",
      "|    reward             | 2.0955386 |\n",
      "|    std                | 1.32      |\n",
      "|    value_loss         | 4.18      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 40300     |\n",
      "|    time_elapsed       | 350       |\n",
      "|    total_timesteps    | 201500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.07     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50299     |\n",
      "|    policy_loss        | 9.43      |\n",
      "|    reward             | -4.105862 |\n",
      "|    std                | 1.32      |\n",
      "|    value_loss         | 5.17      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 575        |\n",
      "|    iterations         | 40400      |\n",
      "|    time_elapsed       | 351        |\n",
      "|    total_timesteps    | 202000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.07      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 50399      |\n",
      "|    policy_loss        | -8.86      |\n",
      "|    reward             | -2.0157728 |\n",
      "|    std                | 1.32       |\n",
      "|    value_loss         | 2.4        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 575        |\n",
      "|    iterations         | 40500      |\n",
      "|    time_elapsed       | 351        |\n",
      "|    total_timesteps    | 202500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.07      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 50499      |\n",
      "|    policy_loss        | 12         |\n",
      "|    reward             | -0.9966735 |\n",
      "|    std                | 1.32       |\n",
      "|    value_loss         | 23.3       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 575         |\n",
      "|    iterations         | 40600       |\n",
      "|    time_elapsed       | 352         |\n",
      "|    total_timesteps    | 203000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.08       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 50599       |\n",
      "|    policy_loss        | 7.71        |\n",
      "|    reward             | -0.54982877 |\n",
      "|    std                | 1.33        |\n",
      "|    value_loss         | 4.95        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 40700     |\n",
      "|    time_elapsed       | 353       |\n",
      "|    total_timesteps    | 203500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.1      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50699     |\n",
      "|    policy_loss        | -12.5     |\n",
      "|    reward             | 1.7307353 |\n",
      "|    std                | 1.33      |\n",
      "|    value_loss         | 9.96      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 40800     |\n",
      "|    time_elapsed       | 354       |\n",
      "|    total_timesteps    | 204000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.09     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50799     |\n",
      "|    policy_loss        | -4.13     |\n",
      "|    reward             | 1.4611709 |\n",
      "|    std                | 1.33      |\n",
      "|    value_loss         | 0.904     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 40900     |\n",
      "|    time_elapsed       | 355       |\n",
      "|    total_timesteps    | 204500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.08     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50899     |\n",
      "|    policy_loss        | 8.17      |\n",
      "|    reward             | 1.5730276 |\n",
      "|    std                | 1.33      |\n",
      "|    value_loss         | 4.64      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 41000     |\n",
      "|    time_elapsed       | 356       |\n",
      "|    total_timesteps    | 205000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.1      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50999     |\n",
      "|    policy_loss        | -28.6     |\n",
      "|    reward             | 2.5103993 |\n",
      "|    std                | 1.33      |\n",
      "|    value_loss         | 34.1      |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2731933.27\n",
      "total_reward: 1731933.27\n",
      "total_cost: 2079.39\n",
      "total_trades: 6022\n",
      "Sharpe: 0.531\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 41100     |\n",
      "|    time_elapsed       | 356       |\n",
      "|    total_timesteps    | 205500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.09     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51099     |\n",
      "|    policy_loss        | -1.77     |\n",
      "|    reward             | -0.593248 |\n",
      "|    std                | 1.33      |\n",
      "|    value_loss         | 0.458     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 41200     |\n",
      "|    time_elapsed       | 357       |\n",
      "|    total_timesteps    | 206000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.1      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51199     |\n",
      "|    policy_loss        | 1.77      |\n",
      "|    reward             | 1.6401309 |\n",
      "|    std                | 1.33      |\n",
      "|    value_loss         | 2.49      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 576        |\n",
      "|    iterations         | 41300      |\n",
      "|    time_elapsed       | 358        |\n",
      "|    total_timesteps    | 206500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.09      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 51299      |\n",
      "|    policy_loss        | 5.1        |\n",
      "|    reward             | 0.99106365 |\n",
      "|    std                | 1.33       |\n",
      "|    value_loss         | 3.63       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 576       |\n",
      "|    iterations         | 41400     |\n",
      "|    time_elapsed       | 359       |\n",
      "|    total_timesteps    | 207000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.11     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51399     |\n",
      "|    policy_loss        | 5.35      |\n",
      "|    reward             | 2.1126769 |\n",
      "|    std                | 1.34      |\n",
      "|    value_loss         | 6.49      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 576       |\n",
      "|    iterations         | 41500     |\n",
      "|    time_elapsed       | 360       |\n",
      "|    total_timesteps    | 207500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.12     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51499     |\n",
      "|    policy_loss        | -3.81     |\n",
      "|    reward             | -0.612864 |\n",
      "|    std                | 1.34      |\n",
      "|    value_loss         | 1.07      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 576      |\n",
      "|    iterations         | 41600    |\n",
      "|    time_elapsed       | 360      |\n",
      "|    total_timesteps    | 208000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.13    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 51599    |\n",
      "|    policy_loss        | -4.05    |\n",
      "|    reward             | 1.824274 |\n",
      "|    std                | 1.35     |\n",
      "|    value_loss         | 10.7     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 576        |\n",
      "|    iterations         | 41700      |\n",
      "|    time_elapsed       | 361        |\n",
      "|    total_timesteps    | 208500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.14      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 51699      |\n",
      "|    policy_loss        | -25.8      |\n",
      "|    reward             | -1.0074197 |\n",
      "|    std                | 1.35       |\n",
      "|    value_loss         | 22.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 576       |\n",
      "|    iterations         | 41800     |\n",
      "|    time_elapsed       | 362       |\n",
      "|    total_timesteps    | 209000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.15     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51799     |\n",
      "|    policy_loss        | 20.5      |\n",
      "|    reward             | -7.007959 |\n",
      "|    std                | 1.36      |\n",
      "|    value_loss         | 36.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 576      |\n",
      "|    iterations         | 41900    |\n",
      "|    time_elapsed       | 363      |\n",
      "|    total_timesteps    | 209500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.16    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 51899    |\n",
      "|    policy_loss        | -34.1    |\n",
      "|    reward             | -2.27274 |\n",
      "|    std                | 1.36     |\n",
      "|    value_loss         | 39.2     |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 576          |\n",
      "|    iterations         | 42000        |\n",
      "|    time_elapsed       | 364          |\n",
      "|    total_timesteps    | 210000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.16        |\n",
      "|    explained_variance | 0.0159       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 51999        |\n",
      "|    policy_loss        | 8.68         |\n",
      "|    reward             | -0.085118145 |\n",
      "|    std                | 1.36         |\n",
      "|    value_loss         | 4.17         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 576        |\n",
      "|    iterations         | 42100      |\n",
      "|    time_elapsed       | 364        |\n",
      "|    total_timesteps    | 210500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.16      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 52099      |\n",
      "|    policy_loss        | -2.17      |\n",
      "|    reward             | -0.0771262 |\n",
      "|    std                | 1.36       |\n",
      "|    value_loss         | 0.505      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 577        |\n",
      "|    iterations         | 42200      |\n",
      "|    time_elapsed       | 365        |\n",
      "|    total_timesteps    | 211000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.14      |\n",
      "|    explained_variance | -0.174     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 52199      |\n",
      "|    policy_loss        | -12.1      |\n",
      "|    reward             | -3.3350585 |\n",
      "|    std                | 1.35       |\n",
      "|    value_loss         | 5.82       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 577        |\n",
      "|    iterations         | 42300      |\n",
      "|    time_elapsed       | 366        |\n",
      "|    total_timesteps    | 211500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.17      |\n",
      "|    explained_variance | -1.24      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 52299      |\n",
      "|    policy_loss        | 3.36       |\n",
      "|    reward             | 0.30821446 |\n",
      "|    std                | 1.36       |\n",
      "|    value_loss         | 1.07       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 577       |\n",
      "|    iterations         | 42400     |\n",
      "|    time_elapsed       | 367       |\n",
      "|    total_timesteps    | 212000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.15     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52399     |\n",
      "|    policy_loss        | 19.2      |\n",
      "|    reward             | 0.8266466 |\n",
      "|    std                | 1.35      |\n",
      "|    value_loss         | 17.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 577       |\n",
      "|    iterations         | 42500     |\n",
      "|    time_elapsed       | 368       |\n",
      "|    total_timesteps    | 212500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.15     |\n",
      "|    explained_variance | -0.228    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52499     |\n",
      "|    policy_loss        | -17       |\n",
      "|    reward             | 3.7571228 |\n",
      "|    std                | 1.36      |\n",
      "|    value_loss         | 11.4      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 577        |\n",
      "|    iterations         | 42600      |\n",
      "|    time_elapsed       | 368        |\n",
      "|    total_timesteps    | 213000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.18      |\n",
      "|    explained_variance | 0.236      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 52599      |\n",
      "|    policy_loss        | 4.83       |\n",
      "|    reward             | 0.40193638 |\n",
      "|    std                | 1.36       |\n",
      "|    value_loss         | 3.36       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 577       |\n",
      "|    iterations         | 42700     |\n",
      "|    time_elapsed       | 369       |\n",
      "|    total_timesteps    | 213500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.17     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52699     |\n",
      "|    policy_loss        | -13.7     |\n",
      "|    reward             | 4.8997364 |\n",
      "|    std                | 1.36      |\n",
      "|    value_loss         | 13        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 578       |\n",
      "|    iterations         | 42800     |\n",
      "|    time_elapsed       | 370       |\n",
      "|    total_timesteps    | 214000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.17     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52799     |\n",
      "|    policy_loss        | -111      |\n",
      "|    reward             | -8.588378 |\n",
      "|    std                | 1.36      |\n",
      "|    value_loss         | 748       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 578         |\n",
      "|    iterations         | 42900       |\n",
      "|    time_elapsed       | 370         |\n",
      "|    total_timesteps    | 214500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.18       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 52899       |\n",
      "|    policy_loss        | -16.1       |\n",
      "|    reward             | -0.37347794 |\n",
      "|    std                | 1.37        |\n",
      "|    value_loss         | 13.6        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 578        |\n",
      "|    iterations         | 43000      |\n",
      "|    time_elapsed       | 371        |\n",
      "|    total_timesteps    | 215000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.16      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 52999      |\n",
      "|    policy_loss        | 9.76       |\n",
      "|    reward             | -1.6419607 |\n",
      "|    std                | 1.36       |\n",
      "|    value_loss         | 4.26       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 578       |\n",
      "|    iterations         | 43100     |\n",
      "|    time_elapsed       | 372       |\n",
      "|    total_timesteps    | 215500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.16     |\n",
      "|    explained_variance | 4.17e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 53099     |\n",
      "|    policy_loss        | 7.29      |\n",
      "|    reward             | 1.3019663 |\n",
      "|    std                | 1.36      |\n",
      "|    value_loss         | 3.37      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 578        |\n",
      "|    iterations         | 43200      |\n",
      "|    time_elapsed       | 373        |\n",
      "|    total_timesteps    | 216000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.17      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 53199      |\n",
      "|    policy_loss        | 8.05       |\n",
      "|    reward             | -1.4956174 |\n",
      "|    std                | 1.36       |\n",
      "|    value_loss         | 4.77       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 578        |\n",
      "|    iterations         | 43300      |\n",
      "|    time_elapsed       | 373        |\n",
      "|    total_timesteps    | 216500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.18      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 53299      |\n",
      "|    policy_loss        | 21.4       |\n",
      "|    reward             | -0.7242179 |\n",
      "|    std                | 1.36       |\n",
      "|    value_loss         | 21.2       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 43400      |\n",
      "|    time_elapsed       | 374        |\n",
      "|    total_timesteps    | 217000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.17      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 53399      |\n",
      "|    policy_loss        | -1.8       |\n",
      "|    reward             | 0.06280698 |\n",
      "|    std                | 1.36       |\n",
      "|    value_loss         | 0.127      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 43500      |\n",
      "|    time_elapsed       | 375        |\n",
      "|    total_timesteps    | 217500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.16      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 53499      |\n",
      "|    policy_loss        | 17.7       |\n",
      "|    reward             | -0.2684721 |\n",
      "|    std                | 1.36       |\n",
      "|    value_loss         | 13.5       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 579         |\n",
      "|    iterations         | 43600       |\n",
      "|    time_elapsed       | 376         |\n",
      "|    total_timesteps    | 218000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.17       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 53599       |\n",
      "|    policy_loss        | 53.1        |\n",
      "|    reward             | -0.45250064 |\n",
      "|    std                | 1.36        |\n",
      "|    value_loss         | 100         |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 579      |\n",
      "|    iterations         | 43700    |\n",
      "|    time_elapsed       | 377      |\n",
      "|    total_timesteps    | 218500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.19    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 53699    |\n",
      "|    policy_loss        | 1.06     |\n",
      "|    reward             | 0.452749 |\n",
      "|    std                | 1.37     |\n",
      "|    value_loss         | 3.72     |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 579          |\n",
      "|    iterations         | 43800        |\n",
      "|    time_elapsed       | 378          |\n",
      "|    total_timesteps    | 219000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.21        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 53799        |\n",
      "|    policy_loss        | -2.68        |\n",
      "|    reward             | -0.035318665 |\n",
      "|    std                | 1.38         |\n",
      "|    value_loss         | 3.64         |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 579       |\n",
      "|    iterations         | 43900     |\n",
      "|    time_elapsed       | 378       |\n",
      "|    total_timesteps    | 219500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.22     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 53899     |\n",
      "|    policy_loss        | 28.2      |\n",
      "|    reward             | 2.9311004 |\n",
      "|    std                | 1.39      |\n",
      "|    value_loss         | 36.8      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 579         |\n",
      "|    iterations         | 44000       |\n",
      "|    time_elapsed       | 379         |\n",
      "|    total_timesteps    | 220000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.22       |\n",
      "|    explained_variance | 0.133       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 53999       |\n",
      "|    policy_loss        | -17.1       |\n",
      "|    reward             | -0.36949033 |\n",
      "|    std                | 1.39        |\n",
      "|    value_loss         | 13.2        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 44100      |\n",
      "|    time_elapsed       | 380        |\n",
      "|    total_timesteps    | 220500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.21      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 54099      |\n",
      "|    policy_loss        | 16.4       |\n",
      "|    reward             | -0.8241138 |\n",
      "|    std                | 1.38       |\n",
      "|    value_loss         | 14.8       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 579       |\n",
      "|    iterations         | 44200     |\n",
      "|    time_elapsed       | 381       |\n",
      "|    total_timesteps    | 221000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.2      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 54199     |\n",
      "|    policy_loss        | -6.94     |\n",
      "|    reward             | 1.7350309 |\n",
      "|    std                | 1.38      |\n",
      "|    value_loss         | 13.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 44300      |\n",
      "|    time_elapsed       | 382        |\n",
      "|    total_timesteps    | 221500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.21      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 54299      |\n",
      "|    policy_loss        | 3.17       |\n",
      "|    reward             | -3.1144285 |\n",
      "|    std                | 1.38       |\n",
      "|    value_loss         | 0.939      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 579       |\n",
      "|    iterations         | 44400     |\n",
      "|    time_elapsed       | 383       |\n",
      "|    total_timesteps    | 222000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.22     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 54399     |\n",
      "|    policy_loss        | -2.55     |\n",
      "|    reward             | 0.6173848 |\n",
      "|    std                | 1.39      |\n",
      "|    value_loss         | 0.524     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 579       |\n",
      "|    iterations         | 44500     |\n",
      "|    time_elapsed       | 383       |\n",
      "|    total_timesteps    | 222500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.22     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 54499     |\n",
      "|    policy_loss        | 13.7      |\n",
      "|    reward             | 1.2995644 |\n",
      "|    std                | 1.39      |\n",
      "|    value_loss         | 27.4      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 44600      |\n",
      "|    time_elapsed       | 384        |\n",
      "|    total_timesteps    | 223000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.21      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 54599      |\n",
      "|    policy_loss        | -10.5      |\n",
      "|    reward             | 0.49267715 |\n",
      "|    std                | 1.38       |\n",
      "|    value_loss         | 4.61       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 44700      |\n",
      "|    time_elapsed       | 385        |\n",
      "|    total_timesteps    | 223500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.23      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 54699      |\n",
      "|    policy_loss        | 42.3       |\n",
      "|    reward             | 0.83090574 |\n",
      "|    std                | 1.39       |\n",
      "|    value_loss         | 54         |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 579       |\n",
      "|    iterations         | 44800     |\n",
      "|    time_elapsed       | 386       |\n",
      "|    total_timesteps    | 224000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.2      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 54799     |\n",
      "|    policy_loss        | -25.9     |\n",
      "|    reward             | 0.5782587 |\n",
      "|    std                | 1.38      |\n",
      "|    value_loss         | 27.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 579       |\n",
      "|    iterations         | 44900     |\n",
      "|    time_elapsed       | 387       |\n",
      "|    total_timesteps    | 224500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.2      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 54899     |\n",
      "|    policy_loss        | 21.6      |\n",
      "|    reward             | 1.4612918 |\n",
      "|    std                | 1.38      |\n",
      "|    value_loss         | 23        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 45000      |\n",
      "|    time_elapsed       | 388        |\n",
      "|    total_timesteps    | 225000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.2       |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 54999      |\n",
      "|    policy_loss        | -16.5      |\n",
      "|    reward             | -1.1562274 |\n",
      "|    std                | 1.38       |\n",
      "|    value_loss         | 13.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 45100      |\n",
      "|    time_elapsed       | 389        |\n",
      "|    total_timesteps    | 225500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.21      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 55099      |\n",
      "|    policy_loss        | 10.1       |\n",
      "|    reward             | 0.29445496 |\n",
      "|    std                | 1.38       |\n",
      "|    value_loss         | 4.28       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 45200      |\n",
      "|    time_elapsed       | 389        |\n",
      "|    total_timesteps    | 226000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.23      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 55199      |\n",
      "|    policy_loss        | 33.6       |\n",
      "|    reward             | -1.3224328 |\n",
      "|    std                | 1.39       |\n",
      "|    value_loss         | 36.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 579       |\n",
      "|    iterations         | 45300     |\n",
      "|    time_elapsed       | 390       |\n",
      "|    total_timesteps    | 226500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.23     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 55299     |\n",
      "|    policy_loss        | -21.3     |\n",
      "|    reward             | 1.0752629 |\n",
      "|    std                | 1.39      |\n",
      "|    value_loss         | 13.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 45400      |\n",
      "|    time_elapsed       | 391        |\n",
      "|    total_timesteps    | 227000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.22      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 55399      |\n",
      "|    policy_loss        | -17.7      |\n",
      "|    reward             | 0.72928935 |\n",
      "|    std                | 1.39       |\n",
      "|    value_loss         | 13.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 45500      |\n",
      "|    time_elapsed       | 392        |\n",
      "|    total_timesteps    | 227500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.21      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 55499      |\n",
      "|    policy_loss        | -15.3      |\n",
      "|    reward             | 0.25922847 |\n",
      "|    std                | 1.38       |\n",
      "|    value_loss         | 18.5       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 580        |\n",
      "|    iterations         | 45600      |\n",
      "|    time_elapsed       | 393        |\n",
      "|    total_timesteps    | 228000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.2       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 55599      |\n",
      "|    policy_loss        | -36.6      |\n",
      "|    reward             | -5.5516295 |\n",
      "|    std                | 1.37       |\n",
      "|    value_loss         | 74.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 580       |\n",
      "|    iterations         | 45700     |\n",
      "|    time_elapsed       | 393       |\n",
      "|    total_timesteps    | 228500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.19     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 55699     |\n",
      "|    policy_loss        | 62        |\n",
      "|    reward             | 9.254903  |\n",
      "|    std                | 1.37      |\n",
      "|    value_loss         | 231       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 580       |\n",
      "|    iterations         | 45800     |\n",
      "|    time_elapsed       | 394       |\n",
      "|    total_timesteps    | 229000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.21     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 55799     |\n",
      "|    policy_loss        | 7.4       |\n",
      "|    reward             | 1.0802364 |\n",
      "|    std                | 1.38      |\n",
      "|    value_loss         | 2.88      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 580       |\n",
      "|    iterations         | 45900     |\n",
      "|    time_elapsed       | 395       |\n",
      "|    total_timesteps    | 229500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.24     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 55899     |\n",
      "|    policy_loss        | 1.61      |\n",
      "|    reward             | 1.9597266 |\n",
      "|    std                | 1.39      |\n",
      "|    value_loss         | 0.727     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 580        |\n",
      "|    iterations         | 46000      |\n",
      "|    time_elapsed       | 396        |\n",
      "|    total_timesteps    | 230000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.24      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 55999      |\n",
      "|    policy_loss        | -2.23      |\n",
      "|    reward             | -3.5756788 |\n",
      "|    std                | 1.39       |\n",
      "|    value_loss         | 3.54       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 580       |\n",
      "|    iterations         | 46100     |\n",
      "|    time_elapsed       | 397       |\n",
      "|    total_timesteps    | 230500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.26     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 56099     |\n",
      "|    policy_loss        | 16.9      |\n",
      "|    reward             | 1.2659119 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 9.76      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 580      |\n",
      "|    iterations         | 46200    |\n",
      "|    time_elapsed       | 397      |\n",
      "|    total_timesteps    | 231000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.26    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 56199    |\n",
      "|    policy_loss        | 19.3     |\n",
      "|    reward             | 4.145331 |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 19.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 580       |\n",
      "|    iterations         | 46300     |\n",
      "|    time_elapsed       | 398       |\n",
      "|    total_timesteps    | 231500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.24     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 56299     |\n",
      "|    policy_loss        | 10.5      |\n",
      "|    reward             | 1.1660061 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 2.86      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 580       |\n",
      "|    iterations         | 46400     |\n",
      "|    time_elapsed       | 399       |\n",
      "|    total_timesteps    | 232000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.26     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 56399     |\n",
      "|    policy_loss        | -25.4     |\n",
      "|    reward             | 0.8016884 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 36.9      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 580        |\n",
      "|    iterations         | 46500      |\n",
      "|    time_elapsed       | 400        |\n",
      "|    total_timesteps    | 232500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.26      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 56499      |\n",
      "|    policy_loss        | 20.3       |\n",
      "|    reward             | -2.4122744 |\n",
      "|    std                | 1.4        |\n",
      "|    value_loss         | 13.7       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 580        |\n",
      "|    iterations         | 46600      |\n",
      "|    time_elapsed       | 401        |\n",
      "|    total_timesteps    | 233000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.29      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 56599      |\n",
      "|    policy_loss        | -21.9      |\n",
      "|    reward             | 0.18570165 |\n",
      "|    std                | 1.41       |\n",
      "|    value_loss         | 16.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 580       |\n",
      "|    iterations         | 46700     |\n",
      "|    time_elapsed       | 402       |\n",
      "|    total_timesteps    | 233500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.32     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 56699     |\n",
      "|    policy_loss        | -5.83     |\n",
      "|    reward             | 0.9320193 |\n",
      "|    std                | 1.43      |\n",
      "|    value_loss         | 3.31      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 580      |\n",
      "|    iterations         | 46800    |\n",
      "|    time_elapsed       | 402      |\n",
      "|    total_timesteps    | 234000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.3     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 56799    |\n",
      "|    policy_loss        | 1.63     |\n",
      "|    reward             | -4.30658 |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 7.11     |\n",
      "------------------------------------\n",
      "day: 2892, episode: 100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5680192.69\n",
      "total_reward: 4680192.69\n",
      "total_cost: 2755.92\n",
      "total_trades: 5830\n",
      "Sharpe: 0.840\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 580        |\n",
      "|    iterations         | 46900      |\n",
      "|    time_elapsed       | 403        |\n",
      "|    total_timesteps    | 234500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.3       |\n",
      "|    explained_variance | -0.0464    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 56899      |\n",
      "|    policy_loss        | 2.72       |\n",
      "|    reward             | -1.8567452 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 1.02       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 580        |\n",
      "|    iterations         | 47000      |\n",
      "|    time_elapsed       | 404        |\n",
      "|    total_timesteps    | 235000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.31      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 56999      |\n",
      "|    policy_loss        | -27.5      |\n",
      "|    reward             | -1.4170175 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 34.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 47100     |\n",
      "|    time_elapsed       | 405       |\n",
      "|    total_timesteps    | 235500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.32     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 57099     |\n",
      "|    policy_loss        | -16.7     |\n",
      "|    reward             | 1.8050411 |\n",
      "|    std                | 1.43      |\n",
      "|    value_loss         | 12.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 47200      |\n",
      "|    time_elapsed       | 406        |\n",
      "|    total_timesteps    | 236000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.32      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 57199      |\n",
      "|    policy_loss        | -12.7      |\n",
      "|    reward             | 0.32847947 |\n",
      "|    std                | 1.43       |\n",
      "|    value_loss         | 7.85       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 47300     |\n",
      "|    time_elapsed       | 407       |\n",
      "|    total_timesteps    | 236500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.3      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 57299     |\n",
      "|    policy_loss        | 1.23      |\n",
      "|    reward             | 2.3693914 |\n",
      "|    std                | 1.42      |\n",
      "|    value_loss         | 0.729     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 47400     |\n",
      "|    time_elapsed       | 407       |\n",
      "|    total_timesteps    | 237000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.28     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 57399     |\n",
      "|    policy_loss        | -21.2     |\n",
      "|    reward             | 10.404114 |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 46        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 47500      |\n",
      "|    time_elapsed       | 408        |\n",
      "|    total_timesteps    | 237500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.3       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 57499      |\n",
      "|    policy_loss        | -20        |\n",
      "|    reward             | -3.1076488 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 11.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 47600     |\n",
      "|    time_elapsed       | 409       |\n",
      "|    total_timesteps    | 238000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.3      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 57599     |\n",
      "|    policy_loss        | 32.4      |\n",
      "|    reward             | 2.1102607 |\n",
      "|    std                | 1.42      |\n",
      "|    value_loss         | 62.4      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 47700      |\n",
      "|    time_elapsed       | 410        |\n",
      "|    total_timesteps    | 238500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.32      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 57699      |\n",
      "|    policy_loss        | 11.7       |\n",
      "|    reward             | -2.7180917 |\n",
      "|    std                | 1.43       |\n",
      "|    value_loss         | 11.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 47800      |\n",
      "|    time_elapsed       | 411        |\n",
      "|    total_timesteps    | 239000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.31      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 57799      |\n",
      "|    policy_loss        | -18.8      |\n",
      "|    reward             | 0.21575978 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 21.7       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 47900      |\n",
      "|    time_elapsed       | 411        |\n",
      "|    total_timesteps    | 239500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.31      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 57899      |\n",
      "|    policy_loss        | 44.1       |\n",
      "|    reward             | -1.9548671 |\n",
      "|    std                | 1.43       |\n",
      "|    value_loss         | 76.2       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 48000      |\n",
      "|    time_elapsed       | 412        |\n",
      "|    total_timesteps    | 240000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.31      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 57999      |\n",
      "|    policy_loss        | -5.45      |\n",
      "|    reward             | -1.6264253 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 9.88       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 48100      |\n",
      "|    time_elapsed       | 413        |\n",
      "|    total_timesteps    | 240500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.31      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 58099      |\n",
      "|    policy_loss        | -23.2      |\n",
      "|    reward             | -0.2300417 |\n",
      "|    std                | 1.43       |\n",
      "|    value_loss         | 28.7       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 581         |\n",
      "|    iterations         | 48200       |\n",
      "|    time_elapsed       | 414         |\n",
      "|    total_timesteps    | 241000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.31       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 58199       |\n",
      "|    policy_loss        | -19.6       |\n",
      "|    reward             | 0.113602325 |\n",
      "|    std                | 1.43        |\n",
      "|    value_loss         | 23.4        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 48300     |\n",
      "|    time_elapsed       | 415       |\n",
      "|    total_timesteps    | 241500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.32     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 58299     |\n",
      "|    policy_loss        | 0.0771    |\n",
      "|    reward             | -1.469465 |\n",
      "|    std                | 1.43      |\n",
      "|    value_loss         | 0.309     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 48400     |\n",
      "|    time_elapsed       | 416       |\n",
      "|    total_timesteps    | 242000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.32     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 58399     |\n",
      "|    policy_loss        | -11.2     |\n",
      "|    reward             | 3.8810027 |\n",
      "|    std                | 1.43      |\n",
      "|    value_loss         | 9.55      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 581         |\n",
      "|    iterations         | 48500       |\n",
      "|    time_elapsed       | 416         |\n",
      "|    total_timesteps    | 242500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.32       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 58499       |\n",
      "|    policy_loss        | -0.701      |\n",
      "|    reward             | -0.42889452 |\n",
      "|    std                | 1.43        |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 48600     |\n",
      "|    time_elapsed       | 417       |\n",
      "|    total_timesteps    | 243000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.32     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 58599     |\n",
      "|    policy_loss        | 69.4      |\n",
      "|    reward             | 2.9694595 |\n",
      "|    std                | 1.43      |\n",
      "|    value_loss         | 229       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 48700      |\n",
      "|    time_elapsed       | 418        |\n",
      "|    total_timesteps    | 243500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.32      |\n",
      "|    explained_variance | -0.142     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 58699      |\n",
      "|    policy_loss        | 20.8       |\n",
      "|    reward             | -0.7273913 |\n",
      "|    std                | 1.43       |\n",
      "|    value_loss         | 14.6       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 48800     |\n",
      "|    time_elapsed       | 419       |\n",
      "|    total_timesteps    | 244000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.33     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 58799     |\n",
      "|    policy_loss        | 1.36      |\n",
      "|    reward             | 0.3134997 |\n",
      "|    std                | 1.43      |\n",
      "|    value_loss         | 2.8       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 48900    |\n",
      "|    time_elapsed       | 420      |\n",
      "|    total_timesteps    | 244500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.33    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 58899    |\n",
      "|    policy_loss        | -22.8    |\n",
      "|    reward             | 1.717298 |\n",
      "|    std                | 1.43     |\n",
      "|    value_loss         | 16.8     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 49000      |\n",
      "|    time_elapsed       | 421        |\n",
      "|    total_timesteps    | 245000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.33      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 58999      |\n",
      "|    policy_loss        | 12.4       |\n",
      "|    reward             | -2.4449863 |\n",
      "|    std                | 1.43       |\n",
      "|    value_loss         | 9.62       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 49100      |\n",
      "|    time_elapsed       | 421        |\n",
      "|    total_timesteps    | 245500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.33      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 59099      |\n",
      "|    policy_loss        | -62.1      |\n",
      "|    reward             | -12.215819 |\n",
      "|    std                | 1.43       |\n",
      "|    value_loss         | 144        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 581         |\n",
      "|    iterations         | 49200       |\n",
      "|    time_elapsed       | 422         |\n",
      "|    total_timesteps    | 246000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.33       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 59199       |\n",
      "|    policy_loss        | -2.29       |\n",
      "|    reward             | -0.73511535 |\n",
      "|    std                | 1.43        |\n",
      "|    value_loss         | 0.673       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 49300      |\n",
      "|    time_elapsed       | 423        |\n",
      "|    total_timesteps    | 246500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.33      |\n",
      "|    explained_variance | -0.559     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 59299      |\n",
      "|    policy_loss        | -5.28      |\n",
      "|    reward             | -1.8180162 |\n",
      "|    std                | 1.43       |\n",
      "|    value_loss         | 1.87       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 49400     |\n",
      "|    time_elapsed       | 424       |\n",
      "|    total_timesteps    | 247000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.33     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 59399     |\n",
      "|    policy_loss        | 17.7      |\n",
      "|    reward             | 0.5145166 |\n",
      "|    std                | 1.43      |\n",
      "|    value_loss         | 21.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 49500      |\n",
      "|    time_elapsed       | 425        |\n",
      "|    total_timesteps    | 247500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.32      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 59499      |\n",
      "|    policy_loss        | 58.3       |\n",
      "|    reward             | -6.1790366 |\n",
      "|    std                | 1.43       |\n",
      "|    value_loss         | 280        |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 49600    |\n",
      "|    time_elapsed       | 426      |\n",
      "|    total_timesteps    | 248000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.31    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 59599    |\n",
      "|    policy_loss        | 33.6     |\n",
      "|    reward             | 4.072456 |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 55.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 49700     |\n",
      "|    time_elapsed       | 427       |\n",
      "|    total_timesteps    | 248500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.3      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 59699     |\n",
      "|    policy_loss        | 53.1      |\n",
      "|    reward             | 3.8275158 |\n",
      "|    std                | 1.42      |\n",
      "|    value_loss         | 96.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 49800      |\n",
      "|    time_elapsed       | 427        |\n",
      "|    total_timesteps    | 249000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.29      |\n",
      "|    explained_variance | -0.106     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 59799      |\n",
      "|    policy_loss        | 14.3       |\n",
      "|    reward             | -1.0379391 |\n",
      "|    std                | 1.41       |\n",
      "|    value_loss         | 11.2       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 49900    |\n",
      "|    time_elapsed       | 428      |\n",
      "|    total_timesteps    | 249500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.27    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 59899    |\n",
      "|    policy_loss        | 25.1     |\n",
      "|    reward             | 2.141522 |\n",
      "|    std                | 1.41     |\n",
      "|    value_loss         | 30.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 50000     |\n",
      "|    time_elapsed       | 429       |\n",
      "|    total_timesteps    | 250000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.29     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 59999     |\n",
      "|    policy_loss        | -2.94     |\n",
      "|    reward             | 1.7745626 |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 0.562     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 50100      |\n",
      "|    time_elapsed       | 430        |\n",
      "|    total_timesteps    | 250500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.3       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 60099      |\n",
      "|    policy_loss        | 11.1       |\n",
      "|    reward             | 0.85972935 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 5.93       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 50200     |\n",
      "|    time_elapsed       | 431       |\n",
      "|    total_timesteps    | 251000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.29     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 60199     |\n",
      "|    policy_loss        | -31       |\n",
      "|    reward             | 1.3034276 |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 26.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 50300      |\n",
      "|    time_elapsed       | 432        |\n",
      "|    total_timesteps    | 251500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.29      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 60299      |\n",
      "|    policy_loss        | 9.81       |\n",
      "|    reward             | -6.2217593 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 34.5       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 50400      |\n",
      "|    time_elapsed       | 433        |\n",
      "|    total_timesteps    | 252000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.29      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 60399      |\n",
      "|    policy_loss        | -2.94      |\n",
      "|    reward             | -0.7546226 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 0.252      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 50500      |\n",
      "|    time_elapsed       | 434        |\n",
      "|    total_timesteps    | 252500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.29      |\n",
      "|    explained_variance | -0.993     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 60499      |\n",
      "|    policy_loss        | -35.5      |\n",
      "|    reward             | -1.2825516 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 44.9       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 50600    |\n",
      "|    time_elapsed       | 434      |\n",
      "|    total_timesteps    | 253000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.3     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 60599    |\n",
      "|    policy_loss        | -6.26    |\n",
      "|    reward             | 8.896096 |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 4.06     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 50700     |\n",
      "|    time_elapsed       | 435       |\n",
      "|    total_timesteps    | 253500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.29     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 60699     |\n",
      "|    policy_loss        | -2.5      |\n",
      "|    reward             | 6.4342766 |\n",
      "|    std                | 1.42      |\n",
      "|    value_loss         | 22.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 50800     |\n",
      "|    time_elapsed       | 436       |\n",
      "|    total_timesteps    | 254000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.29     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 60799     |\n",
      "|    policy_loss        | 0.593     |\n",
      "|    reward             | 3.5693352 |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 98.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 50900      |\n",
      "|    time_elapsed       | 437        |\n",
      "|    total_timesteps    | 254500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.26      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 60899      |\n",
      "|    policy_loss        | -548       |\n",
      "|    reward             | -56.389206 |\n",
      "|    std                | 1.41       |\n",
      "|    value_loss         | 1.01e+04   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 51000     |\n",
      "|    time_elapsed       | 438       |\n",
      "|    total_timesteps    | 255000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.26     |\n",
      "|    explained_variance | -4.41     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 60999     |\n",
      "|    policy_loss        | 23        |\n",
      "|    reward             | 1.2047532 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 25.8      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 581         |\n",
      "|    iterations         | 51100       |\n",
      "|    time_elapsed       | 439         |\n",
      "|    total_timesteps    | 255500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.25       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 61099       |\n",
      "|    policy_loss        | -6.31       |\n",
      "|    reward             | -0.38221797 |\n",
      "|    std                | 1.4         |\n",
      "|    value_loss         | 1.21        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 51200     |\n",
      "|    time_elapsed       | 439       |\n",
      "|    total_timesteps    | 256000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.24     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 61199     |\n",
      "|    policy_loss        | 9.87      |\n",
      "|    reward             | 2.9869952 |\n",
      "|    std                | 1.39      |\n",
      "|    value_loss         | 4.3       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 51300      |\n",
      "|    time_elapsed       | 440        |\n",
      "|    total_timesteps    | 256500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.24      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 61299      |\n",
      "|    policy_loss        | 31         |\n",
      "|    reward             | -2.2547662 |\n",
      "|    std                | 1.4        |\n",
      "|    value_loss         | 40.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 51400     |\n",
      "|    time_elapsed       | 441       |\n",
      "|    total_timesteps    | 257000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.26     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 61399     |\n",
      "|    policy_loss        | -58.8     |\n",
      "|    reward             | 3.9925928 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 321       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 581         |\n",
      "|    iterations         | 51500       |\n",
      "|    time_elapsed       | 442         |\n",
      "|    total_timesteps    | 257500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.24       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 61499       |\n",
      "|    policy_loss        | -0.887      |\n",
      "|    reward             | 0.010095388 |\n",
      "|    std                | 1.4         |\n",
      "|    value_loss         | 0.032       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 51600     |\n",
      "|    time_elapsed       | 443       |\n",
      "|    total_timesteps    | 258000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.25     |\n",
      "|    explained_variance | -3.85     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 61599     |\n",
      "|    policy_loss        | -0.958    |\n",
      "|    reward             | 0.5112442 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 3.59      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 51700      |\n",
      "|    time_elapsed       | 444        |\n",
      "|    total_timesteps    | 258500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.24      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 61699      |\n",
      "|    policy_loss        | 2.45       |\n",
      "|    reward             | 0.16984974 |\n",
      "|    std                | 1.4        |\n",
      "|    value_loss         | 0.75       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 51800     |\n",
      "|    time_elapsed       | 444       |\n",
      "|    total_timesteps    | 259000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.23     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 61799     |\n",
      "|    policy_loss        | -35.8     |\n",
      "|    reward             | 7.2515817 |\n",
      "|    std                | 1.39      |\n",
      "|    value_loss         | 41.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 51900      |\n",
      "|    time_elapsed       | 445        |\n",
      "|    total_timesteps    | 259500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.23      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 61899      |\n",
      "|    policy_loss        | 3.48       |\n",
      "|    reward             | -1.0751934 |\n",
      "|    std                | 1.39       |\n",
      "|    value_loss         | 2.4        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 52000      |\n",
      "|    time_elapsed       | 446        |\n",
      "|    total_timesteps    | 260000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.25      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 61999      |\n",
      "|    policy_loss        | 56         |\n",
      "|    reward             | -5.2625837 |\n",
      "|    std                | 1.4        |\n",
      "|    value_loss         | 197        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 52100      |\n",
      "|    time_elapsed       | 447        |\n",
      "|    total_timesteps    | 260500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.23      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 62099      |\n",
      "|    policy_loss        | -15.9      |\n",
      "|    reward             | -0.9402326 |\n",
      "|    std                | 1.39       |\n",
      "|    value_loss         | 9.36       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 52200     |\n",
      "|    time_elapsed       | 448       |\n",
      "|    total_timesteps    | 261000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.25     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 62199     |\n",
      "|    policy_loss        | 10.7      |\n",
      "|    reward             | 0.5480986 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 4.76      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 581         |\n",
      "|    iterations         | 52300       |\n",
      "|    time_elapsed       | 449         |\n",
      "|    total_timesteps    | 261500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.24       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 62299       |\n",
      "|    policy_loss        | -39.1       |\n",
      "|    reward             | -0.34123605 |\n",
      "|    std                | 1.39        |\n",
      "|    value_loss         | 51.7        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 581         |\n",
      "|    iterations         | 52400       |\n",
      "|    time_elapsed       | 450         |\n",
      "|    total_timesteps    | 262000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.21       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 62399       |\n",
      "|    policy_loss        | 10.9        |\n",
      "|    reward             | -0.50014096 |\n",
      "|    std                | 1.38        |\n",
      "|    value_loss         | 7.19        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 52500      |\n",
      "|    time_elapsed       | 450        |\n",
      "|    total_timesteps    | 262500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.22      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 62499      |\n",
      "|    policy_loss        | -10.3      |\n",
      "|    reward             | -2.8529134 |\n",
      "|    std                | 1.38       |\n",
      "|    value_loss         | 12.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 52600     |\n",
      "|    time_elapsed       | 451       |\n",
      "|    total_timesteps    | 263000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.25     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 62599     |\n",
      "|    policy_loss        | 125       |\n",
      "|    reward             | 1.1403837 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 701       |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7310748.59\n",
      "total_reward: 6310748.59\n",
      "total_cost: 2501.79\n",
      "total_trades: 5849\n",
      "Sharpe: 0.930\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 52700      |\n",
      "|    time_elapsed       | 452        |\n",
      "|    total_timesteps    | 263500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.25      |\n",
      "|    explained_variance | -0.221     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 62699      |\n",
      "|    policy_loss        | 0.461      |\n",
      "|    reward             | 0.90620875 |\n",
      "|    std                | 1.4        |\n",
      "|    value_loss         | 1.07       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 52800     |\n",
      "|    time_elapsed       | 453       |\n",
      "|    total_timesteps    | 264000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.24     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 62799     |\n",
      "|    policy_loss        | 4.7       |\n",
      "|    reward             | 1.7993032 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 7.96      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 582         |\n",
      "|    iterations         | 52900       |\n",
      "|    time_elapsed       | 454         |\n",
      "|    total_timesteps    | 264500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.27       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 62899       |\n",
      "|    policy_loss        | -5.18       |\n",
      "|    reward             | -0.33706802 |\n",
      "|    std                | 1.41        |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 53000      |\n",
      "|    time_elapsed       | 455        |\n",
      "|    total_timesteps    | 265000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.26      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 62999      |\n",
      "|    policy_loss        | 16.1       |\n",
      "|    reward             | -1.9552759 |\n",
      "|    std                | 1.4        |\n",
      "|    value_loss         | 12.4       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 53100     |\n",
      "|    time_elapsed       | 456       |\n",
      "|    total_timesteps    | 265500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.25     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 63099     |\n",
      "|    policy_loss        | -12       |\n",
      "|    reward             | 1.3492815 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 6.66      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 53200     |\n",
      "|    time_elapsed       | 456       |\n",
      "|    total_timesteps    | 266000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.25     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 63199     |\n",
      "|    policy_loss        | 28.9      |\n",
      "|    reward             | 6.2216454 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 31        |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 582         |\n",
      "|    iterations         | 53300       |\n",
      "|    time_elapsed       | 457         |\n",
      "|    total_timesteps    | 266500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.27       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 63299       |\n",
      "|    policy_loss        | -7.71       |\n",
      "|    reward             | -0.42412943 |\n",
      "|    std                | 1.41        |\n",
      "|    value_loss         | 16.3        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 53400      |\n",
      "|    time_elapsed       | 458        |\n",
      "|    total_timesteps    | 267000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.28      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 63399      |\n",
      "|    policy_loss        | -1.2       |\n",
      "|    reward             | 0.51303697 |\n",
      "|    std                | 1.41       |\n",
      "|    value_loss         | 0.209      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 53500     |\n",
      "|    time_elapsed       | 459       |\n",
      "|    total_timesteps    | 267500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.29     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 63499     |\n",
      "|    policy_loss        | 11.3      |\n",
      "|    reward             | 1.2150097 |\n",
      "|    std                | 1.42      |\n",
      "|    value_loss         | 9.5       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 53600     |\n",
      "|    time_elapsed       | 460       |\n",
      "|    total_timesteps    | 268000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.27     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 63599     |\n",
      "|    policy_loss        | -47       |\n",
      "|    reward             | 2.1161497 |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 151       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 53700     |\n",
      "|    time_elapsed       | 461       |\n",
      "|    total_timesteps    | 268500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.25     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 63699     |\n",
      "|    policy_loss        | 2.18      |\n",
      "|    reward             | 7.3190928 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 17.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 53800     |\n",
      "|    time_elapsed       | 461       |\n",
      "|    total_timesteps    | 269000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.26     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 63799     |\n",
      "|    policy_loss        | 79.2      |\n",
      "|    reward             | 22.563366 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 531       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 53900     |\n",
      "|    time_elapsed       | 462       |\n",
      "|    total_timesteps    | 269500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.25     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 63899     |\n",
      "|    policy_loss        | 4.77      |\n",
      "|    reward             | 1.5560412 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 2.03      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 54000      |\n",
      "|    time_elapsed       | 463        |\n",
      "|    total_timesteps    | 270000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.24      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 63999      |\n",
      "|    policy_loss        | 0.813      |\n",
      "|    reward             | -1.8243325 |\n",
      "|    std                | 1.39       |\n",
      "|    value_loss         | 0.468      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 54100     |\n",
      "|    time_elapsed       | 464       |\n",
      "|    total_timesteps    | 270500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.23     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 64099     |\n",
      "|    policy_loss        | -22.8     |\n",
      "|    reward             | 6.479436  |\n",
      "|    std                | 1.39      |\n",
      "|    value_loss         | 19.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 54200      |\n",
      "|    time_elapsed       | 465        |\n",
      "|    total_timesteps    | 271000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.24      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 64199      |\n",
      "|    policy_loss        | -16        |\n",
      "|    reward             | -1.0745242 |\n",
      "|    std                | 1.4        |\n",
      "|    value_loss         | 14.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 54300     |\n",
      "|    time_elapsed       | 466       |\n",
      "|    total_timesteps    | 271500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.25     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 64299     |\n",
      "|    policy_loss        | 19.6      |\n",
      "|    reward             | 2.4384358 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 32.9      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 54400      |\n",
      "|    time_elapsed       | 467        |\n",
      "|    total_timesteps    | 272000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.26      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 64399      |\n",
      "|    policy_loss        | 0.438      |\n",
      "|    reward             | -1.7275926 |\n",
      "|    std                | 1.4        |\n",
      "|    value_loss         | 0.0743     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 54500      |\n",
      "|    time_elapsed       | 467        |\n",
      "|    total_timesteps    | 272500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.28      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 64499      |\n",
      "|    policy_loss        | -18.3      |\n",
      "|    reward             | 0.10425991 |\n",
      "|    std                | 1.41       |\n",
      "|    value_loss         | 12.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 54600     |\n",
      "|    time_elapsed       | 468       |\n",
      "|    total_timesteps    | 273000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.29     |\n",
      "|    explained_variance | -7.14     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 64599     |\n",
      "|    policy_loss        | -1.64     |\n",
      "|    reward             | 0.3630548 |\n",
      "|    std                | 1.42      |\n",
      "|    value_loss         | 1.17      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 54700      |\n",
      "|    time_elapsed       | 469        |\n",
      "|    total_timesteps    | 273500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.28      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 64699      |\n",
      "|    policy_loss        | -28.4      |\n",
      "|    reward             | 0.22388095 |\n",
      "|    std                | 1.41       |\n",
      "|    value_loss         | 36.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 54800     |\n",
      "|    time_elapsed       | 470       |\n",
      "|    total_timesteps    | 274000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.28     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 64799     |\n",
      "|    policy_loss        | 13.1      |\n",
      "|    reward             | 3.0084808 |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 7.63      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 54900      |\n",
      "|    time_elapsed       | 471        |\n",
      "|    total_timesteps    | 274500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.26      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 64899      |\n",
      "|    policy_loss        | 67.7       |\n",
      "|    reward             | -3.0767696 |\n",
      "|    std                | 1.4        |\n",
      "|    value_loss         | 320        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 55000      |\n",
      "|    time_elapsed       | 472        |\n",
      "|    total_timesteps    | 275000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.27      |\n",
      "|    explained_variance | 0.122      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 64999      |\n",
      "|    policy_loss        | 9.4        |\n",
      "|    reward             | -0.9313636 |\n",
      "|    std                | 1.41       |\n",
      "|    value_loss         | 3.83       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 55100    |\n",
      "|    time_elapsed       | 472      |\n",
      "|    total_timesteps    | 275500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.25    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 65099    |\n",
      "|    policy_loss        | 11.3     |\n",
      "|    reward             | 4.75117  |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 13.6     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 55200      |\n",
      "|    time_elapsed       | 473        |\n",
      "|    total_timesteps    | 276000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.27      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 65199      |\n",
      "|    policy_loss        | -3.04      |\n",
      "|    reward             | 0.77996194 |\n",
      "|    std                | 1.41       |\n",
      "|    value_loss         | 0.982      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 55300     |\n",
      "|    time_elapsed       | 474       |\n",
      "|    total_timesteps    | 276500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.28     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 65299     |\n",
      "|    policy_loss        | -13.9     |\n",
      "|    reward             | 1.1669015 |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 9.04      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 55400      |\n",
      "|    time_elapsed       | 475        |\n",
      "|    total_timesteps    | 277000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.3       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 65399      |\n",
      "|    policy_loss        | -17.4      |\n",
      "|    reward             | -1.2176772 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 16.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 55500     |\n",
      "|    time_elapsed       | 476       |\n",
      "|    total_timesteps    | 277500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.3      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 65499     |\n",
      "|    policy_loss        | -10.2     |\n",
      "|    reward             | 8.878034  |\n",
      "|    std                | 1.42      |\n",
      "|    value_loss         | 8.96      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 55600     |\n",
      "|    time_elapsed       | 477       |\n",
      "|    total_timesteps    | 278000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.28     |\n",
      "|    explained_variance | 5.1e-05   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 65599     |\n",
      "|    policy_loss        | -18.4     |\n",
      "|    reward             | 0.6536334 |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 24.5      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 55700      |\n",
      "|    time_elapsed       | 478        |\n",
      "|    total_timesteps    | 278500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.3       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 65699      |\n",
      "|    policy_loss        | -2.88      |\n",
      "|    reward             | -0.5707716 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 0.354      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 55800     |\n",
      "|    time_elapsed       | 478       |\n",
      "|    total_timesteps    | 279000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.28     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 65799     |\n",
      "|    policy_loss        | 17.7      |\n",
      "|    reward             | 0.6189705 |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 13.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 55900     |\n",
      "|    time_elapsed       | 479       |\n",
      "|    total_timesteps    | 279500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.29     |\n",
      "|    explained_variance | 0.147     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 65899     |\n",
      "|    policy_loss        | -23.7     |\n",
      "|    reward             | -2.333065 |\n",
      "|    std                | 1.42      |\n",
      "|    value_loss         | 41.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 56000     |\n",
      "|    time_elapsed       | 480       |\n",
      "|    total_timesteps    | 280000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.31     |\n",
      "|    explained_variance | -0.00323  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 65999     |\n",
      "|    policy_loss        | 46.7      |\n",
      "|    reward             | 0.8599959 |\n",
      "|    std                | 1.43      |\n",
      "|    value_loss         | 56.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 56100    |\n",
      "|    time_elapsed       | 481      |\n",
      "|    total_timesteps    | 280500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.28    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 66099    |\n",
      "|    policy_loss        | -13      |\n",
      "|    reward             | 9.298039 |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 11.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 56200     |\n",
      "|    time_elapsed       | 482       |\n",
      "|    total_timesteps    | 281000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.28     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 66199     |\n",
      "|    policy_loss        | -38.4     |\n",
      "|    reward             | 3.0826983 |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 39.4      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 583        |\n",
      "|    iterations         | 56300      |\n",
      "|    time_elapsed       | 482        |\n",
      "|    total_timesteps    | 281500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.28      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 66299      |\n",
      "|    policy_loss        | -16.9      |\n",
      "|    reward             | -1.5445831 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 14.1       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 583         |\n",
      "|    iterations         | 56400       |\n",
      "|    time_elapsed       | 483         |\n",
      "|    total_timesteps    | 282000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.28       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 66399       |\n",
      "|    policy_loss        | 1.56        |\n",
      "|    reward             | -0.96823895 |\n",
      "|    std                | 1.42        |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 583       |\n",
      "|    iterations         | 56500     |\n",
      "|    time_elapsed       | 484       |\n",
      "|    total_timesteps    | 282500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.3      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 66499     |\n",
      "|    policy_loss        | -30.7     |\n",
      "|    reward             | 3.1519942 |\n",
      "|    std                | 1.42      |\n",
      "|    value_loss         | 40.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 583        |\n",
      "|    iterations         | 56600      |\n",
      "|    time_elapsed       | 485        |\n",
      "|    total_timesteps    | 283000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.32      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 66599      |\n",
      "|    policy_loss        | 6.89       |\n",
      "|    reward             | -3.3188741 |\n",
      "|    std                | 1.43       |\n",
      "|    value_loss         | 6.06       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 583        |\n",
      "|    iterations         | 56700      |\n",
      "|    time_elapsed       | 486        |\n",
      "|    total_timesteps    | 283500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.31      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 66699      |\n",
      "|    policy_loss        | 0.323      |\n",
      "|    reward             | -38.389324 |\n",
      "|    std                | 1.43       |\n",
      "|    value_loss         | 23.8       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 583         |\n",
      "|    iterations         | 56800       |\n",
      "|    time_elapsed       | 486         |\n",
      "|    total_timesteps    | 284000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.34       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 66799       |\n",
      "|    policy_loss        | -10.8       |\n",
      "|    reward             | -0.52084094 |\n",
      "|    std                | 1.44        |\n",
      "|    value_loss         | 6.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 583         |\n",
      "|    iterations         | 56900       |\n",
      "|    time_elapsed       | 487         |\n",
      "|    total_timesteps    | 284500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.34       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 66899       |\n",
      "|    policy_loss        | 11.6        |\n",
      "|    reward             | -0.78870225 |\n",
      "|    std                | 1.44        |\n",
      "|    value_loss         | 9.15        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 583        |\n",
      "|    iterations         | 57000      |\n",
      "|    time_elapsed       | 488        |\n",
      "|    total_timesteps    | 285000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.33      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 66999      |\n",
      "|    policy_loss        | -18.1      |\n",
      "|    reward             | 0.78157324 |\n",
      "|    std                | 1.44       |\n",
      "|    value_loss         | 12.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 583       |\n",
      "|    iterations         | 57100     |\n",
      "|    time_elapsed       | 489       |\n",
      "|    total_timesteps    | 285500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.33     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 67099     |\n",
      "|    policy_loss        | -18.2     |\n",
      "|    reward             | 2.9235947 |\n",
      "|    std                | 1.44      |\n",
      "|    value_loss         | 13.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 583       |\n",
      "|    iterations         | 57200     |\n",
      "|    time_elapsed       | 490       |\n",
      "|    total_timesteps    | 286000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.35     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 67199     |\n",
      "|    policy_loss        | 60        |\n",
      "|    reward             | 6.8828244 |\n",
      "|    std                | 1.45      |\n",
      "|    value_loss         | 227       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 583       |\n",
      "|    iterations         | 57300     |\n",
      "|    time_elapsed       | 491       |\n",
      "|    total_timesteps    | 286500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.35     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 67299     |\n",
      "|    policy_loss        | -4.63     |\n",
      "|    reward             | 1.9367155 |\n",
      "|    std                | 1.45      |\n",
      "|    value_loss         | 1.89      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 583        |\n",
      "|    iterations         | 57400      |\n",
      "|    time_elapsed       | 491        |\n",
      "|    total_timesteps    | 287000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.36      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 67399      |\n",
      "|    policy_loss        | -6.04      |\n",
      "|    reward             | -1.1501844 |\n",
      "|    std                | 1.45       |\n",
      "|    value_loss         | 1.36       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 583        |\n",
      "|    iterations         | 57500      |\n",
      "|    time_elapsed       | 492        |\n",
      "|    total_timesteps    | 287500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.37      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 67499      |\n",
      "|    policy_loss        | 13.6       |\n",
      "|    reward             | 0.68682593 |\n",
      "|    std                | 1.46       |\n",
      "|    value_loss         | 19.5       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 583         |\n",
      "|    iterations         | 57600       |\n",
      "|    time_elapsed       | 493         |\n",
      "|    total_timesteps    | 288000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.36       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 67599       |\n",
      "|    policy_loss        | 69.5        |\n",
      "|    reward             | -0.77001786 |\n",
      "|    std                | 1.46        |\n",
      "|    value_loss         | 157         |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 583       |\n",
      "|    iterations         | 57700     |\n",
      "|    time_elapsed       | 494       |\n",
      "|    total_timesteps    | 288500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.34     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 67699     |\n",
      "|    policy_loss        | -22.7     |\n",
      "|    reward             | 1.2846099 |\n",
      "|    std                | 1.45      |\n",
      "|    value_loss         | 26.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 583       |\n",
      "|    iterations         | 57800     |\n",
      "|    time_elapsed       | 495       |\n",
      "|    total_timesteps    | 289000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.34     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 67799     |\n",
      "|    policy_loss        | 9.27      |\n",
      "|    reward             | -1.505775 |\n",
      "|    std                | 1.45      |\n",
      "|    value_loss         | 7.76      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 583       |\n",
      "|    iterations         | 57900     |\n",
      "|    time_elapsed       | 496       |\n",
      "|    total_timesteps    | 289500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.34     |\n",
      "|    explained_variance | -0.0207   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 67899     |\n",
      "|    policy_loss        | 19.9      |\n",
      "|    reward             | 0.8743158 |\n",
      "|    std                | 1.44      |\n",
      "|    value_loss         | 15.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 583       |\n",
      "|    iterations         | 58000     |\n",
      "|    time_elapsed       | 496       |\n",
      "|    total_timesteps    | 290000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.35     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 67999     |\n",
      "|    policy_loss        | 6.69      |\n",
      "|    reward             | 0.6167798 |\n",
      "|    std                | 1.45      |\n",
      "|    value_loss         | 7.48      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 583       |\n",
      "|    iterations         | 58100     |\n",
      "|    time_elapsed       | 497       |\n",
      "|    total_timesteps    | 290500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.35     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 68099     |\n",
      "|    policy_loss        | 1.03      |\n",
      "|    reward             | 1.6632274 |\n",
      "|    std                | 1.45      |\n",
      "|    value_loss         | 0.434     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 583      |\n",
      "|    iterations         | 58200    |\n",
      "|    time_elapsed       | 498      |\n",
      "|    total_timesteps    | 291000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.38    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 68199    |\n",
      "|    policy_loss        | -19.3    |\n",
      "|    reward             | 5.728549 |\n",
      "|    std                | 1.47     |\n",
      "|    value_loss         | 14.5     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 583         |\n",
      "|    iterations         | 58300       |\n",
      "|    time_elapsed       | 499         |\n",
      "|    total_timesteps    | 291500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.35       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 68299       |\n",
      "|    policy_loss        | -14.6       |\n",
      "|    reward             | 0.060728606 |\n",
      "|    std                | 1.45        |\n",
      "|    value_loss         | 9.46        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 583      |\n",
      "|    iterations         | 58400    |\n",
      "|    time_elapsed       | 500      |\n",
      "|    total_timesteps    | 292000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.36    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 68399    |\n",
      "|    policy_loss        | 18.6     |\n",
      "|    reward             | 7.264137 |\n",
      "|    std                | 1.45     |\n",
      "|    value_loss         | 17.2     |\n",
      "------------------------------------\n",
      "day: 2892, episode: 120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7332811.07\n",
      "total_reward: 6332811.07\n",
      "total_cost: 2359.14\n",
      "total_trades: 5787\n",
      "Sharpe: 0.933\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 583        |\n",
      "|    iterations         | 58500      |\n",
      "|    time_elapsed       | 500        |\n",
      "|    total_timesteps    | 292500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.38      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 68499      |\n",
      "|    policy_loss        | 1.27       |\n",
      "|    reward             | -0.9411056 |\n",
      "|    std                | 1.46       |\n",
      "|    value_loss         | 0.604      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 584        |\n",
      "|    iterations         | 58600      |\n",
      "|    time_elapsed       | 501        |\n",
      "|    total_timesteps    | 293000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.38      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 68599      |\n",
      "|    policy_loss        | 2.07       |\n",
      "|    reward             | -0.5477487 |\n",
      "|    std                | 1.46       |\n",
      "|    value_loss         | 1.66       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 583        |\n",
      "|    iterations         | 58700      |\n",
      "|    time_elapsed       | 502        |\n",
      "|    total_timesteps    | 293500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.38      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 68699      |\n",
      "|    policy_loss        | -2.26      |\n",
      "|    reward             | -1.5669318 |\n",
      "|    std                | 1.46       |\n",
      "|    value_loss         | 1.07       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 583       |\n",
      "|    iterations         | 58800     |\n",
      "|    time_elapsed       | 503       |\n",
      "|    total_timesteps    | 294000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.37     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 68799     |\n",
      "|    policy_loss        | 27.5      |\n",
      "|    reward             | 4.2710667 |\n",
      "|    std                | 1.46      |\n",
      "|    value_loss         | 33.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 583       |\n",
      "|    iterations         | 58900     |\n",
      "|    time_elapsed       | 504       |\n",
      "|    total_timesteps    | 294500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.38     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 68899     |\n",
      "|    policy_loss        | 54.8      |\n",
      "|    reward             | 3.3714762 |\n",
      "|    std                | 1.46      |\n",
      "|    value_loss         | 135       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 583        |\n",
      "|    iterations         | 59000      |\n",
      "|    time_elapsed       | 505        |\n",
      "|    total_timesteps    | 295000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.38      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 68999      |\n",
      "|    policy_loss        | -124       |\n",
      "|    reward             | 10.5462885 |\n",
      "|    std                | 1.46       |\n",
      "|    value_loss         | 573        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 584        |\n",
      "|    iterations         | 59100      |\n",
      "|    time_elapsed       | 505        |\n",
      "|    total_timesteps    | 295500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.39      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 69099      |\n",
      "|    policy_loss        | 1.43       |\n",
      "|    reward             | 0.34301126 |\n",
      "|    std                | 1.47       |\n",
      "|    value_loss         | 1.17       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 584       |\n",
      "|    iterations         | 59200     |\n",
      "|    time_elapsed       | 506       |\n",
      "|    total_timesteps    | 296000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.39     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 69199     |\n",
      "|    policy_loss        | 1.88      |\n",
      "|    reward             | 0.524656  |\n",
      "|    std                | 1.47      |\n",
      "|    value_loss         | 0.636     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 584       |\n",
      "|    iterations         | 59300     |\n",
      "|    time_elapsed       | 507       |\n",
      "|    total_timesteps    | 296500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.39     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 69299     |\n",
      "|    policy_loss        | -0.953    |\n",
      "|    reward             | 1.2529967 |\n",
      "|    std                | 1.47      |\n",
      "|    value_loss         | 1.91      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 584         |\n",
      "|    iterations         | 59400       |\n",
      "|    time_elapsed       | 508         |\n",
      "|    total_timesteps    | 297000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.38       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 69399       |\n",
      "|    policy_loss        | 2.98        |\n",
      "|    reward             | -0.39386922 |\n",
      "|    std                | 1.46        |\n",
      "|    value_loss         | 0.566       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 584       |\n",
      "|    iterations         | 59500     |\n",
      "|    time_elapsed       | 508       |\n",
      "|    total_timesteps    | 297500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.39     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 69499     |\n",
      "|    policy_loss        | -62.1     |\n",
      "|    reward             | -0.661183 |\n",
      "|    std                | 1.47      |\n",
      "|    value_loss         | 168       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 584        |\n",
      "|    iterations         | 59600      |\n",
      "|    time_elapsed       | 509        |\n",
      "|    total_timesteps    | 298000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.41      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 69599      |\n",
      "|    policy_loss        | -0.0376    |\n",
      "|    reward             | 0.40272254 |\n",
      "|    std                | 1.48       |\n",
      "|    value_loss         | 0.0464     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 584        |\n",
      "|    iterations         | 59700      |\n",
      "|    time_elapsed       | 510        |\n",
      "|    total_timesteps    | 298500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.41      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 69699      |\n",
      "|    policy_loss        | 6.91       |\n",
      "|    reward             | 0.26016113 |\n",
      "|    std                | 1.48       |\n",
      "|    value_loss         | 2.21       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 584         |\n",
      "|    iterations         | 59800       |\n",
      "|    time_elapsed       | 511         |\n",
      "|    total_timesteps    | 299000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.41       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 69799       |\n",
      "|    policy_loss        | -1.02       |\n",
      "|    reward             | -0.08114949 |\n",
      "|    std                | 1.48        |\n",
      "|    value_loss         | 0.357       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 584        |\n",
      "|    iterations         | 59900      |\n",
      "|    time_elapsed       | 512        |\n",
      "|    total_timesteps    | 299500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.44      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 69899      |\n",
      "|    policy_loss        | -7.72      |\n",
      "|    reward             | 0.38990802 |\n",
      "|    std                | 1.5        |\n",
      "|    value_loss         | 8.15       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 584        |\n",
      "|    iterations         | 60000      |\n",
      "|    time_elapsed       | 512        |\n",
      "|    total_timesteps    | 300000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.46      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 69999      |\n",
      "|    policy_loss        | -4.47      |\n",
      "|    reward             | -1.9313456 |\n",
      "|    std                | 1.51       |\n",
      "|    value_loss         | 2.64       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 584       |\n",
      "|    iterations         | 60100     |\n",
      "|    time_elapsed       | 513       |\n",
      "|    total_timesteps    | 300500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.45     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 70099     |\n",
      "|    policy_loss        | 27.7      |\n",
      "|    reward             | 6.1753006 |\n",
      "|    std                | 1.5       |\n",
      "|    value_loss         | 167       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 584        |\n",
      "|    iterations         | 60200      |\n",
      "|    time_elapsed       | 514        |\n",
      "|    total_timesteps    | 301000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.46      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 70199      |\n",
      "|    policy_loss        | -2.79      |\n",
      "|    reward             | 0.35884675 |\n",
      "|    std                | 1.51       |\n",
      "|    value_loss         | 0.624      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 584       |\n",
      "|    iterations         | 60300     |\n",
      "|    time_elapsed       | 515       |\n",
      "|    total_timesteps    | 301500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.46     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 70299     |\n",
      "|    policy_loss        | 3.11      |\n",
      "|    reward             | 1.5082501 |\n",
      "|    std                | 1.51      |\n",
      "|    value_loss         | 1.7       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 585       |\n",
      "|    iterations         | 60400     |\n",
      "|    time_elapsed       | 516       |\n",
      "|    total_timesteps    | 302000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.45     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 70399     |\n",
      "|    policy_loss        | -33.9     |\n",
      "|    reward             | 1.1956091 |\n",
      "|    std                | 1.5       |\n",
      "|    value_loss         | 51.3      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 585         |\n",
      "|    iterations         | 60500       |\n",
      "|    time_elapsed       | 516         |\n",
      "|    total_timesteps    | 302500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.44       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 70499       |\n",
      "|    policy_loss        | -10         |\n",
      "|    reward             | -0.72203016 |\n",
      "|    std                | 1.5         |\n",
      "|    value_loss         | 7.4         |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 585      |\n",
      "|    iterations         | 60600    |\n",
      "|    time_elapsed       | 517      |\n",
      "|    total_timesteps    | 303000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.46    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 70599    |\n",
      "|    policy_loss        | -48.2    |\n",
      "|    reward             | 0.810983 |\n",
      "|    std                | 1.51     |\n",
      "|    value_loss         | 51.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 585      |\n",
      "|    iterations         | 60700    |\n",
      "|    time_elapsed       | 518      |\n",
      "|    total_timesteps    | 303500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.46    |\n",
      "|    explained_variance | -0.502   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 70699    |\n",
      "|    policy_loss        | 116      |\n",
      "|    reward             | 3.813084 |\n",
      "|    std                | 1.51     |\n",
      "|    value_loss         | 488      |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 585         |\n",
      "|    iterations         | 60800       |\n",
      "|    time_elapsed       | 519         |\n",
      "|    total_timesteps    | 304000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.45       |\n",
      "|    explained_variance | 0.00162     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 70799       |\n",
      "|    policy_loss        | 4.49        |\n",
      "|    reward             | -0.51106834 |\n",
      "|    std                | 1.5         |\n",
      "|    value_loss         | 2.06        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 585        |\n",
      "|    iterations         | 60900      |\n",
      "|    time_elapsed       | 520        |\n",
      "|    total_timesteps    | 304500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.43      |\n",
      "|    explained_variance | -0.0776    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 70899      |\n",
      "|    policy_loss        | -27.3      |\n",
      "|    reward             | -0.8219187 |\n",
      "|    std                | 1.49       |\n",
      "|    value_loss         | 37.6       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 585       |\n",
      "|    iterations         | 61000     |\n",
      "|    time_elapsed       | 520       |\n",
      "|    total_timesteps    | 305000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.44     |\n",
      "|    explained_variance | 0.0662    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 70999     |\n",
      "|    policy_loss        | -4.81     |\n",
      "|    reward             | 1.4962788 |\n",
      "|    std                | 1.49      |\n",
      "|    value_loss         | 8.29      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 585      |\n",
      "|    iterations         | 61100    |\n",
      "|    time_elapsed       | 521      |\n",
      "|    total_timesteps    | 305500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.43    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 71099    |\n",
      "|    policy_loss        | 6.47     |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.49     |\n",
      "|    value_loss         | 9.5      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 585       |\n",
      "|    iterations         | 61200     |\n",
      "|    time_elapsed       | 522       |\n",
      "|    total_timesteps    | 306000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.45     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 71199     |\n",
      "|    policy_loss        | -10.9     |\n",
      "|    reward             | 1.4064287 |\n",
      "|    std                | 1.5       |\n",
      "|    value_loss         | 5.64      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 585       |\n",
      "|    iterations         | 61300     |\n",
      "|    time_elapsed       | 523       |\n",
      "|    total_timesteps    | 306500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.44     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 71299     |\n",
      "|    policy_loss        | -8.82     |\n",
      "|    reward             | 1.5665375 |\n",
      "|    std                | 1.5       |\n",
      "|    value_loss         | 12.9      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 586        |\n",
      "|    iterations         | 61400      |\n",
      "|    time_elapsed       | 523        |\n",
      "|    total_timesteps    | 307000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.46      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 71399      |\n",
      "|    policy_loss        | -30.7      |\n",
      "|    reward             | -1.0931203 |\n",
      "|    std                | 1.51       |\n",
      "|    value_loss         | 40.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 585        |\n",
      "|    iterations         | 61500      |\n",
      "|    time_elapsed       | 524        |\n",
      "|    total_timesteps    | 307500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.45      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 71499      |\n",
      "|    policy_loss        | 6.17       |\n",
      "|    reward             | -1.5166004 |\n",
      "|    std                | 1.5        |\n",
      "|    value_loss         | 3.37       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 585        |\n",
      "|    iterations         | 61600      |\n",
      "|    time_elapsed       | 525        |\n",
      "|    total_timesteps    | 308000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.46      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 71599      |\n",
      "|    policy_loss        | 18         |\n",
      "|    reward             | -0.9443582 |\n",
      "|    std                | 1.51       |\n",
      "|    value_loss         | 12.1       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 585        |\n",
      "|    iterations         | 61700      |\n",
      "|    time_elapsed       | 526        |\n",
      "|    total_timesteps    | 308500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.45      |\n",
      "|    explained_variance | 0.526      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 71699      |\n",
      "|    policy_loss        | -4.98      |\n",
      "|    reward             | -5.3389025 |\n",
      "|    std                | 1.5        |\n",
      "|    value_loss         | 2.39       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 586       |\n",
      "|    iterations         | 61800     |\n",
      "|    time_elapsed       | 527       |\n",
      "|    total_timesteps    | 309000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.45     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 71799     |\n",
      "|    policy_loss        | 83.8      |\n",
      "|    reward             | -11.89273 |\n",
      "|    std                | 1.51      |\n",
      "|    value_loss         | 229       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 586       |\n",
      "|    iterations         | 61900     |\n",
      "|    time_elapsed       | 528       |\n",
      "|    total_timesteps    | 309500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.45     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 71899     |\n",
      "|    policy_loss        | 72.4      |\n",
      "|    reward             | -19.45177 |\n",
      "|    std                | 1.5       |\n",
      "|    value_loss         | 795       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 586        |\n",
      "|    iterations         | 62000      |\n",
      "|    time_elapsed       | 528        |\n",
      "|    total_timesteps    | 310000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.42      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 71999      |\n",
      "|    policy_loss        | 3.95       |\n",
      "|    reward             | 0.03898714 |\n",
      "|    std                | 1.49       |\n",
      "|    value_loss         | 1.05       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 586         |\n",
      "|    iterations         | 62100       |\n",
      "|    time_elapsed       | 529         |\n",
      "|    total_timesteps    | 310500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.42       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 72099       |\n",
      "|    policy_loss        | -21.1       |\n",
      "|    reward             | -0.42898852 |\n",
      "|    std                | 1.49        |\n",
      "|    value_loss         | 18.8        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 586        |\n",
      "|    iterations         | 62200      |\n",
      "|    time_elapsed       | 530        |\n",
      "|    total_timesteps    | 311000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.43      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 72199      |\n",
      "|    policy_loss        | -9.31      |\n",
      "|    reward             | 0.03002208 |\n",
      "|    std                | 1.5        |\n",
      "|    value_loss         | 10.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 586        |\n",
      "|    iterations         | 62300      |\n",
      "|    time_elapsed       | 531        |\n",
      "|    total_timesteps    | 311500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.44      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 72299      |\n",
      "|    policy_loss        | 16.1       |\n",
      "|    reward             | -3.6100974 |\n",
      "|    std                | 1.5        |\n",
      "|    value_loss         | 11         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 586        |\n",
      "|    iterations         | 62400      |\n",
      "|    time_elapsed       | 532        |\n",
      "|    total_timesteps    | 312000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.44      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 72399      |\n",
      "|    policy_loss        | 20.4       |\n",
      "|    reward             | -1.3371077 |\n",
      "|    std                | 1.49       |\n",
      "|    value_loss         | 42.8       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 586         |\n",
      "|    iterations         | 62500       |\n",
      "|    time_elapsed       | 533         |\n",
      "|    total_timesteps    | 312500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.46       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 72499       |\n",
      "|    policy_loss        | 0.807       |\n",
      "|    reward             | -0.11446997 |\n",
      "|    std                | 1.51        |\n",
      "|    value_loss         | 0.0733      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 586       |\n",
      "|    iterations         | 62600     |\n",
      "|    time_elapsed       | 533       |\n",
      "|    total_timesteps    | 313000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.47     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 72599     |\n",
      "|    policy_loss        | -4.11     |\n",
      "|    reward             | 0.8469879 |\n",
      "|    std                | 1.51      |\n",
      "|    value_loss         | 2.17      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 586        |\n",
      "|    iterations         | 62700      |\n",
      "|    time_elapsed       | 534        |\n",
      "|    total_timesteps    | 313500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.46      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 72699      |\n",
      "|    policy_loss        | 2.08       |\n",
      "|    reward             | -0.6917354 |\n",
      "|    std                | 1.51       |\n",
      "|    value_loss         | 1.03       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 586        |\n",
      "|    iterations         | 62800      |\n",
      "|    time_elapsed       | 535        |\n",
      "|    total_timesteps    | 314000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.47      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 72799      |\n",
      "|    policy_loss        | -21.6      |\n",
      "|    reward             | -0.5696989 |\n",
      "|    std                | 1.52       |\n",
      "|    value_loss         | 18.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 586        |\n",
      "|    iterations         | 62900      |\n",
      "|    time_elapsed       | 536        |\n",
      "|    total_timesteps    | 314500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.46      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 72899      |\n",
      "|    policy_loss        | -14.6      |\n",
      "|    reward             | 0.24218987 |\n",
      "|    std                | 1.51       |\n",
      "|    value_loss         | 6.29       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 586       |\n",
      "|    iterations         | 63000     |\n",
      "|    time_elapsed       | 536       |\n",
      "|    total_timesteps    | 315000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.45     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 72999     |\n",
      "|    policy_loss        | 63.5      |\n",
      "|    reward             | 2.4809802 |\n",
      "|    std                | 1.5       |\n",
      "|    value_loss         | 183       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 586        |\n",
      "|    iterations         | 63100      |\n",
      "|    time_elapsed       | 537        |\n",
      "|    total_timesteps    | 315500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.45      |\n",
      "|    explained_variance | 0.0056     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 73099      |\n",
      "|    policy_loss        | -0.747     |\n",
      "|    reward             | 0.38209945 |\n",
      "|    std                | 1.5        |\n",
      "|    value_loss         | 1.21       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 586       |\n",
      "|    iterations         | 63200     |\n",
      "|    time_elapsed       | 538       |\n",
      "|    total_timesteps    | 316000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.45     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 73199     |\n",
      "|    policy_loss        | -2.74     |\n",
      "|    reward             | -4.908402 |\n",
      "|    std                | 1.5       |\n",
      "|    value_loss         | 11.5      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 586         |\n",
      "|    iterations         | 63300       |\n",
      "|    time_elapsed       | 539         |\n",
      "|    total_timesteps    | 316500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.45       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 73299       |\n",
      "|    policy_loss        | -0.336      |\n",
      "|    reward             | -0.19802928 |\n",
      "|    std                | 1.51        |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 586       |\n",
      "|    iterations         | 63400     |\n",
      "|    time_elapsed       | 540       |\n",
      "|    total_timesteps    | 317000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.45     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 73399     |\n",
      "|    policy_loss        | 4.18      |\n",
      "|    reward             | 1.3936015 |\n",
      "|    std                | 1.51      |\n",
      "|    value_loss         | 1.12      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 587        |\n",
      "|    iterations         | 63500      |\n",
      "|    time_elapsed       | 540        |\n",
      "|    total_timesteps    | 317500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.43      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 73499      |\n",
      "|    policy_loss        | -17.5      |\n",
      "|    reward             | -1.8571169 |\n",
      "|    std                | 1.5        |\n",
      "|    value_loss         | 19.7       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 587       |\n",
      "|    iterations         | 63600     |\n",
      "|    time_elapsed       | 541       |\n",
      "|    total_timesteps    | 318000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.44     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 73599     |\n",
      "|    policy_loss        | 43.9      |\n",
      "|    reward             | -5.879576 |\n",
      "|    std                | 1.5       |\n",
      "|    value_loss         | 87.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 587       |\n",
      "|    iterations         | 63700     |\n",
      "|    time_elapsed       | 542       |\n",
      "|    total_timesteps    | 318500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.47     |\n",
      "|    explained_variance | -0.00704  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 73699     |\n",
      "|    policy_loss        | -38.8     |\n",
      "|    reward             | -2.706791 |\n",
      "|    std                | 1.52      |\n",
      "|    value_loss         | 54.7      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 587         |\n",
      "|    iterations         | 63800       |\n",
      "|    time_elapsed       | 543         |\n",
      "|    total_timesteps    | 319000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.47       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 73799       |\n",
      "|    policy_loss        | -0.107      |\n",
      "|    reward             | -0.39971882 |\n",
      "|    std                | 1.52        |\n",
      "|    value_loss         | 0.0234      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 587        |\n",
      "|    iterations         | 63900      |\n",
      "|    time_elapsed       | 544        |\n",
      "|    total_timesteps    | 319500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.47      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 73899      |\n",
      "|    policy_loss        | -30.9      |\n",
      "|    reward             | -1.3980987 |\n",
      "|    std                | 1.52       |\n",
      "|    value_loss         | 29.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 587       |\n",
      "|    iterations         | 64000     |\n",
      "|    time_elapsed       | 544       |\n",
      "|    total_timesteps    | 320000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.48     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 73999     |\n",
      "|    policy_loss        | -65.8     |\n",
      "|    reward             | 5.9554453 |\n",
      "|    std                | 1.52      |\n",
      "|    value_loss         | 171       |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 587          |\n",
      "|    iterations         | 64100        |\n",
      "|    time_elapsed       | 545          |\n",
      "|    total_timesteps    | 320500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.49        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 74099        |\n",
      "|    policy_loss        | 6.98         |\n",
      "|    reward             | -0.047615785 |\n",
      "|    std                | 1.53         |\n",
      "|    value_loss         | 1.81         |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 587      |\n",
      "|    iterations         | 64200    |\n",
      "|    time_elapsed       | 546      |\n",
      "|    total_timesteps    | 321000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.48    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 74199    |\n",
      "|    policy_loss        | 28.1     |\n",
      "|    reward             | 1.426736 |\n",
      "|    std                | 1.52     |\n",
      "|    value_loss         | 39.2     |\n",
      "------------------------------------\n",
      "day: 2892, episode: 130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8446836.78\n",
      "total_reward: 7446836.78\n",
      "total_cost: 2973.85\n",
      "total_trades: 5785\n",
      "Sharpe: 0.972\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 587         |\n",
      "|    iterations         | 64300       |\n",
      "|    time_elapsed       | 547         |\n",
      "|    total_timesteps    | 321500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.48       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 74299       |\n",
      "|    policy_loss        | -22.6       |\n",
      "|    reward             | -0.14908893 |\n",
      "|    std                | 1.52        |\n",
      "|    value_loss         | 22.5        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 587         |\n",
      "|    iterations         | 64400       |\n",
      "|    time_elapsed       | 548         |\n",
      "|    total_timesteps    | 322000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.48       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 74399       |\n",
      "|    policy_loss        | 19          |\n",
      "|    reward             | 0.051218305 |\n",
      "|    std                | 1.52        |\n",
      "|    value_loss         | 19.1        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 587        |\n",
      "|    iterations         | 64500      |\n",
      "|    time_elapsed       | 548        |\n",
      "|    total_timesteps    | 322500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.48      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 74499      |\n",
      "|    policy_loss        | 7.2        |\n",
      "|    reward             | -1.3854135 |\n",
      "|    std                | 1.52       |\n",
      "|    value_loss         | 3.18       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 587         |\n",
      "|    iterations         | 64600       |\n",
      "|    time_elapsed       | 549         |\n",
      "|    total_timesteps    | 323000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.49       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 74599       |\n",
      "|    policy_loss        | -12.3       |\n",
      "|    reward             | -0.47583207 |\n",
      "|    std                | 1.53        |\n",
      "|    value_loss         | 7.39        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 587       |\n",
      "|    iterations         | 64700     |\n",
      "|    time_elapsed       | 550       |\n",
      "|    total_timesteps    | 323500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.49     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 74699     |\n",
      "|    policy_loss        | 41.6      |\n",
      "|    reward             | -2.036156 |\n",
      "|    std                | 1.53      |\n",
      "|    value_loss         | 95.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 587       |\n",
      "|    iterations         | 64800     |\n",
      "|    time_elapsed       | 551       |\n",
      "|    total_timesteps    | 324000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.48     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 74799     |\n",
      "|    policy_loss        | 67.1      |\n",
      "|    reward             | 6.5204816 |\n",
      "|    std                | 1.52      |\n",
      "|    value_loss         | 131       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 587       |\n",
      "|    iterations         | 64900     |\n",
      "|    time_elapsed       | 552       |\n",
      "|    total_timesteps    | 324500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.49     |\n",
      "|    explained_variance | 0.764     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 74899     |\n",
      "|    policy_loss        | -3.35     |\n",
      "|    reward             | 0.5178418 |\n",
      "|    std                | 1.53      |\n",
      "|    value_loss         | 0.853     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 587        |\n",
      "|    iterations         | 65000      |\n",
      "|    time_elapsed       | 553        |\n",
      "|    total_timesteps    | 325000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.48      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 74999      |\n",
      "|    policy_loss        | 4.55       |\n",
      "|    reward             | -2.1291525 |\n",
      "|    std                | 1.52       |\n",
      "|    value_loss         | 1.03       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 587       |\n",
      "|    iterations         | 65100     |\n",
      "|    time_elapsed       | 553       |\n",
      "|    total_timesteps    | 325500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.49     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 75099     |\n",
      "|    policy_loss        | 5.19      |\n",
      "|    reward             | -2.170858 |\n",
      "|    std                | 1.52      |\n",
      "|    value_loss         | 4.33      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 587       |\n",
      "|    iterations         | 65200     |\n",
      "|    time_elapsed       | 554       |\n",
      "|    total_timesteps    | 326000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.49     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 75199     |\n",
      "|    policy_loss        | -35.9     |\n",
      "|    reward             | 5.9896603 |\n",
      "|    std                | 1.53      |\n",
      "|    value_loss         | 67.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 587        |\n",
      "|    iterations         | 65300      |\n",
      "|    time_elapsed       | 555        |\n",
      "|    total_timesteps    | 326500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.47      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 75299      |\n",
      "|    policy_loss        | 53         |\n",
      "|    reward             | 0.43844938 |\n",
      "|    std                | 1.52       |\n",
      "|    value_loss         | 154        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 587         |\n",
      "|    iterations         | 65400       |\n",
      "|    time_elapsed       | 556         |\n",
      "|    total_timesteps    | 327000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.49       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 75399       |\n",
      "|    policy_loss        | -7.72       |\n",
      "|    reward             | -0.37675804 |\n",
      "|    std                | 1.53        |\n",
      "|    value_loss         | 2.29        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 587          |\n",
      "|    iterations         | 65500        |\n",
      "|    time_elapsed       | 557          |\n",
      "|    total_timesteps    | 327500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.5         |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 75499        |\n",
      "|    policy_loss        | -11.4        |\n",
      "|    reward             | -0.089954406 |\n",
      "|    std                | 1.53         |\n",
      "|    value_loss         | 5.39         |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 587       |\n",
      "|    iterations         | 65600     |\n",
      "|    time_elapsed       | 557       |\n",
      "|    total_timesteps    | 328000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.52     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 75599     |\n",
      "|    policy_loss        | 33.8      |\n",
      "|    reward             | 0.5420016 |\n",
      "|    std                | 1.54      |\n",
      "|    value_loss         | 43.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 587       |\n",
      "|    iterations         | 65700     |\n",
      "|    time_elapsed       | 558       |\n",
      "|    total_timesteps    | 328500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.52     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 75699     |\n",
      "|    policy_loss        | 24        |\n",
      "|    reward             | -2.652233 |\n",
      "|    std                | 1.55      |\n",
      "|    value_loss         | 29.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 587       |\n",
      "|    iterations         | 65800     |\n",
      "|    time_elapsed       | 559       |\n",
      "|    total_timesteps    | 329000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.52     |\n",
      "|    explained_variance | -0.659    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 75799     |\n",
      "|    policy_loss        | 0.434     |\n",
      "|    reward             | 1.6964873 |\n",
      "|    std                | 1.54      |\n",
      "|    value_loss         | 2.79      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 588      |\n",
      "|    iterations         | 65900    |\n",
      "|    time_elapsed       | 560      |\n",
      "|    total_timesteps    | 329500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.51    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 75899    |\n",
      "|    policy_loss        | 25.6     |\n",
      "|    reward             | 1.413469 |\n",
      "|    std                | 1.54     |\n",
      "|    value_loss         | 21.9     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 66000      |\n",
      "|    time_elapsed       | 561        |\n",
      "|    total_timesteps    | 330000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.51      |\n",
      "|    explained_variance | -0.0256    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 75999      |\n",
      "|    policy_loss        | 12.5       |\n",
      "|    reward             | 0.78524977 |\n",
      "|    std                | 1.54       |\n",
      "|    value_loss         | 5.42       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 66100     |\n",
      "|    time_elapsed       | 561       |\n",
      "|    total_timesteps    | 330500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.52     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 76099     |\n",
      "|    policy_loss        | -21.9     |\n",
      "|    reward             | 3.8838308 |\n",
      "|    std                | 1.54      |\n",
      "|    value_loss         | 23        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 66200      |\n",
      "|    time_elapsed       | 562        |\n",
      "|    total_timesteps    | 331000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.53      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 76199      |\n",
      "|    policy_loss        | -7.6       |\n",
      "|    reward             | -2.7228687 |\n",
      "|    std                | 1.54       |\n",
      "|    value_loss         | 1.76       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 588         |\n",
      "|    iterations         | 66300       |\n",
      "|    time_elapsed       | 563         |\n",
      "|    total_timesteps    | 331500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.55       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 76299       |\n",
      "|    policy_loss        | -5.78       |\n",
      "|    reward             | 0.124735385 |\n",
      "|    std                | 1.55        |\n",
      "|    value_loss         | 4.24        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 66400     |\n",
      "|    time_elapsed       | 564       |\n",
      "|    total_timesteps    | 332000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.54     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 76399     |\n",
      "|    policy_loss        | -0.728    |\n",
      "|    reward             | 0.5498441 |\n",
      "|    std                | 1.55      |\n",
      "|    value_loss         | 0.421     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 588         |\n",
      "|    iterations         | 66500       |\n",
      "|    time_elapsed       | 565         |\n",
      "|    total_timesteps    | 332500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.53       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 76499       |\n",
      "|    policy_loss        | -16.8       |\n",
      "|    reward             | -0.53022534 |\n",
      "|    std                | 1.55        |\n",
      "|    value_loss         | 10.6        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 66600      |\n",
      "|    time_elapsed       | 566        |\n",
      "|    total_timesteps    | 333000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.54      |\n",
      "|    explained_variance | 0.000605   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 76599      |\n",
      "|    policy_loss        | 3.89       |\n",
      "|    reward             | 0.20688593 |\n",
      "|    std                | 1.55       |\n",
      "|    value_loss         | 1.34       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 66700      |\n",
      "|    time_elapsed       | 567        |\n",
      "|    total_timesteps    | 333500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.54      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 76699      |\n",
      "|    policy_loss        | -4.38      |\n",
      "|    reward             | 0.83837587 |\n",
      "|    std                | 1.55       |\n",
      "|    value_loss         | 1.98       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 66800      |\n",
      "|    time_elapsed       | 567        |\n",
      "|    total_timesteps    | 334000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.55      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 76799      |\n",
      "|    policy_loss        | 8.58       |\n",
      "|    reward             | 0.03710248 |\n",
      "|    std                | 1.55       |\n",
      "|    value_loss         | 3.06       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 588         |\n",
      "|    iterations         | 66900       |\n",
      "|    time_elapsed       | 568         |\n",
      "|    total_timesteps    | 334500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.55       |\n",
      "|    explained_variance | 0.00011     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 76899       |\n",
      "|    policy_loss        | -21.6       |\n",
      "|    reward             | -0.18342185 |\n",
      "|    std                | 1.55        |\n",
      "|    value_loss         | 16.8        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 67000     |\n",
      "|    time_elapsed       | 569       |\n",
      "|    total_timesteps    | 335000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.54     |\n",
      "|    explained_variance | -0.00069  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 76999     |\n",
      "|    policy_loss        | -16.1     |\n",
      "|    reward             | -3.617308 |\n",
      "|    std                | 1.54      |\n",
      "|    value_loss         | 11.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 67100     |\n",
      "|    time_elapsed       | 570       |\n",
      "|    total_timesteps    | 335500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.54     |\n",
      "|    explained_variance | 0.000282  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 77099     |\n",
      "|    policy_loss        | 9.83      |\n",
      "|    reward             | 1.6546812 |\n",
      "|    std                | 1.55      |\n",
      "|    value_loss         | 6.59      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 67200      |\n",
      "|    time_elapsed       | 571        |\n",
      "|    total_timesteps    | 336000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.54      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 77199      |\n",
      "|    policy_loss        | -17.2      |\n",
      "|    reward             | -0.6969344 |\n",
      "|    std                | 1.55       |\n",
      "|    value_loss         | 11.1       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 67300      |\n",
      "|    time_elapsed       | 572        |\n",
      "|    total_timesteps    | 336500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.54      |\n",
      "|    explained_variance | -0.00572   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 77299      |\n",
      "|    policy_loss        | 16.7       |\n",
      "|    reward             | 0.19001639 |\n",
      "|    std                | 1.55       |\n",
      "|    value_loss         | 9.04       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 67400     |\n",
      "|    time_elapsed       | 572       |\n",
      "|    total_timesteps    | 337000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.54     |\n",
      "|    explained_variance | -5.87e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 77399     |\n",
      "|    policy_loss        | -21.9     |\n",
      "|    reward             | 1.3034499 |\n",
      "|    std                | 1.55      |\n",
      "|    value_loss         | 19.5      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 67500      |\n",
      "|    time_elapsed       | 573        |\n",
      "|    total_timesteps    | 337500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.53      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 77499      |\n",
      "|    policy_loss        | -3.15      |\n",
      "|    reward             | 0.09613123 |\n",
      "|    std                | 1.55       |\n",
      "|    value_loss         | 1.34       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 67600     |\n",
      "|    time_elapsed       | 574       |\n",
      "|    total_timesteps    | 338000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.53     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 77599     |\n",
      "|    policy_loss        | 11.4      |\n",
      "|    reward             | 1.3349793 |\n",
      "|    std                | 1.54      |\n",
      "|    value_loss         | 11.6      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 588         |\n",
      "|    iterations         | 67700       |\n",
      "|    time_elapsed       | 575         |\n",
      "|    total_timesteps    | 338500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.54       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 77699       |\n",
      "|    policy_loss        | -0.513      |\n",
      "|    reward             | -0.16025072 |\n",
      "|    std                | 1.55        |\n",
      "|    value_loss         | 0.0626      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 67800     |\n",
      "|    time_elapsed       | 576       |\n",
      "|    total_timesteps    | 339000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.55     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 77799     |\n",
      "|    policy_loss        | 10.1      |\n",
      "|    reward             | 1.5407101 |\n",
      "|    std                | 1.56      |\n",
      "|    value_loss         | 3.11      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 67900     |\n",
      "|    time_elapsed       | 576       |\n",
      "|    total_timesteps    | 339500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.55     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 77899     |\n",
      "|    policy_loss        | -3.5      |\n",
      "|    reward             | 1.2427479 |\n",
      "|    std                | 1.56      |\n",
      "|    value_loss         | 0.758     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 68000      |\n",
      "|    time_elapsed       | 577        |\n",
      "|    total_timesteps    | 340000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.55      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 77999      |\n",
      "|    policy_loss        | 2.28       |\n",
      "|    reward             | -1.6289176 |\n",
      "|    std                | 1.56       |\n",
      "|    value_loss         | 9.05       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 68100     |\n",
      "|    time_elapsed       | 578       |\n",
      "|    total_timesteps    | 340500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.53     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 78099     |\n",
      "|    policy_loss        | -1.78     |\n",
      "|    reward             | -2.035099 |\n",
      "|    std                | 1.55      |\n",
      "|    value_loss         | 1.11      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 68200     |\n",
      "|    time_elapsed       | 579       |\n",
      "|    total_timesteps    | 341000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.53     |\n",
      "|    explained_variance | 0.00162   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 78199     |\n",
      "|    policy_loss        | 14.4      |\n",
      "|    reward             | 1.0992032 |\n",
      "|    std                | 1.55      |\n",
      "|    value_loss         | 35.8      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 588         |\n",
      "|    iterations         | 68300       |\n",
      "|    time_elapsed       | 580         |\n",
      "|    total_timesteps    | 341500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.54       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 78299       |\n",
      "|    policy_loss        | 0.611       |\n",
      "|    reward             | -0.17840102 |\n",
      "|    std                | 1.55        |\n",
      "|    value_loss         | 0.484       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 68400     |\n",
      "|    time_elapsed       | 581       |\n",
      "|    total_timesteps    | 342000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.54     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 78399     |\n",
      "|    policy_loss        | 12.1      |\n",
      "|    reward             | 2.5818746 |\n",
      "|    std                | 1.56      |\n",
      "|    value_loss         | 5.85      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 68500     |\n",
      "|    time_elapsed       | 581       |\n",
      "|    total_timesteps    | 342500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.54     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 78499     |\n",
      "|    policy_loss        | 8.72      |\n",
      "|    reward             | 1.2383233 |\n",
      "|    std                | 1.56      |\n",
      "|    value_loss         | 3.25      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 68600      |\n",
      "|    time_elapsed       | 582        |\n",
      "|    total_timesteps    | 343000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.58      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 78599      |\n",
      "|    policy_loss        | -5.44      |\n",
      "|    reward             | -1.7313905 |\n",
      "|    std                | 1.58       |\n",
      "|    value_loss         | 3.3        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 588         |\n",
      "|    iterations         | 68700       |\n",
      "|    time_elapsed       | 583         |\n",
      "|    total_timesteps    | 343500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.59       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 78699       |\n",
      "|    policy_loss        | -6.61       |\n",
      "|    reward             | -0.76391554 |\n",
      "|    std                | 1.58        |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 68800     |\n",
      "|    time_elapsed       | 584       |\n",
      "|    total_timesteps    | 344000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.6      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 78799     |\n",
      "|    policy_loss        | 17.1      |\n",
      "|    reward             | 1.0692635 |\n",
      "|    std                | 1.59      |\n",
      "|    value_loss         | 19.9      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 588         |\n",
      "|    iterations         | 68900       |\n",
      "|    time_elapsed       | 585         |\n",
      "|    total_timesteps    | 344500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.59       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 78899       |\n",
      "|    policy_loss        | -12.1       |\n",
      "|    reward             | -0.12088955 |\n",
      "|    std                | 1.58        |\n",
      "|    value_loss         | 6.39        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 69000      |\n",
      "|    time_elapsed       | 585        |\n",
      "|    total_timesteps    | 345000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.6       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 78999      |\n",
      "|    policy_loss        | -34.9      |\n",
      "|    reward             | -1.1190132 |\n",
      "|    std                | 1.58       |\n",
      "|    value_loss         | 37.4       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 69100     |\n",
      "|    time_elapsed       | 586       |\n",
      "|    total_timesteps    | 345500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.6      |\n",
      "|    explained_variance | 0.000103  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 79099     |\n",
      "|    policy_loss        | 1.49      |\n",
      "|    reward             | -2.036265 |\n",
      "|    std                | 1.59      |\n",
      "|    value_loss         | 0.324     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 69200     |\n",
      "|    time_elapsed       | 587       |\n",
      "|    total_timesteps    | 346000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.6      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 79199     |\n",
      "|    policy_loss        | -21.5     |\n",
      "|    reward             | 0.9534348 |\n",
      "|    std                | 1.59      |\n",
      "|    value_loss         | 24.4      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 69300      |\n",
      "|    time_elapsed       | 588        |\n",
      "|    total_timesteps    | 346500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.58      |\n",
      "|    explained_variance | -0.000405  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 79299      |\n",
      "|    policy_loss        | -7.41      |\n",
      "|    reward             | 0.62568295 |\n",
      "|    std                | 1.58       |\n",
      "|    value_loss         | 2.35       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 69400      |\n",
      "|    time_elapsed       | 589        |\n",
      "|    total_timesteps    | 347000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.56      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 79399      |\n",
      "|    policy_loss        | 17         |\n",
      "|    reward             | -1.8252403 |\n",
      "|    std                | 1.57       |\n",
      "|    value_loss         | 13.6       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 69500      |\n",
      "|    time_elapsed       | 590        |\n",
      "|    total_timesteps    | 347500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.55      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 79499      |\n",
      "|    policy_loss        | -12.1      |\n",
      "|    reward             | 0.40428075 |\n",
      "|    std                | 1.57       |\n",
      "|    value_loss         | 6.19       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 69600      |\n",
      "|    time_elapsed       | 590        |\n",
      "|    total_timesteps    | 348000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.56      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 79599      |\n",
      "|    policy_loss        | 26.6       |\n",
      "|    reward             | -0.6965606 |\n",
      "|    std                | 1.57       |\n",
      "|    value_loss         | 17.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 69700      |\n",
      "|    time_elapsed       | 591        |\n",
      "|    total_timesteps    | 348500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.58      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 79699      |\n",
      "|    policy_loss        | -12.2      |\n",
      "|    reward             | -2.9968555 |\n",
      "|    std                | 1.58       |\n",
      "|    value_loss         | 10.7       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 69800      |\n",
      "|    time_elapsed       | 592        |\n",
      "|    total_timesteps    | 349000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.59      |\n",
      "|    explained_variance | -0.047     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 79799      |\n",
      "|    policy_loss        | -30.5      |\n",
      "|    reward             | -0.8409862 |\n",
      "|    std                | 1.58       |\n",
      "|    value_loss         | 26.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 69900     |\n",
      "|    time_elapsed       | 593       |\n",
      "|    total_timesteps    | 349500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.59     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 79899     |\n",
      "|    policy_loss        | 19.3      |\n",
      "|    reward             | -4.367807 |\n",
      "|    std                | 1.58      |\n",
      "|    value_loss         | 29.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 589      |\n",
      "|    iterations         | 70000    |\n",
      "|    time_elapsed       | 594      |\n",
      "|    total_timesteps    | 350000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.58    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 79999    |\n",
      "|    policy_loss        | 93.3     |\n",
      "|    reward             | 4.560148 |\n",
      "|    std                | 1.58     |\n",
      "|    value_loss         | 543      |\n",
      "------------------------------------\n",
      "day: 2892, episode: 140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4417623.48\n",
      "total_reward: 3417623.48\n",
      "total_cost: 8842.94\n",
      "total_trades: 5886\n",
      "Sharpe: 0.740\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 70100      |\n",
      "|    time_elapsed       | 594        |\n",
      "|    total_timesteps    | 350500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.58      |\n",
      "|    explained_variance | 0.00234    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 80099      |\n",
      "|    policy_loss        | 7.39       |\n",
      "|    reward             | 0.44798297 |\n",
      "|    std                | 1.58       |\n",
      "|    value_loss         | 2.44       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 70200      |\n",
      "|    time_elapsed       | 595        |\n",
      "|    total_timesteps    | 351000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.58      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 80199      |\n",
      "|    policy_loss        | -6.3       |\n",
      "|    reward             | 0.24061678 |\n",
      "|    std                | 1.57       |\n",
      "|    value_loss         | 4.23       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 589         |\n",
      "|    iterations         | 70300       |\n",
      "|    time_elapsed       | 596         |\n",
      "|    total_timesteps    | 351500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.6        |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 80299       |\n",
      "|    policy_loss        | -27         |\n",
      "|    reward             | -0.46543917 |\n",
      "|    std                | 1.58        |\n",
      "|    value_loss         | 27.7        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 589      |\n",
      "|    iterations         | 70400    |\n",
      "|    time_elapsed       | 597      |\n",
      "|    total_timesteps    | 352000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.61    |\n",
      "|    explained_variance | 0.00121  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 80399    |\n",
      "|    policy_loss        | -4.04    |\n",
      "|    reward             | 4.36709  |\n",
      "|    std                | 1.59     |\n",
      "|    value_loss         | 1.56     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 70500     |\n",
      "|    time_elapsed       | 598       |\n",
      "|    total_timesteps    | 352500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.63     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 80499     |\n",
      "|    policy_loss        | 40.1      |\n",
      "|    reward             | 1.7465501 |\n",
      "|    std                | 1.6       |\n",
      "|    value_loss         | 70.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 70600     |\n",
      "|    time_elapsed       | 599       |\n",
      "|    total_timesteps    | 353000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.62     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 80599     |\n",
      "|    policy_loss        | 2.77      |\n",
      "|    reward             | 2.1758084 |\n",
      "|    std                | 1.59      |\n",
      "|    value_loss         | 0.824     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 70700      |\n",
      "|    time_elapsed       | 599        |\n",
      "|    total_timesteps    | 353500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.64      |\n",
      "|    explained_variance | -2.53e-05  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 80699      |\n",
      "|    policy_loss        | 16         |\n",
      "|    reward             | -5.3508716 |\n",
      "|    std                | 1.6        |\n",
      "|    value_loss         | 8.25       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 70800     |\n",
      "|    time_elapsed       | 600       |\n",
      "|    total_timesteps    | 354000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.65     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 80799     |\n",
      "|    policy_loss        | 15.7      |\n",
      "|    reward             | 1.1518984 |\n",
      "|    std                | 1.61      |\n",
      "|    value_loss         | 13.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 70900     |\n",
      "|    time_elapsed       | 601       |\n",
      "|    total_timesteps    | 354500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.64     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 80899     |\n",
      "|    policy_loss        | -13.5     |\n",
      "|    reward             | 2.6322243 |\n",
      "|    std                | 1.61      |\n",
      "|    value_loss         | 7.23      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 71000     |\n",
      "|    time_elapsed       | 602       |\n",
      "|    total_timesteps    | 355000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.62     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 80999     |\n",
      "|    policy_loss        | 2.12      |\n",
      "|    reward             | -2.877408 |\n",
      "|    std                | 1.6       |\n",
      "|    value_loss         | 0.477     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 589         |\n",
      "|    iterations         | 71100       |\n",
      "|    time_elapsed       | 603         |\n",
      "|    total_timesteps    | 355500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.61       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 81099       |\n",
      "|    policy_loss        | 4.75        |\n",
      "|    reward             | -0.91059864 |\n",
      "|    std                | 1.59        |\n",
      "|    value_loss         | 3.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 589         |\n",
      "|    iterations         | 71200       |\n",
      "|    time_elapsed       | 603         |\n",
      "|    total_timesteps    | 356000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.6        |\n",
      "|    explained_variance | 0.00061     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 81199       |\n",
      "|    policy_loss        | -11.8       |\n",
      "|    reward             | -0.22073153 |\n",
      "|    std                | 1.59        |\n",
      "|    value_loss         | 5.13        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 71300      |\n",
      "|    time_elapsed       | 604        |\n",
      "|    total_timesteps    | 356500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.59      |\n",
      "|    explained_variance | 1.69e-05   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 81299      |\n",
      "|    policy_loss        | -49.1      |\n",
      "|    reward             | 0.07248174 |\n",
      "|    std                | 1.58       |\n",
      "|    value_loss         | 105        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 71400      |\n",
      "|    time_elapsed       | 605        |\n",
      "|    total_timesteps    | 357000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.58      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 81399      |\n",
      "|    policy_loss        | -22.1      |\n",
      "|    reward             | -0.5176074 |\n",
      "|    std                | 1.58       |\n",
      "|    value_loss         | 17.4       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 71500     |\n",
      "|    time_elapsed       | 606       |\n",
      "|    total_timesteps    | 357500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.58     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 81499     |\n",
      "|    policy_loss        | -7.15     |\n",
      "|    reward             | 2.2861018 |\n",
      "|    std                | 1.58      |\n",
      "|    value_loss         | 3.73      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 71600      |\n",
      "|    time_elapsed       | 607        |\n",
      "|    total_timesteps    | 358000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.57      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 81599      |\n",
      "|    policy_loss        | -13.8      |\n",
      "|    reward             | 0.34326866 |\n",
      "|    std                | 1.57       |\n",
      "|    value_loss         | 9.42       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 71700      |\n",
      "|    time_elapsed       | 608        |\n",
      "|    total_timesteps    | 358500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.56      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 81699      |\n",
      "|    policy_loss        | 29.8       |\n",
      "|    reward             | -7.2466493 |\n",
      "|    std                | 1.57       |\n",
      "|    value_loss         | 48         |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 71800     |\n",
      "|    time_elapsed       | 608       |\n",
      "|    total_timesteps    | 359000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.57     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 81799     |\n",
      "|    policy_loss        | -10.5     |\n",
      "|    reward             | 0.6456351 |\n",
      "|    std                | 1.58      |\n",
      "|    value_loss         | 4.79      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 589      |\n",
      "|    iterations         | 71900    |\n",
      "|    time_elapsed       | 609      |\n",
      "|    total_timesteps    | 359500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.6     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 81899    |\n",
      "|    policy_loss        | -9.26    |\n",
      "|    reward             | 8.46218  |\n",
      "|    std                | 1.59     |\n",
      "|    value_loss         | 4.55     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 72000     |\n",
      "|    time_elapsed       | 610       |\n",
      "|    total_timesteps    | 360000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.59     |\n",
      "|    explained_variance | 0.000111  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 81999     |\n",
      "|    policy_loss        | -8.01     |\n",
      "|    reward             | 1.0378971 |\n",
      "|    std                | 1.59      |\n",
      "|    value_loss         | 3.1       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 72100      |\n",
      "|    time_elapsed       | 611        |\n",
      "|    total_timesteps    | 360500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.6       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 82099      |\n",
      "|    policy_loss        | -18.3      |\n",
      "|    reward             | 0.47396025 |\n",
      "|    std                | 1.59       |\n",
      "|    value_loss         | 16.6       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 72200     |\n",
      "|    time_elapsed       | 612       |\n",
      "|    total_timesteps    | 361000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.6      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 82199     |\n",
      "|    policy_loss        | 6.13      |\n",
      "|    reward             | 2.3732712 |\n",
      "|    std                | 1.59      |\n",
      "|    value_loss         | 1.77      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 589      |\n",
      "|    iterations         | 72300    |\n",
      "|    time_elapsed       | 613      |\n",
      "|    total_timesteps    | 361500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.58    |\n",
      "|    explained_variance | 0.000139 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 82299    |\n",
      "|    policy_loss        | 8.8      |\n",
      "|    reward             | 5.863525 |\n",
      "|    std                | 1.58     |\n",
      "|    value_loss         | 8.87     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 72400      |\n",
      "|    time_elapsed       | 614        |\n",
      "|    total_timesteps    | 362000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.58      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 82399      |\n",
      "|    policy_loss        | -8.43      |\n",
      "|    reward             | -1.6276729 |\n",
      "|    std                | 1.58       |\n",
      "|    value_loss         | 3.06       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 72500     |\n",
      "|    time_elapsed       | 614       |\n",
      "|    total_timesteps    | 362500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.57     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 82499     |\n",
      "|    policy_loss        | 24.9      |\n",
      "|    reward             | 1.0638492 |\n",
      "|    std                | 1.58      |\n",
      "|    value_loss         | 21.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 72600      |\n",
      "|    time_elapsed       | 615        |\n",
      "|    total_timesteps    | 363000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.56      |\n",
      "|    explained_variance | 0.000218   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 82599      |\n",
      "|    policy_loss        | -7.65      |\n",
      "|    reward             | -0.8024144 |\n",
      "|    std                | 1.57       |\n",
      "|    value_loss         | 7.54       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 589         |\n",
      "|    iterations         | 72700       |\n",
      "|    time_elapsed       | 616         |\n",
      "|    total_timesteps    | 363500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.57       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 82699       |\n",
      "|    policy_loss        | 0.792       |\n",
      "|    reward             | -0.54528236 |\n",
      "|    std                | 1.58        |\n",
      "|    value_loss         | 0.467       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 589         |\n",
      "|    iterations         | 72800       |\n",
      "|    time_elapsed       | 617         |\n",
      "|    total_timesteps    | 364000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.55       |\n",
      "|    explained_variance | 0.000309    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 82799       |\n",
      "|    policy_loss        | 25.3        |\n",
      "|    reward             | -0.42929822 |\n",
      "|    std                | 1.57        |\n",
      "|    value_loss         | 21.6        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 72900     |\n",
      "|    time_elapsed       | 618       |\n",
      "|    total_timesteps    | 364500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.55     |\n",
      "|    explained_variance | -6.66e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 82899     |\n",
      "|    policy_loss        | 27.3      |\n",
      "|    reward             | 9.937378  |\n",
      "|    std                | 1.57      |\n",
      "|    value_loss         | 24.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 73000     |\n",
      "|    time_elapsed       | 618       |\n",
      "|    total_timesteps    | 365000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.57     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 82999     |\n",
      "|    policy_loss        | -9.32     |\n",
      "|    reward             | 3.2748425 |\n",
      "|    std                | 1.58      |\n",
      "|    value_loss         | 3.64      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 73100      |\n",
      "|    time_elapsed       | 619        |\n",
      "|    total_timesteps    | 365500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.57      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 83099      |\n",
      "|    policy_loss        | 9.72       |\n",
      "|    reward             | -1.7647079 |\n",
      "|    std                | 1.57       |\n",
      "|    value_loss         | 6.64       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 73200      |\n",
      "|    time_elapsed       | 620        |\n",
      "|    total_timesteps    | 366000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.58      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 83199      |\n",
      "|    policy_loss        | 6.3        |\n",
      "|    reward             | 0.15667969 |\n",
      "|    std                | 1.58       |\n",
      "|    value_loss         | 1.88       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 73300     |\n",
      "|    time_elapsed       | 621       |\n",
      "|    total_timesteps    | 366500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.59     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 83299     |\n",
      "|    policy_loss        | 22.1      |\n",
      "|    reward             | 2.4699614 |\n",
      "|    std                | 1.59      |\n",
      "|    value_loss         | 21.4      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 73400      |\n",
      "|    time_elapsed       | 622        |\n",
      "|    total_timesteps    | 367000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.59      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 83399      |\n",
      "|    policy_loss        | -7.27      |\n",
      "|    reward             | -4.0522294 |\n",
      "|    std                | 1.59       |\n",
      "|    value_loss         | 25.7       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 73500     |\n",
      "|    time_elapsed       | 623       |\n",
      "|    total_timesteps    | 367500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.61     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 83499     |\n",
      "|    policy_loss        | 2.84      |\n",
      "|    reward             | 0.7980291 |\n",
      "|    std                | 1.6       |\n",
      "|    value_loss         | 0.692     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 73600      |\n",
      "|    time_elapsed       | 624        |\n",
      "|    total_timesteps    | 368000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.61      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 83599      |\n",
      "|    policy_loss        | 14.4       |\n",
      "|    reward             | -1.9698616 |\n",
      "|    std                | 1.6        |\n",
      "|    value_loss         | 10.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 73700     |\n",
      "|    time_elapsed       | 625       |\n",
      "|    total_timesteps    | 368500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.61     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 83699     |\n",
      "|    policy_loss        | 13.6      |\n",
      "|    reward             | 2.7875714 |\n",
      "|    std                | 1.6       |\n",
      "|    value_loss         | 22.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 73800     |\n",
      "|    time_elapsed       | 625       |\n",
      "|    total_timesteps    | 369000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.61     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 83799     |\n",
      "|    policy_loss        | 7.35      |\n",
      "|    reward             | 4.4031954 |\n",
      "|    std                | 1.6       |\n",
      "|    value_loss         | 5.97      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 73900      |\n",
      "|    time_elapsed       | 626        |\n",
      "|    total_timesteps    | 369500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.61      |\n",
      "|    explained_variance | -0.00247   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 83899      |\n",
      "|    policy_loss        | -15.5      |\n",
      "|    reward             | 0.13797164 |\n",
      "|    std                | 1.6        |\n",
      "|    value_loss         | 10.2       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 74000      |\n",
      "|    time_elapsed       | 627        |\n",
      "|    total_timesteps    | 370000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.61      |\n",
      "|    explained_variance | -0.000621  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 83999      |\n",
      "|    policy_loss        | 1.19       |\n",
      "|    reward             | -5.4902596 |\n",
      "|    std                | 1.6        |\n",
      "|    value_loss         | 1.48       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 74100      |\n",
      "|    time_elapsed       | 628        |\n",
      "|    total_timesteps    | 370500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.62      |\n",
      "|    explained_variance | 0.000375   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 84099      |\n",
      "|    policy_loss        | 7.05       |\n",
      "|    reward             | 0.07432705 |\n",
      "|    std                | 1.6        |\n",
      "|    value_loss         | 2.45       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 74200     |\n",
      "|    time_elapsed       | 629       |\n",
      "|    total_timesteps    | 371000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.64     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 84199     |\n",
      "|    policy_loss        | 20.6      |\n",
      "|    reward             | 4.5206857 |\n",
      "|    std                | 1.61      |\n",
      "|    value_loss         | 29.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 74300      |\n",
      "|    time_elapsed       | 630        |\n",
      "|    total_timesteps    | 371500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.66      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 84299      |\n",
      "|    policy_loss        | -5.35      |\n",
      "|    reward             | -1.0025887 |\n",
      "|    std                | 1.63       |\n",
      "|    value_loss         | 4.5        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 74400      |\n",
      "|    time_elapsed       | 630        |\n",
      "|    total_timesteps    | 372000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.66      |\n",
      "|    explained_variance | -4.51e-05  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 84399      |\n",
      "|    policy_loss        | -17.9      |\n",
      "|    reward             | 0.12679906 |\n",
      "|    std                | 1.63       |\n",
      "|    value_loss         | 11.6       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 74500      |\n",
      "|    time_elapsed       | 631        |\n",
      "|    total_timesteps    | 372500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.66      |\n",
      "|    explained_variance | 0.000225   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 84499      |\n",
      "|    policy_loss        | -0.262     |\n",
      "|    reward             | 0.09023015 |\n",
      "|    std                | 1.63       |\n",
      "|    value_loss         | 2.61       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 589      |\n",
      "|    iterations         | 74600    |\n",
      "|    time_elapsed       | 632      |\n",
      "|    total_timesteps    | 373000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.64    |\n",
      "|    explained_variance | 0.000616 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 84599    |\n",
      "|    policy_loss        | 1.82     |\n",
      "|    reward             | 4.087872 |\n",
      "|    std                | 1.62     |\n",
      "|    value_loss         | 1.02     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 74700     |\n",
      "|    time_elapsed       | 633       |\n",
      "|    total_timesteps    | 373500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.64     |\n",
      "|    explained_variance | 7.15e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 84699     |\n",
      "|    policy_loss        | 5.46      |\n",
      "|    reward             | 0.4700077 |\n",
      "|    std                | 1.62      |\n",
      "|    value_loss         | 1.41      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 74800     |\n",
      "|    time_elapsed       | 634       |\n",
      "|    total_timesteps    | 374000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.65     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 84799     |\n",
      "|    policy_loss        | 8.61      |\n",
      "|    reward             | 0.3630264 |\n",
      "|    std                | 1.63      |\n",
      "|    value_loss         | 3.42      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 74900      |\n",
      "|    time_elapsed       | 635        |\n",
      "|    total_timesteps    | 374500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.68      |\n",
      "|    explained_variance | -0.000132  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 84899      |\n",
      "|    policy_loss        | -2.26      |\n",
      "|    reward             | -1.2120439 |\n",
      "|    std                | 1.64       |\n",
      "|    value_loss         | 0.841      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 75000     |\n",
      "|    time_elapsed       | 635       |\n",
      "|    total_timesteps    | 375000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.68     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 84999     |\n",
      "|    policy_loss        | 7.95      |\n",
      "|    reward             | 0.8896982 |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 2.96      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 75100      |\n",
      "|    time_elapsed       | 636        |\n",
      "|    total_timesteps    | 375500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.67      |\n",
      "|    explained_variance | 0.000167   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 85099      |\n",
      "|    policy_loss        | 16.3       |\n",
      "|    reward             | -3.3842022 |\n",
      "|    std                | 1.64       |\n",
      "|    value_loss         | 23.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 75200     |\n",
      "|    time_elapsed       | 637       |\n",
      "|    total_timesteps    | 376000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.65     |\n",
      "|    explained_variance | -0.000984 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 85199     |\n",
      "|    policy_loss        | -18.3     |\n",
      "|    reward             | -12.53328 |\n",
      "|    std                | 1.63      |\n",
      "|    value_loss         | 21.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 75300      |\n",
      "|    time_elapsed       | 638        |\n",
      "|    total_timesteps    | 376500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.65      |\n",
      "|    explained_variance | 0.000914   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 85299      |\n",
      "|    policy_loss        | -20.2      |\n",
      "|    reward             | -0.7719736 |\n",
      "|    std                | 1.62       |\n",
      "|    value_loss         | 12.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 75400      |\n",
      "|    time_elapsed       | 639        |\n",
      "|    total_timesteps    | 377000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.64      |\n",
      "|    explained_variance | 0.000719   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 85399      |\n",
      "|    policy_loss        | 12.6       |\n",
      "|    reward             | -0.2738605 |\n",
      "|    std                | 1.62       |\n",
      "|    value_loss         | 6.71       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 75500     |\n",
      "|    time_elapsed       | 640       |\n",
      "|    total_timesteps    | 377500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.65     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 85499     |\n",
      "|    policy_loss        | -18.6     |\n",
      "|    reward             | 0.7238806 |\n",
      "|    std                | 1.62      |\n",
      "|    value_loss         | 19.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 75600     |\n",
      "|    time_elapsed       | 640       |\n",
      "|    total_timesteps    | 378000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.64     |\n",
      "|    explained_variance | -0.000248 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 85599     |\n",
      "|    policy_loss        | -6.65     |\n",
      "|    reward             | 1.3667188 |\n",
      "|    std                | 1.62      |\n",
      "|    value_loss         | 2.32      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 75700      |\n",
      "|    time_elapsed       | 641        |\n",
      "|    total_timesteps    | 378500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.65      |\n",
      "|    explained_variance | 0.000236   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 85699      |\n",
      "|    policy_loss        | 17.3       |\n",
      "|    reward             | 0.42911586 |\n",
      "|    std                | 1.62       |\n",
      "|    value_loss         | 9.01       |\n",
      "--------------------------------------\n",
      "day: 2892, episode: 150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4137860.42\n",
      "total_reward: 3137860.42\n",
      "total_cost: 19539.19\n",
      "total_trades: 6490\n",
      "Sharpe: 0.712\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 75800     |\n",
      "|    time_elapsed       | 642       |\n",
      "|    total_timesteps    | 379000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.66     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 85799     |\n",
      "|    policy_loss        | 2.13      |\n",
      "|    reward             | 0.3442245 |\n",
      "|    std                | 1.63      |\n",
      "|    value_loss         | 0.174     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 75900     |\n",
      "|    time_elapsed       | 643       |\n",
      "|    total_timesteps    | 379500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.66     |\n",
      "|    explained_variance | -0.00105  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 85899     |\n",
      "|    policy_loss        | -1.19     |\n",
      "|    reward             | -0.633491 |\n",
      "|    std                | 1.63      |\n",
      "|    value_loss         | 0.81      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 76000     |\n",
      "|    time_elapsed       | 644       |\n",
      "|    total_timesteps    | 380000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.65     |\n",
      "|    explained_variance | -0.000219 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 85999     |\n",
      "|    policy_loss        | -7.23     |\n",
      "|    reward             | 1.1471999 |\n",
      "|    std                | 1.63      |\n",
      "|    value_loss         | 3.78      |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 589          |\n",
      "|    iterations         | 76100        |\n",
      "|    time_elapsed       | 645          |\n",
      "|    total_timesteps    | 380500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.66        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 86099        |\n",
      "|    policy_loss        | -32.9        |\n",
      "|    reward             | -0.011241011 |\n",
      "|    std                | 1.63         |\n",
      "|    value_loss         | 34.9         |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 76200     |\n",
      "|    time_elapsed       | 645       |\n",
      "|    total_timesteps    | 381000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.65     |\n",
      "|    explained_variance | -3.95e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 86199     |\n",
      "|    policy_loss        | -7.79     |\n",
      "|    reward             | 1.5829738 |\n",
      "|    std                | 1.63      |\n",
      "|    value_loss         | 2.48      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 589      |\n",
      "|    iterations         | 76300    |\n",
      "|    time_elapsed       | 646      |\n",
      "|    total_timesteps    | 381500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.67    |\n",
      "|    explained_variance | 0.000142 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 86299    |\n",
      "|    policy_loss        | -18.2    |\n",
      "|    reward             | -8.46618 |\n",
      "|    std                | 1.64     |\n",
      "|    value_loss         | 97.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 76400     |\n",
      "|    time_elapsed       | 647       |\n",
      "|    total_timesteps    | 382000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.64     |\n",
      "|    explained_variance | -12.3     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 86399     |\n",
      "|    policy_loss        | 8.46      |\n",
      "|    reward             | 0.5128258 |\n",
      "|    std                | 1.62      |\n",
      "|    value_loss         | 17.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 76500      |\n",
      "|    time_elapsed       | 648        |\n",
      "|    total_timesteps    | 382500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.63      |\n",
      "|    explained_variance | -0.00494   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 86499      |\n",
      "|    policy_loss        | 5.66       |\n",
      "|    reward             | -1.2914102 |\n",
      "|    std                | 1.62       |\n",
      "|    value_loss         | 1.58       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 76600      |\n",
      "|    time_elapsed       | 649        |\n",
      "|    total_timesteps    | 383000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.62      |\n",
      "|    explained_variance | -0.00165   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 86599      |\n",
      "|    policy_loss        | -19.6      |\n",
      "|    reward             | -1.7896446 |\n",
      "|    std                | 1.61       |\n",
      "|    value_loss         | 13.6       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 76700      |\n",
      "|    time_elapsed       | 650        |\n",
      "|    total_timesteps    | 383500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.64      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 86699      |\n",
      "|    policy_loss        | 11.4       |\n",
      "|    reward             | 0.52758807 |\n",
      "|    std                | 1.63       |\n",
      "|    value_loss         | 8.19       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 589         |\n",
      "|    iterations         | 76800       |\n",
      "|    time_elapsed       | 650         |\n",
      "|    total_timesteps    | 384000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.66       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 86799       |\n",
      "|    policy_loss        | 21.7        |\n",
      "|    reward             | -0.45775023 |\n",
      "|    std                | 1.63        |\n",
      "|    value_loss         | 17          |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 589      |\n",
      "|    iterations         | 76900    |\n",
      "|    time_elapsed       | 651      |\n",
      "|    total_timesteps    | 384500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.67    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 86899    |\n",
      "|    policy_loss        | -40.8    |\n",
      "|    reward             | 9.641897 |\n",
      "|    std                | 1.64     |\n",
      "|    value_loss         | 79.4     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 77000      |\n",
      "|    time_elapsed       | 652        |\n",
      "|    total_timesteps    | 385000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.67      |\n",
      "|    explained_variance | -0.0118    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 86999      |\n",
      "|    policy_loss        | -2.52      |\n",
      "|    reward             | -0.8589784 |\n",
      "|    std                | 1.64       |\n",
      "|    value_loss         | 0.824      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 589         |\n",
      "|    iterations         | 77100       |\n",
      "|    time_elapsed       | 653         |\n",
      "|    total_timesteps    | 385500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.67       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 87099       |\n",
      "|    policy_loss        | -19.3       |\n",
      "|    reward             | -0.91076046 |\n",
      "|    std                | 1.64        |\n",
      "|    value_loss         | 12.1        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 77200      |\n",
      "|    time_elapsed       | 654        |\n",
      "|    total_timesteps    | 386000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.66      |\n",
      "|    explained_variance | 0.0248     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 87199      |\n",
      "|    policy_loss        | 3.72       |\n",
      "|    reward             | 0.20876065 |\n",
      "|    std                | 1.64       |\n",
      "|    value_loss         | 1.51       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 589         |\n",
      "|    iterations         | 77300       |\n",
      "|    time_elapsed       | 655         |\n",
      "|    total_timesteps    | 386500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.66       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 87299       |\n",
      "|    policy_loss        | -24.8       |\n",
      "|    reward             | -0.98594534 |\n",
      "|    std                | 1.63        |\n",
      "|    value_loss         | 24.6        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 77400      |\n",
      "|    time_elapsed       | 655        |\n",
      "|    total_timesteps    | 387000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.66      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 87399      |\n",
      "|    policy_loss        | -3.73      |\n",
      "|    reward             | -1.3826666 |\n",
      "|    std                | 1.63       |\n",
      "|    value_loss         | 1.37       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 77500      |\n",
      "|    time_elapsed       | 656        |\n",
      "|    total_timesteps    | 387500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.65      |\n",
      "|    explained_variance | 0.000335   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 87499      |\n",
      "|    policy_loss        | 4.64       |\n",
      "|    reward             | 0.98118174 |\n",
      "|    std                | 1.63       |\n",
      "|    value_loss         | 25         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 77600      |\n",
      "|    time_elapsed       | 657        |\n",
      "|    total_timesteps    | 388000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.67      |\n",
      "|    explained_variance | -0.000429  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 87599      |\n",
      "|    policy_loss        | -11.1      |\n",
      "|    reward             | -2.5589688 |\n",
      "|    std                | 1.64       |\n",
      "|    value_loss         | 3.79       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 77700     |\n",
      "|    time_elapsed       | 658       |\n",
      "|    total_timesteps    | 388500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.67     |\n",
      "|    explained_variance | 1.91e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 87699     |\n",
      "|    policy_loss        | -0.814    |\n",
      "|    reward             | 0.5301717 |\n",
      "|    std                | 1.64      |\n",
      "|    value_loss         | 4.68      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 590         |\n",
      "|    iterations         | 77800       |\n",
      "|    time_elapsed       | 659         |\n",
      "|    total_timesteps    | 389000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.66       |\n",
      "|    explained_variance | -0.351      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 87799       |\n",
      "|    policy_loss        | -4.66       |\n",
      "|    reward             | -0.23703814 |\n",
      "|    std                | 1.64        |\n",
      "|    value_loss         | 4.22        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 77900      |\n",
      "|    time_elapsed       | 659        |\n",
      "|    total_timesteps    | 389500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.65      |\n",
      "|    explained_variance | -0.156     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 87899      |\n",
      "|    policy_loss        | 19.4       |\n",
      "|    reward             | -14.286976 |\n",
      "|    std                | 1.63       |\n",
      "|    value_loss         | 14.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 78000      |\n",
      "|    time_elapsed       | 660        |\n",
      "|    total_timesteps    | 390000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.67      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 87999      |\n",
      "|    policy_loss        | 7.18       |\n",
      "|    reward             | -6.0803547 |\n",
      "|    std                | 1.64       |\n",
      "|    value_loss         | 22.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 78100     |\n",
      "|    time_elapsed       | 661       |\n",
      "|    total_timesteps    | 390500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.68     |\n",
      "|    explained_variance | -0.00218  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 88099     |\n",
      "|    policy_loss        | 198       |\n",
      "|    reward             | 30.272745 |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 1.44e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 78200      |\n",
      "|    time_elapsed       | 662        |\n",
      "|    total_timesteps    | 391000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.69      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 88199      |\n",
      "|    policy_loss        | -2.91      |\n",
      "|    reward             | 0.16054733 |\n",
      "|    std                | 1.65       |\n",
      "|    value_loss         | 0.4        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 590         |\n",
      "|    iterations         | 78300       |\n",
      "|    time_elapsed       | 663         |\n",
      "|    total_timesteps    | 391500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.69       |\n",
      "|    explained_variance | -0.0002     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 88299       |\n",
      "|    policy_loss        | -14.3       |\n",
      "|    reward             | -0.06962028 |\n",
      "|    std                | 1.65        |\n",
      "|    value_loss         | 7.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 590         |\n",
      "|    iterations         | 78400       |\n",
      "|    time_elapsed       | 664         |\n",
      "|    total_timesteps    | 392000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.69       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 88399       |\n",
      "|    policy_loss        | -13.3       |\n",
      "|    reward             | -0.10059004 |\n",
      "|    std                | 1.65        |\n",
      "|    value_loss         | 6.16        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 78500      |\n",
      "|    time_elapsed       | 665        |\n",
      "|    total_timesteps    | 392500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.68      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 88499      |\n",
      "|    policy_loss        | -0.066     |\n",
      "|    reward             | -1.7773725 |\n",
      "|    std                | 1.65       |\n",
      "|    value_loss         | 3.38       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 78600      |\n",
      "|    time_elapsed       | 665        |\n",
      "|    total_timesteps    | 393000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.67      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 88599      |\n",
      "|    policy_loss        | 38.9       |\n",
      "|    reward             | -3.1821878 |\n",
      "|    std                | 1.65       |\n",
      "|    value_loss         | 40.6       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 78700      |\n",
      "|    time_elapsed       | 666        |\n",
      "|    total_timesteps    | 393500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.68      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 88699      |\n",
      "|    policy_loss        | 5.53       |\n",
      "|    reward             | 0.24432927 |\n",
      "|    std                | 1.65       |\n",
      "|    value_loss         | 1.41       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 78800     |\n",
      "|    time_elapsed       | 667       |\n",
      "|    total_timesteps    | 394000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.7      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 88799     |\n",
      "|    policy_loss        | -12       |\n",
      "|    reward             | -0.656841 |\n",
      "|    std                | 1.67      |\n",
      "|    value_loss         | 6.14      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 78900      |\n",
      "|    time_elapsed       | 668        |\n",
      "|    total_timesteps    | 394500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.71      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 88899      |\n",
      "|    policy_loss        | 25.2       |\n",
      "|    reward             | -0.4462751 |\n",
      "|    std                | 1.67       |\n",
      "|    value_loss         | 14.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 79000     |\n",
      "|    time_elapsed       | 669       |\n",
      "|    total_timesteps    | 395000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.73     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 88999     |\n",
      "|    policy_loss        | -12.2     |\n",
      "|    reward             | 1.3374    |\n",
      "|    std                | 1.69      |\n",
      "|    value_loss         | 4.72      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 590         |\n",
      "|    iterations         | 79100       |\n",
      "|    time_elapsed       | 669         |\n",
      "|    total_timesteps    | 395500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.72       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 89099       |\n",
      "|    policy_loss        | -4.37       |\n",
      "|    reward             | -0.18599574 |\n",
      "|    std                | 1.68        |\n",
      "|    value_loss         | 1.05        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 79200     |\n",
      "|    time_elapsed       | 670       |\n",
      "|    total_timesteps    | 396000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.72     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 89199     |\n",
      "|    policy_loss        | 30.1      |\n",
      "|    reward             | 1.5296693 |\n",
      "|    std                | 1.67      |\n",
      "|    value_loss         | 36.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 590      |\n",
      "|    iterations         | 79300    |\n",
      "|    time_elapsed       | 671      |\n",
      "|    total_timesteps    | 396500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.71    |\n",
      "|    explained_variance | 0.0307   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 89299    |\n",
      "|    policy_loss        | 3.54     |\n",
      "|    reward             | 0.322759 |\n",
      "|    std                | 1.67     |\n",
      "|    value_loss         | 0.854    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 79400     |\n",
      "|    time_elapsed       | 672       |\n",
      "|    total_timesteps    | 397000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.7      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 89399     |\n",
      "|    policy_loss        | -54.9     |\n",
      "|    reward             | 3.9081326 |\n",
      "|    std                | 1.66      |\n",
      "|    value_loss         | 118       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 79500     |\n",
      "|    time_elapsed       | 673       |\n",
      "|    total_timesteps    | 397500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.7      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 89499     |\n",
      "|    policy_loss        | -3.68     |\n",
      "|    reward             | 1.2043847 |\n",
      "|    std                | 1.66      |\n",
      "|    value_loss         | 0.581     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 79600      |\n",
      "|    time_elapsed       | 674        |\n",
      "|    total_timesteps    | 398000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.68      |\n",
      "|    explained_variance | 6.53e-05   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 89599      |\n",
      "|    policy_loss        | 7.13       |\n",
      "|    reward             | -1.5898976 |\n",
      "|    std                | 1.65       |\n",
      "|    value_loss         | 4.13       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 79700      |\n",
      "|    time_elapsed       | 674        |\n",
      "|    total_timesteps    | 398500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.71      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 89699      |\n",
      "|    policy_loss        | -12        |\n",
      "|    reward             | 0.47006217 |\n",
      "|    std                | 1.66       |\n",
      "|    value_loss         | 11.9       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 590         |\n",
      "|    iterations         | 79800       |\n",
      "|    time_elapsed       | 675         |\n",
      "|    total_timesteps    | 399000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.72       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 89799       |\n",
      "|    policy_loss        | 30          |\n",
      "|    reward             | -0.93134224 |\n",
      "|    std                | 1.67        |\n",
      "|    value_loss         | 41          |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 79900     |\n",
      "|    time_elapsed       | 676       |\n",
      "|    total_timesteps    | 399500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.7      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 89899     |\n",
      "|    policy_loss        | 5.09      |\n",
      "|    reward             | 0.8466609 |\n",
      "|    std                | 1.66      |\n",
      "|    value_loss         | 1.52      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 80000      |\n",
      "|    time_elapsed       | 677        |\n",
      "|    total_timesteps    | 400000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.71      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 89999      |\n",
      "|    policy_loss        | -15.9      |\n",
      "|    reward             | 0.93466276 |\n",
      "|    std                | 1.66       |\n",
      "|    value_loss         | 9.69       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 80100     |\n",
      "|    time_elapsed       | 678       |\n",
      "|    total_timesteps    | 400500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.7      |\n",
      "|    explained_variance | 5.87e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 90099     |\n",
      "|    policy_loss        | 11.3      |\n",
      "|    reward             | 2.3918576 |\n",
      "|    std                | 1.66      |\n",
      "|    value_loss         | 4.81      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 80200      |\n",
      "|    time_elapsed       | 679        |\n",
      "|    total_timesteps    | 401000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.7       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 90199      |\n",
      "|    policy_loss        | -11.5      |\n",
      "|    reward             | -1.0243162 |\n",
      "|    std                | 1.65       |\n",
      "|    value_loss         | 5.07       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 80300     |\n",
      "|    time_elapsed       | 680       |\n",
      "|    total_timesteps    | 401500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.69     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 90299     |\n",
      "|    policy_loss        | -3.64     |\n",
      "|    reward             | 4.9429827 |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 1.75      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 80400      |\n",
      "|    time_elapsed       | 680        |\n",
      "|    total_timesteps    | 402000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.67      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 90399      |\n",
      "|    policy_loss        | 20.6       |\n",
      "|    reward             | -4.3720274 |\n",
      "|    std                | 1.64       |\n",
      "|    value_loss         | 11.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 80500     |\n",
      "|    time_elapsed       | 681       |\n",
      "|    total_timesteps    | 402500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.68     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 90499     |\n",
      "|    policy_loss        | -0.885    |\n",
      "|    reward             | 1.3063031 |\n",
      "|    std                | 1.64      |\n",
      "|    value_loss         | 0.799     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 80600      |\n",
      "|    time_elapsed       | 682        |\n",
      "|    total_timesteps    | 403000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.68      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 90599      |\n",
      "|    policy_loss        | -8.1       |\n",
      "|    reward             | 0.11741416 |\n",
      "|    std                | 1.64       |\n",
      "|    value_loss         | 3.29       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 80700     |\n",
      "|    time_elapsed       | 683       |\n",
      "|    total_timesteps    | 403500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.69     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 90699     |\n",
      "|    policy_loss        | -23.2     |\n",
      "|    reward             | 1.1589998 |\n",
      "|    std                | 1.64      |\n",
      "|    value_loss         | 13.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 80800      |\n",
      "|    time_elapsed       | 684        |\n",
      "|    total_timesteps    | 404000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.68      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 90799      |\n",
      "|    policy_loss        | -6.7       |\n",
      "|    reward             | -2.6437268 |\n",
      "|    std                | 1.64       |\n",
      "|    value_loss         | 2.16       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 80900      |\n",
      "|    time_elapsed       | 685        |\n",
      "|    total_timesteps    | 404500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.67      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 90899      |\n",
      "|    policy_loss        | -11.5      |\n",
      "|    reward             | -1.3477421 |\n",
      "|    std                | 1.64       |\n",
      "|    value_loss         | 6.13       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 81000     |\n",
      "|    time_elapsed       | 685       |\n",
      "|    total_timesteps    | 405000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.69     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 90999     |\n",
      "|    policy_loss        | 19        |\n",
      "|    reward             | 4.0244493 |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 16.8      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 590         |\n",
      "|    iterations         | 81100       |\n",
      "|    time_elapsed       | 686         |\n",
      "|    total_timesteps    | 405500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.69       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 91099       |\n",
      "|    policy_loss        | 5.37        |\n",
      "|    reward             | -0.76636297 |\n",
      "|    std                | 1.65        |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 81200     |\n",
      "|    time_elapsed       | 687       |\n",
      "|    total_timesteps    | 406000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.69     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 91199     |\n",
      "|    policy_loss        | -21.8     |\n",
      "|    reward             | 3.5910845 |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 21.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 81300      |\n",
      "|    time_elapsed       | 688        |\n",
      "|    total_timesteps    | 406500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.69      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 91299      |\n",
      "|    policy_loss        | 10.4       |\n",
      "|    reward             | -2.5206554 |\n",
      "|    std                | 1.64       |\n",
      "|    value_loss         | 3.51       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 81400     |\n",
      "|    time_elapsed       | 689       |\n",
      "|    total_timesteps    | 407000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.71     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 91399     |\n",
      "|    policy_loss        | -12.5     |\n",
      "|    reward             | 1.4126698 |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 4.36      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 81500     |\n",
      "|    time_elapsed       | 689       |\n",
      "|    total_timesteps    | 407500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.71     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 91499     |\n",
      "|    policy_loss        | -26.4     |\n",
      "|    reward             | 7.4636073 |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 70.3      |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4147273.16\n",
      "total_reward: 3147273.16\n",
      "total_cost: 1027.91\n",
      "total_trades: 5910\n",
      "Sharpe: 0.712\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 590         |\n",
      "|    iterations         | 81600       |\n",
      "|    time_elapsed       | 690         |\n",
      "|    total_timesteps    | 408000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.7        |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 91599       |\n",
      "|    policy_loss        | 5.9         |\n",
      "|    reward             | -0.47622964 |\n",
      "|    std                | 1.65        |\n",
      "|    value_loss         | 1.36        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 81700      |\n",
      "|    time_elapsed       | 691        |\n",
      "|    total_timesteps    | 408500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.72      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 91699      |\n",
      "|    policy_loss        | 11.8       |\n",
      "|    reward             | 0.76030207 |\n",
      "|    std                | 1.66       |\n",
      "|    value_loss         | 5.36       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 81800     |\n",
      "|    time_elapsed       | 692       |\n",
      "|    total_timesteps    | 409000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.72     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 91799     |\n",
      "|    policy_loss        | -33.9     |\n",
      "|    reward             | 3.4656975 |\n",
      "|    std                | 1.66      |\n",
      "|    value_loss         | 119       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 590      |\n",
      "|    iterations         | 81900    |\n",
      "|    time_elapsed       | 693      |\n",
      "|    total_timesteps    | 409500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.71    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 91899    |\n",
      "|    policy_loss        | -18.3    |\n",
      "|    reward             | 5.33252  |\n",
      "|    std                | 1.65     |\n",
      "|    value_loss         | 8.32     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 82000     |\n",
      "|    time_elapsed       | 693       |\n",
      "|    total_timesteps    | 410000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.7      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 91999     |\n",
      "|    policy_loss        | -14.2     |\n",
      "|    reward             | -8.403894 |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 8.21      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 590         |\n",
      "|    iterations         | 82100       |\n",
      "|    time_elapsed       | 694         |\n",
      "|    total_timesteps    | 410500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.7        |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 92099       |\n",
      "|    policy_loss        | 1.96        |\n",
      "|    reward             | -0.32002845 |\n",
      "|    std                | 1.65        |\n",
      "|    value_loss         | 0.601       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 82200     |\n",
      "|    time_elapsed       | 695       |\n",
      "|    total_timesteps    | 411000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.7      |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 92199     |\n",
      "|    policy_loss        | -9.13     |\n",
      "|    reward             | 2.7977085 |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 3.41      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 590      |\n",
      "|    iterations         | 82300    |\n",
      "|    time_elapsed       | 696      |\n",
      "|    total_timesteps    | 411500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.69    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 92299    |\n",
      "|    policy_loss        | 21.8     |\n",
      "|    reward             | 2.118794 |\n",
      "|    std                | 1.64     |\n",
      "|    value_loss         | 25.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 82400     |\n",
      "|    time_elapsed       | 697       |\n",
      "|    total_timesteps    | 412000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.69     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 92399     |\n",
      "|    policy_loss        | -18.5     |\n",
      "|    reward             | 1.3927205 |\n",
      "|    std                | 1.64      |\n",
      "|    value_loss         | 12.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 82500     |\n",
      "|    time_elapsed       | 697       |\n",
      "|    total_timesteps    | 412500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.7      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 92499     |\n",
      "|    policy_loss        | -18.6     |\n",
      "|    reward             | 0.9559394 |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 13.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 82600     |\n",
      "|    time_elapsed       | 698       |\n",
      "|    total_timesteps    | 413000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.69     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 92599     |\n",
      "|    policy_loss        | 14.5      |\n",
      "|    reward             | 0.7986704 |\n",
      "|    std                | 1.64      |\n",
      "|    value_loss         | 10.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 82700     |\n",
      "|    time_elapsed       | 699       |\n",
      "|    total_timesteps    | 413500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.7      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 92699     |\n",
      "|    policy_loss        | 15.5      |\n",
      "|    reward             | 1.1497368 |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 33.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 82800     |\n",
      "|    time_elapsed       | 700       |\n",
      "|    total_timesteps    | 414000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.69     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 92799     |\n",
      "|    policy_loss        | -8.23     |\n",
      "|    reward             | 0.7696554 |\n",
      "|    std                | 1.64      |\n",
      "|    value_loss         | 1.84      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 591      |\n",
      "|    iterations         | 82900    |\n",
      "|    time_elapsed       | 701      |\n",
      "|    total_timesteps    | 414500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.68    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 92899    |\n",
      "|    policy_loss        | 2.09     |\n",
      "|    reward             | 1.911599 |\n",
      "|    std                | 1.64     |\n",
      "|    value_loss         | 0.344    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 591      |\n",
      "|    iterations         | 83000    |\n",
      "|    time_elapsed       | 701      |\n",
      "|    total_timesteps    | 415000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.7     |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 92999    |\n",
      "|    policy_loss        | 6.99     |\n",
      "|    reward             | 0.48543  |\n",
      "|    std                | 1.65     |\n",
      "|    value_loss         | 1.83     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 83100     |\n",
      "|    time_elapsed       | 702       |\n",
      "|    total_timesteps    | 415500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.71     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 93099     |\n",
      "|    policy_loss        | 6.28      |\n",
      "|    reward             | 5.2738347 |\n",
      "|    std                | 1.66      |\n",
      "|    value_loss         | 20        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 83200     |\n",
      "|    time_elapsed       | 703       |\n",
      "|    total_timesteps    | 416000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.72     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 93199     |\n",
      "|    policy_loss        | 55.2      |\n",
      "|    reward             | 5.5312533 |\n",
      "|    std                | 1.66      |\n",
      "|    value_loss         | 136       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 83300      |\n",
      "|    time_elapsed       | 704        |\n",
      "|    total_timesteps    | 416500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.71      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 93299      |\n",
      "|    policy_loss        | 7.84       |\n",
      "|    reward             | -3.7376945 |\n",
      "|    std                | 1.66       |\n",
      "|    value_loss         | 17.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 83400      |\n",
      "|    time_elapsed       | 705        |\n",
      "|    total_timesteps    | 417000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.73      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 93399      |\n",
      "|    policy_loss        | -1.12      |\n",
      "|    reward             | 0.93588674 |\n",
      "|    std                | 1.67       |\n",
      "|    value_loss         | 0.264      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 591         |\n",
      "|    iterations         | 83500       |\n",
      "|    time_elapsed       | 706         |\n",
      "|    total_timesteps    | 417500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.71       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 93499       |\n",
      "|    policy_loss        | -8.76       |\n",
      "|    reward             | -0.11029927 |\n",
      "|    std                | 1.66        |\n",
      "|    value_loss         | 4.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 591         |\n",
      "|    iterations         | 83600       |\n",
      "|    time_elapsed       | 707         |\n",
      "|    total_timesteps    | 418000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.72       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 93599       |\n",
      "|    policy_loss        | -26.8       |\n",
      "|    reward             | -0.09525273 |\n",
      "|    std                | 1.67        |\n",
      "|    value_loss         | 22.6        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 83700      |\n",
      "|    time_elapsed       | 707        |\n",
      "|    total_timesteps    | 418500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.73      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 93699      |\n",
      "|    policy_loss        | 16.1       |\n",
      "|    reward             | -0.6333179 |\n",
      "|    std                | 1.67       |\n",
      "|    value_loss         | 23.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 83800      |\n",
      "|    time_elapsed       | 708        |\n",
      "|    total_timesteps    | 419000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.73      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 93799      |\n",
      "|    policy_loss        | 15.9       |\n",
      "|    reward             | -6.3131976 |\n",
      "|    std                | 1.67       |\n",
      "|    value_loss         | 9.22       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 83900      |\n",
      "|    time_elapsed       | 709        |\n",
      "|    total_timesteps    | 419500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.71      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 93899      |\n",
      "|    policy_loss        | -0.686     |\n",
      "|    reward             | 0.22477162 |\n",
      "|    std                | 1.66       |\n",
      "|    value_loss         | 0.0283     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 84000     |\n",
      "|    time_elapsed       | 710       |\n",
      "|    total_timesteps    | 420000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.72     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 93999     |\n",
      "|    policy_loss        | -7.51     |\n",
      "|    reward             | 2.7717013 |\n",
      "|    std                | 1.66      |\n",
      "|    value_loss         | 2.26      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 84100     |\n",
      "|    time_elapsed       | 710       |\n",
      "|    total_timesteps    | 420500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.73     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 94099     |\n",
      "|    policy_loss        | -14.1     |\n",
      "|    reward             | 0.6227473 |\n",
      "|    std                | 1.67      |\n",
      "|    value_loss         | 7.98      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 591         |\n",
      "|    iterations         | 84200       |\n",
      "|    time_elapsed       | 711         |\n",
      "|    total_timesteps    | 421000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.73       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 94199       |\n",
      "|    policy_loss        | -7.2        |\n",
      "|    reward             | -0.49886927 |\n",
      "|    std                | 1.67        |\n",
      "|    value_loss         | 5.99        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 84300      |\n",
      "|    time_elapsed       | 712        |\n",
      "|    total_timesteps    | 421500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.73      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 94299      |\n",
      "|    policy_loss        | -5.15      |\n",
      "|    reward             | 0.71877015 |\n",
      "|    std                | 1.67       |\n",
      "|    value_loss         | 1.24       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 84400     |\n",
      "|    time_elapsed       | 713       |\n",
      "|    total_timesteps    | 422000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.73     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 94399     |\n",
      "|    policy_loss        | -103      |\n",
      "|    reward             | 3.5867882 |\n",
      "|    std                | 1.67      |\n",
      "|    value_loss         | 369       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 84500      |\n",
      "|    time_elapsed       | 714        |\n",
      "|    total_timesteps    | 422500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.75      |\n",
      "|    explained_variance | 0.651      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 94499      |\n",
      "|    policy_loss        | -9.33      |\n",
      "|    reward             | 0.56031775 |\n",
      "|    std                | 1.68       |\n",
      "|    value_loss         | 3.02       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 591         |\n",
      "|    iterations         | 84600       |\n",
      "|    time_elapsed       | 715         |\n",
      "|    total_timesteps    | 423000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.73       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 94599       |\n",
      "|    policy_loss        | -11         |\n",
      "|    reward             | -0.56220585 |\n",
      "|    std                | 1.67        |\n",
      "|    value_loss         | 4.38        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 84700      |\n",
      "|    time_elapsed       | 715        |\n",
      "|    total_timesteps    | 423500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.74      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 94699      |\n",
      "|    policy_loss        | -16.1      |\n",
      "|    reward             | -2.7920992 |\n",
      "|    std                | 1.67       |\n",
      "|    value_loss         | 10.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 84800      |\n",
      "|    time_elapsed       | 716        |\n",
      "|    total_timesteps    | 424000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.73      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 94799      |\n",
      "|    policy_loss        | -28.8      |\n",
      "|    reward             | -1.5733061 |\n",
      "|    std                | 1.67       |\n",
      "|    value_loss         | 29.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 84900      |\n",
      "|    time_elapsed       | 717        |\n",
      "|    total_timesteps    | 424500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.73      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 94899      |\n",
      "|    policy_loss        | 4.2        |\n",
      "|    reward             | -0.1291947 |\n",
      "|    std                | 1.67       |\n",
      "|    value_loss         | 1.18       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 85000     |\n",
      "|    time_elapsed       | 718       |\n",
      "|    total_timesteps    | 425000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.75     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 94999     |\n",
      "|    policy_loss        | -49.4     |\n",
      "|    reward             | 5.2149057 |\n",
      "|    std                | 1.68      |\n",
      "|    value_loss         | 69.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 85100      |\n",
      "|    time_elapsed       | 718        |\n",
      "|    total_timesteps    | 425500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.75      |\n",
      "|    explained_variance | -0.35      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 95099      |\n",
      "|    policy_loss        | -7.94      |\n",
      "|    reward             | 0.74604887 |\n",
      "|    std                | 1.68       |\n",
      "|    value_loss         | 2.26       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 85200      |\n",
      "|    time_elapsed       | 719        |\n",
      "|    total_timesteps    | 426000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.76      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 95199      |\n",
      "|    policy_loss        | 12.9       |\n",
      "|    reward             | -0.4733933 |\n",
      "|    std                | 1.69       |\n",
      "|    value_loss         | 9.65       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 85300      |\n",
      "|    time_elapsed       | 720        |\n",
      "|    total_timesteps    | 426500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.76      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 95299      |\n",
      "|    policy_loss        | 9.92       |\n",
      "|    reward             | 0.26505348 |\n",
      "|    std                | 1.69       |\n",
      "|    value_loss         | 5.95       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 85400      |\n",
      "|    time_elapsed       | 721        |\n",
      "|    total_timesteps    | 427000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.76      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 95399      |\n",
      "|    policy_loss        | 4.03       |\n",
      "|    reward             | -1.9045514 |\n",
      "|    std                | 1.69       |\n",
      "|    value_loss         | 2.8        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 85500      |\n",
      "|    time_elapsed       | 722        |\n",
      "|    total_timesteps    | 427500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.78      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 95499      |\n",
      "|    policy_loss        | 13         |\n",
      "|    reward             | 0.74573874 |\n",
      "|    std                | 1.7        |\n",
      "|    value_loss         | 28.9       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 591         |\n",
      "|    iterations         | 85600       |\n",
      "|    time_elapsed       | 723         |\n",
      "|    total_timesteps    | 428000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.78       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 95599       |\n",
      "|    policy_loss        | 35.7        |\n",
      "|    reward             | 0.027207954 |\n",
      "|    std                | 1.7         |\n",
      "|    value_loss         | 58.3        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 85700      |\n",
      "|    time_elapsed       | 723        |\n",
      "|    total_timesteps    | 428500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.81      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 95699      |\n",
      "|    policy_loss        | -0.825     |\n",
      "|    reward             | -0.8333705 |\n",
      "|    std                | 1.72       |\n",
      "|    value_loss         | 0.488      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 85800     |\n",
      "|    time_elapsed       | 724       |\n",
      "|    total_timesteps    | 429000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.82     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 95799     |\n",
      "|    policy_loss        | -7.59     |\n",
      "|    reward             | 0.8542322 |\n",
      "|    std                | 1.72      |\n",
      "|    value_loss         | 8.32      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 591         |\n",
      "|    iterations         | 85900       |\n",
      "|    time_elapsed       | 725         |\n",
      "|    total_timesteps    | 429500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.84       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 95899       |\n",
      "|    policy_loss        | -32.8       |\n",
      "|    reward             | -0.44040465 |\n",
      "|    std                | 1.73        |\n",
      "|    value_loss         | 28.7        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 86000      |\n",
      "|    time_elapsed       | 726        |\n",
      "|    total_timesteps    | 430000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.84      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 95999      |\n",
      "|    policy_loss        | 13.5       |\n",
      "|    reward             | 0.84938025 |\n",
      "|    std                | 1.73       |\n",
      "|    value_loss         | 5.96       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 86100     |\n",
      "|    time_elapsed       | 727       |\n",
      "|    total_timesteps    | 430500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.83     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 96099     |\n",
      "|    policy_loss        | 3.69      |\n",
      "|    reward             | 2.6773016 |\n",
      "|    std                | 1.73      |\n",
      "|    value_loss         | 15.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 86200     |\n",
      "|    time_elapsed       | 727       |\n",
      "|    total_timesteps    | 431000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.81     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 96199     |\n",
      "|    policy_loss        | -4.6      |\n",
      "|    reward             | 2.4074225 |\n",
      "|    std                | 1.71      |\n",
      "|    value_loss         | 70.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 86300      |\n",
      "|    time_elapsed       | 728        |\n",
      "|    total_timesteps    | 431500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.81      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 96299      |\n",
      "|    policy_loss        | 4.86       |\n",
      "|    reward             | 0.24075511 |\n",
      "|    std                | 1.71       |\n",
      "|    value_loss         | 1.73       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 86400     |\n",
      "|    time_elapsed       | 729       |\n",
      "|    total_timesteps    | 432000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.81     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 96399     |\n",
      "|    policy_loss        | -7        |\n",
      "|    reward             | 0.7744433 |\n",
      "|    std                | 1.71      |\n",
      "|    value_loss         | 1.43      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 86500     |\n",
      "|    time_elapsed       | 730       |\n",
      "|    total_timesteps    | 432500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.81     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 96499     |\n",
      "|    policy_loss        | 13.6      |\n",
      "|    reward             | 1.4044042 |\n",
      "|    std                | 1.72      |\n",
      "|    value_loss         | 4.62      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 86600     |\n",
      "|    time_elapsed       | 731       |\n",
      "|    total_timesteps    | 433000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.8      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 96599     |\n",
      "|    policy_loss        | -27.8     |\n",
      "|    reward             | 2.3374538 |\n",
      "|    std                | 1.71      |\n",
      "|    value_loss         | 34.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 86700      |\n",
      "|    time_elapsed       | 731        |\n",
      "|    total_timesteps    | 433500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.8       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 96699      |\n",
      "|    policy_loss        | -8.18      |\n",
      "|    reward             | -2.1927085 |\n",
      "|    std                | 1.71       |\n",
      "|    value_loss         | 10.7       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 86800     |\n",
      "|    time_elapsed       | 732       |\n",
      "|    total_timesteps    | 434000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.83     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 96799     |\n",
      "|    policy_loss        | 1.49      |\n",
      "|    reward             | 0.7420296 |\n",
      "|    std                | 1.73      |\n",
      "|    value_loss         | 0.553     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 86900      |\n",
      "|    time_elapsed       | 733        |\n",
      "|    total_timesteps    | 434500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.82      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 96899      |\n",
      "|    policy_loss        | 9.27       |\n",
      "|    reward             | -3.7178025 |\n",
      "|    std                | 1.72       |\n",
      "|    value_loss         | 2.88       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 87000      |\n",
      "|    time_elapsed       | 734        |\n",
      "|    total_timesteps    | 435000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.81      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 96999      |\n",
      "|    policy_loss        | 4.59       |\n",
      "|    reward             | 0.94130415 |\n",
      "|    std                | 1.72       |\n",
      "|    value_loss         | 3.41       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 87100       |\n",
      "|    time_elapsed       | 735         |\n",
      "|    total_timesteps    | 435500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.84       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 97099       |\n",
      "|    policy_loss        | 12.9        |\n",
      "|    reward             | -0.31768137 |\n",
      "|    std                | 1.73        |\n",
      "|    value_loss         | 4.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 87200       |\n",
      "|    time_elapsed       | 735         |\n",
      "|    total_timesteps    | 436000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.82       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 97199       |\n",
      "|    policy_loss        | 10.1        |\n",
      "|    reward             | -0.28670883 |\n",
      "|    std                | 1.72        |\n",
      "|    value_loss         | 6.96        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 592      |\n",
      "|    iterations         | 87300    |\n",
      "|    time_elapsed       | 736      |\n",
      "|    total_timesteps    | 436500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.82    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 97299    |\n",
      "|    policy_loss        | 25.2     |\n",
      "|    reward             | 3.053184 |\n",
      "|    std                | 1.72     |\n",
      "|    value_loss         | 21.5     |\n",
      "------------------------------------\n",
      "day: 2892, episode: 170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4277834.30\n",
      "total_reward: 3277834.30\n",
      "total_cost: 1308.13\n",
      "total_trades: 7881\n",
      "Sharpe: 0.726\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 87400     |\n",
      "|    time_elapsed       | 737       |\n",
      "|    total_timesteps    | 437000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.83     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 97399     |\n",
      "|    policy_loss        | -9.74     |\n",
      "|    reward             | 1.1544496 |\n",
      "|    std                | 1.73      |\n",
      "|    value_loss         | 2.74      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 592      |\n",
      "|    iterations         | 87500    |\n",
      "|    time_elapsed       | 738      |\n",
      "|    total_timesteps    | 437500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.82    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 97499    |\n",
      "|    policy_loss        | -47.7    |\n",
      "|    reward             | 4.62954  |\n",
      "|    std                | 1.72     |\n",
      "|    value_loss         | 84.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 87600     |\n",
      "|    time_elapsed       | 739       |\n",
      "|    total_timesteps    | 438000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.83     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 97599     |\n",
      "|    policy_loss        | -5.24     |\n",
      "|    reward             | 0.4762628 |\n",
      "|    std                | 1.73      |\n",
      "|    value_loss         | 1.43      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 87700       |\n",
      "|    time_elapsed       | 740         |\n",
      "|    total_timesteps    | 438500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.86       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 97699       |\n",
      "|    policy_loss        | -9.36       |\n",
      "|    reward             | -0.06330743 |\n",
      "|    std                | 1.74        |\n",
      "|    value_loss         | 9.2         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 87800      |\n",
      "|    time_elapsed       | 740        |\n",
      "|    total_timesteps    | 439000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.85      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 97799      |\n",
      "|    policy_loss        | -22.8      |\n",
      "|    reward             | -0.9188203 |\n",
      "|    std                | 1.74       |\n",
      "|    value_loss         | 22.8       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 87900       |\n",
      "|    time_elapsed       | 741         |\n",
      "|    total_timesteps    | 439500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.87       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 97899       |\n",
      "|    policy_loss        | 28          |\n",
      "|    reward             | -0.34633604 |\n",
      "|    std                | 1.75        |\n",
      "|    value_loss         | 24.8        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 88000     |\n",
      "|    time_elapsed       | 742       |\n",
      "|    total_timesteps    | 440000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.88     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 97999     |\n",
      "|    policy_loss        | -2.63     |\n",
      "|    reward             | -1.654096 |\n",
      "|    std                | 1.75      |\n",
      "|    value_loss         | 0.639     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 88100       |\n",
      "|    time_elapsed       | 743         |\n",
      "|    total_timesteps    | 440500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.88       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 98099       |\n",
      "|    policy_loss        | -6.27       |\n",
      "|    reward             | -0.87207454 |\n",
      "|    std                | 1.76        |\n",
      "|    value_loss         | 2.52        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 88200     |\n",
      "|    time_elapsed       | 743       |\n",
      "|    total_timesteps    | 441000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.87     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 98199     |\n",
      "|    policy_loss        | -2.49     |\n",
      "|    reward             | 0.5054795 |\n",
      "|    std                | 1.75      |\n",
      "|    value_loss         | 0.777     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 88300      |\n",
      "|    time_elapsed       | 744        |\n",
      "|    total_timesteps    | 441500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.86      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 98299      |\n",
      "|    policy_loss        | 18         |\n",
      "|    reward             | -1.8562007 |\n",
      "|    std                | 1.74       |\n",
      "|    value_loss         | 9.65       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 88400      |\n",
      "|    time_elapsed       | 745        |\n",
      "|    total_timesteps    | 442000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.85      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 98399      |\n",
      "|    policy_loss        | -15.9      |\n",
      "|    reward             | -0.8631059 |\n",
      "|    std                | 1.74       |\n",
      "|    value_loss         | 7.1        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 88500     |\n",
      "|    time_elapsed       | 746       |\n",
      "|    total_timesteps    | 442500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.85     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 98499     |\n",
      "|    policy_loss        | 0.838     |\n",
      "|    reward             | 1.4074895 |\n",
      "|    std                | 1.73      |\n",
      "|    value_loss         | 2.41      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 88600      |\n",
      "|    time_elapsed       | 747        |\n",
      "|    total_timesteps    | 443000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.85      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 98599      |\n",
      "|    policy_loss        | 8.87       |\n",
      "|    reward             | -1.9102888 |\n",
      "|    std                | 1.74       |\n",
      "|    value_loss         | 4.47       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 88700       |\n",
      "|    time_elapsed       | 748         |\n",
      "|    total_timesteps    | 443500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.84       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 98699       |\n",
      "|    policy_loss        | -2.74       |\n",
      "|    reward             | -0.88509077 |\n",
      "|    std                | 1.73        |\n",
      "|    value_loss         | 7.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 88800       |\n",
      "|    time_elapsed       | 749         |\n",
      "|    total_timesteps    | 444000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.85       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 98799       |\n",
      "|    policy_loss        | 4.32        |\n",
      "|    reward             | 0.083741836 |\n",
      "|    std                | 1.74        |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 88900     |\n",
      "|    time_elapsed       | 749       |\n",
      "|    total_timesteps    | 444500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.86     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 98899     |\n",
      "|    policy_loss        | 2.17      |\n",
      "|    reward             | -1.011821 |\n",
      "|    std                | 1.74      |\n",
      "|    value_loss         | 0.938     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 89000     |\n",
      "|    time_elapsed       | 750       |\n",
      "|    total_timesteps    | 445000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.88     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 98999     |\n",
      "|    policy_loss        | -22.1     |\n",
      "|    reward             | 1.2706994 |\n",
      "|    std                | 1.76      |\n",
      "|    value_loss         | 16.6      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 89100       |\n",
      "|    time_elapsed       | 751         |\n",
      "|    total_timesteps    | 445500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.87       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99099       |\n",
      "|    policy_loss        | -15.3       |\n",
      "|    reward             | -0.47270775 |\n",
      "|    std                | 1.75        |\n",
      "|    value_loss         | 15.2        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 89200     |\n",
      "|    time_elapsed       | 752       |\n",
      "|    total_timesteps    | 446000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.87     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99199     |\n",
      "|    policy_loss        | -19.5     |\n",
      "|    reward             | 2.4491832 |\n",
      "|    std                | 1.75      |\n",
      "|    value_loss         | 13        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 89300      |\n",
      "|    time_elapsed       | 753        |\n",
      "|    total_timesteps    | 446500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.88      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99299      |\n",
      "|    policy_loss        | -26.6      |\n",
      "|    reward             | -1.0112013 |\n",
      "|    std                | 1.76       |\n",
      "|    value_loss         | 24.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 89400     |\n",
      "|    time_elapsed       | 754       |\n",
      "|    total_timesteps    | 447000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.87     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99399     |\n",
      "|    policy_loss        | 4.86      |\n",
      "|    reward             | 1.1973711 |\n",
      "|    std                | 1.75      |\n",
      "|    value_loss         | 1.13      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 89500     |\n",
      "|    time_elapsed       | 755       |\n",
      "|    total_timesteps    | 447500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.88     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99499     |\n",
      "|    policy_loss        | -11.9     |\n",
      "|    reward             | -0.720429 |\n",
      "|    std                | 1.75      |\n",
      "|    value_loss         | 4.37      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 592      |\n",
      "|    iterations         | 89600    |\n",
      "|    time_elapsed       | 755      |\n",
      "|    total_timesteps    | 448000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.9     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99599    |\n",
      "|    policy_loss        | -69.6    |\n",
      "|    reward             | 6.35764  |\n",
      "|    std                | 1.77     |\n",
      "|    value_loss         | 192      |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 89700       |\n",
      "|    time_elapsed       | 756         |\n",
      "|    total_timesteps    | 448500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.9        |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99699       |\n",
      "|    policy_loss        | 7.99        |\n",
      "|    reward             | -0.33007684 |\n",
      "|    std                | 1.77        |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 89800      |\n",
      "|    time_elapsed       | 757        |\n",
      "|    total_timesteps    | 449000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.9       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99799      |\n",
      "|    policy_loss        | 11.1       |\n",
      "|    reward             | -0.9978364 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 4.42       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 89900     |\n",
      "|    time_elapsed       | 758       |\n",
      "|    total_timesteps    | 449500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99899     |\n",
      "|    policy_loss        | -91.7     |\n",
      "|    reward             | 0.1429261 |\n",
      "|    std                | 1.78      |\n",
      "|    value_loss         | 265       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 90000     |\n",
      "|    time_elapsed       | 759       |\n",
      "|    total_timesteps    | 450000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99999     |\n",
      "|    policy_loss        | 11.6      |\n",
      "|    reward             | 1.4104913 |\n",
      "|    std                | 1.78      |\n",
      "|    value_loss         | 3.91      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 90100     |\n",
      "|    time_elapsed       | 759       |\n",
      "|    total_timesteps    | 450500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.9      |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 100099    |\n",
      "|    policy_loss        | -12.4     |\n",
      "|    reward             | 2.1899161 |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 4.58      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 90200      |\n",
      "|    time_elapsed       | 760        |\n",
      "|    total_timesteps    | 451000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.92      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 100199     |\n",
      "|    policy_loss        | 6.98       |\n",
      "|    reward             | 0.98359424 |\n",
      "|    std                | 1.78       |\n",
      "|    value_loss         | 8.85       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 90300     |\n",
      "|    time_elapsed       | 761       |\n",
      "|    total_timesteps    | 451500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.89     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 100299    |\n",
      "|    policy_loss        | -5.42     |\n",
      "|    reward             | 1.1334168 |\n",
      "|    std                | 1.76      |\n",
      "|    value_loss         | 1.69      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 90400      |\n",
      "|    time_elapsed       | 762        |\n",
      "|    total_timesteps    | 452000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.9       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 100399     |\n",
      "|    policy_loss        | -29.7      |\n",
      "|    reward             | -4.2161546 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 28.5       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 90500      |\n",
      "|    time_elapsed       | 763        |\n",
      "|    total_timesteps    | 452500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.91      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 100499     |\n",
      "|    policy_loss        | -20.4      |\n",
      "|    reward             | -2.2219706 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 12.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 90600      |\n",
      "|    time_elapsed       | 764        |\n",
      "|    total_timesteps    | 453000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.91      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 100599     |\n",
      "|    policy_loss        | 13.6       |\n",
      "|    reward             | -0.7357066 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 8.07       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 90700       |\n",
      "|    time_elapsed       | 764         |\n",
      "|    total_timesteps    | 453500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.9        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 100699      |\n",
      "|    policy_loss        | 14.2        |\n",
      "|    reward             | -0.46758205 |\n",
      "|    std                | 1.77        |\n",
      "|    value_loss         | 5.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 90800       |\n",
      "|    time_elapsed       | 765         |\n",
      "|    total_timesteps    | 454000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.89       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 100799      |\n",
      "|    policy_loss        | 34.7        |\n",
      "|    reward             | -0.22834693 |\n",
      "|    std                | 1.76        |\n",
      "|    value_loss         | 48.4        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 90900      |\n",
      "|    time_elapsed       | 766        |\n",
      "|    total_timesteps    | 454500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.91      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 100899     |\n",
      "|    policy_loss        | -2.99      |\n",
      "|    reward             | 0.37377024 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 1.09       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 91000      |\n",
      "|    time_elapsed       | 767        |\n",
      "|    total_timesteps    | 455000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.91      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 100999     |\n",
      "|    policy_loss        | 9.11       |\n",
      "|    reward             | -3.1382842 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 5.2        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 91100     |\n",
      "|    time_elapsed       | 768       |\n",
      "|    total_timesteps    | 455500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 101099    |\n",
      "|    policy_loss        | -3.74     |\n",
      "|    reward             | 2.6643956 |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 0.662     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 91200      |\n",
      "|    time_elapsed       | 769        |\n",
      "|    total_timesteps    | 456000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.91      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 101199     |\n",
      "|    policy_loss        | 62.1       |\n",
      "|    reward             | -3.3106318 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 111        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 91300      |\n",
      "|    time_elapsed       | 769        |\n",
      "|    total_timesteps    | 456500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.93      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 101299     |\n",
      "|    policy_loss        | 2.76       |\n",
      "|    reward             | -2.8351614 |\n",
      "|    std                | 1.78       |\n",
      "|    value_loss         | 26.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 91400     |\n",
      "|    time_elapsed       | 770       |\n",
      "|    total_timesteps    | 457000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.93     |\n",
      "|    explained_variance | -3.58e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 101399    |\n",
      "|    policy_loss        | 89.4      |\n",
      "|    reward             | 3.0023615 |\n",
      "|    std                | 1.78      |\n",
      "|    value_loss         | 279       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 593         |\n",
      "|    iterations         | 91500       |\n",
      "|    time_elapsed       | 771         |\n",
      "|    total_timesteps    | 457500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.94       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 101499      |\n",
      "|    policy_loss        | -3.23       |\n",
      "|    reward             | -0.45082587 |\n",
      "|    std                | 1.78        |\n",
      "|    value_loss         | 0.967       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 91600     |\n",
      "|    time_elapsed       | 772       |\n",
      "|    total_timesteps    | 458000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 101599    |\n",
      "|    policy_loss        | 10.3      |\n",
      "|    reward             | 1.3432081 |\n",
      "|    std                | 1.78      |\n",
      "|    value_loss         | 8.35      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 91700      |\n",
      "|    time_elapsed       | 773        |\n",
      "|    total_timesteps    | 458500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.93      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 101699     |\n",
      "|    policy_loss        | -7.82      |\n",
      "|    reward             | -2.5855117 |\n",
      "|    std                | 1.78       |\n",
      "|    value_loss         | 1.55       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 592          |\n",
      "|    iterations         | 91800        |\n",
      "|    time_elapsed       | 774          |\n",
      "|    total_timesteps    | 459000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.93        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 101799       |\n",
      "|    policy_loss        | 22           |\n",
      "|    reward             | -0.104508005 |\n",
      "|    std                | 1.78         |\n",
      "|    value_loss         | 18.8         |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 593      |\n",
      "|    iterations         | 91900    |\n",
      "|    time_elapsed       | 774      |\n",
      "|    total_timesteps    | 459500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.95    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 101899   |\n",
      "|    policy_loss        | -2.15    |\n",
      "|    reward             | 4.468169 |\n",
      "|    std                | 1.78     |\n",
      "|    value_loss         | 3.41     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 92000     |\n",
      "|    time_elapsed       | 775       |\n",
      "|    total_timesteps    | 460000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.95     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 101999    |\n",
      "|    policy_loss        | -1.86     |\n",
      "|    reward             | -0.316706 |\n",
      "|    std                | 1.79      |\n",
      "|    value_loss         | 0.12      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 92100     |\n",
      "|    time_elapsed       | 776       |\n",
      "|    total_timesteps    | 460500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 102099    |\n",
      "|    policy_loss        | 1.91      |\n",
      "|    reward             | 1.0944039 |\n",
      "|    std                | 1.78      |\n",
      "|    value_loss         | 0.715     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 92200     |\n",
      "|    time_elapsed       | 777       |\n",
      "|    total_timesteps    | 461000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.92     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 102199    |\n",
      "|    policy_loss        | 0.725     |\n",
      "|    reward             | 1.7678173 |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 5.53      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 92300       |\n",
      "|    time_elapsed       | 778         |\n",
      "|    total_timesteps    | 461500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.93       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 102299      |\n",
      "|    policy_loss        | -17.4       |\n",
      "|    reward             | -0.19889253 |\n",
      "|    std                | 1.77        |\n",
      "|    value_loss         | 10          |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 92400      |\n",
      "|    time_elapsed       | 779        |\n",
      "|    total_timesteps    | 462000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 102399     |\n",
      "|    policy_loss        | 0.0665     |\n",
      "|    reward             | -1.5645821 |\n",
      "|    std                | 1.78       |\n",
      "|    value_loss         | 0.566      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 92500     |\n",
      "|    time_elapsed       | 780       |\n",
      "|    total_timesteps    | 462500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 102499    |\n",
      "|    policy_loss        | -45.6     |\n",
      "|    reward             | 3.3119793 |\n",
      "|    std                | 1.78      |\n",
      "|    value_loss         | 74.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 92600     |\n",
      "|    time_elapsed       | 780       |\n",
      "|    total_timesteps    | 463000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.93     |\n",
      "|    explained_variance | 0.28      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 102599    |\n",
      "|    policy_loss        | -5.82     |\n",
      "|    reward             | 1.5899769 |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 1.2       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 92700      |\n",
      "|    time_elapsed       | 781        |\n",
      "|    total_timesteps    | 463500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.93      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 102699     |\n",
      "|    policy_loss        | -7.27      |\n",
      "|    reward             | 0.71568495 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 1.83       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 92800     |\n",
      "|    time_elapsed       | 782       |\n",
      "|    total_timesteps    | 464000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.92     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 102799    |\n",
      "|    policy_loss        | -4.29     |\n",
      "|    reward             | 1.4278095 |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 5.76      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 92900       |\n",
      "|    time_elapsed       | 783         |\n",
      "|    total_timesteps    | 464500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.94       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 102899      |\n",
      "|    policy_loss        | -17.2       |\n",
      "|    reward             | -0.33747736 |\n",
      "|    std                | 1.78        |\n",
      "|    value_loss         | 9.59        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 93000     |\n",
      "|    time_elapsed       | 784       |\n",
      "|    total_timesteps    | 465000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.93     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 102999    |\n",
      "|    policy_loss        | 2.65      |\n",
      "|    reward             | 0.2734533 |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 0.893     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 93100      |\n",
      "|    time_elapsed       | 785        |\n",
      "|    total_timesteps    | 465500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.93      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 103099     |\n",
      "|    policy_loss        | -30.6      |\n",
      "|    reward             | -3.8165119 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 22.7       |\n",
      "--------------------------------------\n",
      "day: 2892, episode: 180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4125156.71\n",
      "total_reward: 3125156.71\n",
      "total_cost: 1006.99\n",
      "total_trades: 5810\n",
      "Sharpe: 0.710\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 93200     |\n",
      "|    time_elapsed       | 785       |\n",
      "|    total_timesteps    | 466000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.93     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 103199    |\n",
      "|    policy_loss        | 5.04      |\n",
      "|    reward             | -0.655184 |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 1.34      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 93300      |\n",
      "|    time_elapsed       | 786        |\n",
      "|    total_timesteps    | 466500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.93      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 103299     |\n",
      "|    policy_loss        | 11.3       |\n",
      "|    reward             | -0.6811851 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 8.16       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 93400      |\n",
      "|    time_elapsed       | 787        |\n",
      "|    total_timesteps    | 467000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 103399     |\n",
      "|    policy_loss        | 13         |\n",
      "|    reward             | 0.63983214 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 5.82       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 593         |\n",
      "|    iterations         | 93500       |\n",
      "|    time_elapsed       | 788         |\n",
      "|    total_timesteps    | 467500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.92       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 103499      |\n",
      "|    policy_loss        | 7.07        |\n",
      "|    reward             | -0.23926465 |\n",
      "|    std                | 1.77        |\n",
      "|    value_loss         | 3.7         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 93600      |\n",
      "|    time_elapsed       | 789        |\n",
      "|    total_timesteps    | 468000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.93      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 103599     |\n",
      "|    policy_loss        | 20.7       |\n",
      "|    reward             | -0.2935019 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 25.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 93700     |\n",
      "|    time_elapsed       | 789       |\n",
      "|    total_timesteps    | 468500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.92     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 103699    |\n",
      "|    policy_loss        | 26.8      |\n",
      "|    reward             | 2.4094553 |\n",
      "|    std                | 1.76      |\n",
      "|    value_loss         | 28.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 93800     |\n",
      "|    time_elapsed       | 790       |\n",
      "|    total_timesteps    | 469000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.93     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 103799    |\n",
      "|    policy_loss        | 0.356     |\n",
      "|    reward             | 0.8328723 |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 1.01      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 593      |\n",
      "|    iterations         | 93900    |\n",
      "|    time_elapsed       | 791      |\n",
      "|    total_timesteps    | 469500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.94    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 103899   |\n",
      "|    policy_loss        | -25.2    |\n",
      "|    reward             | 3.323605 |\n",
      "|    std                | 1.77     |\n",
      "|    value_loss         | 16       |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 94000      |\n",
      "|    time_elapsed       | 792        |\n",
      "|    total_timesteps    | 470000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.93      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 103999     |\n",
      "|    policy_loss        | 4.48       |\n",
      "|    reward             | -0.7272983 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 2.49       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 593      |\n",
      "|    iterations         | 94100    |\n",
      "|    time_elapsed       | 793      |\n",
      "|    total_timesteps    | 470500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.93    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 104099   |\n",
      "|    policy_loss        | -8.45    |\n",
      "|    reward             | 1.772587 |\n",
      "|    std                | 1.77     |\n",
      "|    value_loss         | 5.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 593      |\n",
      "|    iterations         | 94200    |\n",
      "|    time_elapsed       | 794      |\n",
      "|    total_timesteps    | 471000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.93    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 104199   |\n",
      "|    policy_loss        | 24.3     |\n",
      "|    reward             | 4.982748 |\n",
      "|    std                | 1.77     |\n",
      "|    value_loss         | 30.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 94300     |\n",
      "|    time_elapsed       | 794       |\n",
      "|    total_timesteps    | 471500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.92     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 104299    |\n",
      "|    policy_loss        | 50.8      |\n",
      "|    reward             | -2.275513 |\n",
      "|    std                | 1.76      |\n",
      "|    value_loss         | 184       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 593         |\n",
      "|    iterations         | 94400       |\n",
      "|    time_elapsed       | 795         |\n",
      "|    total_timesteps    | 472000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.92       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 104399      |\n",
      "|    policy_loss        | 6.96        |\n",
      "|    reward             | -0.82535875 |\n",
      "|    std                | 1.76        |\n",
      "|    value_loss         | 2           |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 94500      |\n",
      "|    time_elapsed       | 796        |\n",
      "|    total_timesteps    | 472500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.91      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 104499     |\n",
      "|    policy_loss        | -1.84      |\n",
      "|    reward             | -1.0840108 |\n",
      "|    std                | 1.76       |\n",
      "|    value_loss         | 1.27       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 94600     |\n",
      "|    time_elapsed       | 797       |\n",
      "|    total_timesteps    | 473000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 104599    |\n",
      "|    policy_loss        | 1.07      |\n",
      "|    reward             | 1.2354064 |\n",
      "|    std                | 1.76      |\n",
      "|    value_loss         | 0.346     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 94700     |\n",
      "|    time_elapsed       | 798       |\n",
      "|    total_timesteps    | 473500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 104699    |\n",
      "|    policy_loss        | -9.97     |\n",
      "|    reward             | 0.5742753 |\n",
      "|    std                | 1.75      |\n",
      "|    value_loss         | 10        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 94800     |\n",
      "|    time_elapsed       | 799       |\n",
      "|    total_timesteps    | 474000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.89     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 104799    |\n",
      "|    policy_loss        | -35.7     |\n",
      "|    reward             | 4.0263333 |\n",
      "|    std                | 1.74      |\n",
      "|    value_loss         | 18.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 94900      |\n",
      "|    time_elapsed       | 800        |\n",
      "|    total_timesteps    | 474500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.89      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 104899     |\n",
      "|    policy_loss        | -5.81      |\n",
      "|    reward             | -0.1400185 |\n",
      "|    std                | 1.75       |\n",
      "|    value_loss         | 1.55       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 95000     |\n",
      "|    time_elapsed       | 800       |\n",
      "|    total_timesteps    | 475000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.88     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 104999    |\n",
      "|    policy_loss        | -12       |\n",
      "|    reward             | 2.1574388 |\n",
      "|    std                | 1.74      |\n",
      "|    value_loss         | 4.71      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 95100     |\n",
      "|    time_elapsed       | 801       |\n",
      "|    total_timesteps    | 475500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.89     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 105099    |\n",
      "|    policy_loss        | -6.79     |\n",
      "|    reward             | 1.3816112 |\n",
      "|    std                | 1.75      |\n",
      "|    value_loss         | 3.1       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 95200     |\n",
      "|    time_elapsed       | 802       |\n",
      "|    total_timesteps    | 476000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.9      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 105199    |\n",
      "|    policy_loss        | 13.5      |\n",
      "|    reward             | 0.7030274 |\n",
      "|    std                | 1.75      |\n",
      "|    value_loss         | 8.21      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 95300     |\n",
      "|    time_elapsed       | 803       |\n",
      "|    total_timesteps    | 476500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.9      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 105299    |\n",
      "|    policy_loss        | 20.2      |\n",
      "|    reward             | 0.6892752 |\n",
      "|    std                | 1.75      |\n",
      "|    value_loss         | 12.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 95400     |\n",
      "|    time_elapsed       | 804       |\n",
      "|    total_timesteps    | 477000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.87     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 105399    |\n",
      "|    policy_loss        | -6.83     |\n",
      "|    reward             | 0.6366623 |\n",
      "|    std                | 1.74      |\n",
      "|    value_loss         | 3.28      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 95500     |\n",
      "|    time_elapsed       | 805       |\n",
      "|    total_timesteps    | 477500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.88     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 105499    |\n",
      "|    policy_loss        | 2.65      |\n",
      "|    reward             | -0.740017 |\n",
      "|    std                | 1.74      |\n",
      "|    value_loss         | 0.894     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 593      |\n",
      "|    iterations         | 95600    |\n",
      "|    time_elapsed       | 805      |\n",
      "|    total_timesteps    | 478000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.91    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 105599   |\n",
      "|    policy_loss        | -27.7    |\n",
      "|    reward             | 4.879873 |\n",
      "|    std                | 1.76     |\n",
      "|    value_loss         | 19.3     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 95700      |\n",
      "|    time_elapsed       | 806        |\n",
      "|    total_timesteps    | 478500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.91      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 105699     |\n",
      "|    policy_loss        | -3.48      |\n",
      "|    reward             | -4.0812807 |\n",
      "|    std                | 1.76       |\n",
      "|    value_loss         | 0.77       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 95800     |\n",
      "|    time_elapsed       | 807       |\n",
      "|    total_timesteps    | 479000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 105799    |\n",
      "|    policy_loss        | -40.2     |\n",
      "|    reward             | 0.7819324 |\n",
      "|    std                | 1.76      |\n",
      "|    value_loss         | 80.6      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 593         |\n",
      "|    iterations         | 95900       |\n",
      "|    time_elapsed       | 808         |\n",
      "|    total_timesteps    | 479500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.91       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 105899      |\n",
      "|    policy_loss        | -29.8       |\n",
      "|    reward             | -0.99280834 |\n",
      "|    std                | 1.76        |\n",
      "|    value_loss         | 26.1        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 96000     |\n",
      "|    time_elapsed       | 809       |\n",
      "|    total_timesteps    | 480000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 105999    |\n",
      "|    policy_loss        | 5.75      |\n",
      "|    reward             | 1.6796885 |\n",
      "|    std                | 1.76      |\n",
      "|    value_loss         | 6.44      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 96100     |\n",
      "|    time_elapsed       | 810       |\n",
      "|    total_timesteps    | 480500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 106099    |\n",
      "|    policy_loss        | -11.4     |\n",
      "|    reward             | 2.1690996 |\n",
      "|    std                | 1.76      |\n",
      "|    value_loss         | 4.99      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 96200      |\n",
      "|    time_elapsed       | 810        |\n",
      "|    total_timesteps    | 481000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.92      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 106199     |\n",
      "|    policy_loss        | 8.37       |\n",
      "|    reward             | 0.71516573 |\n",
      "|    std                | 1.76       |\n",
      "|    value_loss         | 3.04       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 96300      |\n",
      "|    time_elapsed       | 811        |\n",
      "|    total_timesteps    | 481500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.91      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 106299     |\n",
      "|    policy_loss        | 16.2       |\n",
      "|    reward             | -2.2729313 |\n",
      "|    std                | 1.76       |\n",
      "|    value_loss         | 8.55       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 96400      |\n",
      "|    time_elapsed       | 812        |\n",
      "|    total_timesteps    | 482000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.89      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 106399     |\n",
      "|    policy_loss        | 7.3        |\n",
      "|    reward             | -2.3658621 |\n",
      "|    std                | 1.75       |\n",
      "|    value_loss         | 5.99       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 96500     |\n",
      "|    time_elapsed       | 813       |\n",
      "|    total_timesteps    | 482500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.9      |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 106499    |\n",
      "|    policy_loss        | -6.73     |\n",
      "|    reward             | 0.6829218 |\n",
      "|    std                | 1.75      |\n",
      "|    value_loss         | 3.47      |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 593          |\n",
      "|    iterations         | 96600        |\n",
      "|    time_elapsed       | 814          |\n",
      "|    total_timesteps    | 483000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.87        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 106599       |\n",
      "|    policy_loss        | 18.1         |\n",
      "|    reward             | -0.047350522 |\n",
      "|    std                | 1.74         |\n",
      "|    value_loss         | 13           |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 96700      |\n",
      "|    time_elapsed       | 815        |\n",
      "|    total_timesteps    | 483500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.89      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 106699     |\n",
      "|    policy_loss        | 20.6       |\n",
      "|    reward             | -1.3020796 |\n",
      "|    std                | 1.75       |\n",
      "|    value_loss         | 17.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 96800     |\n",
      "|    time_elapsed       | 815       |\n",
      "|    total_timesteps    | 484000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.88     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 106799    |\n",
      "|    policy_loss        | 19.5      |\n",
      "|    reward             | 1.9425244 |\n",
      "|    std                | 1.74      |\n",
      "|    value_loss         | 15.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 96900      |\n",
      "|    time_elapsed       | 816        |\n",
      "|    total_timesteps    | 484500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.87      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 106899     |\n",
      "|    policy_loss        | 8.93       |\n",
      "|    reward             | -1.2319022 |\n",
      "|    std                | 1.74       |\n",
      "|    value_loss         | 3.05       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 97000     |\n",
      "|    time_elapsed       | 817       |\n",
      "|    total_timesteps    | 485000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.88     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 106999    |\n",
      "|    policy_loss        | 21.3      |\n",
      "|    reward             | 0.5718086 |\n",
      "|    std                | 1.74      |\n",
      "|    value_loss         | 27.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 97100     |\n",
      "|    time_elapsed       | 818       |\n",
      "|    total_timesteps    | 485500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.9      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 107099    |\n",
      "|    policy_loss        | 0.29      |\n",
      "|    reward             | 2.6115031 |\n",
      "|    std                | 1.75      |\n",
      "|    value_loss         | 1.22      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 97200      |\n",
      "|    time_elapsed       | 819        |\n",
      "|    total_timesteps    | 486000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.9       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 107199     |\n",
      "|    policy_loss        | 35.3       |\n",
      "|    reward             | -1.6943358 |\n",
      "|    std                | 1.75       |\n",
      "|    value_loss         | 67.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 97300      |\n",
      "|    time_elapsed       | 820        |\n",
      "|    total_timesteps    | 486500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.9       |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 107299     |\n",
      "|    policy_loss        | -13.5      |\n",
      "|    reward             | 0.32857502 |\n",
      "|    std                | 1.75       |\n",
      "|    value_loss         | 8.53       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 97400      |\n",
      "|    time_elapsed       | 821        |\n",
      "|    total_timesteps    | 487000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.9       |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 107399     |\n",
      "|    policy_loss        | -18.9      |\n",
      "|    reward             | 0.88787407 |\n",
      "|    std                | 1.75       |\n",
      "|    value_loss         | 13.6       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 97500     |\n",
      "|    time_elapsed       | 821       |\n",
      "|    total_timesteps    | 487500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 107499    |\n",
      "|    policy_loss        | -10.5     |\n",
      "|    reward             | -1.419413 |\n",
      "|    std                | 1.76      |\n",
      "|    value_loss         | 3.33      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 593      |\n",
      "|    iterations         | 97600    |\n",
      "|    time_elapsed       | 822      |\n",
      "|    total_timesteps    | 488000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.93    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 107599   |\n",
      "|    policy_loss        | 6.9      |\n",
      "|    reward             | 4.642913 |\n",
      "|    std                | 1.77     |\n",
      "|    value_loss         | 1.75     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 97700     |\n",
      "|    time_elapsed       | 823       |\n",
      "|    total_timesteps    | 488500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.93     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 107699    |\n",
      "|    policy_loss        | -22.2     |\n",
      "|    reward             | 1.0959715 |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 23.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 97800      |\n",
      "|    time_elapsed       | 824        |\n",
      "|    total_timesteps    | 489000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 107799     |\n",
      "|    policy_loss        | -0.964     |\n",
      "|    reward             | 0.71181875 |\n",
      "|    std                | 1.78       |\n",
      "|    value_loss         | 0.152      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 97900     |\n",
      "|    time_elapsed       | 825       |\n",
      "|    total_timesteps    | 489500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 107899    |\n",
      "|    policy_loss        | -1.95     |\n",
      "|    reward             | 1.7928663 |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 0.46      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 98000     |\n",
      "|    time_elapsed       | 826       |\n",
      "|    total_timesteps    | 490000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 107999    |\n",
      "|    policy_loss        | -15       |\n",
      "|    reward             | 1.1267631 |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 7.66      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 98100     |\n",
      "|    time_elapsed       | 826       |\n",
      "|    total_timesteps    | 490500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 108099    |\n",
      "|    policy_loss        | -0.372    |\n",
      "|    reward             | 6.4148035 |\n",
      "|    std                | 1.78      |\n",
      "|    value_loss         | 0.102     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 593         |\n",
      "|    iterations         | 98200       |\n",
      "|    time_elapsed       | 827         |\n",
      "|    total_timesteps    | 491000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.95       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 108199      |\n",
      "|    policy_loss        | -9.32       |\n",
      "|    reward             | -0.14380254 |\n",
      "|    std                | 1.78        |\n",
      "|    value_loss         | 3.32        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 98300      |\n",
      "|    time_elapsed       | 828        |\n",
      "|    total_timesteps    | 491500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.96      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 108299     |\n",
      "|    policy_loss        | 19.5       |\n",
      "|    reward             | -2.0894246 |\n",
      "|    std                | 1.78       |\n",
      "|    value_loss         | 17         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 98400      |\n",
      "|    time_elapsed       | 829        |\n",
      "|    total_timesteps    | 492000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.95      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 108399     |\n",
      "|    policy_loss        | -9.9       |\n",
      "|    reward             | 0.26702634 |\n",
      "|    std                | 1.78       |\n",
      "|    value_loss         | 3.14       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 593         |\n",
      "|    iterations         | 98500       |\n",
      "|    time_elapsed       | 830         |\n",
      "|    total_timesteps    | 492500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.94       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 108499      |\n",
      "|    policy_loss        | 2.72        |\n",
      "|    reward             | -0.22179851 |\n",
      "|    std                | 1.78        |\n",
      "|    value_loss         | 5.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 593         |\n",
      "|    iterations         | 98600       |\n",
      "|    time_elapsed       | 831         |\n",
      "|    total_timesteps    | 493000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.96       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 108599      |\n",
      "|    policy_loss        | 16.5        |\n",
      "|    reward             | -0.41057318 |\n",
      "|    std                | 1.79        |\n",
      "|    value_loss         | 6.41        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 98700     |\n",
      "|    time_elapsed       | 832       |\n",
      "|    total_timesteps    | 493500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.96     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 108699    |\n",
      "|    policy_loss        | -5.46     |\n",
      "|    reward             | 2.4610407 |\n",
      "|    std                | 1.78      |\n",
      "|    value_loss         | 3.24      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 98800      |\n",
      "|    time_elapsed       | 832        |\n",
      "|    total_timesteps    | 494000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.99      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 108799     |\n",
      "|    policy_loss        | -3.17      |\n",
      "|    reward             | -0.8558262 |\n",
      "|    std                | 1.8        |\n",
      "|    value_loss         | 0.563      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 98900      |\n",
      "|    time_elapsed       | 833        |\n",
      "|    total_timesteps    | 494500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.99      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 108899     |\n",
      "|    policy_loss        | 19.1       |\n",
      "|    reward             | -1.6586671 |\n",
      "|    std                | 1.8        |\n",
      "|    value_loss         | 18.7       |\n",
      "--------------------------------------\n",
      "day: 2892, episode: 190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3271178.95\n",
      "total_reward: 2271178.95\n",
      "total_cost: 1245.19\n",
      "total_trades: 6047\n",
      "Sharpe: 0.609\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 99000      |\n",
      "|    time_elapsed       | 834        |\n",
      "|    total_timesteps    | 495000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.99      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 108999     |\n",
      "|    policy_loss        | -7.43      |\n",
      "|    reward             | 0.22576833 |\n",
      "|    std                | 1.8        |\n",
      "|    value_loss         | 1.69       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 99100     |\n",
      "|    time_elapsed       | 835       |\n",
      "|    total_timesteps    | 495500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.98     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 109099    |\n",
      "|    policy_loss        | 17.1      |\n",
      "|    reward             | 0.9854156 |\n",
      "|    std                | 1.8       |\n",
      "|    value_loss         | 9.97      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 99200      |\n",
      "|    time_elapsed       | 836        |\n",
      "|    total_timesteps    | 496000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.98      |\n",
      "|    explained_variance | 0.00542    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 109199     |\n",
      "|    policy_loss        | -1.37      |\n",
      "|    reward             | 0.31071833 |\n",
      "|    std                | 1.79       |\n",
      "|    value_loss         | 0.599      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 99300      |\n",
      "|    time_elapsed       | 837        |\n",
      "|    total_timesteps    | 496500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.99      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 109299     |\n",
      "|    policy_loss        | 45.9       |\n",
      "|    reward             | 0.55810064 |\n",
      "|    std                | 1.81       |\n",
      "|    value_loss         | 50.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 99400      |\n",
      "|    time_elapsed       | 837        |\n",
      "|    total_timesteps    | 497000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.02      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 109399     |\n",
      "|    policy_loss        | -25.1      |\n",
      "|    reward             | -0.3823005 |\n",
      "|    std                | 1.82       |\n",
      "|    value_loss         | 52.5       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 99500      |\n",
      "|    time_elapsed       | 838        |\n",
      "|    total_timesteps    | 497500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.02      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 109499     |\n",
      "|    policy_loss        | 96.5       |\n",
      "|    reward             | -2.0884597 |\n",
      "|    std                | 1.82       |\n",
      "|    value_loss         | 470        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 99600      |\n",
      "|    time_elapsed       | 839        |\n",
      "|    total_timesteps    | 498000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6         |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 109599     |\n",
      "|    policy_loss        | 7.24       |\n",
      "|    reward             | -1.9335707 |\n",
      "|    std                | 1.81       |\n",
      "|    value_loss         | 2.22       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 99700     |\n",
      "|    time_elapsed       | 840       |\n",
      "|    total_timesteps    | 498500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.02     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 109699    |\n",
      "|    policy_loss        | 23.8      |\n",
      "|    reward             | 4.1661496 |\n",
      "|    std                | 1.82      |\n",
      "|    value_loss         | 19        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 99800      |\n",
      "|    time_elapsed       | 841        |\n",
      "|    total_timesteps    | 499000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.01      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 109799     |\n",
      "|    policy_loss        | 2.65       |\n",
      "|    reward             | -2.6489031 |\n",
      "|    std                | 1.81       |\n",
      "|    value_loss         | 1.73       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 593         |\n",
      "|    iterations         | 99900       |\n",
      "|    time_elapsed       | 842         |\n",
      "|    total_timesteps    | 499500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.01       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 109899      |\n",
      "|    policy_loss        | 19.7        |\n",
      "|    reward             | -0.79048043 |\n",
      "|    std                | 1.81        |\n",
      "|    value_loss         | 12.7        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 100000     |\n",
      "|    time_elapsed       | 843        |\n",
      "|    total_timesteps    | 500000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.99      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 109999     |\n",
      "|    policy_loss        | 8.76       |\n",
      "|    reward             | 0.80595475 |\n",
      "|    std                | 1.8        |\n",
      "|    value_loss         | 5.74       |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=500000) if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(model=trained_a2c, \n",
    "                        environment = e_train_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_account_value_a2c.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_actions_a2c[df_actions_a2c['inm'] >= 100 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aapl</th>\n",
       "      <th>ibm</th>\n",
       "      <th>msft</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01-02</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-05</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-06</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-07</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-08</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2892 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aapl  ibm  msft\n",
       "date                       \n",
       "2009-01-02     0  100   100\n",
       "2009-01-05     0  100   100\n",
       "2009-01-06     0  100   100\n",
       "2009-01-07     0  100   100\n",
       "2009-01-08     0  100   100\n",
       "...          ...  ...   ...\n",
       "2020-06-23     0    0     0\n",
       "2020-06-24     0    0     0\n",
       "2020-06-25     0    0     0\n",
       "2020-06-26     0    0     0\n",
       "2020-06-29     0    0     0\n",
       "\n",
       "[2892 rows x 3 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions_a2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "ex = ccxt.binance()\n",
    "\n",
    "df_rrw = ex.fetch_ohlcv('BTC/USDT', '1d', since=1496787634826, limit=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-17</th>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4485.39</td>\n",
       "      <td>4200.74</td>\n",
       "      <td>4285.08</td>\n",
       "      <td>795.150377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-18</th>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>4285.08</td>\n",
       "      <td>4371.52</td>\n",
       "      <td>3938.77</td>\n",
       "      <td>4108.37</td>\n",
       "      <td>1199.888264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-19</th>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>4108.37</td>\n",
       "      <td>4184.69</td>\n",
       "      <td>3850.00</td>\n",
       "      <td>4139.98</td>\n",
       "      <td>381.309763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-20</th>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>4120.98</td>\n",
       "      <td>4211.08</td>\n",
       "      <td>4032.62</td>\n",
       "      <td>4086.29</td>\n",
       "      <td>467.083022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-21</th>\n",
       "      <td>2017-08-21</td>\n",
       "      <td>4069.13</td>\n",
       "      <td>4119.62</td>\n",
       "      <td>3911.79</td>\n",
       "      <td>4016.00</td>\n",
       "      <td>691.743060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date     open     high      low    close       volume\n",
       "date                                                                  \n",
       "2017-08-17 2017-08-17  4261.48  4485.39  4200.74  4285.08   795.150377\n",
       "2017-08-18 2017-08-18  4285.08  4371.52  3938.77  4108.37  1199.888264\n",
       "2017-08-19 2017-08-19  4108.37  4184.69  3850.00  4139.98   381.309763\n",
       "2017-08-20 2017-08-20  4120.98  4211.08  4032.62  4086.29   467.083022\n",
       "2017-08-21 2017-08-21  4069.13  4119.62  3911.79  4016.00   691.743060"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(df_rrw, columns=['date', 'open', 'high', 'low', 'close', 'volume'])\n",
    "df['date'] = pd.to_datetime(df['date'], unit='ms')\n",
    "df.set_index(df['date'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_df = df.loc['2018-01-01':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='date'>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sliced_df['close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='date'>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Download data for US Federal Funds Rate\n",
    "fed_funds_data = yf.download(\"^IRX\", start=\"2018-01-01\", end=\"2020-06-05\")\n",
    "\n",
    "# Access closing prices (daily interest rates)\n",
    "daily_rates = fed_funds_data[\"Close\"]\n",
    "\n",
    "# Print the first few daily rates\n",
    "daily_rates.plot()\n",
    "df['close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_price = np.array(df['close']).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "preprocessor = MinMaxScaler()\n",
    "df['close_scaled'] = preprocessor.fit_transform(close_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='date'>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['close_scaled'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, open, high, low, close, volume]\n",
       "Index: []"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliced_df = df.loc['2018-01-01':]\n",
    "sliced_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='date'>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "daily_rates.plot()\n",
    "df['close_scaled'].plot( color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='api.example.com', port=443): Max retries exceeded with url: /ftse-global-digital-asset-index?index=FTSE_GLOBAL_DIGITAL_ASSET_50&start_date=2023-01-01&end_date=2023-12-31 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001712601E890>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    175\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\urllib3\\util\\connection.py:72\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m six\u001b[38;5;241m.\u001b[39mraise_from(\n\u001b[0;32m     69\u001b[0m         LocationParseError(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label empty or too long\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m host), \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     )\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     73\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:955\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    954\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 955\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    956\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\urllib3\\connectionpool.py:715\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 715\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\urllib3\\connectionpool.py:404\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 404\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\urllib3\\connectionpool.py:1058\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1058\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\urllib3\\connection.py:363\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\urllib3\\connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x000001712601E890>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\requests\\adapters.py:589\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 589\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\urllib3\\connectionpool.py:799\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    797\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 799\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    802\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api.example.com', port=443): Max retries exceeded with url: /ftse-global-digital-asset-index?index=FTSE_GLOBAL_DIGITAL_ASSET_50&start_date=2023-01-01&end_date=2023-12-31 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001712601E890>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[194], line 13\u001b[0m\n\u001b[0;32m      6\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFTSE_GLOBAL_DIGITAL_ASSET_50\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_date\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_date\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023-12-31\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     10\u001b[0m }\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Fetch the data\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Convert the data to a pandas DataFrame\u001b[39;00m\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\requests\\adapters.py:622\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    619\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    620\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m--> 622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='api.example.com', port=443): Max retries exceeded with url: /ftse-global-digital-asset-index?index=FTSE_GLOBAL_DIGITAL_ASSET_50&start_date=2023-01-01&end_date=2023-12-31 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001712601E890>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Define the API endpoint and parameters\n",
    "api_url = \"https://api.example.com/ftse-global-digital-asset-index\"\n",
    "params = {\n",
    "    'index': 'FTSE_GLOBAL_DIGITAL_ASSET_50',\n",
    "    'start_date': '2023-01-01',\n",
    "    'end_date': '2023-12-31'\n",
    "}\n",
    "\n",
    "# Fetch the data\n",
    "response = requests.get(api_url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "# Convert the data to a pandas DataFrame\n",
    "df = pd.DataFrame(data['prices'])\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not parse JSON data!\n",
      "Reason: HTTPSConnectionPool(host='api.example.com', port=443): Max retries exceeded with url: /ftse-global-digital-asset-index (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000171279A9BA0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "try:\n",
    "  # Your code to fetch data (replace with your actual API call)\n",
    "  response = requests.get(\"https://api.example.com/ftse-global-digital-asset-index\")\n",
    "  data = response.json()  # This line might raise the JSONDecodeError\n",
    "\n",
    "  # Process the data here (assuming it's valid JSON)\n",
    "  print(data[\"key\"])  # Access data from the JSON object\n",
    "\n",
    "except Exception as e:\n",
    "  print(\"Error: Could not parse JSON data!\")\n",
    "  print(f\"Reason: {e}\")  # Print the error message for debugging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': {'timestamp': '2024-06-05T16:20:05.848Z', 'error_code': 1002, 'error_message': 'API key missing.', 'elapsed': 0, 'credit_count': 0}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from json import JSONDecodeError\n",
    "\n",
    "try:\n",
    "  response = requests.get(\"https://pro-api.coinmarketcap.com/v1/global-metrics/quotes/historical\")\n",
    "  data = response.json()  # This line might raise the JSONDecodeError or other exceptions\n",
    "\n",
    "  # Process the data here (assuming it's valid JSON)\n",
    "  print(data)  # Access data from the JSON object\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "  # Handle different request exceptions\n",
    "  if isinstance(e, requests.exceptions.ConnectionError):\n",
    "    print(\"Error: Could not connect to the API server!\")\n",
    "    print(f\"Reason: {e}\")  # Print the connection error details\n",
    "  elif isinstance(e, requests.exceptions.Timeout):\n",
    "    print(\"Error: API request timed out!\")\n",
    "  else:\n",
    "    print(f\"An error occurred while making the API request: {e}\")\n",
    "\n",
    "except JSONDecodeError as e:\n",
    "  print(\"Error: Could not parse JSON data!\")\n",
    "  print(f\"Reason: {e}\")  # Print the JSON parsing error for debugging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_var():\n",
    "    global new_var \n",
    "    new_var = 4; \n",
    "    return new_var \n",
    "\n",
    "# global_var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_var(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class variable: 10\n",
      "Class attribute: Global value\n",
      "Instance variable: 20\n",
      "Class variable: 10\n",
      "Class attribute: Global value\n",
      "Instance variable: 30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class MyClass:\n",
    "    class_var = 10  # Class variable (shared)\n",
    "\n",
    "    def __init__(self, value):\n",
    "        self.instance_var = value  # Instance variable\n",
    "\n",
    "    def some_method(self):\n",
    "        print(\"Class variable:\", MyClass.class_var)  # No `global` needed\n",
    "        print(\"Class attribute:\", MyClass.shared_data)  # No `global` needed\n",
    "        print(\"Instance variable:\", self.instance_var)\n",
    "\n",
    "# Set class-level attribute\n",
    "MyClass.shared_data = \"Global value\"\n",
    "\n",
    "obj1 = MyClass(20)\n",
    "obj2 = MyClass(30)\n",
    "\n",
    "obj1.some_method()\n",
    "obj2.some_method()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\RL-Project\\Py310-venv\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> \n",
       "\n",
       " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> \n",
       "\n",
       " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " flatten (\u001b[38;5;33mFlatten\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m12,416\u001b[0m \n",
       "\n",
       " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m16,512\u001b[0m \n",
       "\n",
       " dense_2 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                         \u001b[38;5;34m129\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,057</span> (113.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,057\u001b[0m (113.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,057</span> (113.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,057\u001b[0m (113.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer (flattening the input)\n",
    "model.add(Flatten(input_shape=(6, 16)))  # 6 time steps, 16 features per time step\n",
    "\n",
    "# Hidden layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Output layer (example with a single output, e.g., future price or action value)\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traditional_opportunity_cost(current_balance, initial_balance, max_steps, current_step):\n",
    "  \"\"\"\n",
    "  Calculates opportunity cost based on traditional definition.\n",
    "\n",
    "  Args:\n",
    "      current_balance (float): The current account balance.\n",
    "      initial_balance (float): The initial account balance.\n",
    "      max_steps (int): The maximum number of steps (e.g., investment period).\n",
    "      current_step (int): The current step in the investment period.\n",
    "\n",
    "  Returns:\n",
    "      float: The opportunity cost.\n",
    "  \"\"\"\n",
    "\n",
    "  # Check for zero initial balance to avoid division by zero\n",
    "  if initial_balance == 0:\n",
    "    return 0\n",
    "\n",
    "  # Calculate the potential return if invested elsewhere\n",
    "  potential_return = (max_steps - current_step) * (current_balance - initial_balance) / initial_balance\n",
    "\n",
    "  return potential_return\n",
    "\n",
    "\n",
    "\n",
    "def custom_opportunity_cost(current_balance, max_steps, current_step):\n",
    "  \"\"\"\n",
    "  Calculates opportunity cost based on the custom definition.\n",
    "\n",
    "  Args:\n",
    "      current_balance (float): The current account balance.\n",
    "      max_steps (int): The maximum number of steps (e.g., investment period).\n",
    "      current_step (int): The current step in the investment period.\n",
    "\n",
    "  Returns:\n",
    "      float: The opportunity cost.\n",
    "  \"\"\"\n",
    "\n",
    "  # Avoid division by zero\n",
    "  if current_step == 0:\n",
    "    return 0\n",
    "\n",
    "  return current_balance * current_step / max_steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Failed to fetch data: 400\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 44\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Assume you already have your daily OHLC data in a DataFrame called ohlc_df\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Example OHLC DataFrame structure\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m ohlc_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdate_range\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2018-01-01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2023-12-31\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopen\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1516\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcumsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhigh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1516\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcumsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1516\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcumsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1516\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcumsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m ohlc_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(ohlc_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     52\u001b[0m ohlc_df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "# Function to fetch data from FRED API\n",
    "def fetch_interest_rate_data(api_key, series_id, start_date, end_date):\n",
    "    url = f\"https://api.stlouisfed.org/fred/series/observations\"\n",
    "    params = {\n",
    "        \"series_id\": series_id,\n",
    "        \"api_key\": api_key,\n",
    "        \"file_type\": \"json\",\n",
    "        \"observation_start\": start_date,\n",
    "        \"observation_end\": end_date,\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to fetch data: {response.status_code}\")\n",
    "    data = response.json()\n",
    "    if 'observations' not in data:\n",
    "        raise KeyError(\"'observations' not found in the API response\")\n",
    "    observations = data['observations']\n",
    "    dates = [obs['date'] for obs in observations]\n",
    "    values = [float(obs['value']) for obs in observations]\n",
    "    return pd.DataFrame({'date': dates, 'interest_rate': values})\n",
    "\n",
    "# Your FRED API key\n",
    "api_key = 'your_fred_api_key'\n",
    "series_id = 'DFF'  # This is the FRED series ID for the Federal Funds Rate\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2023-12-31'\n",
    "\n",
    "try:\n",
    "    # Fetch the interest rate data\n",
    "    interest_rate_df = fetch_interest_rate_data(api_key, series_id, start_date, end_date)\n",
    "    interest_rate_df['date'] = pd.to_datetime(interest_rate_df['date'])\n",
    "    interest_rate_df.set_index('date', inplace=True)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Assume you already have your daily OHLC data in a DataFrame called ohlc_df\n",
    "# Example OHLC DataFrame structure\n",
    "ohlc_df = pd.DataFrame({\n",
    "    'date': pd.date_range(start='2018-01-01', end='2023-12-31', freq='B'),\n",
    "    'open': 100 + np.random.randn(1516).cumsum(),\n",
    "    'high': 100 + np.random.randn(1516).cumsum(),\n",
    "    'low': 100 + np.random.randn(1516).cumsum(),\n",
    "    'close': 100 + np.random.randn(1516).cumsum()\n",
    "})\n",
    "ohlc_df['date'] = pd.to_datetime(ohlc_df['date'])\n",
    "ohlc_df.set_index('date', inplace=True)\n",
    "\n",
    "if 'interest_rate_df' in locals():\n",
    "    # Merge and backfill the interest rate data to match the OHLC data frequency\n",
    "    merged_df = ohlc_df.merge(interest_rate_df, left_index=True, right_index=True, how='left')\n",
    "    merged_df['interest_rate'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "    # Display the merged DataFrame\n",
    "    print(merged_df.head(10))\n",
    "else:\n",
    "    print(\"Interest rate data was not successfully fetched.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
