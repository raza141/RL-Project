{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from main import get_preprocessed_data\n",
    "from indicator_and_strategy.indicators import Indicator\n",
    "from indicator_and_strategy.momentumstrategy import MomentumStrategy\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import talib\n",
    "import datetime as dt\n",
    "\n",
    "from finrl.meta.preprocessor.yahoodownloader import  YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl import config_tickers\n",
    "from finrl.config import INDICATORS\n",
    "import itertools\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dollar PnL calculation\n",
    "\n",
    "pnls = []\n",
    "dates = []\n",
    "entry = None\n",
    "for i in range(len(df)):\n",
    "    if df['emas'].iloc[i] > df['emal'].iloc[i] and df['emas'].iloc[i-1] < df['emal'].iloc[i-1]:\n",
    "        if entry:\n",
    "            pnl = entry - df['close'].iloc[i]\n",
    "            pnls.append(pnl)\n",
    "            dates.append(df.index[i])\n",
    "            print(f'Buy on {df.index[i]} and at {df.close.iloc[i]}: {pnl}')\n",
    "        entry = df['close'].iloc[i]\n",
    "\n",
    "    elif df['emas'].iloc[i] < df['emal'].iloc[i] and df['emas'].iloc[i-1] > df['emal'].iloc[i-1]:\n",
    "        if entry:\n",
    "            pnl = df['close'].iloc[i] - entry\n",
    "            pnls.append(pnl)\n",
    "            dates.append(df.index[i])\n",
    "            print(f'Sell on {df.index[i]} at {df.close.iloc[i]}: {pnl}')\n",
    "        entry = df['close'].iloc[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentage PnL calculation\n",
    "pnls = []\n",
    "dates = []\n",
    "entry = None\n",
    "for i in range(len(df)):\n",
    "    if df['emas'].iloc[i] > df['emal'].iloc[i] and df['emas'].iloc[i-1] < df['emal'].iloc[i-1]:\n",
    "        if entry:\n",
    "            pnl = (entry - df['close'].iloc[i]) / entry\n",
    "            pnls.append(pnl)\n",
    "            dates.append(df.index[i])\n",
    "            print(f'Buy on {df.index[i]} and at {df.close.iloc[i]}: {pnl}')\n",
    "        entry = df['close'].iloc[i]\n",
    "\n",
    "\n",
    "    elif df['emas'].iloc[i] < df['emal'].iloc[i] and df['emas'].iloc[i-1] > df['emal'].iloc[i-1]:\n",
    "        if entry:\n",
    "            pnl = (df['close'].iloc[i] - entry) / entry\n",
    "            pnls.append(pnl)\n",
    "            dates.append(df.index[i])\n",
    "            print(f'Sell on {df.index[i]} at {df.close.iloc[i]}: {pnl}')\n",
    "        entry = df['close'].iloc[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Unrealized PnL \n",
    "\n",
    "entry = None\n",
    "pnls = []\n",
    "dates = []\n",
    "inpos = 0\n",
    "unrlzd = []\n",
    "urlzd_dates = []\n",
    "hold_time = []\n",
    "for i in range(len(df)):\n",
    "    unr = (spy.iloc[i] -spy.iloc[i - 1]) * inpos\n",
    "    unrlzd.append(unr)\n",
    "    urlzd_dates.append(df.index[i])\n",
    "    hold_time.append((df['close'].index[i] - start).days)\n",
    "    if df['emas'].iloc[i] > df['emal'].iloc[i] and df['emas'].iloc[i-1] < df['emal'].iloc[i-1]:\n",
    "        if entry:\n",
    "            pnl = entry - spy.iloc[i]\n",
    "            pnls.append(pnl)\n",
    "            dates.append(df.index[i])\n",
    "            print(f'Buy on {df.index[i]} and at {df.close.iloc[i]}: {pnl}')\n",
    "        entry = df['close'].index[i]\n",
    "        inpos = 1\n",
    "        start = df.index[i]\n",
    "\n",
    "    elif df['emas'].iloc[i] < df['emal'].iloc[i] and df['emas'].iloc[i-1] > df['emal'].iloc[i-1]:\n",
    "        if entry:\n",
    "            pnl = spy.iloc[i] - entry\n",
    "            pnls.append(pnl)\n",
    "            dates.append(df.index[i])\n",
    "            print(f'Sell on {df.index[i]} at {df.close.iloc[i]}: {pnl}')\n",
    "        entry = df['close'].iloc[i]\n",
    "        inpos = -1\n",
    "        start = df['close'].index[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Unrealized PnL vs Realized PnL')\n",
    "plt.plot(urlzd_dates, np.cumsum(unrlzd))\n",
    "plt.plot(dates, np.cumsum(pnls), '-o')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantifying the strategy: How good is it?\n",
    "\n",
    "sharp_ratio = np.mean(unrlzd) / np.std(unrlzd) * np.sqrt(252)\n",
    "print(f'Annualized Sharpe Ratio: {sharp_ratio}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sharp_ratio = np.mean(unrlzd) / np.std(unrlzd) * 16\n",
    "print(f'Annualized Sharpe Ratio: {sharp_ratio}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_START_DATE = '2009-01-01'\n",
    "TRAIN_END_DATE = '2020-07-01'\n",
    "TRADE_START_DATE = '2020-07-01'\n",
    "TRADE_END_DATE = '2023-05-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = [\n",
    "    'aapl', \n",
    "    'msft',\n",
    "    'meta',\n",
    "    'ibm'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (13569, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw = YahooDownloader(start_date = TRAIN_START_DATE,\n",
    "                     end_date = TRADE_END_DATE,\n",
    "                     ticker_list = symbols\n",
    "                     ).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>3.067143</td>\n",
       "      <td>3.251429</td>\n",
       "      <td>3.041429</td>\n",
       "      <td>2.740173</td>\n",
       "      <td>746015200</td>\n",
       "      <td>aapl</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>80.200768</td>\n",
       "      <td>83.738052</td>\n",
       "      <td>80.200768</td>\n",
       "      <td>49.160149</td>\n",
       "      <td>7905877</td>\n",
       "      <td>ibm</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>19.530001</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>19.370001</td>\n",
       "      <td>15.011639</td>\n",
       "      <td>50084000</td>\n",
       "      <td>msft</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>3.327500</td>\n",
       "      <td>3.435000</td>\n",
       "      <td>3.311071</td>\n",
       "      <td>2.855819</td>\n",
       "      <td>1181608400</td>\n",
       "      <td>aapl</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>82.619499</td>\n",
       "      <td>83.814529</td>\n",
       "      <td>82.390060</td>\n",
       "      <td>48.850681</td>\n",
       "      <td>8698222</td>\n",
       "      <td>ibm</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>20.200001</td>\n",
       "      <td>20.670000</td>\n",
       "      <td>20.059999</td>\n",
       "      <td>15.151946</td>\n",
       "      <td>61475200</td>\n",
       "      <td>msft</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2009-01-06</td>\n",
       "      <td>3.426786</td>\n",
       "      <td>3.470357</td>\n",
       "      <td>3.299643</td>\n",
       "      <td>2.808713</td>\n",
       "      <td>1289310400</td>\n",
       "      <td>aapl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2009-01-06</td>\n",
       "      <td>83.279160</td>\n",
       "      <td>86.434036</td>\n",
       "      <td>82.571701</td>\n",
       "      <td>50.206703</td>\n",
       "      <td>10093377</td>\n",
       "      <td>ibm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2009-01-06</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>20.610001</td>\n",
       "      <td>15.329155</td>\n",
       "      <td>58083400</td>\n",
       "      <td>msft</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2009-01-07</td>\n",
       "      <td>3.278929</td>\n",
       "      <td>3.303571</td>\n",
       "      <td>3.223571</td>\n",
       "      <td>2.748023</td>\n",
       "      <td>753048800</td>\n",
       "      <td>aapl</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       open       high        low      close      volume   tic  \\\n",
       "0  2009-01-02   3.067143   3.251429   3.041429   2.740173   746015200  aapl   \n",
       "1  2009-01-02  80.200768  83.738052  80.200768  49.160149     7905877   ibm   \n",
       "2  2009-01-02  19.530001  20.400000  19.370001  15.011639    50084000  msft   \n",
       "3  2009-01-05   3.327500   3.435000   3.311071   2.855819  1181608400  aapl   \n",
       "4  2009-01-05  82.619499  83.814529  82.390060  48.850681     8698222   ibm   \n",
       "5  2009-01-05  20.200001  20.670000  20.059999  15.151946    61475200  msft   \n",
       "6  2009-01-06   3.426786   3.470357   3.299643   2.808713  1289310400  aapl   \n",
       "7  2009-01-06  83.279160  86.434036  82.571701  50.206703    10093377   ibm   \n",
       "8  2009-01-06  20.750000  21.000000  20.610001  15.329155    58083400  msft   \n",
       "9  2009-01-07   3.278929   3.303571   3.223571   2.748023   753048800  aapl   \n",
       "\n",
       "   day  \n",
       "0    4  \n",
       "1    4  \n",
       "2    4  \n",
       "3    0  \n",
       "4    0  \n",
       "5    0  \n",
       "6    1  \n",
       "7    1  \n",
       "8    1  \n",
       "9    2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (3604, 8)\n",
      "Successfully added vix\n",
      "Successfully added turbulence index\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>3.067143</td>\n",
       "      <td>3.251429</td>\n",
       "      <td>3.041429</td>\n",
       "      <td>2.740173</td>\n",
       "      <td>746015200</td>\n",
       "      <td>aapl</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.961544</td>\n",
       "      <td>2.634448</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.740173</td>\n",
       "      <td>2.740173</td>\n",
       "      <td>39.189999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>80.200768</td>\n",
       "      <td>83.738052</td>\n",
       "      <td>80.200768</td>\n",
       "      <td>49.160149</td>\n",
       "      <td>7905877</td>\n",
       "      <td>ibm</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.961544</td>\n",
       "      <td>2.634448</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>49.160149</td>\n",
       "      <td>49.160149</td>\n",
       "      <td>39.189999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>19.530001</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>19.370001</td>\n",
       "      <td>15.011639</td>\n",
       "      <td>50084000</td>\n",
       "      <td>msft</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.961544</td>\n",
       "      <td>2.634448</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>15.011639</td>\n",
       "      <td>15.011639</td>\n",
       "      <td>39.189999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>3.327500</td>\n",
       "      <td>3.435000</td>\n",
       "      <td>3.311071</td>\n",
       "      <td>2.855819</td>\n",
       "      <td>1181608400</td>\n",
       "      <td>aapl</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002595</td>\n",
       "      <td>2.961544</td>\n",
       "      <td>2.634448</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.797996</td>\n",
       "      <td>2.797996</td>\n",
       "      <td>39.080002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>82.619499</td>\n",
       "      <td>83.814529</td>\n",
       "      <td>82.390060</td>\n",
       "      <td>48.850681</td>\n",
       "      <td>8698222</td>\n",
       "      <td>ibm</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006943</td>\n",
       "      <td>49.443068</td>\n",
       "      <td>48.567762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>49.005415</td>\n",
       "      <td>49.005415</td>\n",
       "      <td>39.080002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       open       high        low      close      volume   tic  \\\n",
       "0  2009-01-02   3.067143   3.251429   3.041429   2.740173   746015200  aapl   \n",
       "1  2009-01-02  80.200768  83.738052  80.200768  49.160149     7905877   ibm   \n",
       "2  2009-01-02  19.530001  20.400000  19.370001  15.011639    50084000  msft   \n",
       "3  2009-01-05   3.327500   3.435000   3.311071   2.855819  1181608400  aapl   \n",
       "4  2009-01-05  82.619499  83.814529  82.390060  48.850681     8698222   ibm   \n",
       "\n",
       "   day      macd    boll_ub    boll_lb  rsi_30     cci_30  dx_30  \\\n",
       "0    4  0.000000   2.961544   2.634448   100.0  66.666667  100.0   \n",
       "1    4  0.000000   2.961544   2.634448   100.0  66.666667  100.0   \n",
       "2    4  0.000000   2.961544   2.634448   100.0  66.666667  100.0   \n",
       "3    0  0.002595   2.961544   2.634448   100.0  66.666667  100.0   \n",
       "4    0 -0.006943  49.443068  48.567762     0.0  66.666667  100.0   \n",
       "\n",
       "   close_30_sma  close_60_sma        vix  turbulence  \n",
       "0      2.740173      2.740173  39.189999         0.0  \n",
       "1     49.160149     49.160149  39.189999         0.0  \n",
       "2     15.011639     15.011639  39.189999         0.0  \n",
       "3      2.797996      2.797996  39.080002         0.0  \n",
       "4     49.005415     49.005415  39.080002         0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe = FeatureEngineer(use_technical_indicator=True,\n",
    "                     tech_indicator_list = INDICATORS,\n",
    "                     use_vix=True,\n",
    "                     use_turbulence=True,\n",
    "                     user_defined_feature = False)\n",
    "df = fe.preprocess_data(df_raw)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ticker = df['tic'].unique().tolist()\n",
    "list_date = list(pd.date_range(df['date'].min(), df['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date, list_ticker))\n",
    "\n",
    "procesed_df = pd.DataFrame(combination, columns=['date', 'tic']).merge(df, on=['date', 'tic'], how='left')\n",
    "procesed_df = procesed_df[procesed_df['date'].isin(df['date'])]\n",
    "procesed_df = procesed_df.sort_values(['date', 'tic'])\n",
    "procesed_df = procesed_df.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>aapl</td>\n",
       "      <td>3.067143</td>\n",
       "      <td>3.251429</td>\n",
       "      <td>3.041429</td>\n",
       "      <td>2.740173</td>\n",
       "      <td>7.460152e+08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.961544</td>\n",
       "      <td>2.634448</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.740173</td>\n",
       "      <td>2.740173</td>\n",
       "      <td>39.189999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>ibm</td>\n",
       "      <td>80.200768</td>\n",
       "      <td>83.738052</td>\n",
       "      <td>80.200768</td>\n",
       "      <td>49.160149</td>\n",
       "      <td>7.905877e+06</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.961544</td>\n",
       "      <td>2.634448</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>49.160149</td>\n",
       "      <td>49.160149</td>\n",
       "      <td>39.189999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>msft</td>\n",
       "      <td>19.530001</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>19.370001</td>\n",
       "      <td>15.011639</td>\n",
       "      <td>5.008400e+07</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.961544</td>\n",
       "      <td>2.634448</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>15.011639</td>\n",
       "      <td>15.011639</td>\n",
       "      <td>39.189999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>aapl</td>\n",
       "      <td>3.327500</td>\n",
       "      <td>3.435000</td>\n",
       "      <td>3.311071</td>\n",
       "      <td>2.855819</td>\n",
       "      <td>1.181608e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002595</td>\n",
       "      <td>2.961544</td>\n",
       "      <td>2.634448</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.797996</td>\n",
       "      <td>2.797996</td>\n",
       "      <td>39.080002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>ibm</td>\n",
       "      <td>82.619499</td>\n",
       "      <td>83.814529</td>\n",
       "      <td>82.390060</td>\n",
       "      <td>48.850681</td>\n",
       "      <td>8.698222e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.006943</td>\n",
       "      <td>49.443068</td>\n",
       "      <td>48.567762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>49.005415</td>\n",
       "      <td>49.005415</td>\n",
       "      <td>39.080002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date   tic       open       high        low      close  \\\n",
       "0   2009-01-02  aapl   3.067143   3.251429   3.041429   2.740173   \n",
       "1   2009-01-02   ibm  80.200768  83.738052  80.200768  49.160149   \n",
       "2   2009-01-02  msft  19.530001  20.400000  19.370001  15.011639   \n",
       "9   2009-01-05  aapl   3.327500   3.435000   3.311071   2.855819   \n",
       "10  2009-01-05   ibm  82.619499  83.814529  82.390060  48.850681   \n",
       "\n",
       "          volume  day      macd    boll_ub    boll_lb  rsi_30     cci_30  \\\n",
       "0   7.460152e+08  4.0  0.000000   2.961544   2.634448   100.0  66.666667   \n",
       "1   7.905877e+06  4.0  0.000000   2.961544   2.634448   100.0  66.666667   \n",
       "2   5.008400e+07  4.0  0.000000   2.961544   2.634448   100.0  66.666667   \n",
       "9   1.181608e+09  0.0  0.002595   2.961544   2.634448   100.0  66.666667   \n",
       "10  8.698222e+06  0.0 -0.006943  49.443068  48.567762     0.0  66.666667   \n",
       "\n",
       "    dx_30  close_30_sma  close_60_sma        vix  turbulence  \n",
       "0   100.0      2.740173      2.740173  39.189999         0.0  \n",
       "1   100.0     49.160149     49.160149  39.189999         0.0  \n",
       "2   100.0     15.011639     15.011639  39.189999         0.0  \n",
       "9   100.0      2.797996      2.797996  39.080002         0.0  \n",
       "10  100.0     49.005415     49.005415  39.080002         0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "procesed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8679\n",
      "2133\n"
     ]
    }
   ],
   "source": [
    "train = data_split(procesed_df, TRAIN_START_DATE, TRAIN_END_DATE)\n",
    "trade = data_split(procesed_df, TRADE_START_DATE, TRADE_END_DATE)\n",
    "\n",
    "print(len(train))\n",
    "print(len(trade))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(Path.cwd() / 'train.csv')\n",
    "trade.to_csv(Path.cwd() / 'trade.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traing part of Finrl:\n",
    "\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from stable_baselines3.common.logger import configure\n",
    "from finrl import config_tickers\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import INDICATORS, TRAINED_MODEL_DIR, RESULTS_DIR\n",
    "\n",
    "check_and_make_directories([TRAINED_MODEL_DIR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Stock: 3 || State Space: 31\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2 * stock_dimension + len(INDICATORS) * stock_dimension\n",
    "print(f'Number of Stock: {stock_dimension} || State Space: {state_space}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    'hmax': 100,    # the maximum number of shares that can be purchased at each step\n",
    "    'initial_amount': 1000000, \n",
    "    'num_stock_shares': num_stock_shares,\n",
    "    'buy_cost_pct': buy_cost_list,\n",
    "    'sell_cost_pct': sell_cost_list,\n",
    "    'state_space': state_space,\n",
    "    'stock_dim': stock_dimension,\n",
    "    'tech_indicator_list': INDICATORS,\n",
    "    'action_space': stock_dimension,\n",
    "    'reward_scaling': 1e-4\n",
    "}\n",
    "\n",
    "e_train_gym = StockTradingEnv(df=train, **env_kwargs)   # This is state-space representation of the env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "if_using_a2c = False\n",
    "if_using_ddpg = False\n",
    "if_using_ppo = False\n",
    "if_using_td3 = False\n",
    "if_using_sac = False\n",
    "if_using_ddpg = False\n",
    "if_using_dqn = False\n",
    "if_using_a2c = False\n",
    "if_using_ddpg = False\n",
    "if_using_ppo = True\n",
    "if_using_td3 = False\n",
    "if_using_sac = False\n",
    "if_using_dqn = False\n",
    "if_using_a2c = True\n",
    "if_using_ddpg = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Logging to trained_modelsa2c\n"
     ]
    }
   ],
   "source": [
    "model_a2c = agent.get_model(\"a2c\")\n",
    "model_ppo = agent.get_model(\"ppo\")\n",
    "\n",
    "if if_using_a2c:\n",
    "    tmp_path = TRAINED_MODEL_DIR + 'a2c'\n",
    "    new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "    model_a2c.set_logger(new_logger_a2c)\n",
    "\n",
    "if if_using_dqn:\n",
    "    tmp_path = TRAINED_MODEL_DIR + 'ppo'\n",
    "    new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "    model_a2c.set_logger(new_logger_ppo)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 587         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 0           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.5        |\n",
      "|    explained_variance | 0.209       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10099       |\n",
      "|    policy_loss        | -2.43       |\n",
      "|    reward             | 0.075249605 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.399       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 578       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.48     |\n",
      "|    explained_variance | 0.185     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10199     |\n",
      "|    policy_loss        | -10.2     |\n",
      "|    reward             | -1.356469 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 5.41      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 500       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.49     |\n",
      "|    explained_variance | -0.0483   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10299     |\n",
      "|    policy_loss        | -27.9     |\n",
      "|    reward             | 2.8598154 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 57.7      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 519         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 3           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.49       |\n",
      "|    explained_variance | -0.0313     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10399       |\n",
      "|    policy_loss        | -13.4       |\n",
      "|    reward             | -0.24219681 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 23.8        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 530        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 4          |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.48      |\n",
      "|    explained_variance | 0.0149     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10499      |\n",
      "|    policy_loss        | 76.2       |\n",
      "|    reward             | -19.739641 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 375        |\n",
      "--------------------------------------\n",
      "day: 2892, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8386382.61\n",
      "total_reward: 7386382.61\n",
      "total_cost: 33312.37\n",
      "total_trades: 8169\n",
      "Sharpe: 0.976\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 542         |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.47       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10599       |\n",
      "|    policy_loss        | 12.7        |\n",
      "|    reward             | 0.026155284 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 7.26        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 553        |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.46      |\n",
      "|    explained_variance | -0.102     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10699      |\n",
      "|    policy_loss        | -12.8      |\n",
      "|    reward             | -2.5582747 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 10.5       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 556        |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.44      |\n",
      "|    explained_variance | -0.0986    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10799      |\n",
      "|    policy_loss        | 9.21       |\n",
      "|    reward             | 0.09491101 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 9.16       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 556        |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 8          |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.45      |\n",
      "|    explained_variance | -0.301     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10899      |\n",
      "|    policy_loss        | -0.236     |\n",
      "|    reward             | -1.2913368 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 2.53       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 558       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.45     |\n",
      "|    explained_variance | -0.151    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10999     |\n",
      "|    policy_loss        | -13.2     |\n",
      "|    reward             | -3.902351 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 15.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 557      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.46    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | -21.9    |\n",
      "|    reward             | 2.956093 |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 21.9     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 555        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 10         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.45      |\n",
      "|    explained_variance | -0.014     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11199      |\n",
      "|    policy_loss        | -8.1       |\n",
      "|    reward             | 0.78671443 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 3.48       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 556       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.46     |\n",
      "|    explained_variance | 0.00223   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11299     |\n",
      "|    policy_loss        | 0.56      |\n",
      "|    reward             | -3.470238 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 3.26      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 555       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.46     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | -17.2     |\n",
      "|    reward             | 4.855009  |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 54        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 553        |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 13         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.47      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11499      |\n",
      "|    policy_loss        | -3.2       |\n",
      "|    reward             | 0.67765206 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 2.08       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 556       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.49     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11599     |\n",
      "|    policy_loss        | 2.23      |\n",
      "|    reward             | 16.069164 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.919     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 556      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.49    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | -26      |\n",
      "|    reward             | 1.298461 |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 31.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 557       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.48     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11799     |\n",
      "|    policy_loss        | -2.27     |\n",
      "|    reward             | 2.2888033 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.427     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 556        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.48      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11899      |\n",
      "|    policy_loss        | 6.65       |\n",
      "|    reward             | -0.6322151 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 3.02       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 557         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.47       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11999       |\n",
      "|    policy_loss        | 0.579       |\n",
      "|    reward             | -0.97319233 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 12.8        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 558        |\n",
      "|    iterations         | 2100       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 10500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.49      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12099      |\n",
      "|    policy_loss        | 8.86       |\n",
      "|    reward             | -1.1064858 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 9.82       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 557       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.52     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12199     |\n",
      "|    policy_loss        | 3.87      |\n",
      "|    reward             | -4.148563 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 1.86      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 559       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.53     |\n",
      "|    explained_variance | 0.128     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12299     |\n",
      "|    policy_loss        | -138      |\n",
      "|    reward             | -4.506291 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 912       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 557       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.54     |\n",
      "|    explained_variance | 0.532     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12399     |\n",
      "|    policy_loss        | -3.1      |\n",
      "|    reward             | 0.6144477 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 1.41      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 559        |\n",
      "|    iterations         | 2500       |\n",
      "|    time_elapsed       | 22         |\n",
      "|    total_timesteps    | 12500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.54      |\n",
      "|    explained_variance | -0.0141    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12499      |\n",
      "|    policy_loss        | -8.19      |\n",
      "|    reward             | 0.25058657 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 4.29       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 561        |\n",
      "|    iterations         | 2600       |\n",
      "|    time_elapsed       | 23         |\n",
      "|    total_timesteps    | 13000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.54      |\n",
      "|    explained_variance | -0.197     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12599      |\n",
      "|    policy_loss        | -0.59      |\n",
      "|    reward             | 0.95214826 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 0.788      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 2700        |\n",
      "|    time_elapsed       | 23          |\n",
      "|    total_timesteps    | 13500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.56       |\n",
      "|    explained_variance | 0.264       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12699       |\n",
      "|    policy_loss        | -1.41       |\n",
      "|    reward             | -0.52228075 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 0.4         |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.55     |\n",
      "|    explained_variance | 0.424     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | 7.79      |\n",
      "|    reward             | 1.5636917 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 3.17      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 566        |\n",
      "|    iterations         | 2900       |\n",
      "|    time_elapsed       | 25         |\n",
      "|    total_timesteps    | 14500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.56      |\n",
      "|    explained_variance | 0.189      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12899      |\n",
      "|    policy_loss        | -4.58      |\n",
      "|    reward             | 0.38767543 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 0.766      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 569       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.55     |\n",
      "|    explained_variance | -0.245    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12999     |\n",
      "|    policy_loss        | -1.09     |\n",
      "|    reward             | 0.5243589 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 1.42      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 567        |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 27         |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.55      |\n",
      "|    explained_variance | -0.0487    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13099      |\n",
      "|    policy_loss        | -12.4      |\n",
      "|    reward             | 0.17553276 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 5.05       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 567        |\n",
      "|    iterations         | 3200       |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 16000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.55      |\n",
      "|    explained_variance | -0.233     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13199      |\n",
      "|    policy_loss        | 0.479      |\n",
      "|    reward             | -1.0245433 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 8.97       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 566        |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 29         |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.56      |\n",
      "|    explained_variance | -0.0371    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13299      |\n",
      "|    policy_loss        | 26.2       |\n",
      "|    reward             | 0.14117254 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 68.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 30        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.55     |\n",
      "|    explained_variance | -0.14     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13399     |\n",
      "|    policy_loss        | 50.9      |\n",
      "|    reward             | 2.0188243 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 142       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 3500       |\n",
      "|    time_elapsed       | 30         |\n",
      "|    total_timesteps    | 17500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.54      |\n",
      "|    explained_variance | -0.0592    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13499      |\n",
      "|    policy_loss        | 22.1       |\n",
      "|    reward             | 0.09313928 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 48.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.55     |\n",
      "|    explained_variance | 0.0142    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13599     |\n",
      "|    policy_loss        | -7.49     |\n",
      "|    reward             | 1.1198509 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 4.98      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.56     |\n",
      "|    explained_variance | 0.0846    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13699     |\n",
      "|    policy_loss        | -0.727    |\n",
      "|    reward             | 2.8707101 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 1.73      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 3800       |\n",
      "|    time_elapsed       | 33         |\n",
      "|    total_timesteps    | 19000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.56      |\n",
      "|    explained_variance | -0.107     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13799      |\n",
      "|    policy_loss        | 3.63       |\n",
      "|    reward             | -0.6661759 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 1.78       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.58     |\n",
      "|    explained_variance | -0.0587   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13899     |\n",
      "|    policy_loss        | -13.2     |\n",
      "|    reward             | 1.5498006 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 7.87      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 569       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.59     |\n",
      "|    explained_variance | 0.038     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13999     |\n",
      "|    policy_loss        | -18       |\n",
      "|    reward             | 2.3608718 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 18.5      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 570         |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 35          |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.6        |\n",
      "|    explained_variance | -0.305      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14099       |\n",
      "|    policy_loss        | -1.07       |\n",
      "|    reward             | -0.13518086 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 1.34        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 569        |\n",
      "|    iterations         | 4200       |\n",
      "|    time_elapsed       | 36         |\n",
      "|    total_timesteps    | 21000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.61      |\n",
      "|    explained_variance | -0.0575    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 14199      |\n",
      "|    policy_loss        | -16.7      |\n",
      "|    reward             | -4.7983303 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 13.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 569       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.61     |\n",
      "|    explained_variance | 0.0299    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14299     |\n",
      "|    policy_loss        | -12.7     |\n",
      "|    reward             | 2.3319438 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 11.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 568      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.64    |\n",
      "|    explained_variance | -0.117   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | 7.53     |\n",
      "|    reward             | 3.478586 |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 6.43     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 569        |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 39         |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.63      |\n",
      "|    explained_variance | -0.0974    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 14499      |\n",
      "|    policy_loss        | 9.26       |\n",
      "|    reward             | -1.1144376 |\n",
      "|    std                | 1.13       |\n",
      "|    value_loss         | 6.63       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 569       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.63     |\n",
      "|    explained_variance | -0.243    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14599     |\n",
      "|    policy_loss        | 20.9      |\n",
      "|    reward             | 0.8873846 |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 27.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.62     |\n",
      "|    explained_variance | 0.0471    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14699     |\n",
      "|    policy_loss        | -14.1     |\n",
      "|    reward             | 0.7995146 |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 15.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 570        |\n",
      "|    iterations         | 4800       |\n",
      "|    time_elapsed       | 42         |\n",
      "|    total_timesteps    | 24000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.6       |\n",
      "|    explained_variance | -0.0996    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 14799      |\n",
      "|    policy_loss        | -28.1      |\n",
      "|    reward             | -1.5367855 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 31.6       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 569        |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 42         |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.62      |\n",
      "|    explained_variance | -0.0241    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 14899      |\n",
      "|    policy_loss        | -9.68      |\n",
      "|    reward             | 0.46711382 |\n",
      "|    std                | 1.13       |\n",
      "|    value_loss         | 9.8        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 570       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.61     |\n",
      "|    explained_variance | 0.0594    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14999     |\n",
      "|    policy_loss        | 8.69      |\n",
      "|    reward             | 1.0103874 |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 8.05      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 571       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.59     |\n",
      "|    explained_variance | -0.0313   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15099     |\n",
      "|    policy_loss        | 52.5      |\n",
      "|    reward             | 0.7468605 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 227       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 571       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.61     |\n",
      "|    explained_variance | -0.00183  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15199     |\n",
      "|    policy_loss        | 1.31      |\n",
      "|    reward             | 10.280145 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 213       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 571         |\n",
      "|    iterations         | 5300        |\n",
      "|    time_elapsed       | 46          |\n",
      "|    total_timesteps    | 26500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.59       |\n",
      "|    explained_variance | -0.733      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15299       |\n",
      "|    policy_loss        | 5.27        |\n",
      "|    reward             | -0.14126843 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 1.83        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 571        |\n",
      "|    iterations         | 5400       |\n",
      "|    time_elapsed       | 47         |\n",
      "|    total_timesteps    | 27000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.6       |\n",
      "|    explained_variance | -0.000774  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15399      |\n",
      "|    policy_loss        | -41.9      |\n",
      "|    reward             | 0.80181396 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 105        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 571       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.61     |\n",
      "|    explained_variance | 0.0106    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15499     |\n",
      "|    policy_loss        | -14.3     |\n",
      "|    reward             | 3.6484876 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 17        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 570        |\n",
      "|    iterations         | 5600       |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 28000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.62      |\n",
      "|    explained_variance | 0.00974    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15599      |\n",
      "|    policy_loss        | 2.44       |\n",
      "|    reward             | -0.5705773 |\n",
      "|    std                | 1.13       |\n",
      "|    value_loss         | 1.88       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 570        |\n",
      "|    iterations         | 5700       |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 28500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.62      |\n",
      "|    explained_variance | -7.18e-05  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15699      |\n",
      "|    policy_loss        | -83.9      |\n",
      "|    reward             | -12.660566 |\n",
      "|    std                | 1.13       |\n",
      "|    value_loss         | 340        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 569         |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.63       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15799       |\n",
      "|    policy_loss        | -2.98       |\n",
      "|    reward             | -0.43785322 |\n",
      "|    std                | 1.13        |\n",
      "|    value_loss         | 0.982       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 569       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 51        |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.64     |\n",
      "|    explained_variance | 0.0266    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15899     |\n",
      "|    policy_loss        | -0.783    |\n",
      "|    reward             | 0.2731493 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 0.306     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 570        |\n",
      "|    iterations         | 6000       |\n",
      "|    time_elapsed       | 52         |\n",
      "|    total_timesteps    | 30000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.64      |\n",
      "|    explained_variance | -0.0555    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15999      |\n",
      "|    policy_loss        | -3.88      |\n",
      "|    reward             | -1.0019428 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 0.988      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 570       |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 53        |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.65     |\n",
      "|    explained_variance | -0.00498  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16099     |\n",
      "|    policy_loss        | 1.88      |\n",
      "|    reward             | -3.430594 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 2.15      |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 571          |\n",
      "|    iterations         | 6200         |\n",
      "|    time_elapsed       | 54           |\n",
      "|    total_timesteps    | 31000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.64        |\n",
      "|    explained_variance | -0.000812    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16199        |\n",
      "|    policy_loss        | 1.78         |\n",
      "|    reward             | -0.051043905 |\n",
      "|    std                | 1.14         |\n",
      "|    value_loss         | 1.26         |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 570      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.66    |\n",
      "|    explained_variance | 0.000484 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | 82.6     |\n",
      "|    reward             | 19.20318 |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 368      |\n",
      "------------------------------------\n",
      "day: 2892, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 12222226.54\n",
      "total_reward: 11222226.54\n",
      "total_cost: 34044.17\n",
      "total_trades: 8277\n",
      "Sharpe: 1.129\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 570       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.63     |\n",
      "|    explained_variance | 0.582     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | -1.72     |\n",
      "|    reward             | 2.0094411 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 0.363     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 570        |\n",
      "|    iterations         | 6500       |\n",
      "|    time_elapsed       | 56         |\n",
      "|    total_timesteps    | 32500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.64      |\n",
      "|    explained_variance | 0.015      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16499      |\n",
      "|    policy_loss        | -2.74      |\n",
      "|    reward             | -3.6428678 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 8.15       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 569         |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 57          |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.63       |\n",
      "|    explained_variance | 0.0852      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16599       |\n",
      "|    policy_loss        | -8.06       |\n",
      "|    reward             | -0.62618786 |\n",
      "|    std                | 1.14        |\n",
      "|    value_loss         | 8.35        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 569       |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 58        |\n",
      "|    total_timesteps    | 33500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.62     |\n",
      "|    explained_variance | -0.019    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16699     |\n",
      "|    policy_loss        | -78.8     |\n",
      "|    reward             | -9.833089 |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 531       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 569      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.62    |\n",
      "|    explained_variance | -0.037   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | -19.6    |\n",
      "|    reward             | 1.016658 |\n",
      "|    std                | 1.13     |\n",
      "|    value_loss         | 31.4     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 568        |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.63      |\n",
      "|    explained_variance | 0.0511     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16899      |\n",
      "|    policy_loss        | -45.1      |\n",
      "|    reward             | -3.6620352 |\n",
      "|    std                | 1.13       |\n",
      "|    value_loss         | 200        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 567        |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 61         |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.64      |\n",
      "|    explained_variance | 0.167      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16999      |\n",
      "|    policy_loss        | 2.23       |\n",
      "|    reward             | -0.7439898 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 0.471      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 567        |\n",
      "|    iterations         | 7100       |\n",
      "|    time_elapsed       | 62         |\n",
      "|    total_timesteps    | 35500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.64      |\n",
      "|    explained_variance | 0.152      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17099      |\n",
      "|    policy_loss        | 1.67       |\n",
      "|    reward             | 0.49905995 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 0.497      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 568        |\n",
      "|    iterations         | 7200       |\n",
      "|    time_elapsed       | 63         |\n",
      "|    total_timesteps    | 36000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.65      |\n",
      "|    explained_variance | 0.163      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17199      |\n",
      "|    policy_loss        | -15        |\n",
      "|    reward             | 0.78508586 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 14.6       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 568         |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.64       |\n",
      "|    explained_variance | 0.105       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17299       |\n",
      "|    policy_loss        | 2.21        |\n",
      "|    reward             | 0.041088037 |\n",
      "|    std                | 1.14        |\n",
      "|    value_loss         | 9.51        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 568        |\n",
      "|    iterations         | 7400       |\n",
      "|    time_elapsed       | 65         |\n",
      "|    total_timesteps    | 37000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.63      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17399      |\n",
      "|    policy_loss        | 34.3       |\n",
      "|    reward             | -5.6790147 |\n",
      "|    std                | 1.13       |\n",
      "|    value_loss         | 63.1       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 568        |\n",
      "|    iterations         | 7500       |\n",
      "|    time_elapsed       | 65         |\n",
      "|    total_timesteps    | 37500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.65      |\n",
      "|    explained_variance | 0.00693    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17499      |\n",
      "|    policy_loss        | 82.7       |\n",
      "|    reward             | -16.632088 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 421        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.66     |\n",
      "|    explained_variance | 0.00167   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17599     |\n",
      "|    policy_loss        | -11.8     |\n",
      "|    reward             | 0.5352998 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 4.89      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 568        |\n",
      "|    iterations         | 7700       |\n",
      "|    time_elapsed       | 67         |\n",
      "|    total_timesteps    | 38500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.64      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17699      |\n",
      "|    policy_loss        | -25.6      |\n",
      "|    reward             | 0.12738858 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 34         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 568        |\n",
      "|    iterations         | 7800       |\n",
      "|    time_elapsed       | 68         |\n",
      "|    total_timesteps    | 39000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.66      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17799      |\n",
      "|    policy_loss        | -0.196     |\n",
      "|    reward             | 0.20537591 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 1.38       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.66     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17899     |\n",
      "|    policy_loss        | 27.4      |\n",
      "|    reward             | 4.5920367 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 79.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 70        |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.67     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17999     |\n",
      "|    policy_loss        | -36.2     |\n",
      "|    reward             | -4.824061 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 102       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 567       |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 71        |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.68     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18099     |\n",
      "|    policy_loss        | 107       |\n",
      "|    reward             | 12.1717   |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 816       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 567        |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 72         |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.67      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18199      |\n",
      "|    policy_loss        | -6.57      |\n",
      "|    reward             | 0.07681858 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 2.79       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 567       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.66     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18299     |\n",
      "|    policy_loss        | 5.81      |\n",
      "|    reward             | -0.960015 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 3.68      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 567       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.66     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18399     |\n",
      "|    policy_loss        | -18.1     |\n",
      "|    reward             | -2.366109 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 13.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 567        |\n",
      "|    iterations         | 8500       |\n",
      "|    time_elapsed       | 74         |\n",
      "|    total_timesteps    | 42500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.67      |\n",
      "|    explained_variance | -0.0257    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18499      |\n",
      "|    policy_loss        | -27        |\n",
      "|    reward             | -0.5863359 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 41.1       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 568        |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 75         |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.65      |\n",
      "|    explained_variance | 0.0311     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18599      |\n",
      "|    policy_loss        | 56.7       |\n",
      "|    reward             | -16.715414 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 149        |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 568          |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 76           |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.66        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18699        |\n",
      "|    policy_loss        | 3.35         |\n",
      "|    reward             | -0.029326674 |\n",
      "|    std                | 1.14         |\n",
      "|    value_loss         | 1.18         |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 77        |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.67     |\n",
      "|    explained_variance | 0.113     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18799     |\n",
      "|    policy_loss        | -4.1      |\n",
      "|    reward             | 0.5511062 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 1.4       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 78        |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.68     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18899     |\n",
      "|    policy_loss        | 26.3      |\n",
      "|    reward             | 0.8269791 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 46.7      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 567         |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 79          |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.7        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18999       |\n",
      "|    policy_loss        | 10.6        |\n",
      "|    reward             | -0.00499845 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 14.8        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 567         |\n",
      "|    iterations         | 9100        |\n",
      "|    time_elapsed       | 80          |\n",
      "|    total_timesteps    | 45500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.71       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19099       |\n",
      "|    policy_loss        | 3.33        |\n",
      "|    reward             | 0.093860865 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 3.2         |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 567      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.68    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | 31.3     |\n",
      "|    reward             | 8.785064 |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 82.4     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 566        |\n",
      "|    iterations         | 9300       |\n",
      "|    time_elapsed       | 82         |\n",
      "|    total_timesteps    | 46500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.68      |\n",
      "|    explained_variance | -0.818     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 19299      |\n",
      "|    policy_loss        | -4.11      |\n",
      "|    reward             | 0.60803515 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 0.797      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 82        |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.68     |\n",
      "|    explained_variance | -0.0622   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19399     |\n",
      "|    policy_loss        | -10.3     |\n",
      "|    reward             | 0.6616416 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 24.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.67    |\n",
      "|    explained_variance | -0.205   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | -24.4    |\n",
      "|    reward             | 2.120314 |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 38.8     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 9600        |\n",
      "|    time_elapsed       | 84          |\n",
      "|    total_timesteps    | 48000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.68       |\n",
      "|    explained_variance | -0.22       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19599       |\n",
      "|    policy_loss        | -13.6       |\n",
      "|    reward             | -0.61209637 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 6.7         |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 85        |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.68     |\n",
      "|    explained_variance | -2.66     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19699     |\n",
      "|    policy_loss        | 13.3      |\n",
      "|    reward             | 1.6151903 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 22.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.68    |\n",
      "|    explained_variance | 0.034    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | 16.5     |\n",
      "|    reward             | 4.769755 |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 39.6     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 87          |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.67       |\n",
      "|    explained_variance | -0.164      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19899       |\n",
      "|    policy_loss        | -1.68       |\n",
      "|    reward             | -0.30597982 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 0.754       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 10000       |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 50000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.66       |\n",
      "|    explained_variance | -0.118      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19999       |\n",
      "|    policy_loss        | 5.51        |\n",
      "|    reward             | -0.10763607 |\n",
      "|    std                | 1.14        |\n",
      "|    value_loss         | 2.86        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 10100     |\n",
      "|    time_elapsed       | 89        |\n",
      "|    total_timesteps    | 50500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.67     |\n",
      "|    explained_variance | 0.183     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 20099     |\n",
      "|    policy_loss        | 28.2      |\n",
      "|    reward             | 2.2306583 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 42.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 10200      |\n",
      "|    time_elapsed       | 90         |\n",
      "|    total_timesteps    | 51000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.69      |\n",
      "|    explained_variance | 0.145      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 20199      |\n",
      "|    policy_loss        | 3.5        |\n",
      "|    reward             | -1.6635041 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 5.87       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 10300      |\n",
      "|    time_elapsed       | 91         |\n",
      "|    total_timesteps    | 51500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.69      |\n",
      "|    explained_variance | 0.0176     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 20299      |\n",
      "|    policy_loss        | -24.8      |\n",
      "|    reward             | -3.9625204 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 67.7       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.67    |\n",
      "|    explained_variance | 0.0102   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20399    |\n",
      "|    policy_loss        | -30.8    |\n",
      "|    reward             | 49.7099  |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 1.02e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 10500     |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 52500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.67     |\n",
      "|    explained_variance | -0.0625   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 20499     |\n",
      "|    policy_loss        | 10.5      |\n",
      "|    reward             | 3.3274822 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 7.83      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 10600       |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 53000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.68       |\n",
      "|    explained_variance | -0.0491     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 20599       |\n",
      "|    policy_loss        | 1.19        |\n",
      "|    reward             | -0.31906897 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 1.09        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 10700     |\n",
      "|    time_elapsed       | 94        |\n",
      "|    total_timesteps    | 53500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.68     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 20699     |\n",
      "|    policy_loss        | -7.23     |\n",
      "|    reward             | -1.913269 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 3.66      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 10800      |\n",
      "|    time_elapsed       | 95         |\n",
      "|    total_timesteps    | 54000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.68      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 20799      |\n",
      "|    policy_loss        | -2.7       |\n",
      "|    reward             | -1.0325166 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 1.03       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.7     |\n",
      "|    explained_variance | 0.0245   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20899    |\n",
      "|    policy_loss        | -27.5    |\n",
      "|    reward             | 7.366134 |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 71.7     |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 564          |\n",
      "|    iterations         | 11000        |\n",
      "|    time_elapsed       | 97           |\n",
      "|    total_timesteps    | 55000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.7         |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 20999        |\n",
      "|    policy_loss        | -0.521       |\n",
      "|    reward             | -0.005553014 |\n",
      "|    std                | 1.16         |\n",
      "|    value_loss         | 0.11         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 11100       |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 55500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.71       |\n",
      "|    explained_variance | -1.44       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 21099       |\n",
      "|    policy_loss        | 6.55        |\n",
      "|    reward             | -0.24764678 |\n",
      "|    std                | 1.17        |\n",
      "|    value_loss         | 2.46        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.7     |\n",
      "|    explained_variance | -0.219   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21199    |\n",
      "|    policy_loss        | -18.5    |\n",
      "|    reward             | 1.803041 |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 14       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.71    |\n",
      "|    explained_variance | -0.00267 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21299    |\n",
      "|    policy_loss        | -61.7    |\n",
      "|    reward             | 3.841261 |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 535      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 11400      |\n",
      "|    time_elapsed       | 101        |\n",
      "|    total_timesteps    | 57000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.7       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 21399      |\n",
      "|    policy_loss        | 25.8       |\n",
      "|    reward             | -3.3061628 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 30.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 11500      |\n",
      "|    time_elapsed       | 102        |\n",
      "|    total_timesteps    | 57500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.69      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 21499      |\n",
      "|    policy_loss        | 96.4       |\n",
      "|    reward             | -14.968709 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 661        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 11600       |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 58000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.69       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 21599       |\n",
      "|    policy_loss        | 40.2        |\n",
      "|    reward             | -0.32871145 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 70.1        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 11700     |\n",
      "|    time_elapsed       | 103       |\n",
      "|    total_timesteps    | 58500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.7      |\n",
      "|    explained_variance | -0.232    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 21699     |\n",
      "|    policy_loss        | -9.54     |\n",
      "|    reward             | 5.8243184 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 4         |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 11800      |\n",
      "|    time_elapsed       | 104        |\n",
      "|    total_timesteps    | 59000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.7       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 21799      |\n",
      "|    policy_loss        | 1.12       |\n",
      "|    reward             | 0.63203335 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 1.1        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 11900      |\n",
      "|    time_elapsed       | 105        |\n",
      "|    total_timesteps    | 59500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.73      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 21899      |\n",
      "|    policy_loss        | -14        |\n",
      "|    reward             | 0.59178436 |\n",
      "|    std                | 1.17       |\n",
      "|    value_loss         | 28.1       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.72    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21999    |\n",
      "|    policy_loss        | -35.6    |\n",
      "|    reward             | 6.303136 |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 92       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 12100     |\n",
      "|    time_elapsed       | 106       |\n",
      "|    total_timesteps    | 60500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.71     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 22099     |\n",
      "|    policy_loss        | 77        |\n",
      "|    reward             | 12.33942  |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 334       |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 14779533.19\n",
      "total_reward: 13779533.19\n",
      "total_cost: 9526.71\n",
      "total_trades: 6323\n",
      "Sharpe: 1.113\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 12200      |\n",
      "|    time_elapsed       | 107        |\n",
      "|    total_timesteps    | 61000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.7       |\n",
      "|    explained_variance | -0.0368    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 22199      |\n",
      "|    policy_loss        | -10.9      |\n",
      "|    reward             | 0.61583745 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 5.51       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 12300      |\n",
      "|    time_elapsed       | 108        |\n",
      "|    total_timesteps    | 61500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.69      |\n",
      "|    explained_variance | -0.00136   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 22299      |\n",
      "|    policy_loss        | -6.76      |\n",
      "|    reward             | -1.9098634 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 2.4        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 12400     |\n",
      "|    time_elapsed       | 109       |\n",
      "|    total_timesteps    | 62000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.66     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 22399     |\n",
      "|    policy_loss        | 4.05      |\n",
      "|    reward             | 1.2613647 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 3.75      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 12500     |\n",
      "|    time_elapsed       | 110       |\n",
      "|    total_timesteps    | 62500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.66     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 22499     |\n",
      "|    policy_loss        | -9.25     |\n",
      "|    reward             | 1.9584376 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 22.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 12600     |\n",
      "|    time_elapsed       | 111       |\n",
      "|    total_timesteps    | 63000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.67     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 22599     |\n",
      "|    policy_loss        | 55.3      |\n",
      "|    reward             | 3.6179109 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 112       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 12700      |\n",
      "|    time_elapsed       | 112        |\n",
      "|    total_timesteps    | 63500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.67      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 22699      |\n",
      "|    policy_loss        | -6.09      |\n",
      "|    reward             | -13.401053 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 4.01       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 12800       |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 64000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.67       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 22799       |\n",
      "|    policy_loss        | -23.6       |\n",
      "|    reward             | -0.12353435 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 34.7        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 12900      |\n",
      "|    time_elapsed       | 114        |\n",
      "|    total_timesteps    | 64500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.68      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 22899      |\n",
      "|    policy_loss        | -31.1      |\n",
      "|    reward             | -0.8228285 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 41.3       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.69    |\n",
      "|    explained_variance | 0.0433   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 22999    |\n",
      "|    policy_loss        | 16.5     |\n",
      "|    reward             | 3.779299 |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 14.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 13100     |\n",
      "|    time_elapsed       | 115       |\n",
      "|    total_timesteps    | 65500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.69     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 23099     |\n",
      "|    policy_loss        | -5.21     |\n",
      "|    reward             | 5.7556734 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 6.5       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 13200     |\n",
      "|    time_elapsed       | 116       |\n",
      "|    total_timesteps    | 66000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.7      |\n",
      "|    explained_variance | -0.000309 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 23199     |\n",
      "|    policy_loss        | -15.7     |\n",
      "|    reward             | 7.144569  |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 57.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.69    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 23299    |\n",
      "|    policy_loss        | 138      |\n",
      "|    reward             | 13.5215  |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 1.38e+03 |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 13400      |\n",
      "|    time_elapsed       | 118        |\n",
      "|    total_timesteps    | 67000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.69      |\n",
      "|    explained_variance | -0.769     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 23399      |\n",
      "|    policy_loss        | -16.1      |\n",
      "|    reward             | 0.66010255 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 15.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 13500     |\n",
      "|    time_elapsed       | 119       |\n",
      "|    total_timesteps    | 67500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.69     |\n",
      "|    explained_variance | 0.131     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 23499     |\n",
      "|    policy_loss        | -7.24     |\n",
      "|    reward             | 0.2270615 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 6.41      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 13600       |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 68000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.7        |\n",
      "|    explained_variance | 0.0043      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 23599       |\n",
      "|    policy_loss        | -45         |\n",
      "|    reward             | -0.36846882 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 90.2        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 13700       |\n",
      "|    time_elapsed       | 121         |\n",
      "|    total_timesteps    | 68500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.7        |\n",
      "|    explained_variance | -0.0186     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 23699       |\n",
      "|    policy_loss        | 26.5        |\n",
      "|    reward             | -0.43521625 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 29          |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 13800     |\n",
      "|    time_elapsed       | 122       |\n",
      "|    total_timesteps    | 69000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.7      |\n",
      "|    explained_variance | -0.0143   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 23799     |\n",
      "|    policy_loss        | -7.08     |\n",
      "|    reward             | -5.383511 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 44.5      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 13900       |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 69500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.7        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 23899       |\n",
      "|    policy_loss        | 8.81        |\n",
      "|    reward             | -0.68030965 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 4.36        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 14000       |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 70000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.69       |\n",
      "|    explained_variance | -0.0707     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 23999       |\n",
      "|    policy_loss        | 13.5        |\n",
      "|    reward             | -0.49202877 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 6.96        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 14100      |\n",
      "|    time_elapsed       | 125        |\n",
      "|    total_timesteps    | 70500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.7       |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 24099      |\n",
      "|    policy_loss        | -0.47      |\n",
      "|    reward             | -0.9052035 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 0.788      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 14200      |\n",
      "|    time_elapsed       | 125        |\n",
      "|    total_timesteps    | 71000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.69      |\n",
      "|    explained_variance | -0.221     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 24199      |\n",
      "|    policy_loss        | 0.509      |\n",
      "|    reward             | -1.7585455 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 17.1       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.68    |\n",
      "|    explained_variance | 0.0215   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24299    |\n",
      "|    policy_loss        | 4.87     |\n",
      "|    reward             | 3.311647 |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 2.16     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 14400      |\n",
      "|    time_elapsed       | 127        |\n",
      "|    total_timesteps    | 72000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.67      |\n",
      "|    explained_variance | 0.0689     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 24399      |\n",
      "|    policy_loss        | 50         |\n",
      "|    reward             | -2.6498184 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 141        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 14500      |\n",
      "|    time_elapsed       | 128        |\n",
      "|    total_timesteps    | 72500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.65      |\n",
      "|    explained_variance | 0.338      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 24499      |\n",
      "|    policy_loss        | 0.205      |\n",
      "|    reward             | 0.84367085 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 1.1        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 14600     |\n",
      "|    time_elapsed       | 129       |\n",
      "|    total_timesteps    | 73000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.63     |\n",
      "|    explained_variance | 0.0221    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 24599     |\n",
      "|    policy_loss        | 15.7      |\n",
      "|    reward             | 2.4082246 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 27.3      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 14700       |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 73500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.64       |\n",
      "|    explained_variance | -0.794      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 24699       |\n",
      "|    policy_loss        | -14.2       |\n",
      "|    reward             | -0.22127312 |\n",
      "|    std                | 1.14        |\n",
      "|    value_loss         | 15.6        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 14800       |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 74000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.63       |\n",
      "|    explained_variance | 0.107       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 24799       |\n",
      "|    policy_loss        | -47.2       |\n",
      "|    reward             | -0.32021686 |\n",
      "|    std                | 1.14        |\n",
      "|    value_loss         | 163         |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 14900     |\n",
      "|    time_elapsed       | 132       |\n",
      "|    total_timesteps    | 74500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.64     |\n",
      "|    explained_variance | 0.522     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 24899     |\n",
      "|    policy_loss        | 2.55      |\n",
      "|    reward             | 1.3438425 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 1.12      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 15000     |\n",
      "|    time_elapsed       | 133       |\n",
      "|    total_timesteps    | 75000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.64     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 24999     |\n",
      "|    policy_loss        | 6.73      |\n",
      "|    reward             | -2.777277 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 14        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 15100     |\n",
      "|    time_elapsed       | 134       |\n",
      "|    total_timesteps    | 75500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.65     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 25099     |\n",
      "|    policy_loss        | -2.89     |\n",
      "|    reward             | 1.0259106 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 3.29      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 15200      |\n",
      "|    time_elapsed       | 135        |\n",
      "|    total_timesteps    | 76000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.65      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 25199      |\n",
      "|    policy_loss        | -2.82      |\n",
      "|    reward             | 0.74256957 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 1.29       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 15300     |\n",
      "|    time_elapsed       | 136       |\n",
      "|    total_timesteps    | 76500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.66     |\n",
      "|    explained_variance | -0.0126   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 25299     |\n",
      "|    policy_loss        | -16.6     |\n",
      "|    reward             | 1.5864868 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 25.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 15400      |\n",
      "|    time_elapsed       | 136        |\n",
      "|    total_timesteps    | 77000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.66      |\n",
      "|    explained_variance | -0.0448    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 25399      |\n",
      "|    policy_loss        | -5.17      |\n",
      "|    reward             | -2.6098864 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 10.4       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.65    |\n",
      "|    explained_variance | 0.0383   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25499    |\n",
      "|    policy_loss        | -12.6    |\n",
      "|    reward             | 2.936791 |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 20.7     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 15600      |\n",
      "|    time_elapsed       | 138        |\n",
      "|    total_timesteps    | 78000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.64      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 25599      |\n",
      "|    policy_loss        | 1.44       |\n",
      "|    reward             | -1.8335121 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 1.07       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 15700      |\n",
      "|    time_elapsed       | 139        |\n",
      "|    total_timesteps    | 78500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.65      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 25699      |\n",
      "|    policy_loss        | 8.84       |\n",
      "|    reward             | -1.3104577 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 4.73       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 561      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.66    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25799    |\n",
      "|    policy_loss        | -21.8    |\n",
      "|    reward             | 3.18708  |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 19.5     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 561        |\n",
      "|    iterations         | 15900      |\n",
      "|    time_elapsed       | 141        |\n",
      "|    total_timesteps    | 79500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.65      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 25899      |\n",
      "|    policy_loss        | 22.1       |\n",
      "|    reward             | 0.34052238 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 37.6       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 561        |\n",
      "|    iterations         | 16000      |\n",
      "|    time_elapsed       | 142        |\n",
      "|    total_timesteps    | 80000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.66      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 25999      |\n",
      "|    policy_loss        | -31.3      |\n",
      "|    reward             | 0.83539206 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 69.1       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 561         |\n",
      "|    iterations         | 16100       |\n",
      "|    time_elapsed       | 143         |\n",
      "|    total_timesteps    | 80500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.67       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 26099       |\n",
      "|    policy_loss        | -14.7       |\n",
      "|    reward             | -0.44438142 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 13.8        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 561       |\n",
      "|    iterations         | 16200     |\n",
      "|    time_elapsed       | 144       |\n",
      "|    total_timesteps    | 81000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.68     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26199     |\n",
      "|    policy_loss        | 10.3      |\n",
      "|    reward             | 3.7473693 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 18.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 16300     |\n",
      "|    time_elapsed       | 144       |\n",
      "|    total_timesteps    | 81500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.66     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26299     |\n",
      "|    policy_loss        | 4.57      |\n",
      "|    reward             | 1.3199434 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 1.16      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 145       |\n",
      "|    total_timesteps    | 82000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.68     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26399     |\n",
      "|    policy_loss        | 13.5      |\n",
      "|    reward             | 2.0836918 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 9.33      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 16500     |\n",
      "|    time_elapsed       | 146       |\n",
      "|    total_timesteps    | 82500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.68     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26499     |\n",
      "|    policy_loss        | 6.82      |\n",
      "|    reward             | 0.6551323 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 3.45      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 16600      |\n",
      "|    time_elapsed       | 147        |\n",
      "|    total_timesteps    | 83000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.7       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 26599      |\n",
      "|    policy_loss        | 1.62       |\n",
      "|    reward             | 0.64183766 |\n",
      "|    std                | 1.17       |\n",
      "|    value_loss         | 1.11       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 16700     |\n",
      "|    time_elapsed       | 148       |\n",
      "|    total_timesteps    | 83500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.68     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26699     |\n",
      "|    policy_loss        | -16.7     |\n",
      "|    reward             | 3.8102338 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 19.9      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 16800      |\n",
      "|    time_elapsed       | 149        |\n",
      "|    total_timesteps    | 84000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.69      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 26799      |\n",
      "|    policy_loss        | 3.39       |\n",
      "|    reward             | -0.8988993 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 1.47       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 16900      |\n",
      "|    time_elapsed       | 150        |\n",
      "|    total_timesteps    | 84500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.69      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 26899      |\n",
      "|    policy_loss        | 0.113      |\n",
      "|    reward             | -0.1973459 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 1.69       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 17000      |\n",
      "|    time_elapsed       | 150        |\n",
      "|    total_timesteps    | 85000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.69      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 26999      |\n",
      "|    policy_loss        | -3.13      |\n",
      "|    reward             | -1.8546537 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 1.64       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 17100       |\n",
      "|    time_elapsed       | 151         |\n",
      "|    total_timesteps    | 85500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.67       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 27099       |\n",
      "|    policy_loss        | -3.98       |\n",
      "|    reward             | -0.23465718 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 2.26        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 17200      |\n",
      "|    time_elapsed       | 152        |\n",
      "|    total_timesteps    | 86000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.68      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 27199      |\n",
      "|    policy_loss        | -2.47      |\n",
      "|    reward             | -0.7569465 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 1.49       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 17300      |\n",
      "|    time_elapsed       | 153        |\n",
      "|    total_timesteps    | 86500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.68      |\n",
      "|    explained_variance | 0.0564     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 27299      |\n",
      "|    policy_loss        | 3.18       |\n",
      "|    reward             | 0.48970282 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 0.971      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 562         |\n",
      "|    iterations         | 17400       |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 87000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.7        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 27399       |\n",
      "|    policy_loss        | -7.08       |\n",
      "|    reward             | 0.022740629 |\n",
      "|    std                | 1.17        |\n",
      "|    value_loss         | 2.74        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 17500     |\n",
      "|    time_elapsed       | 155       |\n",
      "|    total_timesteps    | 87500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.69     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 27499     |\n",
      "|    policy_loss        | -33.8     |\n",
      "|    reward             | 1.7248269 |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 99.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.69    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 27599    |\n",
      "|    policy_loss        | 8.18     |\n",
      "|    reward             | 0.887127 |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 8.23     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 17700      |\n",
      "|    time_elapsed       | 157        |\n",
      "|    total_timesteps    | 88500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.7       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 27699      |\n",
      "|    policy_loss        | 1.35       |\n",
      "|    reward             | -1.3669854 |\n",
      "|    std                | 1.17       |\n",
      "|    value_loss         | 3.26       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 17800     |\n",
      "|    time_elapsed       | 158       |\n",
      "|    total_timesteps    | 89000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.72     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 27799     |\n",
      "|    policy_loss        | 2.26      |\n",
      "|    reward             | -0.742957 |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 0.891     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 17900     |\n",
      "|    time_elapsed       | 158       |\n",
      "|    total_timesteps    | 89500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.71     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 27899     |\n",
      "|    policy_loss        | -12.8     |\n",
      "|    reward             | 1.7875401 |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 10.5      |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1723818.79\n",
      "total_reward: 723818.79\n",
      "total_cost: 2288.19\n",
      "total_trades: 7297\n",
      "Sharpe: 0.328\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 18000      |\n",
      "|    time_elapsed       | 159        |\n",
      "|    total_timesteps    | 90000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.73      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 27999      |\n",
      "|    policy_loss        | -4.41      |\n",
      "|    reward             | -0.5712011 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 1.15       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 18100      |\n",
      "|    time_elapsed       | 160        |\n",
      "|    total_timesteps    | 90500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.73      |\n",
      "|    explained_variance | -0.552     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 28099      |\n",
      "|    policy_loss        | -0.922     |\n",
      "|    reward             | 0.46563858 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 1.39       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 18200     |\n",
      "|    time_elapsed       | 161       |\n",
      "|    total_timesteps    | 91000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.74     |\n",
      "|    explained_variance | -0.0156   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28199     |\n",
      "|    policy_loss        | 2.11      |\n",
      "|    reward             | 1.8182673 |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 8.22      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 18300      |\n",
      "|    time_elapsed       | 162        |\n",
      "|    total_timesteps    | 91500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.75      |\n",
      "|    explained_variance | 0.026      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 28299      |\n",
      "|    policy_loss        | 24.1       |\n",
      "|    reward             | -0.5974337 |\n",
      "|    std                | 1.19       |\n",
      "|    value_loss         | 34         |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 18400     |\n",
      "|    time_elapsed       | 163       |\n",
      "|    total_timesteps    | 92000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.76     |\n",
      "|    explained_variance | -0.535    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28399     |\n",
      "|    policy_loss        | 43.4      |\n",
      "|    reward             | -8.004193 |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 141       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.76    |\n",
      "|    explained_variance | -0.034   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 28499    |\n",
      "|    policy_loss        | -118     |\n",
      "|    reward             | 95.4496  |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 1.1e+03  |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 18600      |\n",
      "|    time_elapsed       | 165        |\n",
      "|    total_timesteps    | 93000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.77      |\n",
      "|    explained_variance | 0.1        |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 28599      |\n",
      "|    policy_loss        | -3.19      |\n",
      "|    reward             | 0.31982046 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 1.61       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 166       |\n",
      "|    total_timesteps    | 93500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.77     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28699     |\n",
      "|    policy_loss        | -5.31     |\n",
      "|    reward             | 2.7426734 |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 3.28      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.77    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 28799    |\n",
      "|    policy_loss        | 1.81     |\n",
      "|    reward             | 3.668219 |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 2.82     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 18900      |\n",
      "|    time_elapsed       | 167        |\n",
      "|    total_timesteps    | 94500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.75      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 28899      |\n",
      "|    policy_loss        | -12.8      |\n",
      "|    reward             | 0.42220044 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 5.01       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 19000     |\n",
      "|    time_elapsed       | 168       |\n",
      "|    total_timesteps    | 95000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.74     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28999     |\n",
      "|    policy_loss        | -41.7     |\n",
      "|    reward             | -5.208156 |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 59.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 19100     |\n",
      "|    time_elapsed       | 169       |\n",
      "|    total_timesteps    | 95500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.71     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 29099     |\n",
      "|    policy_loss        | -1.49     |\n",
      "|    reward             | 0.1484376 |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 0.176     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 19200     |\n",
      "|    time_elapsed       | 170       |\n",
      "|    total_timesteps    | 96000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.71     |\n",
      "|    explained_variance | -0.366    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 29199     |\n",
      "|    policy_loss        | -5        |\n",
      "|    reward             | -1.526906 |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 3.48      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 19300      |\n",
      "|    time_elapsed       | 171        |\n",
      "|    total_timesteps    | 96500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.71      |\n",
      "|    explained_variance | -1.26      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 29299      |\n",
      "|    policy_loss        | 9.71       |\n",
      "|    reward             | 0.66267616 |\n",
      "|    std                | 1.17       |\n",
      "|    value_loss         | 6.68       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 19400     |\n",
      "|    time_elapsed       | 172       |\n",
      "|    total_timesteps    | 97000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.72     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 29399     |\n",
      "|    policy_loss        | -146      |\n",
      "|    reward             | 2.1411996 |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 771       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 562       |\n",
      "|    iterations         | 19500     |\n",
      "|    time_elapsed       | 173       |\n",
      "|    total_timesteps    | 97500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.73     |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 29499     |\n",
      "|    policy_loss        | 2.04      |\n",
      "|    reward             | 10.649992 |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 2.12      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 562        |\n",
      "|    iterations         | 19600      |\n",
      "|    time_elapsed       | 174        |\n",
      "|    total_timesteps    | 98000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.73      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 29599      |\n",
      "|    policy_loss        | 50.3       |\n",
      "|    reward             | -3.7418542 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 210        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 19700       |\n",
      "|    time_elapsed       | 174         |\n",
      "|    total_timesteps    | 98500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.73       |\n",
      "|    explained_variance | -10.4       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 29699       |\n",
      "|    policy_loss        | 23.8        |\n",
      "|    reward             | -0.94392216 |\n",
      "|    std                | 1.18        |\n",
      "|    value_loss         | 35.2        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 19800     |\n",
      "|    time_elapsed       | 175       |\n",
      "|    total_timesteps    | 99000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.72     |\n",
      "|    explained_variance | -0.106    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 29799     |\n",
      "|    policy_loss        | 7.75      |\n",
      "|    reward             | 1.5183295 |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 5.85      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 563         |\n",
      "|    iterations         | 19900       |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 99500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.73       |\n",
      "|    explained_variance | -0.24       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 29899       |\n",
      "|    policy_loss        | -2.93       |\n",
      "|    reward             | -0.13099998 |\n",
      "|    std                | 1.18        |\n",
      "|    value_loss         | 5.44        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 20000      |\n",
      "|    time_elapsed       | 177        |\n",
      "|    total_timesteps    | 100000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.74      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 29999      |\n",
      "|    policy_loss        | -37.4      |\n",
      "|    reward             | -0.4155498 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 95.7       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 20100     |\n",
      "|    time_elapsed       | 178       |\n",
      "|    total_timesteps    | 100500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.75     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30099     |\n",
      "|    policy_loss        | 23        |\n",
      "|    reward             | 3.1841137 |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 43        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 20200     |\n",
      "|    time_elapsed       | 179       |\n",
      "|    total_timesteps    | 101000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.77     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30199     |\n",
      "|    policy_loss        | 106       |\n",
      "|    reward             | 1.6435757 |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 645       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 20300     |\n",
      "|    time_elapsed       | 179       |\n",
      "|    total_timesteps    | 101500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.78     |\n",
      "|    explained_variance | -0.237    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30299     |\n",
      "|    policy_loss        | -0.197    |\n",
      "|    reward             | 1.3305043 |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 1.25      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 20400      |\n",
      "|    time_elapsed       | 180        |\n",
      "|    total_timesteps    | 102000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.8       |\n",
      "|    explained_variance | -0.0908    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 30399      |\n",
      "|    policy_loss        | -3.74      |\n",
      "|    reward             | -1.0209773 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 2.43       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 20500      |\n",
      "|    time_elapsed       | 181        |\n",
      "|    total_timesteps    | 102500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.79      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 30499      |\n",
      "|    policy_loss        | -8.6       |\n",
      "|    reward             | -2.1246881 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 5.34       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 20600      |\n",
      "|    time_elapsed       | 182        |\n",
      "|    total_timesteps    | 103000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.8       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 30599      |\n",
      "|    policy_loss        | 15.6       |\n",
      "|    reward             | -1.3012444 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 14.9       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 563      |\n",
      "|    iterations         | 20700    |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 103500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.81    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 30699    |\n",
      "|    policy_loss        | 6.33     |\n",
      "|    reward             | 0.915522 |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 4.68     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 20800     |\n",
      "|    time_elapsed       | 184       |\n",
      "|    total_timesteps    | 104000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.78     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30799     |\n",
      "|    policy_loss        | -1.08     |\n",
      "|    reward             | -0.865531 |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 4.8       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 20900     |\n",
      "|    time_elapsed       | 185       |\n",
      "|    total_timesteps    | 104500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.78     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30899     |\n",
      "|    policy_loss        | -34       |\n",
      "|    reward             | 3.4460795 |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 51.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 563       |\n",
      "|    iterations         | 21000     |\n",
      "|    time_elapsed       | 186       |\n",
      "|    total_timesteps    | 105000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.77     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30999     |\n",
      "|    policy_loss        | -9.17     |\n",
      "|    reward             | 2.0868108 |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 6.4       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 21100       |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 105500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.79       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 31099       |\n",
      "|    policy_loss        | 12.8        |\n",
      "|    reward             | -0.10441415 |\n",
      "|    std                | 1.2         |\n",
      "|    value_loss         | 9.21        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 21200      |\n",
      "|    time_elapsed       | 187        |\n",
      "|    total_timesteps    | 106000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.81      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 31199      |\n",
      "|    policy_loss        | 4.33       |\n",
      "|    reward             | 0.06883655 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 2.75       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 21300       |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 106500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.82       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 31299       |\n",
      "|    policy_loss        | -3.55       |\n",
      "|    reward             | -0.47031984 |\n",
      "|    std                | 1.21        |\n",
      "|    value_loss         | 1.93        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 21400     |\n",
      "|    time_elapsed       | 189       |\n",
      "|    total_timesteps    | 107000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.82     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 31399     |\n",
      "|    policy_loss        | 28.3      |\n",
      "|    reward             | 2.9751887 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 59.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 21500      |\n",
      "|    time_elapsed       | 190        |\n",
      "|    total_timesteps    | 107500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.82      |\n",
      "|    explained_variance | -0.00457   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 31499      |\n",
      "|    policy_loss        | -5.83      |\n",
      "|    reward             | -0.5714341 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 4.55       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 21600     |\n",
      "|    time_elapsed       | 191       |\n",
      "|    total_timesteps    | 108000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.82     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 31599     |\n",
      "|    policy_loss        | 5.82      |\n",
      "|    reward             | 0.6152923 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 4.75      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 21700      |\n",
      "|    time_elapsed       | 192        |\n",
      "|    total_timesteps    | 108500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.84      |\n",
      "|    explained_variance | 0.0176     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 31699      |\n",
      "|    policy_loss        | -25.3      |\n",
      "|    reward             | -11.705679 |\n",
      "|    std                | 1.22       |\n",
      "|    value_loss         | 47.1       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 21800      |\n",
      "|    time_elapsed       | 193        |\n",
      "|    total_timesteps    | 109000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.84      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 31799      |\n",
      "|    policy_loss        | -3.74      |\n",
      "|    reward             | -0.8237433 |\n",
      "|    std                | 1.22       |\n",
      "|    value_loss         | 2.19       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 21900       |\n",
      "|    time_elapsed       | 194         |\n",
      "|    total_timesteps    | 109500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.85       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 31899       |\n",
      "|    policy_loss        | 14.5        |\n",
      "|    reward             | 0.004817628 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 13.6        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 22000      |\n",
      "|    time_elapsed       | 194        |\n",
      "|    total_timesteps    | 110000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.83      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 31999      |\n",
      "|    policy_loss        | 1.13       |\n",
      "|    reward             | 0.94962895 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 0.565      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 22100     |\n",
      "|    time_elapsed       | 195       |\n",
      "|    total_timesteps    | 110500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.81     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32099     |\n",
      "|    policy_loss        | 15.4      |\n",
      "|    reward             | 1.0611125 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 16        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 22200     |\n",
      "|    time_elapsed       | 196       |\n",
      "|    total_timesteps    | 111000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.81     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32199     |\n",
      "|    policy_loss        | -10.9     |\n",
      "|    reward             | -1.055371 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 5.21      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 22300      |\n",
      "|    time_elapsed       | 197        |\n",
      "|    total_timesteps    | 111500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.82      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 32299      |\n",
      "|    policy_loss        | 15.2       |\n",
      "|    reward             | -4.8422484 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 14.1       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 22400      |\n",
      "|    time_elapsed       | 198        |\n",
      "|    total_timesteps    | 112000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.82      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 32399      |\n",
      "|    policy_loss        | -13.3      |\n",
      "|    reward             | 0.08926102 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 13.8       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 22500     |\n",
      "|    time_elapsed       | 199       |\n",
      "|    total_timesteps    | 112500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.81     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32499     |\n",
      "|    policy_loss        | -21.3     |\n",
      "|    reward             | 1.4039721 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 21.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 22600     |\n",
      "|    time_elapsed       | 200       |\n",
      "|    total_timesteps    | 113000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.82     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32599     |\n",
      "|    policy_loss        | -12.4     |\n",
      "|    reward             | 0.9218965 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 8.31      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 22700      |\n",
      "|    time_elapsed       | 201        |\n",
      "|    total_timesteps    | 113500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.83      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 32699      |\n",
      "|    policy_loss        | 27         |\n",
      "|    reward             | -3.5110807 |\n",
      "|    std                | 1.22       |\n",
      "|    value_loss         | 54.7       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 22800       |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 114000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.82       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 32799       |\n",
      "|    policy_loss        | 15.8        |\n",
      "|    reward             | -0.50171196 |\n",
      "|    std                | 1.21        |\n",
      "|    value_loss         | 9.26        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 22900    |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 114500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.82    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 32899    |\n",
      "|    policy_loss        | -10.4    |\n",
      "|    reward             | 8.272052 |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 6.3      |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 23000       |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 115000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.8        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 32999       |\n",
      "|    policy_loss        | 9.48        |\n",
      "|    reward             | 0.016323797 |\n",
      "|    std                | 1.2         |\n",
      "|    value_loss         | 4.65        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 23100     |\n",
      "|    time_elapsed       | 204       |\n",
      "|    total_timesteps    | 115500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.81     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 33099     |\n",
      "|    policy_loss        | -5.21     |\n",
      "|    reward             | 6.1214323 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 31.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 23200      |\n",
      "|    time_elapsed       | 205        |\n",
      "|    total_timesteps    | 116000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.82      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 33199      |\n",
      "|    policy_loss        | -6.23      |\n",
      "|    reward             | 0.21223594 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 3.18       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 23300     |\n",
      "|    time_elapsed       | 206       |\n",
      "|    total_timesteps    | 116500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.82     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 33299     |\n",
      "|    policy_loss        | 4.38      |\n",
      "|    reward             | 0.6437203 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 0.989     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 23400       |\n",
      "|    time_elapsed       | 207         |\n",
      "|    total_timesteps    | 117000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.84       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 33399       |\n",
      "|    policy_loss        | -25.4       |\n",
      "|    reward             | -0.20571694 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 37.9        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 23500     |\n",
      "|    time_elapsed       | 207       |\n",
      "|    total_timesteps    | 117500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.84     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 33499     |\n",
      "|    policy_loss        | -21.2     |\n",
      "|    reward             | 6.2206345 |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 39.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 23600      |\n",
      "|    time_elapsed       | 208        |\n",
      "|    total_timesteps    | 118000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.86      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 33599      |\n",
      "|    policy_loss        | 31.5       |\n",
      "|    reward             | -0.9428614 |\n",
      "|    std                | 1.23       |\n",
      "|    value_loss         | 44         |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 23700       |\n",
      "|    time_elapsed       | 209         |\n",
      "|    total_timesteps    | 118500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.84       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 33699       |\n",
      "|    policy_loss        | 25.9        |\n",
      "|    reward             | -0.23695904 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 50.8        |\n",
      "---------------------------------------\n",
      "day: 2892, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4695860.62\n",
      "total_reward: 3695860.62\n",
      "total_cost: 2090.89\n",
      "total_trades: 8241\n",
      "Sharpe: 0.763\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 23800     |\n",
      "|    time_elapsed       | 210       |\n",
      "|    total_timesteps    | 119000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.83     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 33799     |\n",
      "|    policy_loss        | 20.9      |\n",
      "|    reward             | 1.6168485 |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 13.4      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 23900      |\n",
      "|    time_elapsed       | 211        |\n",
      "|    total_timesteps    | 119500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.82      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 33899      |\n",
      "|    policy_loss        | 13.2       |\n",
      "|    reward             | -1.5489888 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 7.31       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 24000     |\n",
      "|    time_elapsed       | 212       |\n",
      "|    total_timesteps    | 120000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.84     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 33999     |\n",
      "|    policy_loss        | 12.6      |\n",
      "|    reward             | 0.5156945 |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 8.93      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 24100    |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 120500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.83    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 34099    |\n",
      "|    policy_loss        | -35.2    |\n",
      "|    reward             | 0.305985 |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 64       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 24200     |\n",
      "|    time_elapsed       | 214       |\n",
      "|    total_timesteps    | 121000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.84     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34199     |\n",
      "|    policy_loss        | 17.1      |\n",
      "|    reward             | -6.564025 |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 12.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 24300     |\n",
      "|    time_elapsed       | 214       |\n",
      "|    total_timesteps    | 121500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.85     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34299     |\n",
      "|    policy_loss        | 74.8      |\n",
      "|    reward             | 5.9327145 |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 492       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 24400       |\n",
      "|    time_elapsed       | 215         |\n",
      "|    total_timesteps    | 122000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.84       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 34399       |\n",
      "|    policy_loss        | 0.755       |\n",
      "|    reward             | 0.085210495 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 0.361       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 24500      |\n",
      "|    time_elapsed       | 216        |\n",
      "|    total_timesteps    | 122500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.85      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 34499      |\n",
      "|    policy_loss        | -0.985     |\n",
      "|    reward             | -0.8913134 |\n",
      "|    std                | 1.22       |\n",
      "|    value_loss         | 1.65       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 24600      |\n",
      "|    time_elapsed       | 217        |\n",
      "|    total_timesteps    | 123000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.86      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 34599      |\n",
      "|    policy_loss        | 6.83       |\n",
      "|    reward             | 0.16854373 |\n",
      "|    std                | 1.23       |\n",
      "|    value_loss         | 3.44       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 24700      |\n",
      "|    time_elapsed       | 218        |\n",
      "|    total_timesteps    | 123500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.83      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 34699      |\n",
      "|    policy_loss        | -2.89      |\n",
      "|    reward             | 0.28617465 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 2.35       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 24800    |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 124000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.82    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 34799    |\n",
      "|    policy_loss        | -101     |\n",
      "|    reward             | 17.45193 |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 464      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 24900     |\n",
      "|    time_elapsed       | 219       |\n",
      "|    total_timesteps    | 124500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.82     |\n",
      "|    explained_variance | -0.267    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34899     |\n",
      "|    policy_loss        | -1.71     |\n",
      "|    reward             | 1.1794027 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 1.55      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 566        |\n",
      "|    iterations         | 25000      |\n",
      "|    time_elapsed       | 220        |\n",
      "|    total_timesteps    | 125000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.82      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 34999      |\n",
      "|    policy_loss        | -15.1      |\n",
      "|    reward             | -1.9138523 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 8.39       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 25100       |\n",
      "|    time_elapsed       | 221         |\n",
      "|    total_timesteps    | 125500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.81       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 35099       |\n",
      "|    policy_loss        | -7.99       |\n",
      "|    reward             | -0.31749734 |\n",
      "|    std                | 1.21        |\n",
      "|    value_loss         | 2.01        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 25200     |\n",
      "|    time_elapsed       | 222       |\n",
      "|    total_timesteps    | 126000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.82     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35199     |\n",
      "|    policy_loss        | -16.3     |\n",
      "|    reward             | 3.2849157 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 12.4      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 25300       |\n",
      "|    time_elapsed       | 223         |\n",
      "|    total_timesteps    | 126500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.83       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 35299       |\n",
      "|    policy_loss        | 1.89        |\n",
      "|    reward             | -0.63086414 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 0.37        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 25400      |\n",
      "|    time_elapsed       | 224        |\n",
      "|    total_timesteps    | 127000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.82      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 35399      |\n",
      "|    policy_loss        | 25.3       |\n",
      "|    reward             | -1.2609321 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 40.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 25500     |\n",
      "|    time_elapsed       | 225       |\n",
      "|    total_timesteps    | 127500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.82     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35499     |\n",
      "|    policy_loss        | -3.23     |\n",
      "|    reward             | 1.341549  |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 5.37      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 25600     |\n",
      "|    time_elapsed       | 226       |\n",
      "|    total_timesteps    | 128000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.82     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35599     |\n",
      "|    policy_loss        | -3.51     |\n",
      "|    reward             | 0.5449002 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 3.11      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 25700       |\n",
      "|    time_elapsed       | 227         |\n",
      "|    total_timesteps    | 128500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.82       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 35699       |\n",
      "|    policy_loss        | 18.9        |\n",
      "|    reward             | -0.73837435 |\n",
      "|    std                | 1.21        |\n",
      "|    value_loss         | 26.8        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 25800     |\n",
      "|    time_elapsed       | 227       |\n",
      "|    total_timesteps    | 129000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.84     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35799     |\n",
      "|    policy_loss        | 26.5      |\n",
      "|    reward             | 0.5386896 |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 45.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 25900     |\n",
      "|    time_elapsed       | 228       |\n",
      "|    total_timesteps    | 129500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.84     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35899     |\n",
      "|    policy_loss        | 3.88      |\n",
      "|    reward             | 1.0666208 |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 0.994     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 566        |\n",
      "|    iterations         | 26000      |\n",
      "|    time_elapsed       | 229        |\n",
      "|    total_timesteps    | 130000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.84      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 35999      |\n",
      "|    policy_loss        | 11.8       |\n",
      "|    reward             | -3.3350966 |\n",
      "|    std                | 1.22       |\n",
      "|    value_loss         | 11.8       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 26100       |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 130500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.83       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 36099       |\n",
      "|    policy_loss        | -4.44       |\n",
      "|    reward             | -0.27094236 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 26200       |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 131000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.85       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 36199       |\n",
      "|    policy_loss        | -7.08       |\n",
      "|    reward             | -0.34023142 |\n",
      "|    std                | 1.23        |\n",
      "|    value_loss         | 4.07        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 566        |\n",
      "|    iterations         | 26300      |\n",
      "|    time_elapsed       | 232        |\n",
      "|    total_timesteps    | 131500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.86      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 36299      |\n",
      "|    policy_loss        | 3.53       |\n",
      "|    reward             | -2.8255954 |\n",
      "|    std                | 1.23       |\n",
      "|    value_loss         | 5.05       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 26400     |\n",
      "|    time_elapsed       | 233       |\n",
      "|    total_timesteps    | 132000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.84     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 36399     |\n",
      "|    policy_loss        | 21.2      |\n",
      "|    reward             | 1.9364188 |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 12.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 26500     |\n",
      "|    time_elapsed       | 234       |\n",
      "|    total_timesteps    | 132500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.84     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 36499     |\n",
      "|    policy_loss        | 8.34      |\n",
      "|    reward             | 1.9560816 |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 6.35      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 26600      |\n",
      "|    time_elapsed       | 235        |\n",
      "|    total_timesteps    | 133000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.85      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 36599      |\n",
      "|    policy_loss        | 45.5       |\n",
      "|    reward             | -18.945978 |\n",
      "|    std                | 1.22       |\n",
      "|    value_loss         | 201        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 26700      |\n",
      "|    time_elapsed       | 235        |\n",
      "|    total_timesteps    | 133500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.85      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 36699      |\n",
      "|    policy_loss        | -10.2      |\n",
      "|    reward             | -1.7205213 |\n",
      "|    std                | 1.22       |\n",
      "|    value_loss         | 6.16       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 26800     |\n",
      "|    time_elapsed       | 236       |\n",
      "|    total_timesteps    | 134000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.85     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 36799     |\n",
      "|    policy_loss        | -13.5     |\n",
      "|    reward             | 0.1995225 |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 9.56      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 26900       |\n",
      "|    time_elapsed       | 237         |\n",
      "|    total_timesteps    | 134500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.85       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 36899       |\n",
      "|    policy_loss        | 7.36        |\n",
      "|    reward             | -0.83796793 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 4.35        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 566        |\n",
      "|    iterations         | 27000      |\n",
      "|    time_elapsed       | 238        |\n",
      "|    total_timesteps    | 135000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.87      |\n",
      "|    explained_variance | -0.0801    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 36999      |\n",
      "|    policy_loss        | -2.25      |\n",
      "|    reward             | 0.07709232 |\n",
      "|    std                | 1.23       |\n",
      "|    value_loss         | 0.943      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 27100     |\n",
      "|    time_elapsed       | 239       |\n",
      "|    total_timesteps    | 135500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.86     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37099     |\n",
      "|    policy_loss        | 14.3      |\n",
      "|    reward             | 0.8606953 |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 12.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 566        |\n",
      "|    iterations         | 27200      |\n",
      "|    time_elapsed       | 240        |\n",
      "|    total_timesteps    | 136000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.86      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 37199      |\n",
      "|    policy_loss        | 3.21       |\n",
      "|    reward             | -0.2381595 |\n",
      "|    std                | 1.23       |\n",
      "|    value_loss         | 0.438      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 27300     |\n",
      "|    time_elapsed       | 241       |\n",
      "|    total_timesteps    | 136500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.86     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37299     |\n",
      "|    policy_loss        | 4.93      |\n",
      "|    reward             | 1.5720356 |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 2.65      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 27400       |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 137000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.87       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 37399       |\n",
      "|    policy_loss        | 5.87        |\n",
      "|    reward             | -0.70865613 |\n",
      "|    std                | 1.23        |\n",
      "|    value_loss         | 9.59        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 27500     |\n",
      "|    time_elapsed       | 242       |\n",
      "|    total_timesteps    | 137500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.9      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37499     |\n",
      "|    policy_loss        | 8.17      |\n",
      "|    reward             | -4.381416 |\n",
      "|    std                | 1.25      |\n",
      "|    value_loss         | 6.52      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 27600     |\n",
      "|    time_elapsed       | 243       |\n",
      "|    total_timesteps    | 138000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.9      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37599     |\n",
      "|    policy_loss        | -6.32     |\n",
      "|    reward             | 2.3936477 |\n",
      "|    std                | 1.24      |\n",
      "|    value_loss         | 2.4       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 27700      |\n",
      "|    time_elapsed       | 244        |\n",
      "|    total_timesteps    | 138500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.9       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 37699      |\n",
      "|    policy_loss        | -10.9      |\n",
      "|    reward             | -4.8687057 |\n",
      "|    std                | 1.24       |\n",
      "|    value_loss         | 10.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 27800     |\n",
      "|    time_elapsed       | 245       |\n",
      "|    total_timesteps    | 139000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.89     |\n",
      "|    explained_variance | -0.756    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37799     |\n",
      "|    policy_loss        | 17.4      |\n",
      "|    reward             | 1.0522265 |\n",
      "|    std                | 1.24      |\n",
      "|    value_loss         | 12.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 27900      |\n",
      "|    time_elapsed       | 246        |\n",
      "|    total_timesteps    | 139500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.89      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 37899      |\n",
      "|    policy_loss        | 18.1       |\n",
      "|    reward             | 0.33887726 |\n",
      "|    std                | 1.24       |\n",
      "|    value_loss         | 20.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 28000     |\n",
      "|    time_elapsed       | 247       |\n",
      "|    total_timesteps    | 140000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.88     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37999     |\n",
      "|    policy_loss        | -12.8     |\n",
      "|    reward             | 1.3632307 |\n",
      "|    std                | 1.24      |\n",
      "|    value_loss         | 9.65      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 28100       |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 140500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.88       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 38099       |\n",
      "|    policy_loss        | -12.8       |\n",
      "|    reward             | -0.30028638 |\n",
      "|    std                | 1.24        |\n",
      "|    value_loss         | 11          |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 28200     |\n",
      "|    time_elapsed       | 249       |\n",
      "|    total_timesteps    | 141000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.89     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38199     |\n",
      "|    policy_loss        | -5.02     |\n",
      "|    reward             | 1.7889097 |\n",
      "|    std                | 1.24      |\n",
      "|    value_loss         | 1.62      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 28300     |\n",
      "|    time_elapsed       | 250       |\n",
      "|    total_timesteps    | 141500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.89     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38299     |\n",
      "|    policy_loss        | 37.4      |\n",
      "|    reward             | -11.12972 |\n",
      "|    std                | 1.24      |\n",
      "|    value_loss         | 52.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 28400     |\n",
      "|    time_elapsed       | 251       |\n",
      "|    total_timesteps    | 142000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.87     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38399     |\n",
      "|    policy_loss        | 5.89      |\n",
      "|    reward             | 1.3021044 |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 1.72      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 28500       |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 142500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.87       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 38499       |\n",
      "|    policy_loss        | 18.3        |\n",
      "|    reward             | -0.54287606 |\n",
      "|    std                | 1.23        |\n",
      "|    value_loss         | 26.4        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 28600      |\n",
      "|    time_elapsed       | 253        |\n",
      "|    total_timesteps    | 143000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.86      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 38599      |\n",
      "|    policy_loss        | -7.51      |\n",
      "|    reward             | -1.0761545 |\n",
      "|    std                | 1.23       |\n",
      "|    value_loss         | 4.32       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 28700     |\n",
      "|    time_elapsed       | 254       |\n",
      "|    total_timesteps    | 143500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.88     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38699     |\n",
      "|    policy_loss        | -1.27     |\n",
      "|    reward             | 3.7288156 |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 0.68      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 28800      |\n",
      "|    time_elapsed       | 254        |\n",
      "|    total_timesteps    | 144000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.88      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 38799      |\n",
      "|    policy_loss        | 22.6       |\n",
      "|    reward             | -1.1769534 |\n",
      "|    std                | 1.24       |\n",
      "|    value_loss         | 14         |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 564      |\n",
      "|    iterations         | 28900    |\n",
      "|    time_elapsed       | 255      |\n",
      "|    total_timesteps    | 144500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.89    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 38899    |\n",
      "|    policy_loss        | 13.9     |\n",
      "|    reward             | 4.199649 |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 10.4     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 29000       |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 145000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.89       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 38999       |\n",
      "|    policy_loss        | -6.67       |\n",
      "|    reward             | -0.19788606 |\n",
      "|    std                | 1.24        |\n",
      "|    value_loss         | 4.81        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 29100      |\n",
      "|    time_elapsed       | 257        |\n",
      "|    total_timesteps    | 145500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.9       |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 39099      |\n",
      "|    policy_loss        | -13.5      |\n",
      "|    reward             | -1.7537483 |\n",
      "|    std                | 1.25       |\n",
      "|    value_loss         | 13.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 29200      |\n",
      "|    time_elapsed       | 258        |\n",
      "|    total_timesteps    | 146000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.91      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 39199      |\n",
      "|    policy_loss        | -6.87      |\n",
      "|    reward             | -2.8389542 |\n",
      "|    std                | 1.25       |\n",
      "|    value_loss         | 4.56       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 29300     |\n",
      "|    time_elapsed       | 259       |\n",
      "|    total_timesteps    | 146500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.91     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 39299     |\n",
      "|    policy_loss        | -25.5     |\n",
      "|    reward             | 3.8084347 |\n",
      "|    std                | 1.25      |\n",
      "|    value_loss         | 28        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 29400     |\n",
      "|    time_elapsed       | 260       |\n",
      "|    total_timesteps    | 147000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.93     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 39399     |\n",
      "|    policy_loss        | 14.6      |\n",
      "|    reward             | 3.5631793 |\n",
      "|    std                | 1.26      |\n",
      "|    value_loss         | 12.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 29500      |\n",
      "|    time_elapsed       | 261        |\n",
      "|    total_timesteps    | 147500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.92      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 39499      |\n",
      "|    policy_loss        | -13.9      |\n",
      "|    reward             | -0.5056667 |\n",
      "|    std                | 1.25       |\n",
      "|    value_loss         | 53.8       |\n",
      "--------------------------------------\n",
      "day: 2892, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4569736.68\n",
      "total_reward: 3569736.68\n",
      "total_cost: 1145.08\n",
      "total_trades: 6709\n",
      "Sharpe: 0.753\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 29600     |\n",
      "|    time_elapsed       | 262       |\n",
      "|    total_timesteps    | 148000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.95     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 39599     |\n",
      "|    policy_loss        | -16.1     |\n",
      "|    reward             | 1.5735931 |\n",
      "|    std                | 1.27      |\n",
      "|    value_loss         | 11.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 29700      |\n",
      "|    time_elapsed       | 263        |\n",
      "|    total_timesteps    | 148500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.96      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 39699      |\n",
      "|    policy_loss        | -17.9      |\n",
      "|    reward             | -4.8121834 |\n",
      "|    std                | 1.27       |\n",
      "|    value_loss         | 20         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 29800      |\n",
      "|    time_elapsed       | 263        |\n",
      "|    total_timesteps    | 149000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.95      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 39799      |\n",
      "|    policy_loss        | -8.26      |\n",
      "|    reward             | -2.3328571 |\n",
      "|    std                | 1.27       |\n",
      "|    value_loss         | 7.01       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 29900      |\n",
      "|    time_elapsed       | 264        |\n",
      "|    total_timesteps    | 149500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.97      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 39899      |\n",
      "|    policy_loss        | -13        |\n",
      "|    reward             | -3.3387504 |\n",
      "|    std                | 1.28       |\n",
      "|    value_loss         | 6.31       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 30000      |\n",
      "|    time_elapsed       | 265        |\n",
      "|    total_timesteps    | 150000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.95      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 39999      |\n",
      "|    policy_loss        | 0.409      |\n",
      "|    reward             | -3.3123846 |\n",
      "|    std                | 1.27       |\n",
      "|    value_loss         | 0.753      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 30100       |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 150500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.95       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 40099       |\n",
      "|    policy_loss        | -8.27       |\n",
      "|    reward             | -0.19156349 |\n",
      "|    std                | 1.27        |\n",
      "|    value_loss         | 2.88        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 30200     |\n",
      "|    time_elapsed       | 267       |\n",
      "|    total_timesteps    | 151000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.97     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 40199     |\n",
      "|    policy_loss        | 14.7      |\n",
      "|    reward             | 0.7359695 |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 12.5      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 30300      |\n",
      "|    time_elapsed       | 268        |\n",
      "|    total_timesteps    | 151500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.97      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 40299      |\n",
      "|    policy_loss        | 3.51       |\n",
      "|    reward             | -0.9143304 |\n",
      "|    std                | 1.28       |\n",
      "|    value_loss         | 1.99       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 30400     |\n",
      "|    time_elapsed       | 269       |\n",
      "|    total_timesteps    | 152000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.97     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 40399     |\n",
      "|    policy_loss        | -5.27     |\n",
      "|    reward             | 1.4720254 |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 9.33      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 30500     |\n",
      "|    time_elapsed       | 270       |\n",
      "|    total_timesteps    | 152500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.98     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 40499     |\n",
      "|    policy_loss        | -12       |\n",
      "|    reward             | 1.1151961 |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 6.56      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 564       |\n",
      "|    iterations         | 30600     |\n",
      "|    time_elapsed       | 270       |\n",
      "|    total_timesteps    | 153000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.98     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 40599     |\n",
      "|    policy_loss        | -12.7     |\n",
      "|    reward             | 1.8302482 |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 7.95      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 30700       |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 153500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.99       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 40699       |\n",
      "|    policy_loss        | -5.13       |\n",
      "|    reward             | 0.045053057 |\n",
      "|    std                | 1.29        |\n",
      "|    value_loss         | 1.35        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 30800      |\n",
      "|    time_elapsed       | 272        |\n",
      "|    total_timesteps    | 154000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.01      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 40799      |\n",
      "|    policy_loss        | 11.6       |\n",
      "|    reward             | 0.04214717 |\n",
      "|    std                | 1.29       |\n",
      "|    value_loss         | 29.5       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 564        |\n",
      "|    iterations         | 30900      |\n",
      "|    time_elapsed       | 273        |\n",
      "|    total_timesteps    | 154500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5         |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 40899      |\n",
      "|    policy_loss        | -5.5       |\n",
      "|    reward             | -0.8354715 |\n",
      "|    std                | 1.29       |\n",
      "|    value_loss         | 4.11       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 31000      |\n",
      "|    time_elapsed       | 274        |\n",
      "|    total_timesteps    | 155000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.01      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 40999      |\n",
      "|    policy_loss        | 3.43       |\n",
      "|    reward             | -6.8403244 |\n",
      "|    std                | 1.29       |\n",
      "|    value_loss         | 1.81       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 31100     |\n",
      "|    time_elapsed       | 275       |\n",
      "|    total_timesteps    | 155500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5        |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41099     |\n",
      "|    policy_loss        | -18.4     |\n",
      "|    reward             | -4.155699 |\n",
      "|    std                | 1.29      |\n",
      "|    value_loss         | 11.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 31200     |\n",
      "|    time_elapsed       | 276       |\n",
      "|    total_timesteps    | 156000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5        |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41199     |\n",
      "|    policy_loss        | -32.3     |\n",
      "|    reward             | -13.36883 |\n",
      "|    std                | 1.29      |\n",
      "|    value_loss         | 103       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 564         |\n",
      "|    iterations         | 31300       |\n",
      "|    time_elapsed       | 276         |\n",
      "|    total_timesteps    | 156500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5          |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 41299       |\n",
      "|    policy_loss        | 0.194       |\n",
      "|    reward             | -0.33183333 |\n",
      "|    std                | 1.28        |\n",
      "|    value_loss         | 3.03        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 31400    |\n",
      "|    time_elapsed       | 277      |\n",
      "|    total_timesteps    | 157000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.99    |\n",
      "|    explained_variance | -0.627   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41399    |\n",
      "|    policy_loss        | -6.71    |\n",
      "|    reward             | 2.053454 |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 2.27     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 31500     |\n",
      "|    time_elapsed       | 278       |\n",
      "|    total_timesteps    | 157500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.98     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41499     |\n",
      "|    policy_loss        | -20.3     |\n",
      "|    reward             | 1.3733749 |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 30.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 31600     |\n",
      "|    time_elapsed       | 279       |\n",
      "|    total_timesteps    | 158000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5        |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41599     |\n",
      "|    policy_loss        | -46.6     |\n",
      "|    reward             | -3.265002 |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 104       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 31700     |\n",
      "|    time_elapsed       | 280       |\n",
      "|    total_timesteps    | 158500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5        |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41699     |\n",
      "|    policy_loss        | 14.4      |\n",
      "|    reward             | 3.876054  |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 6.31      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 565      |\n",
      "|    iterations         | 31800    |\n",
      "|    time_elapsed       | 281      |\n",
      "|    total_timesteps    | 159000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.01    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41799    |\n",
      "|    policy_loss        | 37       |\n",
      "|    reward             | 8.314627 |\n",
      "|    std                | 1.29     |\n",
      "|    value_loss         | 72.2     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 31900      |\n",
      "|    time_elapsed       | 282        |\n",
      "|    total_timesteps    | 159500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5         |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 41899      |\n",
      "|    policy_loss        | 20.7       |\n",
      "|    reward             | 0.09078616 |\n",
      "|    std                | 1.28       |\n",
      "|    value_loss         | 18.1       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 32000      |\n",
      "|    time_elapsed       | 282        |\n",
      "|    total_timesteps    | 160000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.01      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 41999      |\n",
      "|    policy_loss        | 10.3       |\n",
      "|    reward             | -1.6762846 |\n",
      "|    std                | 1.29       |\n",
      "|    value_loss         | 7.72       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 565         |\n",
      "|    iterations         | 32100       |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 160500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.01       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 42099       |\n",
      "|    policy_loss        | 3.06        |\n",
      "|    reward             | -0.11266205 |\n",
      "|    std                | 1.29        |\n",
      "|    value_loss         | 1.04        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 32200     |\n",
      "|    time_elapsed       | 284       |\n",
      "|    total_timesteps    | 161000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5        |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42199     |\n",
      "|    policy_loss        | 5.07      |\n",
      "|    reward             | 4.4601912 |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 3.57      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 32300     |\n",
      "|    time_elapsed       | 285       |\n",
      "|    total_timesteps    | 161500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5        |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42299     |\n",
      "|    policy_loss        | -10.9     |\n",
      "|    reward             | -6.971006 |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 7.51      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 32400     |\n",
      "|    time_elapsed       | 286       |\n",
      "|    total_timesteps    | 162000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5        |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42399     |\n",
      "|    policy_loss        | -58       |\n",
      "|    reward             | -4.36307  |\n",
      "|    std                | 1.29      |\n",
      "|    value_loss         | 272       |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 565          |\n",
      "|    iterations         | 32500        |\n",
      "|    time_elapsed       | 287          |\n",
      "|    total_timesteps    | 162500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5           |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 42499        |\n",
      "|    policy_loss        | -9.84        |\n",
      "|    reward             | -0.095857404 |\n",
      "|    std                | 1.29         |\n",
      "|    value_loss         | 6.58         |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 32600     |\n",
      "|    time_elapsed       | 288       |\n",
      "|    total_timesteps    | 163000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.02     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42599     |\n",
      "|    policy_loss        | -14.3     |\n",
      "|    reward             | 1.9133866 |\n",
      "|    std                | 1.29      |\n",
      "|    value_loss         | 13.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 32700      |\n",
      "|    time_elapsed       | 288        |\n",
      "|    total_timesteps    | 163500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.03      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 42699      |\n",
      "|    policy_loss        | -3.68      |\n",
      "|    reward             | -1.6703734 |\n",
      "|    std                | 1.3        |\n",
      "|    value_loss         | 2.27       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 32800      |\n",
      "|    time_elapsed       | 289        |\n",
      "|    total_timesteps    | 164000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.04      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 42799      |\n",
      "|    policy_loss        | 20.5       |\n",
      "|    reward             | -3.3489482 |\n",
      "|    std                | 1.3        |\n",
      "|    value_loss         | 22.6       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 32900     |\n",
      "|    time_elapsed       | 290       |\n",
      "|    total_timesteps    | 164500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.05     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42899     |\n",
      "|    policy_loss        | 26.9      |\n",
      "|    reward             | 12.392672 |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 42.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 565        |\n",
      "|    iterations         | 33000      |\n",
      "|    time_elapsed       | 291        |\n",
      "|    total_timesteps    | 165000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.06      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 42999      |\n",
      "|    policy_loss        | 8.29       |\n",
      "|    reward             | -1.2598584 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 3.18       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 565       |\n",
      "|    iterations         | 33100     |\n",
      "|    time_elapsed       | 292       |\n",
      "|    total_timesteps    | 165500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.06     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43099     |\n",
      "|    policy_loss        | -1.13     |\n",
      "|    reward             | 0.1578381 |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 0.61      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 33200     |\n",
      "|    time_elapsed       | 293       |\n",
      "|    total_timesteps    | 166000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.06     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43199     |\n",
      "|    policy_loss        | -14.3     |\n",
      "|    reward             | 1.3870882 |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 7.78      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 33300       |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 166500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.05       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 43299       |\n",
      "|    policy_loss        | -27.5       |\n",
      "|    reward             | -0.34848472 |\n",
      "|    std                | 1.31        |\n",
      "|    value_loss         | 26.1        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 566        |\n",
      "|    iterations         | 33400      |\n",
      "|    time_elapsed       | 294        |\n",
      "|    total_timesteps    | 167000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.06      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 43399      |\n",
      "|    policy_loss        | 14.4       |\n",
      "|    reward             | -1.3451093 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 9.56       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 33500     |\n",
      "|    time_elapsed       | 295       |\n",
      "|    total_timesteps    | 167500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.06     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43499     |\n",
      "|    policy_loss        | 118       |\n",
      "|    reward             | -6.835462 |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 356       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 33600     |\n",
      "|    time_elapsed       | 296       |\n",
      "|    total_timesteps    | 168000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.08     |\n",
      "|    explained_variance | -0.0239   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43599     |\n",
      "|    policy_loss        | -12.2     |\n",
      "|    reward             | 0.2014803 |\n",
      "|    std                | 1.32      |\n",
      "|    value_loss         | 9.88      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 566         |\n",
      "|    iterations         | 33700       |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 168500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.06       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 43699       |\n",
      "|    policy_loss        | 7.66        |\n",
      "|    reward             | -0.29455608 |\n",
      "|    std                | 1.31        |\n",
      "|    value_loss         | 6.89        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 566       |\n",
      "|    iterations         | 33800     |\n",
      "|    time_elapsed       | 298       |\n",
      "|    total_timesteps    | 169000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.05     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43799     |\n",
      "|    policy_loss        | 8.15      |\n",
      "|    reward             | -6.561422 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 9.33      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 566        |\n",
      "|    iterations         | 33900      |\n",
      "|    time_elapsed       | 299        |\n",
      "|    total_timesteps    | 169500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.04      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 43899      |\n",
      "|    policy_loss        | 32.4       |\n",
      "|    reward             | -1.2583965 |\n",
      "|    std                | 1.3        |\n",
      "|    value_loss         | 62.6       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 567          |\n",
      "|    iterations         | 34000        |\n",
      "|    time_elapsed       | 299          |\n",
      "|    total_timesteps    | 170000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.02        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 43999        |\n",
      "|    policy_loss        | 5.53         |\n",
      "|    reward             | -0.077096775 |\n",
      "|    std                | 1.29         |\n",
      "|    value_loss         | 2.51         |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 567      |\n",
      "|    iterations         | 34100    |\n",
      "|    time_elapsed       | 300      |\n",
      "|    total_timesteps    | 170500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.03    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44099    |\n",
      "|    policy_loss        | 5.26     |\n",
      "|    reward             | 5.032139 |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 16.7     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 567         |\n",
      "|    iterations         | 34200       |\n",
      "|    time_elapsed       | 301         |\n",
      "|    total_timesteps    | 171000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.02       |\n",
      "|    explained_variance | -1.72       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 44199       |\n",
      "|    policy_loss        | 3.82        |\n",
      "|    reward             | -0.24471138 |\n",
      "|    std                | 1.3         |\n",
      "|    value_loss         | 1.37        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 567       |\n",
      "|    iterations         | 34300     |\n",
      "|    time_elapsed       | 302       |\n",
      "|    total_timesteps    | 171500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.01     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 44299     |\n",
      "|    policy_loss        | -1.52     |\n",
      "|    reward             | 2.7392704 |\n",
      "|    std                | 1.29      |\n",
      "|    value_loss         | 2.66      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 567       |\n",
      "|    iterations         | 34400     |\n",
      "|    time_elapsed       | 303       |\n",
      "|    total_timesteps    | 172000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.01     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 44399     |\n",
      "|    policy_loss        | 1.51      |\n",
      "|    reward             | 1.8347001 |\n",
      "|    std                | 1.29      |\n",
      "|    value_loss         | 2.81      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 567       |\n",
      "|    iterations         | 34500     |\n",
      "|    time_elapsed       | 303       |\n",
      "|    total_timesteps    | 172500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5        |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 44499     |\n",
      "|    policy_loss        | 3.77      |\n",
      "|    reward             | 2.3163886 |\n",
      "|    std                | 1.29      |\n",
      "|    value_loss         | 2.76      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 567        |\n",
      "|    iterations         | 34600      |\n",
      "|    time_elapsed       | 304        |\n",
      "|    total_timesteps    | 173000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.02      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 44599      |\n",
      "|    policy_loss        | -2.4       |\n",
      "|    reward             | -7.0903263 |\n",
      "|    std                | 1.29       |\n",
      "|    value_loss         | 5.67       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 567        |\n",
      "|    iterations         | 34700      |\n",
      "|    time_elapsed       | 305        |\n",
      "|    total_timesteps    | 173500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.01      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 44699      |\n",
      "|    policy_loss        | 74.7       |\n",
      "|    reward             | -38.520298 |\n",
      "|    std                | 1.29       |\n",
      "|    value_loss         | 574        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 567         |\n",
      "|    iterations         | 34800       |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 174000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.02       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 44799       |\n",
      "|    policy_loss        | -18.7       |\n",
      "|    reward             | -0.35426733 |\n",
      "|    std                | 1.3         |\n",
      "|    value_loss         | 15.3        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 568        |\n",
      "|    iterations         | 34900      |\n",
      "|    time_elapsed       | 307        |\n",
      "|    total_timesteps    | 174500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.04      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 44899      |\n",
      "|    policy_loss        | 4.48       |\n",
      "|    reward             | -0.9875106 |\n",
      "|    std                | 1.3        |\n",
      "|    value_loss         | 2.43       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 35000     |\n",
      "|    time_elapsed       | 308       |\n",
      "|    total_timesteps    | 175000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.03     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 44999     |\n",
      "|    policy_loss        | 19.1      |\n",
      "|    reward             | 0.5312148 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 13        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 35100     |\n",
      "|    time_elapsed       | 308       |\n",
      "|    total_timesteps    | 175500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.04     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45099     |\n",
      "|    policy_loss        | 9.9       |\n",
      "|    reward             | 0.7367167 |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 4.27      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 35200     |\n",
      "|    time_elapsed       | 309       |\n",
      "|    total_timesteps    | 176000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.03     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45199     |\n",
      "|    policy_loss        | 28.6      |\n",
      "|    reward             | 4.1202946 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 37.7      |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6616430.34\n",
      "total_reward: 5616430.34\n",
      "total_cost: 1969.72\n",
      "total_trades: 6099\n",
      "Sharpe: 0.896\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 35300     |\n",
      "|    time_elapsed       | 310       |\n",
      "|    total_timesteps    | 176500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.04     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45299     |\n",
      "|    policy_loss        | -0.434    |\n",
      "|    reward             | 0.3603484 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 0.0571    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 35400     |\n",
      "|    time_elapsed       | 311       |\n",
      "|    total_timesteps    | 177000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.06     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45399     |\n",
      "|    policy_loss        | -11.5     |\n",
      "|    reward             | 0.5453879 |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 8.47      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 35500     |\n",
      "|    time_elapsed       | 312       |\n",
      "|    total_timesteps    | 177500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.07     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45499     |\n",
      "|    policy_loss        | 25.7      |\n",
      "|    reward             | 2.4719408 |\n",
      "|    std                | 1.32      |\n",
      "|    value_loss         | 32.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 568        |\n",
      "|    iterations         | 35600      |\n",
      "|    time_elapsed       | 313        |\n",
      "|    total_timesteps    | 178000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.06      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 45599      |\n",
      "|    policy_loss        | -18.5      |\n",
      "|    reward             | -4.9666348 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 15.8       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 35700     |\n",
      "|    time_elapsed       | 313       |\n",
      "|    total_timesteps    | 178500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.04     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45699     |\n",
      "|    policy_loss        | -3.75     |\n",
      "|    reward             | 0.9080987 |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 2.55      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 568       |\n",
      "|    iterations         | 35800     |\n",
      "|    time_elapsed       | 314       |\n",
      "|    total_timesteps    | 179000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.04     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45799     |\n",
      "|    policy_loss        | 34        |\n",
      "|    reward             | 2.3951116 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 121       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 569       |\n",
      "|    iterations         | 35900     |\n",
      "|    time_elapsed       | 315       |\n",
      "|    total_timesteps    | 179500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.04     |\n",
      "|    explained_variance | 0.312     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45899     |\n",
      "|    policy_loss        | 12.3      |\n",
      "|    reward             | 2.9365394 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 6.95      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 569       |\n",
      "|    iterations         | 36000     |\n",
      "|    time_elapsed       | 316       |\n",
      "|    total_timesteps    | 180000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.05     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45999     |\n",
      "|    policy_loss        | 20.5      |\n",
      "|    reward             | -1.580535 |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 27.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 569        |\n",
      "|    iterations         | 36100      |\n",
      "|    time_elapsed       | 317        |\n",
      "|    total_timesteps    | 180500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.05      |\n",
      "|    explained_variance | 0.508      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 46099      |\n",
      "|    policy_loss        | -10.2      |\n",
      "|    reward             | 0.26686272 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 6.57       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 569       |\n",
      "|    iterations         | 36200     |\n",
      "|    time_elapsed       | 317       |\n",
      "|    total_timesteps    | 181000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.06     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 46199     |\n",
      "|    policy_loss        | -9.38     |\n",
      "|    reward             | 2.0174942 |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 5.31      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 569         |\n",
      "|    iterations         | 36300       |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 181500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.05       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 46299       |\n",
      "|    policy_loss        | 7.75        |\n",
      "|    reward             | -0.54615027 |\n",
      "|    std                | 1.31        |\n",
      "|    value_loss         | 2.31        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 569        |\n",
      "|    iterations         | 36400      |\n",
      "|    time_elapsed       | 319        |\n",
      "|    total_timesteps    | 182000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.04      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 46399      |\n",
      "|    policy_loss        | 3.18       |\n",
      "|    reward             | 0.35853842 |\n",
      "|    std                | 1.3        |\n",
      "|    value_loss         | 3.12       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 569        |\n",
      "|    iterations         | 36500      |\n",
      "|    time_elapsed       | 320        |\n",
      "|    total_timesteps    | 182500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.06      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 46499      |\n",
      "|    policy_loss        | 1.96       |\n",
      "|    reward             | 0.27026635 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 0.427      |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 570      |\n",
      "|    iterations         | 36600    |\n",
      "|    time_elapsed       | 321      |\n",
      "|    total_timesteps    | 183000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.04    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46599    |\n",
      "|    policy_loss        | 20.9     |\n",
      "|    reward             | 2.843458 |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 40.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 570       |\n",
      "|    iterations         | 36700     |\n",
      "|    time_elapsed       | 321       |\n",
      "|    total_timesteps    | 183500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.04     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 46699     |\n",
      "|    policy_loss        | -0.432    |\n",
      "|    reward             | 1.8379475 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 4.9       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 570        |\n",
      "|    iterations         | 36800      |\n",
      "|    time_elapsed       | 322        |\n",
      "|    total_timesteps    | 184000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.03      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 46799      |\n",
      "|    policy_loss        | 9.05       |\n",
      "|    reward             | -1.4563167 |\n",
      "|    std                | 1.3        |\n",
      "|    value_loss         | 7.6        |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 570      |\n",
      "|    iterations         | 36900    |\n",
      "|    time_elapsed       | 323      |\n",
      "|    total_timesteps    | 184500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.04    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46899    |\n",
      "|    policy_loss        | -7.66    |\n",
      "|    reward             | 1.049987 |\n",
      "|    std                | 1.31     |\n",
      "|    value_loss         | 3.18     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 570       |\n",
      "|    iterations         | 37000     |\n",
      "|    time_elapsed       | 324       |\n",
      "|    total_timesteps    | 185000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.03     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 46999     |\n",
      "|    policy_loss        | 0.949     |\n",
      "|    reward             | 0.4537979 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 0.891     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 570       |\n",
      "|    iterations         | 37100     |\n",
      "|    time_elapsed       | 325       |\n",
      "|    total_timesteps    | 185500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.03     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 47099     |\n",
      "|    policy_loss        | 9.15      |\n",
      "|    reward             | 0.9889557 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 16.3      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 570         |\n",
      "|    iterations         | 37200       |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 186000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.03       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 47199       |\n",
      "|    policy_loss        | -26.6       |\n",
      "|    reward             | -0.66928506 |\n",
      "|    std                | 1.3         |\n",
      "|    value_loss         | 29.3        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 570       |\n",
      "|    iterations         | 37300     |\n",
      "|    time_elapsed       | 326       |\n",
      "|    total_timesteps    | 186500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.03     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 47299     |\n",
      "|    policy_loss        | -19.6     |\n",
      "|    reward             | 0.6312937 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 27.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 571      |\n",
      "|    iterations         | 37400    |\n",
      "|    time_elapsed       | 327      |\n",
      "|    total_timesteps    | 187000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.04    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47399    |\n",
      "|    policy_loss        | -23.1    |\n",
      "|    reward             | 2.677736 |\n",
      "|    std                | 1.31     |\n",
      "|    value_loss         | 26.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 571       |\n",
      "|    iterations         | 37500     |\n",
      "|    time_elapsed       | 328       |\n",
      "|    total_timesteps    | 187500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.04     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 47499     |\n",
      "|    policy_loss        | -25.2     |\n",
      "|    reward             | -4.684973 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 36.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 571       |\n",
      "|    iterations         | 37600     |\n",
      "|    time_elapsed       | 329       |\n",
      "|    total_timesteps    | 188000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.01     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 47599     |\n",
      "|    policy_loss        | -74.8     |\n",
      "|    reward             | -7.031432 |\n",
      "|    std                | 1.29      |\n",
      "|    value_loss         | 266       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 571         |\n",
      "|    iterations         | 37700       |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 188500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.02       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 47699       |\n",
      "|    policy_loss        | 6.59        |\n",
      "|    reward             | -0.18030421 |\n",
      "|    std                | 1.29        |\n",
      "|    value_loss         | 2.82        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 571       |\n",
      "|    iterations         | 37800     |\n",
      "|    time_elapsed       | 330       |\n",
      "|    total_timesteps    | 189000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.03     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 47799     |\n",
      "|    policy_loss        | -14.3     |\n",
      "|    reward             | 1.4992532 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 9.52      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 571        |\n",
      "|    iterations         | 37900      |\n",
      "|    time_elapsed       | 331        |\n",
      "|    total_timesteps    | 189500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.03      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 47899      |\n",
      "|    policy_loss        | -16        |\n",
      "|    reward             | 0.36412975 |\n",
      "|    std                | 1.3        |\n",
      "|    value_loss         | 12.7       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 571         |\n",
      "|    iterations         | 38000       |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 190000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.05       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 47999       |\n",
      "|    policy_loss        | 9.03        |\n",
      "|    reward             | -0.88210106 |\n",
      "|    std                | 1.31        |\n",
      "|    value_loss         | 6.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 572         |\n",
      "|    iterations         | 38100       |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 190500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.03       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 48099       |\n",
      "|    policy_loss        | 8.3         |\n",
      "|    reward             | -0.43274504 |\n",
      "|    std                | 1.3         |\n",
      "|    value_loss         | 8.2         |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 572       |\n",
      "|    iterations         | 38200     |\n",
      "|    time_elapsed       | 333       |\n",
      "|    total_timesteps    | 191000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.05     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48199     |\n",
      "|    policy_loss        | 7.38      |\n",
      "|    reward             | 1.1814845 |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 2.45      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 572         |\n",
      "|    iterations         | 38300       |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 191500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.04       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 48299       |\n",
      "|    policy_loss        | 1.91        |\n",
      "|    reward             | -0.92090213 |\n",
      "|    std                | 1.31        |\n",
      "|    value_loss         | 10.5        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 572      |\n",
      "|    iterations         | 38400    |\n",
      "|    time_elapsed       | 335      |\n",
      "|    total_timesteps    | 192000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.04    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 48399    |\n",
      "|    policy_loss        | -0.436   |\n",
      "|    reward             | -1.24302 |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 3.37     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 572        |\n",
      "|    iterations         | 38500      |\n",
      "|    time_elapsed       | 336        |\n",
      "|    total_timesteps    | 192500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.04      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 48499      |\n",
      "|    policy_loss        | -15.8      |\n",
      "|    reward             | -0.2958855 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 16.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 572        |\n",
      "|    iterations         | 38600      |\n",
      "|    time_elapsed       | 336        |\n",
      "|    total_timesteps    | 193000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.04      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 48599      |\n",
      "|    policy_loss        | -1.86      |\n",
      "|    reward             | -1.1424316 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 1.69       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 573      |\n",
      "|    iterations         | 38700    |\n",
      "|    time_elapsed       | 337      |\n",
      "|    total_timesteps    | 193500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.04    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 48699    |\n",
      "|    policy_loss        | -6.12    |\n",
      "|    reward             | 6.265475 |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 1.61     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 573        |\n",
      "|    iterations         | 38800      |\n",
      "|    time_elapsed       | 338        |\n",
      "|    total_timesteps    | 194000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.04      |\n",
      "|    explained_variance | 0.41       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 48799      |\n",
      "|    policy_loss        | -0.872     |\n",
      "|    reward             | 0.47365102 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 0.148      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 573       |\n",
      "|    iterations         | 38900     |\n",
      "|    time_elapsed       | 339       |\n",
      "|    total_timesteps    | 194500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.03     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48899     |\n",
      "|    policy_loss        | -36.2     |\n",
      "|    reward             | 3.6054273 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 107       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 573        |\n",
      "|    iterations         | 39000      |\n",
      "|    time_elapsed       | 340        |\n",
      "|    total_timesteps    | 195000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.01      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 48999      |\n",
      "|    policy_loss        | -21.1      |\n",
      "|    reward             | -1.2862055 |\n",
      "|    std                | 1.29       |\n",
      "|    value_loss         | 18.7       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 573       |\n",
      "|    iterations         | 39100     |\n",
      "|    time_elapsed       | 340       |\n",
      "|    total_timesteps    | 195500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.03     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 49099     |\n",
      "|    policy_loss        | -5.84     |\n",
      "|    reward             | -2.267981 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 2.39      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 573         |\n",
      "|    iterations         | 39200       |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 196000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.05       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 49199       |\n",
      "|    policy_loss        | -6.36       |\n",
      "|    reward             | -0.25472462 |\n",
      "|    std                | 1.31        |\n",
      "|    value_loss         | 2.2         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 573        |\n",
      "|    iterations         | 39300      |\n",
      "|    time_elapsed       | 342        |\n",
      "|    total_timesteps    | 196500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.06      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 49299      |\n",
      "|    policy_loss        | -81.7      |\n",
      "|    reward             | -4.8670883 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 285        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 573        |\n",
      "|    iterations         | 39400      |\n",
      "|    time_elapsed       | 343        |\n",
      "|    total_timesteps    | 197000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.04      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 49399      |\n",
      "|    policy_loss        | -8.07      |\n",
      "|    reward             | -1.2192187 |\n",
      "|    std                | 1.3        |\n",
      "|    value_loss         | 5.86       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 574        |\n",
      "|    iterations         | 39500      |\n",
      "|    time_elapsed       | 344        |\n",
      "|    total_timesteps    | 197500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.06      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 49499      |\n",
      "|    policy_loss        | 20.3       |\n",
      "|    reward             | 0.40294948 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 42.1       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 574          |\n",
      "|    iterations         | 39600        |\n",
      "|    time_elapsed       | 344          |\n",
      "|    total_timesteps    | 198000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.06        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 49599        |\n",
      "|    policy_loss        | -27.1        |\n",
      "|    reward             | 0.0036362854 |\n",
      "|    std                | 1.31         |\n",
      "|    value_loss         | 39.8         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 574         |\n",
      "|    iterations         | 39700       |\n",
      "|    time_elapsed       | 345         |\n",
      "|    total_timesteps    | 198500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.07       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 49699       |\n",
      "|    policy_loss        | -18.2       |\n",
      "|    reward             | -0.87041295 |\n",
      "|    std                | 1.32        |\n",
      "|    value_loss         | 17.4        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 574        |\n",
      "|    iterations         | 39800      |\n",
      "|    time_elapsed       | 346        |\n",
      "|    total_timesteps    | 199000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.06      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 49799      |\n",
      "|    policy_loss        | 12.3       |\n",
      "|    reward             | 0.60910064 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 14.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 574        |\n",
      "|    iterations         | 39900      |\n",
      "|    time_elapsed       | 347        |\n",
      "|    total_timesteps    | 199500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.09      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 49899      |\n",
      "|    policy_loss        | -1.88      |\n",
      "|    reward             | -1.6103864 |\n",
      "|    std                | 1.33       |\n",
      "|    value_loss         | 2.9        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 574       |\n",
      "|    iterations         | 40000     |\n",
      "|    time_elapsed       | 348       |\n",
      "|    total_timesteps    | 200000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.09     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 49999     |\n",
      "|    policy_loss        | -3.97     |\n",
      "|    reward             | 1.8457631 |\n",
      "|    std                | 1.33      |\n",
      "|    value_loss         | 8.43      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 574        |\n",
      "|    iterations         | 40100      |\n",
      "|    time_elapsed       | 348        |\n",
      "|    total_timesteps    | 200500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.09      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 50099      |\n",
      "|    policy_loss        | -7.81      |\n",
      "|    reward             | -0.6560743 |\n",
      "|    std                | 1.33       |\n",
      "|    value_loss         | 9.49       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 574       |\n",
      "|    iterations         | 40200     |\n",
      "|    time_elapsed       | 349       |\n",
      "|    total_timesteps    | 201000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.08     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50199     |\n",
      "|    policy_loss        | -9.04     |\n",
      "|    reward             | 2.0955386 |\n",
      "|    std                | 1.32      |\n",
      "|    value_loss         | 4.18      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 40300     |\n",
      "|    time_elapsed       | 350       |\n",
      "|    total_timesteps    | 201500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.07     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50299     |\n",
      "|    policy_loss        | 9.43      |\n",
      "|    reward             | -4.105862 |\n",
      "|    std                | 1.32      |\n",
      "|    value_loss         | 5.17      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 575        |\n",
      "|    iterations         | 40400      |\n",
      "|    time_elapsed       | 351        |\n",
      "|    total_timesteps    | 202000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.07      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 50399      |\n",
      "|    policy_loss        | -8.86      |\n",
      "|    reward             | -2.0157728 |\n",
      "|    std                | 1.32       |\n",
      "|    value_loss         | 2.4        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 575        |\n",
      "|    iterations         | 40500      |\n",
      "|    time_elapsed       | 351        |\n",
      "|    total_timesteps    | 202500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.07      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 50499      |\n",
      "|    policy_loss        | 12         |\n",
      "|    reward             | -0.9966735 |\n",
      "|    std                | 1.32       |\n",
      "|    value_loss         | 23.3       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 575         |\n",
      "|    iterations         | 40600       |\n",
      "|    time_elapsed       | 352         |\n",
      "|    total_timesteps    | 203000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.08       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 50599       |\n",
      "|    policy_loss        | 7.71        |\n",
      "|    reward             | -0.54982877 |\n",
      "|    std                | 1.33        |\n",
      "|    value_loss         | 4.95        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 40700     |\n",
      "|    time_elapsed       | 353       |\n",
      "|    total_timesteps    | 203500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.1      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50699     |\n",
      "|    policy_loss        | -12.5     |\n",
      "|    reward             | 1.7307353 |\n",
      "|    std                | 1.33      |\n",
      "|    value_loss         | 9.96      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 40800     |\n",
      "|    time_elapsed       | 354       |\n",
      "|    total_timesteps    | 204000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.09     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50799     |\n",
      "|    policy_loss        | -4.13     |\n",
      "|    reward             | 1.4611709 |\n",
      "|    std                | 1.33      |\n",
      "|    value_loss         | 0.904     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 40900     |\n",
      "|    time_elapsed       | 355       |\n",
      "|    total_timesteps    | 204500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.08     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50899     |\n",
      "|    policy_loss        | 8.17      |\n",
      "|    reward             | 1.5730276 |\n",
      "|    std                | 1.33      |\n",
      "|    value_loss         | 4.64      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 41000     |\n",
      "|    time_elapsed       | 356       |\n",
      "|    total_timesteps    | 205000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.1      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50999     |\n",
      "|    policy_loss        | -28.6     |\n",
      "|    reward             | 2.5103993 |\n",
      "|    std                | 1.33      |\n",
      "|    value_loss         | 34.1      |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2731933.27\n",
      "total_reward: 1731933.27\n",
      "total_cost: 2079.39\n",
      "total_trades: 6022\n",
      "Sharpe: 0.531\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 41100     |\n",
      "|    time_elapsed       | 356       |\n",
      "|    total_timesteps    | 205500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.09     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51099     |\n",
      "|    policy_loss        | -1.77     |\n",
      "|    reward             | -0.593248 |\n",
      "|    std                | 1.33      |\n",
      "|    value_loss         | 0.458     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 575       |\n",
      "|    iterations         | 41200     |\n",
      "|    time_elapsed       | 357       |\n",
      "|    total_timesteps    | 206000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.1      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51199     |\n",
      "|    policy_loss        | 1.77      |\n",
      "|    reward             | 1.6401309 |\n",
      "|    std                | 1.33      |\n",
      "|    value_loss         | 2.49      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 576        |\n",
      "|    iterations         | 41300      |\n",
      "|    time_elapsed       | 358        |\n",
      "|    total_timesteps    | 206500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.09      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 51299      |\n",
      "|    policy_loss        | 5.1        |\n",
      "|    reward             | 0.99106365 |\n",
      "|    std                | 1.33       |\n",
      "|    value_loss         | 3.63       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 576       |\n",
      "|    iterations         | 41400     |\n",
      "|    time_elapsed       | 359       |\n",
      "|    total_timesteps    | 207000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.11     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51399     |\n",
      "|    policy_loss        | 5.35      |\n",
      "|    reward             | 2.1126769 |\n",
      "|    std                | 1.34      |\n",
      "|    value_loss         | 6.49      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 576       |\n",
      "|    iterations         | 41500     |\n",
      "|    time_elapsed       | 360       |\n",
      "|    total_timesteps    | 207500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.12     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51499     |\n",
      "|    policy_loss        | -3.81     |\n",
      "|    reward             | -0.612864 |\n",
      "|    std                | 1.34      |\n",
      "|    value_loss         | 1.07      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 576      |\n",
      "|    iterations         | 41600    |\n",
      "|    time_elapsed       | 360      |\n",
      "|    total_timesteps    | 208000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.13    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 51599    |\n",
      "|    policy_loss        | -4.05    |\n",
      "|    reward             | 1.824274 |\n",
      "|    std                | 1.35     |\n",
      "|    value_loss         | 10.7     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 576        |\n",
      "|    iterations         | 41700      |\n",
      "|    time_elapsed       | 361        |\n",
      "|    total_timesteps    | 208500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.14      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 51699      |\n",
      "|    policy_loss        | -25.8      |\n",
      "|    reward             | -1.0074197 |\n",
      "|    std                | 1.35       |\n",
      "|    value_loss         | 22.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 576       |\n",
      "|    iterations         | 41800     |\n",
      "|    time_elapsed       | 362       |\n",
      "|    total_timesteps    | 209000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.15     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51799     |\n",
      "|    policy_loss        | 20.5      |\n",
      "|    reward             | -7.007959 |\n",
      "|    std                | 1.36      |\n",
      "|    value_loss         | 36.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 576      |\n",
      "|    iterations         | 41900    |\n",
      "|    time_elapsed       | 363      |\n",
      "|    total_timesteps    | 209500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.16    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 51899    |\n",
      "|    policy_loss        | -34.1    |\n",
      "|    reward             | -2.27274 |\n",
      "|    std                | 1.36     |\n",
      "|    value_loss         | 39.2     |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 576          |\n",
      "|    iterations         | 42000        |\n",
      "|    time_elapsed       | 364          |\n",
      "|    total_timesteps    | 210000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.16        |\n",
      "|    explained_variance | 0.0159       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 51999        |\n",
      "|    policy_loss        | 8.68         |\n",
      "|    reward             | -0.085118145 |\n",
      "|    std                | 1.36         |\n",
      "|    value_loss         | 4.17         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 576        |\n",
      "|    iterations         | 42100      |\n",
      "|    time_elapsed       | 364        |\n",
      "|    total_timesteps    | 210500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.16      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 52099      |\n",
      "|    policy_loss        | -2.17      |\n",
      "|    reward             | -0.0771262 |\n",
      "|    std                | 1.36       |\n",
      "|    value_loss         | 0.505      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 577        |\n",
      "|    iterations         | 42200      |\n",
      "|    time_elapsed       | 365        |\n",
      "|    total_timesteps    | 211000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.14      |\n",
      "|    explained_variance | -0.174     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 52199      |\n",
      "|    policy_loss        | -12.1      |\n",
      "|    reward             | -3.3350585 |\n",
      "|    std                | 1.35       |\n",
      "|    value_loss         | 5.82       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 577        |\n",
      "|    iterations         | 42300      |\n",
      "|    time_elapsed       | 366        |\n",
      "|    total_timesteps    | 211500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.17      |\n",
      "|    explained_variance | -1.24      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 52299      |\n",
      "|    policy_loss        | 3.36       |\n",
      "|    reward             | 0.30821446 |\n",
      "|    std                | 1.36       |\n",
      "|    value_loss         | 1.07       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 577       |\n",
      "|    iterations         | 42400     |\n",
      "|    time_elapsed       | 367       |\n",
      "|    total_timesteps    | 212000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.15     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52399     |\n",
      "|    policy_loss        | 19.2      |\n",
      "|    reward             | 0.8266466 |\n",
      "|    std                | 1.35      |\n",
      "|    value_loss         | 17.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 577       |\n",
      "|    iterations         | 42500     |\n",
      "|    time_elapsed       | 368       |\n",
      "|    total_timesteps    | 212500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.15     |\n",
      "|    explained_variance | -0.228    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52499     |\n",
      "|    policy_loss        | -17       |\n",
      "|    reward             | 3.7571228 |\n",
      "|    std                | 1.36      |\n",
      "|    value_loss         | 11.4      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 577        |\n",
      "|    iterations         | 42600      |\n",
      "|    time_elapsed       | 368        |\n",
      "|    total_timesteps    | 213000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.18      |\n",
      "|    explained_variance | 0.236      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 52599      |\n",
      "|    policy_loss        | 4.83       |\n",
      "|    reward             | 0.40193638 |\n",
      "|    std                | 1.36       |\n",
      "|    value_loss         | 3.36       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 577       |\n",
      "|    iterations         | 42700     |\n",
      "|    time_elapsed       | 369       |\n",
      "|    total_timesteps    | 213500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.17     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52699     |\n",
      "|    policy_loss        | -13.7     |\n",
      "|    reward             | 4.8997364 |\n",
      "|    std                | 1.36      |\n",
      "|    value_loss         | 13        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 578       |\n",
      "|    iterations         | 42800     |\n",
      "|    time_elapsed       | 370       |\n",
      "|    total_timesteps    | 214000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.17     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52799     |\n",
      "|    policy_loss        | -111      |\n",
      "|    reward             | -8.588378 |\n",
      "|    std                | 1.36      |\n",
      "|    value_loss         | 748       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 578         |\n",
      "|    iterations         | 42900       |\n",
      "|    time_elapsed       | 370         |\n",
      "|    total_timesteps    | 214500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.18       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 52899       |\n",
      "|    policy_loss        | -16.1       |\n",
      "|    reward             | -0.37347794 |\n",
      "|    std                | 1.37        |\n",
      "|    value_loss         | 13.6        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 578        |\n",
      "|    iterations         | 43000      |\n",
      "|    time_elapsed       | 371        |\n",
      "|    total_timesteps    | 215000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.16      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 52999      |\n",
      "|    policy_loss        | 9.76       |\n",
      "|    reward             | -1.6419607 |\n",
      "|    std                | 1.36       |\n",
      "|    value_loss         | 4.26       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 578       |\n",
      "|    iterations         | 43100     |\n",
      "|    time_elapsed       | 372       |\n",
      "|    total_timesteps    | 215500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.16     |\n",
      "|    explained_variance | 4.17e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 53099     |\n",
      "|    policy_loss        | 7.29      |\n",
      "|    reward             | 1.3019663 |\n",
      "|    std                | 1.36      |\n",
      "|    value_loss         | 3.37      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 578        |\n",
      "|    iterations         | 43200      |\n",
      "|    time_elapsed       | 373        |\n",
      "|    total_timesteps    | 216000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.17      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 53199      |\n",
      "|    policy_loss        | 8.05       |\n",
      "|    reward             | -1.4956174 |\n",
      "|    std                | 1.36       |\n",
      "|    value_loss         | 4.77       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 578        |\n",
      "|    iterations         | 43300      |\n",
      "|    time_elapsed       | 373        |\n",
      "|    total_timesteps    | 216500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.18      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 53299      |\n",
      "|    policy_loss        | 21.4       |\n",
      "|    reward             | -0.7242179 |\n",
      "|    std                | 1.36       |\n",
      "|    value_loss         | 21.2       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 43400      |\n",
      "|    time_elapsed       | 374        |\n",
      "|    total_timesteps    | 217000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.17      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 53399      |\n",
      "|    policy_loss        | -1.8       |\n",
      "|    reward             | 0.06280698 |\n",
      "|    std                | 1.36       |\n",
      "|    value_loss         | 0.127      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 43500      |\n",
      "|    time_elapsed       | 375        |\n",
      "|    total_timesteps    | 217500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.16      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 53499      |\n",
      "|    policy_loss        | 17.7       |\n",
      "|    reward             | -0.2684721 |\n",
      "|    std                | 1.36       |\n",
      "|    value_loss         | 13.5       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 579         |\n",
      "|    iterations         | 43600       |\n",
      "|    time_elapsed       | 376         |\n",
      "|    total_timesteps    | 218000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.17       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 53599       |\n",
      "|    policy_loss        | 53.1        |\n",
      "|    reward             | -0.45250064 |\n",
      "|    std                | 1.36        |\n",
      "|    value_loss         | 100         |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 579      |\n",
      "|    iterations         | 43700    |\n",
      "|    time_elapsed       | 377      |\n",
      "|    total_timesteps    | 218500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.19    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 53699    |\n",
      "|    policy_loss        | 1.06     |\n",
      "|    reward             | 0.452749 |\n",
      "|    std                | 1.37     |\n",
      "|    value_loss         | 3.72     |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 579          |\n",
      "|    iterations         | 43800        |\n",
      "|    time_elapsed       | 378          |\n",
      "|    total_timesteps    | 219000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.21        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 53799        |\n",
      "|    policy_loss        | -2.68        |\n",
      "|    reward             | -0.035318665 |\n",
      "|    std                | 1.38         |\n",
      "|    value_loss         | 3.64         |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 579       |\n",
      "|    iterations         | 43900     |\n",
      "|    time_elapsed       | 378       |\n",
      "|    total_timesteps    | 219500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.22     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 53899     |\n",
      "|    policy_loss        | 28.2      |\n",
      "|    reward             | 2.9311004 |\n",
      "|    std                | 1.39      |\n",
      "|    value_loss         | 36.8      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 579         |\n",
      "|    iterations         | 44000       |\n",
      "|    time_elapsed       | 379         |\n",
      "|    total_timesteps    | 220000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.22       |\n",
      "|    explained_variance | 0.133       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 53999       |\n",
      "|    policy_loss        | -17.1       |\n",
      "|    reward             | -0.36949033 |\n",
      "|    std                | 1.39        |\n",
      "|    value_loss         | 13.2        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 44100      |\n",
      "|    time_elapsed       | 380        |\n",
      "|    total_timesteps    | 220500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.21      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 54099      |\n",
      "|    policy_loss        | 16.4       |\n",
      "|    reward             | -0.8241138 |\n",
      "|    std                | 1.38       |\n",
      "|    value_loss         | 14.8       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 579       |\n",
      "|    iterations         | 44200     |\n",
      "|    time_elapsed       | 381       |\n",
      "|    total_timesteps    | 221000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.2      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 54199     |\n",
      "|    policy_loss        | -6.94     |\n",
      "|    reward             | 1.7350309 |\n",
      "|    std                | 1.38      |\n",
      "|    value_loss         | 13.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 44300      |\n",
      "|    time_elapsed       | 382        |\n",
      "|    total_timesteps    | 221500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.21      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 54299      |\n",
      "|    policy_loss        | 3.17       |\n",
      "|    reward             | -3.1144285 |\n",
      "|    std                | 1.38       |\n",
      "|    value_loss         | 0.939      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 579       |\n",
      "|    iterations         | 44400     |\n",
      "|    time_elapsed       | 383       |\n",
      "|    total_timesteps    | 222000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.22     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 54399     |\n",
      "|    policy_loss        | -2.55     |\n",
      "|    reward             | 0.6173848 |\n",
      "|    std                | 1.39      |\n",
      "|    value_loss         | 0.524     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 579       |\n",
      "|    iterations         | 44500     |\n",
      "|    time_elapsed       | 383       |\n",
      "|    total_timesteps    | 222500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.22     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 54499     |\n",
      "|    policy_loss        | 13.7      |\n",
      "|    reward             | 1.2995644 |\n",
      "|    std                | 1.39      |\n",
      "|    value_loss         | 27.4      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 44600      |\n",
      "|    time_elapsed       | 384        |\n",
      "|    total_timesteps    | 223000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.21      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 54599      |\n",
      "|    policy_loss        | -10.5      |\n",
      "|    reward             | 0.49267715 |\n",
      "|    std                | 1.38       |\n",
      "|    value_loss         | 4.61       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 44700      |\n",
      "|    time_elapsed       | 385        |\n",
      "|    total_timesteps    | 223500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.23      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 54699      |\n",
      "|    policy_loss        | 42.3       |\n",
      "|    reward             | 0.83090574 |\n",
      "|    std                | 1.39       |\n",
      "|    value_loss         | 54         |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 579       |\n",
      "|    iterations         | 44800     |\n",
      "|    time_elapsed       | 386       |\n",
      "|    total_timesteps    | 224000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.2      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 54799     |\n",
      "|    policy_loss        | -25.9     |\n",
      "|    reward             | 0.5782587 |\n",
      "|    std                | 1.38      |\n",
      "|    value_loss         | 27.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 579       |\n",
      "|    iterations         | 44900     |\n",
      "|    time_elapsed       | 387       |\n",
      "|    total_timesteps    | 224500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.2      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 54899     |\n",
      "|    policy_loss        | 21.6      |\n",
      "|    reward             | 1.4612918 |\n",
      "|    std                | 1.38      |\n",
      "|    value_loss         | 23        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 45000      |\n",
      "|    time_elapsed       | 388        |\n",
      "|    total_timesteps    | 225000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.2       |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 54999      |\n",
      "|    policy_loss        | -16.5      |\n",
      "|    reward             | -1.1562274 |\n",
      "|    std                | 1.38       |\n",
      "|    value_loss         | 13.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 45100      |\n",
      "|    time_elapsed       | 389        |\n",
      "|    total_timesteps    | 225500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.21      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 55099      |\n",
      "|    policy_loss        | 10.1       |\n",
      "|    reward             | 0.29445496 |\n",
      "|    std                | 1.38       |\n",
      "|    value_loss         | 4.28       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 45200      |\n",
      "|    time_elapsed       | 389        |\n",
      "|    total_timesteps    | 226000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.23      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 55199      |\n",
      "|    policy_loss        | 33.6       |\n",
      "|    reward             | -1.3224328 |\n",
      "|    std                | 1.39       |\n",
      "|    value_loss         | 36.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 579       |\n",
      "|    iterations         | 45300     |\n",
      "|    time_elapsed       | 390       |\n",
      "|    total_timesteps    | 226500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.23     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 55299     |\n",
      "|    policy_loss        | -21.3     |\n",
      "|    reward             | 1.0752629 |\n",
      "|    std                | 1.39      |\n",
      "|    value_loss         | 13.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 45400      |\n",
      "|    time_elapsed       | 391        |\n",
      "|    total_timesteps    | 227000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.22      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 55399      |\n",
      "|    policy_loss        | -17.7      |\n",
      "|    reward             | 0.72928935 |\n",
      "|    std                | 1.39       |\n",
      "|    value_loss         | 13.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 579        |\n",
      "|    iterations         | 45500      |\n",
      "|    time_elapsed       | 392        |\n",
      "|    total_timesteps    | 227500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.21      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 55499      |\n",
      "|    policy_loss        | -15.3      |\n",
      "|    reward             | 0.25922847 |\n",
      "|    std                | 1.38       |\n",
      "|    value_loss         | 18.5       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 580        |\n",
      "|    iterations         | 45600      |\n",
      "|    time_elapsed       | 393        |\n",
      "|    total_timesteps    | 228000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.2       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 55599      |\n",
      "|    policy_loss        | -36.6      |\n",
      "|    reward             | -5.5516295 |\n",
      "|    std                | 1.37       |\n",
      "|    value_loss         | 74.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 580       |\n",
      "|    iterations         | 45700     |\n",
      "|    time_elapsed       | 393       |\n",
      "|    total_timesteps    | 228500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.19     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 55699     |\n",
      "|    policy_loss        | 62        |\n",
      "|    reward             | 9.254903  |\n",
      "|    std                | 1.37      |\n",
      "|    value_loss         | 231       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 580       |\n",
      "|    iterations         | 45800     |\n",
      "|    time_elapsed       | 394       |\n",
      "|    total_timesteps    | 229000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.21     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 55799     |\n",
      "|    policy_loss        | 7.4       |\n",
      "|    reward             | 1.0802364 |\n",
      "|    std                | 1.38      |\n",
      "|    value_loss         | 2.88      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 580       |\n",
      "|    iterations         | 45900     |\n",
      "|    time_elapsed       | 395       |\n",
      "|    total_timesteps    | 229500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.24     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 55899     |\n",
      "|    policy_loss        | 1.61      |\n",
      "|    reward             | 1.9597266 |\n",
      "|    std                | 1.39      |\n",
      "|    value_loss         | 0.727     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 580        |\n",
      "|    iterations         | 46000      |\n",
      "|    time_elapsed       | 396        |\n",
      "|    total_timesteps    | 230000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.24      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 55999      |\n",
      "|    policy_loss        | -2.23      |\n",
      "|    reward             | -3.5756788 |\n",
      "|    std                | 1.39       |\n",
      "|    value_loss         | 3.54       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 580       |\n",
      "|    iterations         | 46100     |\n",
      "|    time_elapsed       | 397       |\n",
      "|    total_timesteps    | 230500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.26     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 56099     |\n",
      "|    policy_loss        | 16.9      |\n",
      "|    reward             | 1.2659119 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 9.76      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 580      |\n",
      "|    iterations         | 46200    |\n",
      "|    time_elapsed       | 397      |\n",
      "|    total_timesteps    | 231000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.26    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 56199    |\n",
      "|    policy_loss        | 19.3     |\n",
      "|    reward             | 4.145331 |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 19.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 580       |\n",
      "|    iterations         | 46300     |\n",
      "|    time_elapsed       | 398       |\n",
      "|    total_timesteps    | 231500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.24     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 56299     |\n",
      "|    policy_loss        | 10.5      |\n",
      "|    reward             | 1.1660061 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 2.86      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 580       |\n",
      "|    iterations         | 46400     |\n",
      "|    time_elapsed       | 399       |\n",
      "|    total_timesteps    | 232000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.26     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 56399     |\n",
      "|    policy_loss        | -25.4     |\n",
      "|    reward             | 0.8016884 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 36.9      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 580        |\n",
      "|    iterations         | 46500      |\n",
      "|    time_elapsed       | 400        |\n",
      "|    total_timesteps    | 232500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.26      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 56499      |\n",
      "|    policy_loss        | 20.3       |\n",
      "|    reward             | -2.4122744 |\n",
      "|    std                | 1.4        |\n",
      "|    value_loss         | 13.7       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 580        |\n",
      "|    iterations         | 46600      |\n",
      "|    time_elapsed       | 401        |\n",
      "|    total_timesteps    | 233000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.29      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 56599      |\n",
      "|    policy_loss        | -21.9      |\n",
      "|    reward             | 0.18570165 |\n",
      "|    std                | 1.41       |\n",
      "|    value_loss         | 16.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 580       |\n",
      "|    iterations         | 46700     |\n",
      "|    time_elapsed       | 402       |\n",
      "|    total_timesteps    | 233500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.32     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 56699     |\n",
      "|    policy_loss        | -5.83     |\n",
      "|    reward             | 0.9320193 |\n",
      "|    std                | 1.43      |\n",
      "|    value_loss         | 3.31      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 580      |\n",
      "|    iterations         | 46800    |\n",
      "|    time_elapsed       | 402      |\n",
      "|    total_timesteps    | 234000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.3     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 56799    |\n",
      "|    policy_loss        | 1.63     |\n",
      "|    reward             | -4.30658 |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 7.11     |\n",
      "------------------------------------\n",
      "day: 2892, episode: 100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5680192.69\n",
      "total_reward: 4680192.69\n",
      "total_cost: 2755.92\n",
      "total_trades: 5830\n",
      "Sharpe: 0.840\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 580        |\n",
      "|    iterations         | 46900      |\n",
      "|    time_elapsed       | 403        |\n",
      "|    total_timesteps    | 234500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.3       |\n",
      "|    explained_variance | -0.0464    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 56899      |\n",
      "|    policy_loss        | 2.72       |\n",
      "|    reward             | -1.8567452 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 1.02       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 580        |\n",
      "|    iterations         | 47000      |\n",
      "|    time_elapsed       | 404        |\n",
      "|    total_timesteps    | 235000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.31      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 56999      |\n",
      "|    policy_loss        | -27.5      |\n",
      "|    reward             | -1.4170175 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 34.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 47100     |\n",
      "|    time_elapsed       | 405       |\n",
      "|    total_timesteps    | 235500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.32     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 57099     |\n",
      "|    policy_loss        | -16.7     |\n",
      "|    reward             | 1.8050411 |\n",
      "|    std                | 1.43      |\n",
      "|    value_loss         | 12.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 47200      |\n",
      "|    time_elapsed       | 406        |\n",
      "|    total_timesteps    | 236000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.32      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 57199      |\n",
      "|    policy_loss        | -12.7      |\n",
      "|    reward             | 0.32847947 |\n",
      "|    std                | 1.43       |\n",
      "|    value_loss         | 7.85       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 47300     |\n",
      "|    time_elapsed       | 407       |\n",
      "|    total_timesteps    | 236500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.3      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 57299     |\n",
      "|    policy_loss        | 1.23      |\n",
      "|    reward             | 2.3693914 |\n",
      "|    std                | 1.42      |\n",
      "|    value_loss         | 0.729     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 47400     |\n",
      "|    time_elapsed       | 407       |\n",
      "|    total_timesteps    | 237000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.28     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 57399     |\n",
      "|    policy_loss        | -21.2     |\n",
      "|    reward             | 10.404114 |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 46        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 47500      |\n",
      "|    time_elapsed       | 408        |\n",
      "|    total_timesteps    | 237500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.3       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 57499      |\n",
      "|    policy_loss        | -20        |\n",
      "|    reward             | -3.1076488 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 11.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 47600     |\n",
      "|    time_elapsed       | 409       |\n",
      "|    total_timesteps    | 238000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.3      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 57599     |\n",
      "|    policy_loss        | 32.4      |\n",
      "|    reward             | 2.1102607 |\n",
      "|    std                | 1.42      |\n",
      "|    value_loss         | 62.4      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 47700      |\n",
      "|    time_elapsed       | 410        |\n",
      "|    total_timesteps    | 238500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.32      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 57699      |\n",
      "|    policy_loss        | 11.7       |\n",
      "|    reward             | -2.7180917 |\n",
      "|    std                | 1.43       |\n",
      "|    value_loss         | 11.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 47800      |\n",
      "|    time_elapsed       | 411        |\n",
      "|    total_timesteps    | 239000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.31      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 57799      |\n",
      "|    policy_loss        | -18.8      |\n",
      "|    reward             | 0.21575978 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 21.7       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 47900      |\n",
      "|    time_elapsed       | 411        |\n",
      "|    total_timesteps    | 239500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.31      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 57899      |\n",
      "|    policy_loss        | 44.1       |\n",
      "|    reward             | -1.9548671 |\n",
      "|    std                | 1.43       |\n",
      "|    value_loss         | 76.2       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 48000      |\n",
      "|    time_elapsed       | 412        |\n",
      "|    total_timesteps    | 240000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.31      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 57999      |\n",
      "|    policy_loss        | -5.45      |\n",
      "|    reward             | -1.6264253 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 9.88       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 48100      |\n",
      "|    time_elapsed       | 413        |\n",
      "|    total_timesteps    | 240500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.31      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 58099      |\n",
      "|    policy_loss        | -23.2      |\n",
      "|    reward             | -0.2300417 |\n",
      "|    std                | 1.43       |\n",
      "|    value_loss         | 28.7       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 581         |\n",
      "|    iterations         | 48200       |\n",
      "|    time_elapsed       | 414         |\n",
      "|    total_timesteps    | 241000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.31       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 58199       |\n",
      "|    policy_loss        | -19.6       |\n",
      "|    reward             | 0.113602325 |\n",
      "|    std                | 1.43        |\n",
      "|    value_loss         | 23.4        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 48300     |\n",
      "|    time_elapsed       | 415       |\n",
      "|    total_timesteps    | 241500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.32     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 58299     |\n",
      "|    policy_loss        | 0.0771    |\n",
      "|    reward             | -1.469465 |\n",
      "|    std                | 1.43      |\n",
      "|    value_loss         | 0.309     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 48400     |\n",
      "|    time_elapsed       | 416       |\n",
      "|    total_timesteps    | 242000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.32     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 58399     |\n",
      "|    policy_loss        | -11.2     |\n",
      "|    reward             | 3.8810027 |\n",
      "|    std                | 1.43      |\n",
      "|    value_loss         | 9.55      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 581         |\n",
      "|    iterations         | 48500       |\n",
      "|    time_elapsed       | 416         |\n",
      "|    total_timesteps    | 242500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.32       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 58499       |\n",
      "|    policy_loss        | -0.701      |\n",
      "|    reward             | -0.42889452 |\n",
      "|    std                | 1.43        |\n",
      "|    value_loss         | 1.58        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 48600     |\n",
      "|    time_elapsed       | 417       |\n",
      "|    total_timesteps    | 243000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.32     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 58599     |\n",
      "|    policy_loss        | 69.4      |\n",
      "|    reward             | 2.9694595 |\n",
      "|    std                | 1.43      |\n",
      "|    value_loss         | 229       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 48700      |\n",
      "|    time_elapsed       | 418        |\n",
      "|    total_timesteps    | 243500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.32      |\n",
      "|    explained_variance | -0.142     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 58699      |\n",
      "|    policy_loss        | 20.8       |\n",
      "|    reward             | -0.7273913 |\n",
      "|    std                | 1.43       |\n",
      "|    value_loss         | 14.6       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 48800     |\n",
      "|    time_elapsed       | 419       |\n",
      "|    total_timesteps    | 244000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.33     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 58799     |\n",
      "|    policy_loss        | 1.36      |\n",
      "|    reward             | 0.3134997 |\n",
      "|    std                | 1.43      |\n",
      "|    value_loss         | 2.8       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 48900    |\n",
      "|    time_elapsed       | 420      |\n",
      "|    total_timesteps    | 244500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.33    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 58899    |\n",
      "|    policy_loss        | -22.8    |\n",
      "|    reward             | 1.717298 |\n",
      "|    std                | 1.43     |\n",
      "|    value_loss         | 16.8     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 49000      |\n",
      "|    time_elapsed       | 421        |\n",
      "|    total_timesteps    | 245000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.33      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 58999      |\n",
      "|    policy_loss        | 12.4       |\n",
      "|    reward             | -2.4449863 |\n",
      "|    std                | 1.43       |\n",
      "|    value_loss         | 9.62       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 49100      |\n",
      "|    time_elapsed       | 421        |\n",
      "|    total_timesteps    | 245500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.33      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 59099      |\n",
      "|    policy_loss        | -62.1      |\n",
      "|    reward             | -12.215819 |\n",
      "|    std                | 1.43       |\n",
      "|    value_loss         | 144        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 581         |\n",
      "|    iterations         | 49200       |\n",
      "|    time_elapsed       | 422         |\n",
      "|    total_timesteps    | 246000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.33       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 59199       |\n",
      "|    policy_loss        | -2.29       |\n",
      "|    reward             | -0.73511535 |\n",
      "|    std                | 1.43        |\n",
      "|    value_loss         | 0.673       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 49300      |\n",
      "|    time_elapsed       | 423        |\n",
      "|    total_timesteps    | 246500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.33      |\n",
      "|    explained_variance | -0.559     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 59299      |\n",
      "|    policy_loss        | -5.28      |\n",
      "|    reward             | -1.8180162 |\n",
      "|    std                | 1.43       |\n",
      "|    value_loss         | 1.87       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 49400     |\n",
      "|    time_elapsed       | 424       |\n",
      "|    total_timesteps    | 247000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.33     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 59399     |\n",
      "|    policy_loss        | 17.7      |\n",
      "|    reward             | 0.5145166 |\n",
      "|    std                | 1.43      |\n",
      "|    value_loss         | 21.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 49500      |\n",
      "|    time_elapsed       | 425        |\n",
      "|    total_timesteps    | 247500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.32      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 59499      |\n",
      "|    policy_loss        | 58.3       |\n",
      "|    reward             | -6.1790366 |\n",
      "|    std                | 1.43       |\n",
      "|    value_loss         | 280        |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 49600    |\n",
      "|    time_elapsed       | 426      |\n",
      "|    total_timesteps    | 248000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.31    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 59599    |\n",
      "|    policy_loss        | 33.6     |\n",
      "|    reward             | 4.072456 |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 55.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 49700     |\n",
      "|    time_elapsed       | 427       |\n",
      "|    total_timesteps    | 248500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.3      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 59699     |\n",
      "|    policy_loss        | 53.1      |\n",
      "|    reward             | 3.8275158 |\n",
      "|    std                | 1.42      |\n",
      "|    value_loss         | 96.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 49800      |\n",
      "|    time_elapsed       | 427        |\n",
      "|    total_timesteps    | 249000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.29      |\n",
      "|    explained_variance | -0.106     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 59799      |\n",
      "|    policy_loss        | 14.3       |\n",
      "|    reward             | -1.0379391 |\n",
      "|    std                | 1.41       |\n",
      "|    value_loss         | 11.2       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 49900    |\n",
      "|    time_elapsed       | 428      |\n",
      "|    total_timesteps    | 249500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.27    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 59899    |\n",
      "|    policy_loss        | 25.1     |\n",
      "|    reward             | 2.141522 |\n",
      "|    std                | 1.41     |\n",
      "|    value_loss         | 30.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 50000     |\n",
      "|    time_elapsed       | 429       |\n",
      "|    total_timesteps    | 250000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.29     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 59999     |\n",
      "|    policy_loss        | -2.94     |\n",
      "|    reward             | 1.7745626 |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 0.562     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 50100      |\n",
      "|    time_elapsed       | 430        |\n",
      "|    total_timesteps    | 250500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.3       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 60099      |\n",
      "|    policy_loss        | 11.1       |\n",
      "|    reward             | 0.85972935 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 5.93       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 50200     |\n",
      "|    time_elapsed       | 431       |\n",
      "|    total_timesteps    | 251000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.29     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 60199     |\n",
      "|    policy_loss        | -31       |\n",
      "|    reward             | 1.3034276 |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 26.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 50300      |\n",
      "|    time_elapsed       | 432        |\n",
      "|    total_timesteps    | 251500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.29      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 60299      |\n",
      "|    policy_loss        | 9.81       |\n",
      "|    reward             | -6.2217593 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 34.5       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 50400      |\n",
      "|    time_elapsed       | 433        |\n",
      "|    total_timesteps    | 252000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.29      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 60399      |\n",
      "|    policy_loss        | -2.94      |\n",
      "|    reward             | -0.7546226 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 0.252      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 50500      |\n",
      "|    time_elapsed       | 434        |\n",
      "|    total_timesteps    | 252500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.29      |\n",
      "|    explained_variance | -0.993     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 60499      |\n",
      "|    policy_loss        | -35.5      |\n",
      "|    reward             | -1.2825516 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 44.9       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 581      |\n",
      "|    iterations         | 50600    |\n",
      "|    time_elapsed       | 434      |\n",
      "|    total_timesteps    | 253000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.3     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 60599    |\n",
      "|    policy_loss        | -6.26    |\n",
      "|    reward             | 8.896096 |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 4.06     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 50700     |\n",
      "|    time_elapsed       | 435       |\n",
      "|    total_timesteps    | 253500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.29     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 60699     |\n",
      "|    policy_loss        | -2.5      |\n",
      "|    reward             | 6.4342766 |\n",
      "|    std                | 1.42      |\n",
      "|    value_loss         | 22.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 50800     |\n",
      "|    time_elapsed       | 436       |\n",
      "|    total_timesteps    | 254000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.29     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 60799     |\n",
      "|    policy_loss        | 0.593     |\n",
      "|    reward             | 3.5693352 |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 98.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 50900      |\n",
      "|    time_elapsed       | 437        |\n",
      "|    total_timesteps    | 254500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.26      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 60899      |\n",
      "|    policy_loss        | -548       |\n",
      "|    reward             | -56.389206 |\n",
      "|    std                | 1.41       |\n",
      "|    value_loss         | 1.01e+04   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 51000     |\n",
      "|    time_elapsed       | 438       |\n",
      "|    total_timesteps    | 255000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.26     |\n",
      "|    explained_variance | -4.41     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 60999     |\n",
      "|    policy_loss        | 23        |\n",
      "|    reward             | 1.2047532 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 25.8      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 581         |\n",
      "|    iterations         | 51100       |\n",
      "|    time_elapsed       | 439         |\n",
      "|    total_timesteps    | 255500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.25       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 61099       |\n",
      "|    policy_loss        | -6.31       |\n",
      "|    reward             | -0.38221797 |\n",
      "|    std                | 1.4         |\n",
      "|    value_loss         | 1.21        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 51200     |\n",
      "|    time_elapsed       | 439       |\n",
      "|    total_timesteps    | 256000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.24     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 61199     |\n",
      "|    policy_loss        | 9.87      |\n",
      "|    reward             | 2.9869952 |\n",
      "|    std                | 1.39      |\n",
      "|    value_loss         | 4.3       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 581        |\n",
      "|    iterations         | 51300      |\n",
      "|    time_elapsed       | 440        |\n",
      "|    total_timesteps    | 256500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.24      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 61299      |\n",
      "|    policy_loss        | 31         |\n",
      "|    reward             | -2.2547662 |\n",
      "|    std                | 1.4        |\n",
      "|    value_loss         | 40.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 51400     |\n",
      "|    time_elapsed       | 441       |\n",
      "|    total_timesteps    | 257000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.26     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 61399     |\n",
      "|    policy_loss        | -58.8     |\n",
      "|    reward             | 3.9925928 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 321       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 581         |\n",
      "|    iterations         | 51500       |\n",
      "|    time_elapsed       | 442         |\n",
      "|    total_timesteps    | 257500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.24       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 61499       |\n",
      "|    policy_loss        | -0.887      |\n",
      "|    reward             | 0.010095388 |\n",
      "|    std                | 1.4         |\n",
      "|    value_loss         | 0.032       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 581       |\n",
      "|    iterations         | 51600     |\n",
      "|    time_elapsed       | 443       |\n",
      "|    total_timesteps    | 258000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.25     |\n",
      "|    explained_variance | -3.85     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 61599     |\n",
      "|    policy_loss        | -0.958    |\n",
      "|    reward             | 0.5112442 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 3.59      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 51700      |\n",
      "|    time_elapsed       | 444        |\n",
      "|    total_timesteps    | 258500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.24      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 61699      |\n",
      "|    policy_loss        | 2.45       |\n",
      "|    reward             | 0.16984974 |\n",
      "|    std                | 1.4        |\n",
      "|    value_loss         | 0.75       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 51800     |\n",
      "|    time_elapsed       | 444       |\n",
      "|    total_timesteps    | 259000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.23     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 61799     |\n",
      "|    policy_loss        | -35.8     |\n",
      "|    reward             | 7.2515817 |\n",
      "|    std                | 1.39      |\n",
      "|    value_loss         | 41.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 51900      |\n",
      "|    time_elapsed       | 445        |\n",
      "|    total_timesteps    | 259500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.23      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 61899      |\n",
      "|    policy_loss        | 3.48       |\n",
      "|    reward             | -1.0751934 |\n",
      "|    std                | 1.39       |\n",
      "|    value_loss         | 2.4        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 52000      |\n",
      "|    time_elapsed       | 446        |\n",
      "|    total_timesteps    | 260000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.25      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 61999      |\n",
      "|    policy_loss        | 56         |\n",
      "|    reward             | -5.2625837 |\n",
      "|    std                | 1.4        |\n",
      "|    value_loss         | 197        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 52100      |\n",
      "|    time_elapsed       | 447        |\n",
      "|    total_timesteps    | 260500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.23      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 62099      |\n",
      "|    policy_loss        | -15.9      |\n",
      "|    reward             | -0.9402326 |\n",
      "|    std                | 1.39       |\n",
      "|    value_loss         | 9.36       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 52200     |\n",
      "|    time_elapsed       | 448       |\n",
      "|    total_timesteps    | 261000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.25     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 62199     |\n",
      "|    policy_loss        | 10.7      |\n",
      "|    reward             | 0.5480986 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 4.76      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 581         |\n",
      "|    iterations         | 52300       |\n",
      "|    time_elapsed       | 449         |\n",
      "|    total_timesteps    | 261500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.24       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 62299       |\n",
      "|    policy_loss        | -39.1       |\n",
      "|    reward             | -0.34123605 |\n",
      "|    std                | 1.39        |\n",
      "|    value_loss         | 51.7        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 581         |\n",
      "|    iterations         | 52400       |\n",
      "|    time_elapsed       | 450         |\n",
      "|    total_timesteps    | 262000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.21       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 62399       |\n",
      "|    policy_loss        | 10.9        |\n",
      "|    reward             | -0.50014096 |\n",
      "|    std                | 1.38        |\n",
      "|    value_loss         | 7.19        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 52500      |\n",
      "|    time_elapsed       | 450        |\n",
      "|    total_timesteps    | 262500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.22      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 62499      |\n",
      "|    policy_loss        | -10.3      |\n",
      "|    reward             | -2.8529134 |\n",
      "|    std                | 1.38       |\n",
      "|    value_loss         | 12.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 52600     |\n",
      "|    time_elapsed       | 451       |\n",
      "|    total_timesteps    | 263000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.25     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 62599     |\n",
      "|    policy_loss        | 125       |\n",
      "|    reward             | 1.1403837 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 701       |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7310748.59\n",
      "total_reward: 6310748.59\n",
      "total_cost: 2501.79\n",
      "total_trades: 5849\n",
      "Sharpe: 0.930\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 52700      |\n",
      "|    time_elapsed       | 452        |\n",
      "|    total_timesteps    | 263500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.25      |\n",
      "|    explained_variance | -0.221     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 62699      |\n",
      "|    policy_loss        | 0.461      |\n",
      "|    reward             | 0.90620875 |\n",
      "|    std                | 1.4        |\n",
      "|    value_loss         | 1.07       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 52800     |\n",
      "|    time_elapsed       | 453       |\n",
      "|    total_timesteps    | 264000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.24     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 62799     |\n",
      "|    policy_loss        | 4.7       |\n",
      "|    reward             | 1.7993032 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 7.96      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 582         |\n",
      "|    iterations         | 52900       |\n",
      "|    time_elapsed       | 454         |\n",
      "|    total_timesteps    | 264500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.27       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 62899       |\n",
      "|    policy_loss        | -5.18       |\n",
      "|    reward             | -0.33706802 |\n",
      "|    std                | 1.41        |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 53000      |\n",
      "|    time_elapsed       | 455        |\n",
      "|    total_timesteps    | 265000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.26      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 62999      |\n",
      "|    policy_loss        | 16.1       |\n",
      "|    reward             | -1.9552759 |\n",
      "|    std                | 1.4        |\n",
      "|    value_loss         | 12.4       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 53100     |\n",
      "|    time_elapsed       | 456       |\n",
      "|    total_timesteps    | 265500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.25     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 63099     |\n",
      "|    policy_loss        | -12       |\n",
      "|    reward             | 1.3492815 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 6.66      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 53200     |\n",
      "|    time_elapsed       | 456       |\n",
      "|    total_timesteps    | 266000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.25     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 63199     |\n",
      "|    policy_loss        | 28.9      |\n",
      "|    reward             | 6.2216454 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 31        |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 582         |\n",
      "|    iterations         | 53300       |\n",
      "|    time_elapsed       | 457         |\n",
      "|    total_timesteps    | 266500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.27       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 63299       |\n",
      "|    policy_loss        | -7.71       |\n",
      "|    reward             | -0.42412943 |\n",
      "|    std                | 1.41        |\n",
      "|    value_loss         | 16.3        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 53400      |\n",
      "|    time_elapsed       | 458        |\n",
      "|    total_timesteps    | 267000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.28      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 63399      |\n",
      "|    policy_loss        | -1.2       |\n",
      "|    reward             | 0.51303697 |\n",
      "|    std                | 1.41       |\n",
      "|    value_loss         | 0.209      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 53500     |\n",
      "|    time_elapsed       | 459       |\n",
      "|    total_timesteps    | 267500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.29     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 63499     |\n",
      "|    policy_loss        | 11.3      |\n",
      "|    reward             | 1.2150097 |\n",
      "|    std                | 1.42      |\n",
      "|    value_loss         | 9.5       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 53600     |\n",
      "|    time_elapsed       | 460       |\n",
      "|    total_timesteps    | 268000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.27     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 63599     |\n",
      "|    policy_loss        | -47       |\n",
      "|    reward             | 2.1161497 |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 151       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 53700     |\n",
      "|    time_elapsed       | 461       |\n",
      "|    total_timesteps    | 268500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.25     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 63699     |\n",
      "|    policy_loss        | 2.18      |\n",
      "|    reward             | 7.3190928 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 17.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 53800     |\n",
      "|    time_elapsed       | 461       |\n",
      "|    total_timesteps    | 269000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.26     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 63799     |\n",
      "|    policy_loss        | 79.2      |\n",
      "|    reward             | 22.563366 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 531       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 53900     |\n",
      "|    time_elapsed       | 462       |\n",
      "|    total_timesteps    | 269500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.25     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 63899     |\n",
      "|    policy_loss        | 4.77      |\n",
      "|    reward             | 1.5560412 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 2.03      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 54000      |\n",
      "|    time_elapsed       | 463        |\n",
      "|    total_timesteps    | 270000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.24      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 63999      |\n",
      "|    policy_loss        | 0.813      |\n",
      "|    reward             | -1.8243325 |\n",
      "|    std                | 1.39       |\n",
      "|    value_loss         | 0.468      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 54100     |\n",
      "|    time_elapsed       | 464       |\n",
      "|    total_timesteps    | 270500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.23     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 64099     |\n",
      "|    policy_loss        | -22.8     |\n",
      "|    reward             | 6.479436  |\n",
      "|    std                | 1.39      |\n",
      "|    value_loss         | 19.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 54200      |\n",
      "|    time_elapsed       | 465        |\n",
      "|    total_timesteps    | 271000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.24      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 64199      |\n",
      "|    policy_loss        | -16        |\n",
      "|    reward             | -1.0745242 |\n",
      "|    std                | 1.4        |\n",
      "|    value_loss         | 14.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 54300     |\n",
      "|    time_elapsed       | 466       |\n",
      "|    total_timesteps    | 271500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.25     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 64299     |\n",
      "|    policy_loss        | 19.6      |\n",
      "|    reward             | 2.4384358 |\n",
      "|    std                | 1.4       |\n",
      "|    value_loss         | 32.9      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 54400      |\n",
      "|    time_elapsed       | 467        |\n",
      "|    total_timesteps    | 272000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.26      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 64399      |\n",
      "|    policy_loss        | 0.438      |\n",
      "|    reward             | -1.7275926 |\n",
      "|    std                | 1.4        |\n",
      "|    value_loss         | 0.0743     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 54500      |\n",
      "|    time_elapsed       | 467        |\n",
      "|    total_timesteps    | 272500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.28      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 64499      |\n",
      "|    policy_loss        | -18.3      |\n",
      "|    reward             | 0.10425991 |\n",
      "|    std                | 1.41       |\n",
      "|    value_loss         | 12.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 54600     |\n",
      "|    time_elapsed       | 468       |\n",
      "|    total_timesteps    | 273000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.29     |\n",
      "|    explained_variance | -7.14     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 64599     |\n",
      "|    policy_loss        | -1.64     |\n",
      "|    reward             | 0.3630548 |\n",
      "|    std                | 1.42      |\n",
      "|    value_loss         | 1.17      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 54700      |\n",
      "|    time_elapsed       | 469        |\n",
      "|    total_timesteps    | 273500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.28      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 64699      |\n",
      "|    policy_loss        | -28.4      |\n",
      "|    reward             | 0.22388095 |\n",
      "|    std                | 1.41       |\n",
      "|    value_loss         | 36.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 54800     |\n",
      "|    time_elapsed       | 470       |\n",
      "|    total_timesteps    | 274000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.28     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 64799     |\n",
      "|    policy_loss        | 13.1      |\n",
      "|    reward             | 3.0084808 |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 7.63      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 54900      |\n",
      "|    time_elapsed       | 471        |\n",
      "|    total_timesteps    | 274500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.26      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 64899      |\n",
      "|    policy_loss        | 67.7       |\n",
      "|    reward             | -3.0767696 |\n",
      "|    std                | 1.4        |\n",
      "|    value_loss         | 320        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 55000      |\n",
      "|    time_elapsed       | 472        |\n",
      "|    total_timesteps    | 275000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.27      |\n",
      "|    explained_variance | 0.122      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 64999      |\n",
      "|    policy_loss        | 9.4        |\n",
      "|    reward             | -0.9313636 |\n",
      "|    std                | 1.41       |\n",
      "|    value_loss         | 3.83       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 55100    |\n",
      "|    time_elapsed       | 472      |\n",
      "|    total_timesteps    | 275500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.25    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 65099    |\n",
      "|    policy_loss        | 11.3     |\n",
      "|    reward             | 4.75117  |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 13.6     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 55200      |\n",
      "|    time_elapsed       | 473        |\n",
      "|    total_timesteps    | 276000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.27      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 65199      |\n",
      "|    policy_loss        | -3.04      |\n",
      "|    reward             | 0.77996194 |\n",
      "|    std                | 1.41       |\n",
      "|    value_loss         | 0.982      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 55300     |\n",
      "|    time_elapsed       | 474       |\n",
      "|    total_timesteps    | 276500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.28     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 65299     |\n",
      "|    policy_loss        | -13.9     |\n",
      "|    reward             | 1.1669015 |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 9.04      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 55400      |\n",
      "|    time_elapsed       | 475        |\n",
      "|    total_timesteps    | 277000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.3       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 65399      |\n",
      "|    policy_loss        | -17.4      |\n",
      "|    reward             | -1.2176772 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 16.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 55500     |\n",
      "|    time_elapsed       | 476       |\n",
      "|    total_timesteps    | 277500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.3      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 65499     |\n",
      "|    policy_loss        | -10.2     |\n",
      "|    reward             | 8.878034  |\n",
      "|    std                | 1.42      |\n",
      "|    value_loss         | 8.96      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 55600     |\n",
      "|    time_elapsed       | 477       |\n",
      "|    total_timesteps    | 278000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.28     |\n",
      "|    explained_variance | 5.1e-05   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 65599     |\n",
      "|    policy_loss        | -18.4     |\n",
      "|    reward             | 0.6536334 |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 24.5      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 582        |\n",
      "|    iterations         | 55700      |\n",
      "|    time_elapsed       | 478        |\n",
      "|    total_timesteps    | 278500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.3       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 65699      |\n",
      "|    policy_loss        | -2.88      |\n",
      "|    reward             | -0.5707716 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 0.354      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 55800     |\n",
      "|    time_elapsed       | 478       |\n",
      "|    total_timesteps    | 279000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.28     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 65799     |\n",
      "|    policy_loss        | 17.7      |\n",
      "|    reward             | 0.6189705 |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 13.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 55900     |\n",
      "|    time_elapsed       | 479       |\n",
      "|    total_timesteps    | 279500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.29     |\n",
      "|    explained_variance | 0.147     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 65899     |\n",
      "|    policy_loss        | -23.7     |\n",
      "|    reward             | -2.333065 |\n",
      "|    std                | 1.42      |\n",
      "|    value_loss         | 41.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 56000     |\n",
      "|    time_elapsed       | 480       |\n",
      "|    total_timesteps    | 280000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.31     |\n",
      "|    explained_variance | -0.00323  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 65999     |\n",
      "|    policy_loss        | 46.7      |\n",
      "|    reward             | 0.8599959 |\n",
      "|    std                | 1.43      |\n",
      "|    value_loss         | 56.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 56100    |\n",
      "|    time_elapsed       | 481      |\n",
      "|    total_timesteps    | 280500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.28    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 66099    |\n",
      "|    policy_loss        | -13      |\n",
      "|    reward             | 9.298039 |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 11.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 582       |\n",
      "|    iterations         | 56200     |\n",
      "|    time_elapsed       | 482       |\n",
      "|    total_timesteps    | 281000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.28     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 66199     |\n",
      "|    policy_loss        | -38.4     |\n",
      "|    reward             | 3.0826983 |\n",
      "|    std                | 1.41      |\n",
      "|    value_loss         | 39.4      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 583        |\n",
      "|    iterations         | 56300      |\n",
      "|    time_elapsed       | 482        |\n",
      "|    total_timesteps    | 281500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.28      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 66299      |\n",
      "|    policy_loss        | -16.9      |\n",
      "|    reward             | -1.5445831 |\n",
      "|    std                | 1.42       |\n",
      "|    value_loss         | 14.1       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 583         |\n",
      "|    iterations         | 56400       |\n",
      "|    time_elapsed       | 483         |\n",
      "|    total_timesteps    | 282000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.28       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 66399       |\n",
      "|    policy_loss        | 1.56        |\n",
      "|    reward             | -0.96823895 |\n",
      "|    std                | 1.42        |\n",
      "|    value_loss         | 1.44        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 583       |\n",
      "|    iterations         | 56500     |\n",
      "|    time_elapsed       | 484       |\n",
      "|    total_timesteps    | 282500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.3      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 66499     |\n",
      "|    policy_loss        | -30.7     |\n",
      "|    reward             | 3.1519942 |\n",
      "|    std                | 1.42      |\n",
      "|    value_loss         | 40.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 583        |\n",
      "|    iterations         | 56600      |\n",
      "|    time_elapsed       | 485        |\n",
      "|    total_timesteps    | 283000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.32      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 66599      |\n",
      "|    policy_loss        | 6.89       |\n",
      "|    reward             | -3.3188741 |\n",
      "|    std                | 1.43       |\n",
      "|    value_loss         | 6.06       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 583        |\n",
      "|    iterations         | 56700      |\n",
      "|    time_elapsed       | 486        |\n",
      "|    total_timesteps    | 283500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.31      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 66699      |\n",
      "|    policy_loss        | 0.323      |\n",
      "|    reward             | -38.389324 |\n",
      "|    std                | 1.43       |\n",
      "|    value_loss         | 23.8       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 583         |\n",
      "|    iterations         | 56800       |\n",
      "|    time_elapsed       | 486         |\n",
      "|    total_timesteps    | 284000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.34       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 66799       |\n",
      "|    policy_loss        | -10.8       |\n",
      "|    reward             | -0.52084094 |\n",
      "|    std                | 1.44        |\n",
      "|    value_loss         | 6.8         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 583         |\n",
      "|    iterations         | 56900       |\n",
      "|    time_elapsed       | 487         |\n",
      "|    total_timesteps    | 284500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.34       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 66899       |\n",
      "|    policy_loss        | 11.6        |\n",
      "|    reward             | -0.78870225 |\n",
      "|    std                | 1.44        |\n",
      "|    value_loss         | 9.15        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 583        |\n",
      "|    iterations         | 57000      |\n",
      "|    time_elapsed       | 488        |\n",
      "|    total_timesteps    | 285000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.33      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 66999      |\n",
      "|    policy_loss        | -18.1      |\n",
      "|    reward             | 0.78157324 |\n",
      "|    std                | 1.44       |\n",
      "|    value_loss         | 12.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 583       |\n",
      "|    iterations         | 57100     |\n",
      "|    time_elapsed       | 489       |\n",
      "|    total_timesteps    | 285500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.33     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 67099     |\n",
      "|    policy_loss        | -18.2     |\n",
      "|    reward             | 2.9235947 |\n",
      "|    std                | 1.44      |\n",
      "|    value_loss         | 13.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 583       |\n",
      "|    iterations         | 57200     |\n",
      "|    time_elapsed       | 490       |\n",
      "|    total_timesteps    | 286000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.35     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 67199     |\n",
      "|    policy_loss        | 60        |\n",
      "|    reward             | 6.8828244 |\n",
      "|    std                | 1.45      |\n",
      "|    value_loss         | 227       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 583       |\n",
      "|    iterations         | 57300     |\n",
      "|    time_elapsed       | 491       |\n",
      "|    total_timesteps    | 286500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.35     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 67299     |\n",
      "|    policy_loss        | -4.63     |\n",
      "|    reward             | 1.9367155 |\n",
      "|    std                | 1.45      |\n",
      "|    value_loss         | 1.89      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 583        |\n",
      "|    iterations         | 57400      |\n",
      "|    time_elapsed       | 491        |\n",
      "|    total_timesteps    | 287000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.36      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 67399      |\n",
      "|    policy_loss        | -6.04      |\n",
      "|    reward             | -1.1501844 |\n",
      "|    std                | 1.45       |\n",
      "|    value_loss         | 1.36       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 583        |\n",
      "|    iterations         | 57500      |\n",
      "|    time_elapsed       | 492        |\n",
      "|    total_timesteps    | 287500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.37      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 67499      |\n",
      "|    policy_loss        | 13.6       |\n",
      "|    reward             | 0.68682593 |\n",
      "|    std                | 1.46       |\n",
      "|    value_loss         | 19.5       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 583         |\n",
      "|    iterations         | 57600       |\n",
      "|    time_elapsed       | 493         |\n",
      "|    total_timesteps    | 288000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.36       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 67599       |\n",
      "|    policy_loss        | 69.5        |\n",
      "|    reward             | -0.77001786 |\n",
      "|    std                | 1.46        |\n",
      "|    value_loss         | 157         |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 583       |\n",
      "|    iterations         | 57700     |\n",
      "|    time_elapsed       | 494       |\n",
      "|    total_timesteps    | 288500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.34     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 67699     |\n",
      "|    policy_loss        | -22.7     |\n",
      "|    reward             | 1.2846099 |\n",
      "|    std                | 1.45      |\n",
      "|    value_loss         | 26.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 583       |\n",
      "|    iterations         | 57800     |\n",
      "|    time_elapsed       | 495       |\n",
      "|    total_timesteps    | 289000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.34     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 67799     |\n",
      "|    policy_loss        | 9.27      |\n",
      "|    reward             | -1.505775 |\n",
      "|    std                | 1.45      |\n",
      "|    value_loss         | 7.76      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 583       |\n",
      "|    iterations         | 57900     |\n",
      "|    time_elapsed       | 496       |\n",
      "|    total_timesteps    | 289500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.34     |\n",
      "|    explained_variance | -0.0207   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 67899     |\n",
      "|    policy_loss        | 19.9      |\n",
      "|    reward             | 0.8743158 |\n",
      "|    std                | 1.44      |\n",
      "|    value_loss         | 15.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 583       |\n",
      "|    iterations         | 58000     |\n",
      "|    time_elapsed       | 496       |\n",
      "|    total_timesteps    | 290000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.35     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 67999     |\n",
      "|    policy_loss        | 6.69      |\n",
      "|    reward             | 0.6167798 |\n",
      "|    std                | 1.45      |\n",
      "|    value_loss         | 7.48      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 583       |\n",
      "|    iterations         | 58100     |\n",
      "|    time_elapsed       | 497       |\n",
      "|    total_timesteps    | 290500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.35     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 68099     |\n",
      "|    policy_loss        | 1.03      |\n",
      "|    reward             | 1.6632274 |\n",
      "|    std                | 1.45      |\n",
      "|    value_loss         | 0.434     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 583      |\n",
      "|    iterations         | 58200    |\n",
      "|    time_elapsed       | 498      |\n",
      "|    total_timesteps    | 291000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.38    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 68199    |\n",
      "|    policy_loss        | -19.3    |\n",
      "|    reward             | 5.728549 |\n",
      "|    std                | 1.47     |\n",
      "|    value_loss         | 14.5     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 583         |\n",
      "|    iterations         | 58300       |\n",
      "|    time_elapsed       | 499         |\n",
      "|    total_timesteps    | 291500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.35       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 68299       |\n",
      "|    policy_loss        | -14.6       |\n",
      "|    reward             | 0.060728606 |\n",
      "|    std                | 1.45        |\n",
      "|    value_loss         | 9.46        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 583      |\n",
      "|    iterations         | 58400    |\n",
      "|    time_elapsed       | 500      |\n",
      "|    total_timesteps    | 292000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.36    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 68399    |\n",
      "|    policy_loss        | 18.6     |\n",
      "|    reward             | 7.264137 |\n",
      "|    std                | 1.45     |\n",
      "|    value_loss         | 17.2     |\n",
      "------------------------------------\n",
      "day: 2892, episode: 120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7332811.07\n",
      "total_reward: 6332811.07\n",
      "total_cost: 2359.14\n",
      "total_trades: 5787\n",
      "Sharpe: 0.933\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 583        |\n",
      "|    iterations         | 58500      |\n",
      "|    time_elapsed       | 500        |\n",
      "|    total_timesteps    | 292500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.38      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 68499      |\n",
      "|    policy_loss        | 1.27       |\n",
      "|    reward             | -0.9411056 |\n",
      "|    std                | 1.46       |\n",
      "|    value_loss         | 0.604      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 584        |\n",
      "|    iterations         | 58600      |\n",
      "|    time_elapsed       | 501        |\n",
      "|    total_timesteps    | 293000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.38      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 68599      |\n",
      "|    policy_loss        | 2.07       |\n",
      "|    reward             | -0.5477487 |\n",
      "|    std                | 1.46       |\n",
      "|    value_loss         | 1.66       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 583        |\n",
      "|    iterations         | 58700      |\n",
      "|    time_elapsed       | 502        |\n",
      "|    total_timesteps    | 293500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.38      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 68699      |\n",
      "|    policy_loss        | -2.26      |\n",
      "|    reward             | -1.5669318 |\n",
      "|    std                | 1.46       |\n",
      "|    value_loss         | 1.07       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 583       |\n",
      "|    iterations         | 58800     |\n",
      "|    time_elapsed       | 503       |\n",
      "|    total_timesteps    | 294000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.37     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 68799     |\n",
      "|    policy_loss        | 27.5      |\n",
      "|    reward             | 4.2710667 |\n",
      "|    std                | 1.46      |\n",
      "|    value_loss         | 33.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 583       |\n",
      "|    iterations         | 58900     |\n",
      "|    time_elapsed       | 504       |\n",
      "|    total_timesteps    | 294500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.38     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 68899     |\n",
      "|    policy_loss        | 54.8      |\n",
      "|    reward             | 3.3714762 |\n",
      "|    std                | 1.46      |\n",
      "|    value_loss         | 135       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 583        |\n",
      "|    iterations         | 59000      |\n",
      "|    time_elapsed       | 505        |\n",
      "|    total_timesteps    | 295000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.38      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 68999      |\n",
      "|    policy_loss        | -124       |\n",
      "|    reward             | 10.5462885 |\n",
      "|    std                | 1.46       |\n",
      "|    value_loss         | 573        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 584        |\n",
      "|    iterations         | 59100      |\n",
      "|    time_elapsed       | 505        |\n",
      "|    total_timesteps    | 295500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.39      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 69099      |\n",
      "|    policy_loss        | 1.43       |\n",
      "|    reward             | 0.34301126 |\n",
      "|    std                | 1.47       |\n",
      "|    value_loss         | 1.17       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 584       |\n",
      "|    iterations         | 59200     |\n",
      "|    time_elapsed       | 506       |\n",
      "|    total_timesteps    | 296000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.39     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 69199     |\n",
      "|    policy_loss        | 1.88      |\n",
      "|    reward             | 0.524656  |\n",
      "|    std                | 1.47      |\n",
      "|    value_loss         | 0.636     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 584       |\n",
      "|    iterations         | 59300     |\n",
      "|    time_elapsed       | 507       |\n",
      "|    total_timesteps    | 296500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.39     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 69299     |\n",
      "|    policy_loss        | -0.953    |\n",
      "|    reward             | 1.2529967 |\n",
      "|    std                | 1.47      |\n",
      "|    value_loss         | 1.91      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 584         |\n",
      "|    iterations         | 59400       |\n",
      "|    time_elapsed       | 508         |\n",
      "|    total_timesteps    | 297000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.38       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 69399       |\n",
      "|    policy_loss        | 2.98        |\n",
      "|    reward             | -0.39386922 |\n",
      "|    std                | 1.46        |\n",
      "|    value_loss         | 0.566       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 584       |\n",
      "|    iterations         | 59500     |\n",
      "|    time_elapsed       | 508       |\n",
      "|    total_timesteps    | 297500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.39     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 69499     |\n",
      "|    policy_loss        | -62.1     |\n",
      "|    reward             | -0.661183 |\n",
      "|    std                | 1.47      |\n",
      "|    value_loss         | 168       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 584        |\n",
      "|    iterations         | 59600      |\n",
      "|    time_elapsed       | 509        |\n",
      "|    total_timesteps    | 298000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.41      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 69599      |\n",
      "|    policy_loss        | -0.0376    |\n",
      "|    reward             | 0.40272254 |\n",
      "|    std                | 1.48       |\n",
      "|    value_loss         | 0.0464     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 584        |\n",
      "|    iterations         | 59700      |\n",
      "|    time_elapsed       | 510        |\n",
      "|    total_timesteps    | 298500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.41      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 69699      |\n",
      "|    policy_loss        | 6.91       |\n",
      "|    reward             | 0.26016113 |\n",
      "|    std                | 1.48       |\n",
      "|    value_loss         | 2.21       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 584         |\n",
      "|    iterations         | 59800       |\n",
      "|    time_elapsed       | 511         |\n",
      "|    total_timesteps    | 299000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.41       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 69799       |\n",
      "|    policy_loss        | -1.02       |\n",
      "|    reward             | -0.08114949 |\n",
      "|    std                | 1.48        |\n",
      "|    value_loss         | 0.357       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 584        |\n",
      "|    iterations         | 59900      |\n",
      "|    time_elapsed       | 512        |\n",
      "|    total_timesteps    | 299500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.44      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 69899      |\n",
      "|    policy_loss        | -7.72      |\n",
      "|    reward             | 0.38990802 |\n",
      "|    std                | 1.5        |\n",
      "|    value_loss         | 8.15       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 584        |\n",
      "|    iterations         | 60000      |\n",
      "|    time_elapsed       | 512        |\n",
      "|    total_timesteps    | 300000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.46      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 69999      |\n",
      "|    policy_loss        | -4.47      |\n",
      "|    reward             | -1.9313456 |\n",
      "|    std                | 1.51       |\n",
      "|    value_loss         | 2.64       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 584       |\n",
      "|    iterations         | 60100     |\n",
      "|    time_elapsed       | 513       |\n",
      "|    total_timesteps    | 300500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.45     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 70099     |\n",
      "|    policy_loss        | 27.7      |\n",
      "|    reward             | 6.1753006 |\n",
      "|    std                | 1.5       |\n",
      "|    value_loss         | 167       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 584        |\n",
      "|    iterations         | 60200      |\n",
      "|    time_elapsed       | 514        |\n",
      "|    total_timesteps    | 301000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.46      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 70199      |\n",
      "|    policy_loss        | -2.79      |\n",
      "|    reward             | 0.35884675 |\n",
      "|    std                | 1.51       |\n",
      "|    value_loss         | 0.624      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 584       |\n",
      "|    iterations         | 60300     |\n",
      "|    time_elapsed       | 515       |\n",
      "|    total_timesteps    | 301500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.46     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 70299     |\n",
      "|    policy_loss        | 3.11      |\n",
      "|    reward             | 1.5082501 |\n",
      "|    std                | 1.51      |\n",
      "|    value_loss         | 1.7       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 585       |\n",
      "|    iterations         | 60400     |\n",
      "|    time_elapsed       | 516       |\n",
      "|    total_timesteps    | 302000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.45     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 70399     |\n",
      "|    policy_loss        | -33.9     |\n",
      "|    reward             | 1.1956091 |\n",
      "|    std                | 1.5       |\n",
      "|    value_loss         | 51.3      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 585         |\n",
      "|    iterations         | 60500       |\n",
      "|    time_elapsed       | 516         |\n",
      "|    total_timesteps    | 302500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.44       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 70499       |\n",
      "|    policy_loss        | -10         |\n",
      "|    reward             | -0.72203016 |\n",
      "|    std                | 1.5         |\n",
      "|    value_loss         | 7.4         |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 585      |\n",
      "|    iterations         | 60600    |\n",
      "|    time_elapsed       | 517      |\n",
      "|    total_timesteps    | 303000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.46    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 70599    |\n",
      "|    policy_loss        | -48.2    |\n",
      "|    reward             | 0.810983 |\n",
      "|    std                | 1.51     |\n",
      "|    value_loss         | 51.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 585      |\n",
      "|    iterations         | 60700    |\n",
      "|    time_elapsed       | 518      |\n",
      "|    total_timesteps    | 303500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.46    |\n",
      "|    explained_variance | -0.502   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 70699    |\n",
      "|    policy_loss        | 116      |\n",
      "|    reward             | 3.813084 |\n",
      "|    std                | 1.51     |\n",
      "|    value_loss         | 488      |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 585         |\n",
      "|    iterations         | 60800       |\n",
      "|    time_elapsed       | 519         |\n",
      "|    total_timesteps    | 304000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.45       |\n",
      "|    explained_variance | 0.00162     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 70799       |\n",
      "|    policy_loss        | 4.49        |\n",
      "|    reward             | -0.51106834 |\n",
      "|    std                | 1.5         |\n",
      "|    value_loss         | 2.06        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 585        |\n",
      "|    iterations         | 60900      |\n",
      "|    time_elapsed       | 520        |\n",
      "|    total_timesteps    | 304500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.43      |\n",
      "|    explained_variance | -0.0776    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 70899      |\n",
      "|    policy_loss        | -27.3      |\n",
      "|    reward             | -0.8219187 |\n",
      "|    std                | 1.49       |\n",
      "|    value_loss         | 37.6       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 585       |\n",
      "|    iterations         | 61000     |\n",
      "|    time_elapsed       | 520       |\n",
      "|    total_timesteps    | 305000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.44     |\n",
      "|    explained_variance | 0.0662    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 70999     |\n",
      "|    policy_loss        | -4.81     |\n",
      "|    reward             | 1.4962788 |\n",
      "|    std                | 1.49      |\n",
      "|    value_loss         | 8.29      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 585      |\n",
      "|    iterations         | 61100    |\n",
      "|    time_elapsed       | 521      |\n",
      "|    total_timesteps    | 305500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.43    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 71099    |\n",
      "|    policy_loss        | 6.47     |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.49     |\n",
      "|    value_loss         | 9.5      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 585       |\n",
      "|    iterations         | 61200     |\n",
      "|    time_elapsed       | 522       |\n",
      "|    total_timesteps    | 306000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.45     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 71199     |\n",
      "|    policy_loss        | -10.9     |\n",
      "|    reward             | 1.4064287 |\n",
      "|    std                | 1.5       |\n",
      "|    value_loss         | 5.64      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 585       |\n",
      "|    iterations         | 61300     |\n",
      "|    time_elapsed       | 523       |\n",
      "|    total_timesteps    | 306500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.44     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 71299     |\n",
      "|    policy_loss        | -8.82     |\n",
      "|    reward             | 1.5665375 |\n",
      "|    std                | 1.5       |\n",
      "|    value_loss         | 12.9      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 586        |\n",
      "|    iterations         | 61400      |\n",
      "|    time_elapsed       | 523        |\n",
      "|    total_timesteps    | 307000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.46      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 71399      |\n",
      "|    policy_loss        | -30.7      |\n",
      "|    reward             | -1.0931203 |\n",
      "|    std                | 1.51       |\n",
      "|    value_loss         | 40.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 585        |\n",
      "|    iterations         | 61500      |\n",
      "|    time_elapsed       | 524        |\n",
      "|    total_timesteps    | 307500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.45      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 71499      |\n",
      "|    policy_loss        | 6.17       |\n",
      "|    reward             | -1.5166004 |\n",
      "|    std                | 1.5        |\n",
      "|    value_loss         | 3.37       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 585        |\n",
      "|    iterations         | 61600      |\n",
      "|    time_elapsed       | 525        |\n",
      "|    total_timesteps    | 308000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.46      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 71599      |\n",
      "|    policy_loss        | 18         |\n",
      "|    reward             | -0.9443582 |\n",
      "|    std                | 1.51       |\n",
      "|    value_loss         | 12.1       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 585        |\n",
      "|    iterations         | 61700      |\n",
      "|    time_elapsed       | 526        |\n",
      "|    total_timesteps    | 308500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.45      |\n",
      "|    explained_variance | 0.526      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 71699      |\n",
      "|    policy_loss        | -4.98      |\n",
      "|    reward             | -5.3389025 |\n",
      "|    std                | 1.5        |\n",
      "|    value_loss         | 2.39       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 586       |\n",
      "|    iterations         | 61800     |\n",
      "|    time_elapsed       | 527       |\n",
      "|    total_timesteps    | 309000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.45     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 71799     |\n",
      "|    policy_loss        | 83.8      |\n",
      "|    reward             | -11.89273 |\n",
      "|    std                | 1.51      |\n",
      "|    value_loss         | 229       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 586       |\n",
      "|    iterations         | 61900     |\n",
      "|    time_elapsed       | 528       |\n",
      "|    total_timesteps    | 309500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.45     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 71899     |\n",
      "|    policy_loss        | 72.4      |\n",
      "|    reward             | -19.45177 |\n",
      "|    std                | 1.5       |\n",
      "|    value_loss         | 795       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 586        |\n",
      "|    iterations         | 62000      |\n",
      "|    time_elapsed       | 528        |\n",
      "|    total_timesteps    | 310000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.42      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 71999      |\n",
      "|    policy_loss        | 3.95       |\n",
      "|    reward             | 0.03898714 |\n",
      "|    std                | 1.49       |\n",
      "|    value_loss         | 1.05       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 586         |\n",
      "|    iterations         | 62100       |\n",
      "|    time_elapsed       | 529         |\n",
      "|    total_timesteps    | 310500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.42       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 72099       |\n",
      "|    policy_loss        | -21.1       |\n",
      "|    reward             | -0.42898852 |\n",
      "|    std                | 1.49        |\n",
      "|    value_loss         | 18.8        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 586        |\n",
      "|    iterations         | 62200      |\n",
      "|    time_elapsed       | 530        |\n",
      "|    total_timesteps    | 311000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.43      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 72199      |\n",
      "|    policy_loss        | -9.31      |\n",
      "|    reward             | 0.03002208 |\n",
      "|    std                | 1.5        |\n",
      "|    value_loss         | 10.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 586        |\n",
      "|    iterations         | 62300      |\n",
      "|    time_elapsed       | 531        |\n",
      "|    total_timesteps    | 311500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.44      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 72299      |\n",
      "|    policy_loss        | 16.1       |\n",
      "|    reward             | -3.6100974 |\n",
      "|    std                | 1.5        |\n",
      "|    value_loss         | 11         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 586        |\n",
      "|    iterations         | 62400      |\n",
      "|    time_elapsed       | 532        |\n",
      "|    total_timesteps    | 312000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.44      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 72399      |\n",
      "|    policy_loss        | 20.4       |\n",
      "|    reward             | -1.3371077 |\n",
      "|    std                | 1.49       |\n",
      "|    value_loss         | 42.8       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 586         |\n",
      "|    iterations         | 62500       |\n",
      "|    time_elapsed       | 533         |\n",
      "|    total_timesteps    | 312500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.46       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 72499       |\n",
      "|    policy_loss        | 0.807       |\n",
      "|    reward             | -0.11446997 |\n",
      "|    std                | 1.51        |\n",
      "|    value_loss         | 0.0733      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 586       |\n",
      "|    iterations         | 62600     |\n",
      "|    time_elapsed       | 533       |\n",
      "|    total_timesteps    | 313000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.47     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 72599     |\n",
      "|    policy_loss        | -4.11     |\n",
      "|    reward             | 0.8469879 |\n",
      "|    std                | 1.51      |\n",
      "|    value_loss         | 2.17      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 586        |\n",
      "|    iterations         | 62700      |\n",
      "|    time_elapsed       | 534        |\n",
      "|    total_timesteps    | 313500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.46      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 72699      |\n",
      "|    policy_loss        | 2.08       |\n",
      "|    reward             | -0.6917354 |\n",
      "|    std                | 1.51       |\n",
      "|    value_loss         | 1.03       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 586        |\n",
      "|    iterations         | 62800      |\n",
      "|    time_elapsed       | 535        |\n",
      "|    total_timesteps    | 314000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.47      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 72799      |\n",
      "|    policy_loss        | -21.6      |\n",
      "|    reward             | -0.5696989 |\n",
      "|    std                | 1.52       |\n",
      "|    value_loss         | 18.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 586        |\n",
      "|    iterations         | 62900      |\n",
      "|    time_elapsed       | 536        |\n",
      "|    total_timesteps    | 314500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.46      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 72899      |\n",
      "|    policy_loss        | -14.6      |\n",
      "|    reward             | 0.24218987 |\n",
      "|    std                | 1.51       |\n",
      "|    value_loss         | 6.29       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 586       |\n",
      "|    iterations         | 63000     |\n",
      "|    time_elapsed       | 536       |\n",
      "|    total_timesteps    | 315000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.45     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 72999     |\n",
      "|    policy_loss        | 63.5      |\n",
      "|    reward             | 2.4809802 |\n",
      "|    std                | 1.5       |\n",
      "|    value_loss         | 183       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 586        |\n",
      "|    iterations         | 63100      |\n",
      "|    time_elapsed       | 537        |\n",
      "|    total_timesteps    | 315500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.45      |\n",
      "|    explained_variance | 0.0056     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 73099      |\n",
      "|    policy_loss        | -0.747     |\n",
      "|    reward             | 0.38209945 |\n",
      "|    std                | 1.5        |\n",
      "|    value_loss         | 1.21       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 586       |\n",
      "|    iterations         | 63200     |\n",
      "|    time_elapsed       | 538       |\n",
      "|    total_timesteps    | 316000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.45     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 73199     |\n",
      "|    policy_loss        | -2.74     |\n",
      "|    reward             | -4.908402 |\n",
      "|    std                | 1.5       |\n",
      "|    value_loss         | 11.5      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 586         |\n",
      "|    iterations         | 63300       |\n",
      "|    time_elapsed       | 539         |\n",
      "|    total_timesteps    | 316500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.45       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 73299       |\n",
      "|    policy_loss        | -0.336      |\n",
      "|    reward             | -0.19802928 |\n",
      "|    std                | 1.51        |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 586       |\n",
      "|    iterations         | 63400     |\n",
      "|    time_elapsed       | 540       |\n",
      "|    total_timesteps    | 317000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.45     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 73399     |\n",
      "|    policy_loss        | 4.18      |\n",
      "|    reward             | 1.3936015 |\n",
      "|    std                | 1.51      |\n",
      "|    value_loss         | 1.12      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 587        |\n",
      "|    iterations         | 63500      |\n",
      "|    time_elapsed       | 540        |\n",
      "|    total_timesteps    | 317500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.43      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 73499      |\n",
      "|    policy_loss        | -17.5      |\n",
      "|    reward             | -1.8571169 |\n",
      "|    std                | 1.5        |\n",
      "|    value_loss         | 19.7       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 587       |\n",
      "|    iterations         | 63600     |\n",
      "|    time_elapsed       | 541       |\n",
      "|    total_timesteps    | 318000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.44     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 73599     |\n",
      "|    policy_loss        | 43.9      |\n",
      "|    reward             | -5.879576 |\n",
      "|    std                | 1.5       |\n",
      "|    value_loss         | 87.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 587       |\n",
      "|    iterations         | 63700     |\n",
      "|    time_elapsed       | 542       |\n",
      "|    total_timesteps    | 318500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.47     |\n",
      "|    explained_variance | -0.00704  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 73699     |\n",
      "|    policy_loss        | -38.8     |\n",
      "|    reward             | -2.706791 |\n",
      "|    std                | 1.52      |\n",
      "|    value_loss         | 54.7      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 587         |\n",
      "|    iterations         | 63800       |\n",
      "|    time_elapsed       | 543         |\n",
      "|    total_timesteps    | 319000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.47       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 73799       |\n",
      "|    policy_loss        | -0.107      |\n",
      "|    reward             | -0.39971882 |\n",
      "|    std                | 1.52        |\n",
      "|    value_loss         | 0.0234      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 587        |\n",
      "|    iterations         | 63900      |\n",
      "|    time_elapsed       | 544        |\n",
      "|    total_timesteps    | 319500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.47      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 73899      |\n",
      "|    policy_loss        | -30.9      |\n",
      "|    reward             | -1.3980987 |\n",
      "|    std                | 1.52       |\n",
      "|    value_loss         | 29.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 587       |\n",
      "|    iterations         | 64000     |\n",
      "|    time_elapsed       | 544       |\n",
      "|    total_timesteps    | 320000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.48     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 73999     |\n",
      "|    policy_loss        | -65.8     |\n",
      "|    reward             | 5.9554453 |\n",
      "|    std                | 1.52      |\n",
      "|    value_loss         | 171       |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 587          |\n",
      "|    iterations         | 64100        |\n",
      "|    time_elapsed       | 545          |\n",
      "|    total_timesteps    | 320500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.49        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 74099        |\n",
      "|    policy_loss        | 6.98         |\n",
      "|    reward             | -0.047615785 |\n",
      "|    std                | 1.53         |\n",
      "|    value_loss         | 1.81         |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 587      |\n",
      "|    iterations         | 64200    |\n",
      "|    time_elapsed       | 546      |\n",
      "|    total_timesteps    | 321000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.48    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 74199    |\n",
      "|    policy_loss        | 28.1     |\n",
      "|    reward             | 1.426736 |\n",
      "|    std                | 1.52     |\n",
      "|    value_loss         | 39.2     |\n",
      "------------------------------------\n",
      "day: 2892, episode: 130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8446836.78\n",
      "total_reward: 7446836.78\n",
      "total_cost: 2973.85\n",
      "total_trades: 5785\n",
      "Sharpe: 0.972\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 587         |\n",
      "|    iterations         | 64300       |\n",
      "|    time_elapsed       | 547         |\n",
      "|    total_timesteps    | 321500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.48       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 74299       |\n",
      "|    policy_loss        | -22.6       |\n",
      "|    reward             | -0.14908893 |\n",
      "|    std                | 1.52        |\n",
      "|    value_loss         | 22.5        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 587         |\n",
      "|    iterations         | 64400       |\n",
      "|    time_elapsed       | 548         |\n",
      "|    total_timesteps    | 322000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.48       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 74399       |\n",
      "|    policy_loss        | 19          |\n",
      "|    reward             | 0.051218305 |\n",
      "|    std                | 1.52        |\n",
      "|    value_loss         | 19.1        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 587        |\n",
      "|    iterations         | 64500      |\n",
      "|    time_elapsed       | 548        |\n",
      "|    total_timesteps    | 322500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.48      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 74499      |\n",
      "|    policy_loss        | 7.2        |\n",
      "|    reward             | -1.3854135 |\n",
      "|    std                | 1.52       |\n",
      "|    value_loss         | 3.18       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 587         |\n",
      "|    iterations         | 64600       |\n",
      "|    time_elapsed       | 549         |\n",
      "|    total_timesteps    | 323000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.49       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 74599       |\n",
      "|    policy_loss        | -12.3       |\n",
      "|    reward             | -0.47583207 |\n",
      "|    std                | 1.53        |\n",
      "|    value_loss         | 7.39        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 587       |\n",
      "|    iterations         | 64700     |\n",
      "|    time_elapsed       | 550       |\n",
      "|    total_timesteps    | 323500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.49     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 74699     |\n",
      "|    policy_loss        | 41.6      |\n",
      "|    reward             | -2.036156 |\n",
      "|    std                | 1.53      |\n",
      "|    value_loss         | 95.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 587       |\n",
      "|    iterations         | 64800     |\n",
      "|    time_elapsed       | 551       |\n",
      "|    total_timesteps    | 324000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.48     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 74799     |\n",
      "|    policy_loss        | 67.1      |\n",
      "|    reward             | 6.5204816 |\n",
      "|    std                | 1.52      |\n",
      "|    value_loss         | 131       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 587       |\n",
      "|    iterations         | 64900     |\n",
      "|    time_elapsed       | 552       |\n",
      "|    total_timesteps    | 324500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.49     |\n",
      "|    explained_variance | 0.764     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 74899     |\n",
      "|    policy_loss        | -3.35     |\n",
      "|    reward             | 0.5178418 |\n",
      "|    std                | 1.53      |\n",
      "|    value_loss         | 0.853     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 587        |\n",
      "|    iterations         | 65000      |\n",
      "|    time_elapsed       | 553        |\n",
      "|    total_timesteps    | 325000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.48      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 74999      |\n",
      "|    policy_loss        | 4.55       |\n",
      "|    reward             | -2.1291525 |\n",
      "|    std                | 1.52       |\n",
      "|    value_loss         | 1.03       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 587       |\n",
      "|    iterations         | 65100     |\n",
      "|    time_elapsed       | 553       |\n",
      "|    total_timesteps    | 325500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.49     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 75099     |\n",
      "|    policy_loss        | 5.19      |\n",
      "|    reward             | -2.170858 |\n",
      "|    std                | 1.52      |\n",
      "|    value_loss         | 4.33      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 587       |\n",
      "|    iterations         | 65200     |\n",
      "|    time_elapsed       | 554       |\n",
      "|    total_timesteps    | 326000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.49     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 75199     |\n",
      "|    policy_loss        | -35.9     |\n",
      "|    reward             | 5.9896603 |\n",
      "|    std                | 1.53      |\n",
      "|    value_loss         | 67.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 587        |\n",
      "|    iterations         | 65300      |\n",
      "|    time_elapsed       | 555        |\n",
      "|    total_timesteps    | 326500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.47      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 75299      |\n",
      "|    policy_loss        | 53         |\n",
      "|    reward             | 0.43844938 |\n",
      "|    std                | 1.52       |\n",
      "|    value_loss         | 154        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 587         |\n",
      "|    iterations         | 65400       |\n",
      "|    time_elapsed       | 556         |\n",
      "|    total_timesteps    | 327000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.49       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 75399       |\n",
      "|    policy_loss        | -7.72       |\n",
      "|    reward             | -0.37675804 |\n",
      "|    std                | 1.53        |\n",
      "|    value_loss         | 2.29        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 587          |\n",
      "|    iterations         | 65500        |\n",
      "|    time_elapsed       | 557          |\n",
      "|    total_timesteps    | 327500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.5         |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 75499        |\n",
      "|    policy_loss        | -11.4        |\n",
      "|    reward             | -0.089954406 |\n",
      "|    std                | 1.53         |\n",
      "|    value_loss         | 5.39         |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 587       |\n",
      "|    iterations         | 65600     |\n",
      "|    time_elapsed       | 557       |\n",
      "|    total_timesteps    | 328000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.52     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 75599     |\n",
      "|    policy_loss        | 33.8      |\n",
      "|    reward             | 0.5420016 |\n",
      "|    std                | 1.54      |\n",
      "|    value_loss         | 43.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 587       |\n",
      "|    iterations         | 65700     |\n",
      "|    time_elapsed       | 558       |\n",
      "|    total_timesteps    | 328500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.52     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 75699     |\n",
      "|    policy_loss        | 24        |\n",
      "|    reward             | -2.652233 |\n",
      "|    std                | 1.55      |\n",
      "|    value_loss         | 29.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 587       |\n",
      "|    iterations         | 65800     |\n",
      "|    time_elapsed       | 559       |\n",
      "|    total_timesteps    | 329000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.52     |\n",
      "|    explained_variance | -0.659    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 75799     |\n",
      "|    policy_loss        | 0.434     |\n",
      "|    reward             | 1.6964873 |\n",
      "|    std                | 1.54      |\n",
      "|    value_loss         | 2.79      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 588      |\n",
      "|    iterations         | 65900    |\n",
      "|    time_elapsed       | 560      |\n",
      "|    total_timesteps    | 329500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.51    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 75899    |\n",
      "|    policy_loss        | 25.6     |\n",
      "|    reward             | 1.413469 |\n",
      "|    std                | 1.54     |\n",
      "|    value_loss         | 21.9     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 66000      |\n",
      "|    time_elapsed       | 561        |\n",
      "|    total_timesteps    | 330000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.51      |\n",
      "|    explained_variance | -0.0256    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 75999      |\n",
      "|    policy_loss        | 12.5       |\n",
      "|    reward             | 0.78524977 |\n",
      "|    std                | 1.54       |\n",
      "|    value_loss         | 5.42       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 66100     |\n",
      "|    time_elapsed       | 561       |\n",
      "|    total_timesteps    | 330500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.52     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 76099     |\n",
      "|    policy_loss        | -21.9     |\n",
      "|    reward             | 3.8838308 |\n",
      "|    std                | 1.54      |\n",
      "|    value_loss         | 23        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 66200      |\n",
      "|    time_elapsed       | 562        |\n",
      "|    total_timesteps    | 331000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.53      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 76199      |\n",
      "|    policy_loss        | -7.6       |\n",
      "|    reward             | -2.7228687 |\n",
      "|    std                | 1.54       |\n",
      "|    value_loss         | 1.76       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 588         |\n",
      "|    iterations         | 66300       |\n",
      "|    time_elapsed       | 563         |\n",
      "|    total_timesteps    | 331500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.55       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 76299       |\n",
      "|    policy_loss        | -5.78       |\n",
      "|    reward             | 0.124735385 |\n",
      "|    std                | 1.55        |\n",
      "|    value_loss         | 4.24        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 66400     |\n",
      "|    time_elapsed       | 564       |\n",
      "|    total_timesteps    | 332000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.54     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 76399     |\n",
      "|    policy_loss        | -0.728    |\n",
      "|    reward             | 0.5498441 |\n",
      "|    std                | 1.55      |\n",
      "|    value_loss         | 0.421     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 588         |\n",
      "|    iterations         | 66500       |\n",
      "|    time_elapsed       | 565         |\n",
      "|    total_timesteps    | 332500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.53       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 76499       |\n",
      "|    policy_loss        | -16.8       |\n",
      "|    reward             | -0.53022534 |\n",
      "|    std                | 1.55        |\n",
      "|    value_loss         | 10.6        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 66600      |\n",
      "|    time_elapsed       | 566        |\n",
      "|    total_timesteps    | 333000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.54      |\n",
      "|    explained_variance | 0.000605   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 76599      |\n",
      "|    policy_loss        | 3.89       |\n",
      "|    reward             | 0.20688593 |\n",
      "|    std                | 1.55       |\n",
      "|    value_loss         | 1.34       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 66700      |\n",
      "|    time_elapsed       | 567        |\n",
      "|    total_timesteps    | 333500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.54      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 76699      |\n",
      "|    policy_loss        | -4.38      |\n",
      "|    reward             | 0.83837587 |\n",
      "|    std                | 1.55       |\n",
      "|    value_loss         | 1.98       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 66800      |\n",
      "|    time_elapsed       | 567        |\n",
      "|    total_timesteps    | 334000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.55      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 76799      |\n",
      "|    policy_loss        | 8.58       |\n",
      "|    reward             | 0.03710248 |\n",
      "|    std                | 1.55       |\n",
      "|    value_loss         | 3.06       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 588         |\n",
      "|    iterations         | 66900       |\n",
      "|    time_elapsed       | 568         |\n",
      "|    total_timesteps    | 334500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.55       |\n",
      "|    explained_variance | 0.00011     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 76899       |\n",
      "|    policy_loss        | -21.6       |\n",
      "|    reward             | -0.18342185 |\n",
      "|    std                | 1.55        |\n",
      "|    value_loss         | 16.8        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 67000     |\n",
      "|    time_elapsed       | 569       |\n",
      "|    total_timesteps    | 335000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.54     |\n",
      "|    explained_variance | -0.00069  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 76999     |\n",
      "|    policy_loss        | -16.1     |\n",
      "|    reward             | -3.617308 |\n",
      "|    std                | 1.54      |\n",
      "|    value_loss         | 11.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 67100     |\n",
      "|    time_elapsed       | 570       |\n",
      "|    total_timesteps    | 335500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.54     |\n",
      "|    explained_variance | 0.000282  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 77099     |\n",
      "|    policy_loss        | 9.83      |\n",
      "|    reward             | 1.6546812 |\n",
      "|    std                | 1.55      |\n",
      "|    value_loss         | 6.59      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 67200      |\n",
      "|    time_elapsed       | 571        |\n",
      "|    total_timesteps    | 336000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.54      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 77199      |\n",
      "|    policy_loss        | -17.2      |\n",
      "|    reward             | -0.6969344 |\n",
      "|    std                | 1.55       |\n",
      "|    value_loss         | 11.1       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 67300      |\n",
      "|    time_elapsed       | 572        |\n",
      "|    total_timesteps    | 336500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.54      |\n",
      "|    explained_variance | -0.00572   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 77299      |\n",
      "|    policy_loss        | 16.7       |\n",
      "|    reward             | 0.19001639 |\n",
      "|    std                | 1.55       |\n",
      "|    value_loss         | 9.04       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 67400     |\n",
      "|    time_elapsed       | 572       |\n",
      "|    total_timesteps    | 337000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.54     |\n",
      "|    explained_variance | -5.87e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 77399     |\n",
      "|    policy_loss        | -21.9     |\n",
      "|    reward             | 1.3034499 |\n",
      "|    std                | 1.55      |\n",
      "|    value_loss         | 19.5      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 67500      |\n",
      "|    time_elapsed       | 573        |\n",
      "|    total_timesteps    | 337500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.53      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 77499      |\n",
      "|    policy_loss        | -3.15      |\n",
      "|    reward             | 0.09613123 |\n",
      "|    std                | 1.55       |\n",
      "|    value_loss         | 1.34       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 67600     |\n",
      "|    time_elapsed       | 574       |\n",
      "|    total_timesteps    | 338000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.53     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 77599     |\n",
      "|    policy_loss        | 11.4      |\n",
      "|    reward             | 1.3349793 |\n",
      "|    std                | 1.54      |\n",
      "|    value_loss         | 11.6      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 588         |\n",
      "|    iterations         | 67700       |\n",
      "|    time_elapsed       | 575         |\n",
      "|    total_timesteps    | 338500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.54       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 77699       |\n",
      "|    policy_loss        | -0.513      |\n",
      "|    reward             | -0.16025072 |\n",
      "|    std                | 1.55        |\n",
      "|    value_loss         | 0.0626      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 67800     |\n",
      "|    time_elapsed       | 576       |\n",
      "|    total_timesteps    | 339000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.55     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 77799     |\n",
      "|    policy_loss        | 10.1      |\n",
      "|    reward             | 1.5407101 |\n",
      "|    std                | 1.56      |\n",
      "|    value_loss         | 3.11      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 67900     |\n",
      "|    time_elapsed       | 576       |\n",
      "|    total_timesteps    | 339500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.55     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 77899     |\n",
      "|    policy_loss        | -3.5      |\n",
      "|    reward             | 1.2427479 |\n",
      "|    std                | 1.56      |\n",
      "|    value_loss         | 0.758     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 68000      |\n",
      "|    time_elapsed       | 577        |\n",
      "|    total_timesteps    | 340000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.55      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 77999      |\n",
      "|    policy_loss        | 2.28       |\n",
      "|    reward             | -1.6289176 |\n",
      "|    std                | 1.56       |\n",
      "|    value_loss         | 9.05       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 68100     |\n",
      "|    time_elapsed       | 578       |\n",
      "|    total_timesteps    | 340500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.53     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 78099     |\n",
      "|    policy_loss        | -1.78     |\n",
      "|    reward             | -2.035099 |\n",
      "|    std                | 1.55      |\n",
      "|    value_loss         | 1.11      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 68200     |\n",
      "|    time_elapsed       | 579       |\n",
      "|    total_timesteps    | 341000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.53     |\n",
      "|    explained_variance | 0.00162   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 78199     |\n",
      "|    policy_loss        | 14.4      |\n",
      "|    reward             | 1.0992032 |\n",
      "|    std                | 1.55      |\n",
      "|    value_loss         | 35.8      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 588         |\n",
      "|    iterations         | 68300       |\n",
      "|    time_elapsed       | 580         |\n",
      "|    total_timesteps    | 341500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.54       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 78299       |\n",
      "|    policy_loss        | 0.611       |\n",
      "|    reward             | -0.17840102 |\n",
      "|    std                | 1.55        |\n",
      "|    value_loss         | 0.484       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 68400     |\n",
      "|    time_elapsed       | 581       |\n",
      "|    total_timesteps    | 342000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.54     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 78399     |\n",
      "|    policy_loss        | 12.1      |\n",
      "|    reward             | 2.5818746 |\n",
      "|    std                | 1.56      |\n",
      "|    value_loss         | 5.85      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 68500     |\n",
      "|    time_elapsed       | 581       |\n",
      "|    total_timesteps    | 342500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.54     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 78499     |\n",
      "|    policy_loss        | 8.72      |\n",
      "|    reward             | 1.2383233 |\n",
      "|    std                | 1.56      |\n",
      "|    value_loss         | 3.25      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 68600      |\n",
      "|    time_elapsed       | 582        |\n",
      "|    total_timesteps    | 343000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.58      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 78599      |\n",
      "|    policy_loss        | -5.44      |\n",
      "|    reward             | -1.7313905 |\n",
      "|    std                | 1.58       |\n",
      "|    value_loss         | 3.3        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 588         |\n",
      "|    iterations         | 68700       |\n",
      "|    time_elapsed       | 583         |\n",
      "|    total_timesteps    | 343500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.59       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 78699       |\n",
      "|    policy_loss        | -6.61       |\n",
      "|    reward             | -0.76391554 |\n",
      "|    std                | 1.58        |\n",
      "|    value_loss         | 1.57        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 68800     |\n",
      "|    time_elapsed       | 584       |\n",
      "|    total_timesteps    | 344000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.6      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 78799     |\n",
      "|    policy_loss        | 17.1      |\n",
      "|    reward             | 1.0692635 |\n",
      "|    std                | 1.59      |\n",
      "|    value_loss         | 19.9      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 588         |\n",
      "|    iterations         | 68900       |\n",
      "|    time_elapsed       | 585         |\n",
      "|    total_timesteps    | 344500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.59       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 78899       |\n",
      "|    policy_loss        | -12.1       |\n",
      "|    reward             | -0.12088955 |\n",
      "|    std                | 1.58        |\n",
      "|    value_loss         | 6.39        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 69000      |\n",
      "|    time_elapsed       | 585        |\n",
      "|    total_timesteps    | 345000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.6       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 78999      |\n",
      "|    policy_loss        | -34.9      |\n",
      "|    reward             | -1.1190132 |\n",
      "|    std                | 1.58       |\n",
      "|    value_loss         | 37.4       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 69100     |\n",
      "|    time_elapsed       | 586       |\n",
      "|    total_timesteps    | 345500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.6      |\n",
      "|    explained_variance | 0.000103  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 79099     |\n",
      "|    policy_loss        | 1.49      |\n",
      "|    reward             | -2.036265 |\n",
      "|    std                | 1.59      |\n",
      "|    value_loss         | 0.324     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 588       |\n",
      "|    iterations         | 69200     |\n",
      "|    time_elapsed       | 587       |\n",
      "|    total_timesteps    | 346000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.6      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 79199     |\n",
      "|    policy_loss        | -21.5     |\n",
      "|    reward             | 0.9534348 |\n",
      "|    std                | 1.59      |\n",
      "|    value_loss         | 24.4      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 69300      |\n",
      "|    time_elapsed       | 588        |\n",
      "|    total_timesteps    | 346500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.58      |\n",
      "|    explained_variance | -0.000405  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 79299      |\n",
      "|    policy_loss        | -7.41      |\n",
      "|    reward             | 0.62568295 |\n",
      "|    std                | 1.58       |\n",
      "|    value_loss         | 2.35       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 69400      |\n",
      "|    time_elapsed       | 589        |\n",
      "|    total_timesteps    | 347000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.56      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 79399      |\n",
      "|    policy_loss        | 17         |\n",
      "|    reward             | -1.8252403 |\n",
      "|    std                | 1.57       |\n",
      "|    value_loss         | 13.6       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 69500      |\n",
      "|    time_elapsed       | 590        |\n",
      "|    total_timesteps    | 347500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.55      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 79499      |\n",
      "|    policy_loss        | -12.1      |\n",
      "|    reward             | 0.40428075 |\n",
      "|    std                | 1.57       |\n",
      "|    value_loss         | 6.19       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 69600      |\n",
      "|    time_elapsed       | 590        |\n",
      "|    total_timesteps    | 348000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.56      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 79599      |\n",
      "|    policy_loss        | 26.6       |\n",
      "|    reward             | -0.6965606 |\n",
      "|    std                | 1.57       |\n",
      "|    value_loss         | 17.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 69700      |\n",
      "|    time_elapsed       | 591        |\n",
      "|    total_timesteps    | 348500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.58      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 79699      |\n",
      "|    policy_loss        | -12.2      |\n",
      "|    reward             | -2.9968555 |\n",
      "|    std                | 1.58       |\n",
      "|    value_loss         | 10.7       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 69800      |\n",
      "|    time_elapsed       | 592        |\n",
      "|    total_timesteps    | 349000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.59      |\n",
      "|    explained_variance | -0.047     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 79799      |\n",
      "|    policy_loss        | -30.5      |\n",
      "|    reward             | -0.8409862 |\n",
      "|    std                | 1.58       |\n",
      "|    value_loss         | 26.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 69900     |\n",
      "|    time_elapsed       | 593       |\n",
      "|    total_timesteps    | 349500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.59     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 79899     |\n",
      "|    policy_loss        | 19.3      |\n",
      "|    reward             | -4.367807 |\n",
      "|    std                | 1.58      |\n",
      "|    value_loss         | 29.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 589      |\n",
      "|    iterations         | 70000    |\n",
      "|    time_elapsed       | 594      |\n",
      "|    total_timesteps    | 350000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.58    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 79999    |\n",
      "|    policy_loss        | 93.3     |\n",
      "|    reward             | 4.560148 |\n",
      "|    std                | 1.58     |\n",
      "|    value_loss         | 543      |\n",
      "------------------------------------\n",
      "day: 2892, episode: 140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4417623.48\n",
      "total_reward: 3417623.48\n",
      "total_cost: 8842.94\n",
      "total_trades: 5886\n",
      "Sharpe: 0.740\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 70100      |\n",
      "|    time_elapsed       | 594        |\n",
      "|    total_timesteps    | 350500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.58      |\n",
      "|    explained_variance | 0.00234    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 80099      |\n",
      "|    policy_loss        | 7.39       |\n",
      "|    reward             | 0.44798297 |\n",
      "|    std                | 1.58       |\n",
      "|    value_loss         | 2.44       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 70200      |\n",
      "|    time_elapsed       | 595        |\n",
      "|    total_timesteps    | 351000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.58      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 80199      |\n",
      "|    policy_loss        | -6.3       |\n",
      "|    reward             | 0.24061678 |\n",
      "|    std                | 1.57       |\n",
      "|    value_loss         | 4.23       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 589         |\n",
      "|    iterations         | 70300       |\n",
      "|    time_elapsed       | 596         |\n",
      "|    total_timesteps    | 351500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.6        |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 80299       |\n",
      "|    policy_loss        | -27         |\n",
      "|    reward             | -0.46543917 |\n",
      "|    std                | 1.58        |\n",
      "|    value_loss         | 27.7        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 589      |\n",
      "|    iterations         | 70400    |\n",
      "|    time_elapsed       | 597      |\n",
      "|    total_timesteps    | 352000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.61    |\n",
      "|    explained_variance | 0.00121  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 80399    |\n",
      "|    policy_loss        | -4.04    |\n",
      "|    reward             | 4.36709  |\n",
      "|    std                | 1.59     |\n",
      "|    value_loss         | 1.56     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 70500     |\n",
      "|    time_elapsed       | 598       |\n",
      "|    total_timesteps    | 352500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.63     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 80499     |\n",
      "|    policy_loss        | 40.1      |\n",
      "|    reward             | 1.7465501 |\n",
      "|    std                | 1.6       |\n",
      "|    value_loss         | 70.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 70600     |\n",
      "|    time_elapsed       | 599       |\n",
      "|    total_timesteps    | 353000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.62     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 80599     |\n",
      "|    policy_loss        | 2.77      |\n",
      "|    reward             | 2.1758084 |\n",
      "|    std                | 1.59      |\n",
      "|    value_loss         | 0.824     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 70700      |\n",
      "|    time_elapsed       | 599        |\n",
      "|    total_timesteps    | 353500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.64      |\n",
      "|    explained_variance | -2.53e-05  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 80699      |\n",
      "|    policy_loss        | 16         |\n",
      "|    reward             | -5.3508716 |\n",
      "|    std                | 1.6        |\n",
      "|    value_loss         | 8.25       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 70800     |\n",
      "|    time_elapsed       | 600       |\n",
      "|    total_timesteps    | 354000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.65     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 80799     |\n",
      "|    policy_loss        | 15.7      |\n",
      "|    reward             | 1.1518984 |\n",
      "|    std                | 1.61      |\n",
      "|    value_loss         | 13.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 70900     |\n",
      "|    time_elapsed       | 601       |\n",
      "|    total_timesteps    | 354500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.64     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 80899     |\n",
      "|    policy_loss        | -13.5     |\n",
      "|    reward             | 2.6322243 |\n",
      "|    std                | 1.61      |\n",
      "|    value_loss         | 7.23      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 71000     |\n",
      "|    time_elapsed       | 602       |\n",
      "|    total_timesteps    | 355000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.62     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 80999     |\n",
      "|    policy_loss        | 2.12      |\n",
      "|    reward             | -2.877408 |\n",
      "|    std                | 1.6       |\n",
      "|    value_loss         | 0.477     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 589         |\n",
      "|    iterations         | 71100       |\n",
      "|    time_elapsed       | 603         |\n",
      "|    total_timesteps    | 355500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.61       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 81099       |\n",
      "|    policy_loss        | 4.75        |\n",
      "|    reward             | -0.91059864 |\n",
      "|    std                | 1.59        |\n",
      "|    value_loss         | 3.64        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 589         |\n",
      "|    iterations         | 71200       |\n",
      "|    time_elapsed       | 603         |\n",
      "|    total_timesteps    | 356000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.6        |\n",
      "|    explained_variance | 0.00061     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 81199       |\n",
      "|    policy_loss        | -11.8       |\n",
      "|    reward             | -0.22073153 |\n",
      "|    std                | 1.59        |\n",
      "|    value_loss         | 5.13        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 71300      |\n",
      "|    time_elapsed       | 604        |\n",
      "|    total_timesteps    | 356500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.59      |\n",
      "|    explained_variance | 1.69e-05   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 81299      |\n",
      "|    policy_loss        | -49.1      |\n",
      "|    reward             | 0.07248174 |\n",
      "|    std                | 1.58       |\n",
      "|    value_loss         | 105        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 71400      |\n",
      "|    time_elapsed       | 605        |\n",
      "|    total_timesteps    | 357000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.58      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 81399      |\n",
      "|    policy_loss        | -22.1      |\n",
      "|    reward             | -0.5176074 |\n",
      "|    std                | 1.58       |\n",
      "|    value_loss         | 17.4       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 71500     |\n",
      "|    time_elapsed       | 606       |\n",
      "|    total_timesteps    | 357500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.58     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 81499     |\n",
      "|    policy_loss        | -7.15     |\n",
      "|    reward             | 2.2861018 |\n",
      "|    std                | 1.58      |\n",
      "|    value_loss         | 3.73      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 71600      |\n",
      "|    time_elapsed       | 607        |\n",
      "|    total_timesteps    | 358000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.57      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 81599      |\n",
      "|    policy_loss        | -13.8      |\n",
      "|    reward             | 0.34326866 |\n",
      "|    std                | 1.57       |\n",
      "|    value_loss         | 9.42       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 71700      |\n",
      "|    time_elapsed       | 608        |\n",
      "|    total_timesteps    | 358500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.56      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 81699      |\n",
      "|    policy_loss        | 29.8       |\n",
      "|    reward             | -7.2466493 |\n",
      "|    std                | 1.57       |\n",
      "|    value_loss         | 48         |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 71800     |\n",
      "|    time_elapsed       | 608       |\n",
      "|    total_timesteps    | 359000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.57     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 81799     |\n",
      "|    policy_loss        | -10.5     |\n",
      "|    reward             | 0.6456351 |\n",
      "|    std                | 1.58      |\n",
      "|    value_loss         | 4.79      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 589      |\n",
      "|    iterations         | 71900    |\n",
      "|    time_elapsed       | 609      |\n",
      "|    total_timesteps    | 359500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.6     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 81899    |\n",
      "|    policy_loss        | -9.26    |\n",
      "|    reward             | 8.46218  |\n",
      "|    std                | 1.59     |\n",
      "|    value_loss         | 4.55     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 72000     |\n",
      "|    time_elapsed       | 610       |\n",
      "|    total_timesteps    | 360000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.59     |\n",
      "|    explained_variance | 0.000111  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 81999     |\n",
      "|    policy_loss        | -8.01     |\n",
      "|    reward             | 1.0378971 |\n",
      "|    std                | 1.59      |\n",
      "|    value_loss         | 3.1       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 72100      |\n",
      "|    time_elapsed       | 611        |\n",
      "|    total_timesteps    | 360500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.6       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 82099      |\n",
      "|    policy_loss        | -18.3      |\n",
      "|    reward             | 0.47396025 |\n",
      "|    std                | 1.59       |\n",
      "|    value_loss         | 16.6       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 72200     |\n",
      "|    time_elapsed       | 612       |\n",
      "|    total_timesteps    | 361000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.6      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 82199     |\n",
      "|    policy_loss        | 6.13      |\n",
      "|    reward             | 2.3732712 |\n",
      "|    std                | 1.59      |\n",
      "|    value_loss         | 1.77      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 589      |\n",
      "|    iterations         | 72300    |\n",
      "|    time_elapsed       | 613      |\n",
      "|    total_timesteps    | 361500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.58    |\n",
      "|    explained_variance | 0.000139 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 82299    |\n",
      "|    policy_loss        | 8.8      |\n",
      "|    reward             | 5.863525 |\n",
      "|    std                | 1.58     |\n",
      "|    value_loss         | 8.87     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 72400      |\n",
      "|    time_elapsed       | 614        |\n",
      "|    total_timesteps    | 362000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.58      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 82399      |\n",
      "|    policy_loss        | -8.43      |\n",
      "|    reward             | -1.6276729 |\n",
      "|    std                | 1.58       |\n",
      "|    value_loss         | 3.06       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 72500     |\n",
      "|    time_elapsed       | 614       |\n",
      "|    total_timesteps    | 362500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.57     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 82499     |\n",
      "|    policy_loss        | 24.9      |\n",
      "|    reward             | 1.0638492 |\n",
      "|    std                | 1.58      |\n",
      "|    value_loss         | 21.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 72600      |\n",
      "|    time_elapsed       | 615        |\n",
      "|    total_timesteps    | 363000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.56      |\n",
      "|    explained_variance | 0.000218   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 82599      |\n",
      "|    policy_loss        | -7.65      |\n",
      "|    reward             | -0.8024144 |\n",
      "|    std                | 1.57       |\n",
      "|    value_loss         | 7.54       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 589         |\n",
      "|    iterations         | 72700       |\n",
      "|    time_elapsed       | 616         |\n",
      "|    total_timesteps    | 363500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.57       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 82699       |\n",
      "|    policy_loss        | 0.792       |\n",
      "|    reward             | -0.54528236 |\n",
      "|    std                | 1.58        |\n",
      "|    value_loss         | 0.467       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 589         |\n",
      "|    iterations         | 72800       |\n",
      "|    time_elapsed       | 617         |\n",
      "|    total_timesteps    | 364000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.55       |\n",
      "|    explained_variance | 0.000309    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 82799       |\n",
      "|    policy_loss        | 25.3        |\n",
      "|    reward             | -0.42929822 |\n",
      "|    std                | 1.57        |\n",
      "|    value_loss         | 21.6        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 72900     |\n",
      "|    time_elapsed       | 618       |\n",
      "|    total_timesteps    | 364500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.55     |\n",
      "|    explained_variance | -6.66e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 82899     |\n",
      "|    policy_loss        | 27.3      |\n",
      "|    reward             | 9.937378  |\n",
      "|    std                | 1.57      |\n",
      "|    value_loss         | 24.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 73000     |\n",
      "|    time_elapsed       | 618       |\n",
      "|    total_timesteps    | 365000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.57     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 82999     |\n",
      "|    policy_loss        | -9.32     |\n",
      "|    reward             | 3.2748425 |\n",
      "|    std                | 1.58      |\n",
      "|    value_loss         | 3.64      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 73100      |\n",
      "|    time_elapsed       | 619        |\n",
      "|    total_timesteps    | 365500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.57      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 83099      |\n",
      "|    policy_loss        | 9.72       |\n",
      "|    reward             | -1.7647079 |\n",
      "|    std                | 1.57       |\n",
      "|    value_loss         | 6.64       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 73200      |\n",
      "|    time_elapsed       | 620        |\n",
      "|    total_timesteps    | 366000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.58      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 83199      |\n",
      "|    policy_loss        | 6.3        |\n",
      "|    reward             | 0.15667969 |\n",
      "|    std                | 1.58       |\n",
      "|    value_loss         | 1.88       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 73300     |\n",
      "|    time_elapsed       | 621       |\n",
      "|    total_timesteps    | 366500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.59     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 83299     |\n",
      "|    policy_loss        | 22.1      |\n",
      "|    reward             | 2.4699614 |\n",
      "|    std                | 1.59      |\n",
      "|    value_loss         | 21.4      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 73400      |\n",
      "|    time_elapsed       | 622        |\n",
      "|    total_timesteps    | 367000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.59      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 83399      |\n",
      "|    policy_loss        | -7.27      |\n",
      "|    reward             | -4.0522294 |\n",
      "|    std                | 1.59       |\n",
      "|    value_loss         | 25.7       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 73500     |\n",
      "|    time_elapsed       | 623       |\n",
      "|    total_timesteps    | 367500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.61     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 83499     |\n",
      "|    policy_loss        | 2.84      |\n",
      "|    reward             | 0.7980291 |\n",
      "|    std                | 1.6       |\n",
      "|    value_loss         | 0.692     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 73600      |\n",
      "|    time_elapsed       | 624        |\n",
      "|    total_timesteps    | 368000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.61      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 83599      |\n",
      "|    policy_loss        | 14.4       |\n",
      "|    reward             | -1.9698616 |\n",
      "|    std                | 1.6        |\n",
      "|    value_loss         | 10.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 73700     |\n",
      "|    time_elapsed       | 625       |\n",
      "|    total_timesteps    | 368500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.61     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 83699     |\n",
      "|    policy_loss        | 13.6      |\n",
      "|    reward             | 2.7875714 |\n",
      "|    std                | 1.6       |\n",
      "|    value_loss         | 22.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 73800     |\n",
      "|    time_elapsed       | 625       |\n",
      "|    total_timesteps    | 369000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.61     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 83799     |\n",
      "|    policy_loss        | 7.35      |\n",
      "|    reward             | 4.4031954 |\n",
      "|    std                | 1.6       |\n",
      "|    value_loss         | 5.97      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 73900      |\n",
      "|    time_elapsed       | 626        |\n",
      "|    total_timesteps    | 369500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.61      |\n",
      "|    explained_variance | -0.00247   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 83899      |\n",
      "|    policy_loss        | -15.5      |\n",
      "|    reward             | 0.13797164 |\n",
      "|    std                | 1.6        |\n",
      "|    value_loss         | 10.2       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 74000      |\n",
      "|    time_elapsed       | 627        |\n",
      "|    total_timesteps    | 370000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.61      |\n",
      "|    explained_variance | -0.000621  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 83999      |\n",
      "|    policy_loss        | 1.19       |\n",
      "|    reward             | -5.4902596 |\n",
      "|    std                | 1.6        |\n",
      "|    value_loss         | 1.48       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 74100      |\n",
      "|    time_elapsed       | 628        |\n",
      "|    total_timesteps    | 370500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.62      |\n",
      "|    explained_variance | 0.000375   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 84099      |\n",
      "|    policy_loss        | 7.05       |\n",
      "|    reward             | 0.07432705 |\n",
      "|    std                | 1.6        |\n",
      "|    value_loss         | 2.45       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 74200     |\n",
      "|    time_elapsed       | 629       |\n",
      "|    total_timesteps    | 371000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.64     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 84199     |\n",
      "|    policy_loss        | 20.6      |\n",
      "|    reward             | 4.5206857 |\n",
      "|    std                | 1.61      |\n",
      "|    value_loss         | 29.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 74300      |\n",
      "|    time_elapsed       | 630        |\n",
      "|    total_timesteps    | 371500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.66      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 84299      |\n",
      "|    policy_loss        | -5.35      |\n",
      "|    reward             | -1.0025887 |\n",
      "|    std                | 1.63       |\n",
      "|    value_loss         | 4.5        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 74400      |\n",
      "|    time_elapsed       | 630        |\n",
      "|    total_timesteps    | 372000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.66      |\n",
      "|    explained_variance | -4.51e-05  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 84399      |\n",
      "|    policy_loss        | -17.9      |\n",
      "|    reward             | 0.12679906 |\n",
      "|    std                | 1.63       |\n",
      "|    value_loss         | 11.6       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 74500      |\n",
      "|    time_elapsed       | 631        |\n",
      "|    total_timesteps    | 372500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.66      |\n",
      "|    explained_variance | 0.000225   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 84499      |\n",
      "|    policy_loss        | -0.262     |\n",
      "|    reward             | 0.09023015 |\n",
      "|    std                | 1.63       |\n",
      "|    value_loss         | 2.61       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 589      |\n",
      "|    iterations         | 74600    |\n",
      "|    time_elapsed       | 632      |\n",
      "|    total_timesteps    | 373000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.64    |\n",
      "|    explained_variance | 0.000616 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 84599    |\n",
      "|    policy_loss        | 1.82     |\n",
      "|    reward             | 4.087872 |\n",
      "|    std                | 1.62     |\n",
      "|    value_loss         | 1.02     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 74700     |\n",
      "|    time_elapsed       | 633       |\n",
      "|    total_timesteps    | 373500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.64     |\n",
      "|    explained_variance | 7.15e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 84699     |\n",
      "|    policy_loss        | 5.46      |\n",
      "|    reward             | 0.4700077 |\n",
      "|    std                | 1.62      |\n",
      "|    value_loss         | 1.41      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 74800     |\n",
      "|    time_elapsed       | 634       |\n",
      "|    total_timesteps    | 374000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.65     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 84799     |\n",
      "|    policy_loss        | 8.61      |\n",
      "|    reward             | 0.3630264 |\n",
      "|    std                | 1.63      |\n",
      "|    value_loss         | 3.42      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 74900      |\n",
      "|    time_elapsed       | 635        |\n",
      "|    total_timesteps    | 374500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.68      |\n",
      "|    explained_variance | -0.000132  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 84899      |\n",
      "|    policy_loss        | -2.26      |\n",
      "|    reward             | -1.2120439 |\n",
      "|    std                | 1.64       |\n",
      "|    value_loss         | 0.841      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 75000     |\n",
      "|    time_elapsed       | 635       |\n",
      "|    total_timesteps    | 375000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.68     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 84999     |\n",
      "|    policy_loss        | 7.95      |\n",
      "|    reward             | 0.8896982 |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 2.96      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 75100      |\n",
      "|    time_elapsed       | 636        |\n",
      "|    total_timesteps    | 375500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.67      |\n",
      "|    explained_variance | 0.000167   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 85099      |\n",
      "|    policy_loss        | 16.3       |\n",
      "|    reward             | -3.3842022 |\n",
      "|    std                | 1.64       |\n",
      "|    value_loss         | 23.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 75200     |\n",
      "|    time_elapsed       | 637       |\n",
      "|    total_timesteps    | 376000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.65     |\n",
      "|    explained_variance | -0.000984 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 85199     |\n",
      "|    policy_loss        | -18.3     |\n",
      "|    reward             | -12.53328 |\n",
      "|    std                | 1.63      |\n",
      "|    value_loss         | 21.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 75300      |\n",
      "|    time_elapsed       | 638        |\n",
      "|    total_timesteps    | 376500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.65      |\n",
      "|    explained_variance | 0.000914   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 85299      |\n",
      "|    policy_loss        | -20.2      |\n",
      "|    reward             | -0.7719736 |\n",
      "|    std                | 1.62       |\n",
      "|    value_loss         | 12.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 75400      |\n",
      "|    time_elapsed       | 639        |\n",
      "|    total_timesteps    | 377000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.64      |\n",
      "|    explained_variance | 0.000719   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 85399      |\n",
      "|    policy_loss        | 12.6       |\n",
      "|    reward             | -0.2738605 |\n",
      "|    std                | 1.62       |\n",
      "|    value_loss         | 6.71       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 75500     |\n",
      "|    time_elapsed       | 640       |\n",
      "|    total_timesteps    | 377500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.65     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 85499     |\n",
      "|    policy_loss        | -18.6     |\n",
      "|    reward             | 0.7238806 |\n",
      "|    std                | 1.62      |\n",
      "|    value_loss         | 19.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 75600     |\n",
      "|    time_elapsed       | 640       |\n",
      "|    total_timesteps    | 378000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.64     |\n",
      "|    explained_variance | -0.000248 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 85599     |\n",
      "|    policy_loss        | -6.65     |\n",
      "|    reward             | 1.3667188 |\n",
      "|    std                | 1.62      |\n",
      "|    value_loss         | 2.32      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 75700      |\n",
      "|    time_elapsed       | 641        |\n",
      "|    total_timesteps    | 378500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.65      |\n",
      "|    explained_variance | 0.000236   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 85699      |\n",
      "|    policy_loss        | 17.3       |\n",
      "|    reward             | 0.42911586 |\n",
      "|    std                | 1.62       |\n",
      "|    value_loss         | 9.01       |\n",
      "--------------------------------------\n",
      "day: 2892, episode: 150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4137860.42\n",
      "total_reward: 3137860.42\n",
      "total_cost: 19539.19\n",
      "total_trades: 6490\n",
      "Sharpe: 0.712\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 75800     |\n",
      "|    time_elapsed       | 642       |\n",
      "|    total_timesteps    | 379000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.66     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 85799     |\n",
      "|    policy_loss        | 2.13      |\n",
      "|    reward             | 0.3442245 |\n",
      "|    std                | 1.63      |\n",
      "|    value_loss         | 0.174     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 75900     |\n",
      "|    time_elapsed       | 643       |\n",
      "|    total_timesteps    | 379500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.66     |\n",
      "|    explained_variance | -0.00105  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 85899     |\n",
      "|    policy_loss        | -1.19     |\n",
      "|    reward             | -0.633491 |\n",
      "|    std                | 1.63      |\n",
      "|    value_loss         | 0.81      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 76000     |\n",
      "|    time_elapsed       | 644       |\n",
      "|    total_timesteps    | 380000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.65     |\n",
      "|    explained_variance | -0.000219 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 85999     |\n",
      "|    policy_loss        | -7.23     |\n",
      "|    reward             | 1.1471999 |\n",
      "|    std                | 1.63      |\n",
      "|    value_loss         | 3.78      |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 589          |\n",
      "|    iterations         | 76100        |\n",
      "|    time_elapsed       | 645          |\n",
      "|    total_timesteps    | 380500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.66        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 86099        |\n",
      "|    policy_loss        | -32.9        |\n",
      "|    reward             | -0.011241011 |\n",
      "|    std                | 1.63         |\n",
      "|    value_loss         | 34.9         |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 76200     |\n",
      "|    time_elapsed       | 645       |\n",
      "|    total_timesteps    | 381000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.65     |\n",
      "|    explained_variance | -3.95e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 86199     |\n",
      "|    policy_loss        | -7.79     |\n",
      "|    reward             | 1.5829738 |\n",
      "|    std                | 1.63      |\n",
      "|    value_loss         | 2.48      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 589      |\n",
      "|    iterations         | 76300    |\n",
      "|    time_elapsed       | 646      |\n",
      "|    total_timesteps    | 381500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.67    |\n",
      "|    explained_variance | 0.000142 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 86299    |\n",
      "|    policy_loss        | -18.2    |\n",
      "|    reward             | -8.46618 |\n",
      "|    std                | 1.64     |\n",
      "|    value_loss         | 97.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 589       |\n",
      "|    iterations         | 76400     |\n",
      "|    time_elapsed       | 647       |\n",
      "|    total_timesteps    | 382000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.64     |\n",
      "|    explained_variance | -12.3     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 86399     |\n",
      "|    policy_loss        | 8.46      |\n",
      "|    reward             | 0.5128258 |\n",
      "|    std                | 1.62      |\n",
      "|    value_loss         | 17.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 76500      |\n",
      "|    time_elapsed       | 648        |\n",
      "|    total_timesteps    | 382500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.63      |\n",
      "|    explained_variance | -0.00494   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 86499      |\n",
      "|    policy_loss        | 5.66       |\n",
      "|    reward             | -1.2914102 |\n",
      "|    std                | 1.62       |\n",
      "|    value_loss         | 1.58       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 76600      |\n",
      "|    time_elapsed       | 649        |\n",
      "|    total_timesteps    | 383000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.62      |\n",
      "|    explained_variance | -0.00165   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 86599      |\n",
      "|    policy_loss        | -19.6      |\n",
      "|    reward             | -1.7896446 |\n",
      "|    std                | 1.61       |\n",
      "|    value_loss         | 13.6       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 76700      |\n",
      "|    time_elapsed       | 650        |\n",
      "|    total_timesteps    | 383500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.64      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 86699      |\n",
      "|    policy_loss        | 11.4       |\n",
      "|    reward             | 0.52758807 |\n",
      "|    std                | 1.63       |\n",
      "|    value_loss         | 8.19       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 589         |\n",
      "|    iterations         | 76800       |\n",
      "|    time_elapsed       | 650         |\n",
      "|    total_timesteps    | 384000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.66       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 86799       |\n",
      "|    policy_loss        | 21.7        |\n",
      "|    reward             | -0.45775023 |\n",
      "|    std                | 1.63        |\n",
      "|    value_loss         | 17          |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 589      |\n",
      "|    iterations         | 76900    |\n",
      "|    time_elapsed       | 651      |\n",
      "|    total_timesteps    | 384500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.67    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 86899    |\n",
      "|    policy_loss        | -40.8    |\n",
      "|    reward             | 9.641897 |\n",
      "|    std                | 1.64     |\n",
      "|    value_loss         | 79.4     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 77000      |\n",
      "|    time_elapsed       | 652        |\n",
      "|    total_timesteps    | 385000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.67      |\n",
      "|    explained_variance | -0.0118    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 86999      |\n",
      "|    policy_loss        | -2.52      |\n",
      "|    reward             | -0.8589784 |\n",
      "|    std                | 1.64       |\n",
      "|    value_loss         | 0.824      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 589         |\n",
      "|    iterations         | 77100       |\n",
      "|    time_elapsed       | 653         |\n",
      "|    total_timesteps    | 385500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.67       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 87099       |\n",
      "|    policy_loss        | -19.3       |\n",
      "|    reward             | -0.91076046 |\n",
      "|    std                | 1.64        |\n",
      "|    value_loss         | 12.1        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 77200      |\n",
      "|    time_elapsed       | 654        |\n",
      "|    total_timesteps    | 386000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.66      |\n",
      "|    explained_variance | 0.0248     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 87199      |\n",
      "|    policy_loss        | 3.72       |\n",
      "|    reward             | 0.20876065 |\n",
      "|    std                | 1.64       |\n",
      "|    value_loss         | 1.51       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 589         |\n",
      "|    iterations         | 77300       |\n",
      "|    time_elapsed       | 655         |\n",
      "|    total_timesteps    | 386500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.66       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 87299       |\n",
      "|    policy_loss        | -24.8       |\n",
      "|    reward             | -0.98594534 |\n",
      "|    std                | 1.63        |\n",
      "|    value_loss         | 24.6        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 589        |\n",
      "|    iterations         | 77400      |\n",
      "|    time_elapsed       | 655        |\n",
      "|    total_timesteps    | 387000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.66      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 87399      |\n",
      "|    policy_loss        | -3.73      |\n",
      "|    reward             | -1.3826666 |\n",
      "|    std                | 1.63       |\n",
      "|    value_loss         | 1.37       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 77500      |\n",
      "|    time_elapsed       | 656        |\n",
      "|    total_timesteps    | 387500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.65      |\n",
      "|    explained_variance | 0.000335   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 87499      |\n",
      "|    policy_loss        | 4.64       |\n",
      "|    reward             | 0.98118174 |\n",
      "|    std                | 1.63       |\n",
      "|    value_loss         | 25         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 77600      |\n",
      "|    time_elapsed       | 657        |\n",
      "|    total_timesteps    | 388000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.67      |\n",
      "|    explained_variance | -0.000429  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 87599      |\n",
      "|    policy_loss        | -11.1      |\n",
      "|    reward             | -2.5589688 |\n",
      "|    std                | 1.64       |\n",
      "|    value_loss         | 3.79       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 77700     |\n",
      "|    time_elapsed       | 658       |\n",
      "|    total_timesteps    | 388500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.67     |\n",
      "|    explained_variance | 1.91e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 87699     |\n",
      "|    policy_loss        | -0.814    |\n",
      "|    reward             | 0.5301717 |\n",
      "|    std                | 1.64      |\n",
      "|    value_loss         | 4.68      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 590         |\n",
      "|    iterations         | 77800       |\n",
      "|    time_elapsed       | 659         |\n",
      "|    total_timesteps    | 389000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.66       |\n",
      "|    explained_variance | -0.351      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 87799       |\n",
      "|    policy_loss        | -4.66       |\n",
      "|    reward             | -0.23703814 |\n",
      "|    std                | 1.64        |\n",
      "|    value_loss         | 4.22        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 77900      |\n",
      "|    time_elapsed       | 659        |\n",
      "|    total_timesteps    | 389500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.65      |\n",
      "|    explained_variance | -0.156     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 87899      |\n",
      "|    policy_loss        | 19.4       |\n",
      "|    reward             | -14.286976 |\n",
      "|    std                | 1.63       |\n",
      "|    value_loss         | 14.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 78000      |\n",
      "|    time_elapsed       | 660        |\n",
      "|    total_timesteps    | 390000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.67      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 87999      |\n",
      "|    policy_loss        | 7.18       |\n",
      "|    reward             | -6.0803547 |\n",
      "|    std                | 1.64       |\n",
      "|    value_loss         | 22.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 78100     |\n",
      "|    time_elapsed       | 661       |\n",
      "|    total_timesteps    | 390500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.68     |\n",
      "|    explained_variance | -0.00218  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 88099     |\n",
      "|    policy_loss        | 198       |\n",
      "|    reward             | 30.272745 |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 1.44e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 78200      |\n",
      "|    time_elapsed       | 662        |\n",
      "|    total_timesteps    | 391000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.69      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 88199      |\n",
      "|    policy_loss        | -2.91      |\n",
      "|    reward             | 0.16054733 |\n",
      "|    std                | 1.65       |\n",
      "|    value_loss         | 0.4        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 590         |\n",
      "|    iterations         | 78300       |\n",
      "|    time_elapsed       | 663         |\n",
      "|    total_timesteps    | 391500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.69       |\n",
      "|    explained_variance | -0.0002     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 88299       |\n",
      "|    policy_loss        | -14.3       |\n",
      "|    reward             | -0.06962028 |\n",
      "|    std                | 1.65        |\n",
      "|    value_loss         | 7.67        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 590         |\n",
      "|    iterations         | 78400       |\n",
      "|    time_elapsed       | 664         |\n",
      "|    total_timesteps    | 392000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.69       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 88399       |\n",
      "|    policy_loss        | -13.3       |\n",
      "|    reward             | -0.10059004 |\n",
      "|    std                | 1.65        |\n",
      "|    value_loss         | 6.16        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 78500      |\n",
      "|    time_elapsed       | 665        |\n",
      "|    total_timesteps    | 392500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.68      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 88499      |\n",
      "|    policy_loss        | -0.066     |\n",
      "|    reward             | -1.7773725 |\n",
      "|    std                | 1.65       |\n",
      "|    value_loss         | 3.38       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 78600      |\n",
      "|    time_elapsed       | 665        |\n",
      "|    total_timesteps    | 393000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.67      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 88599      |\n",
      "|    policy_loss        | 38.9       |\n",
      "|    reward             | -3.1821878 |\n",
      "|    std                | 1.65       |\n",
      "|    value_loss         | 40.6       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 78700      |\n",
      "|    time_elapsed       | 666        |\n",
      "|    total_timesteps    | 393500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.68      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 88699      |\n",
      "|    policy_loss        | 5.53       |\n",
      "|    reward             | 0.24432927 |\n",
      "|    std                | 1.65       |\n",
      "|    value_loss         | 1.41       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 78800     |\n",
      "|    time_elapsed       | 667       |\n",
      "|    total_timesteps    | 394000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.7      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 88799     |\n",
      "|    policy_loss        | -12       |\n",
      "|    reward             | -0.656841 |\n",
      "|    std                | 1.67      |\n",
      "|    value_loss         | 6.14      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 78900      |\n",
      "|    time_elapsed       | 668        |\n",
      "|    total_timesteps    | 394500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.71      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 88899      |\n",
      "|    policy_loss        | 25.2       |\n",
      "|    reward             | -0.4462751 |\n",
      "|    std                | 1.67       |\n",
      "|    value_loss         | 14.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 79000     |\n",
      "|    time_elapsed       | 669       |\n",
      "|    total_timesteps    | 395000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.73     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 88999     |\n",
      "|    policy_loss        | -12.2     |\n",
      "|    reward             | 1.3374    |\n",
      "|    std                | 1.69      |\n",
      "|    value_loss         | 4.72      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 590         |\n",
      "|    iterations         | 79100       |\n",
      "|    time_elapsed       | 669         |\n",
      "|    total_timesteps    | 395500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.72       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 89099       |\n",
      "|    policy_loss        | -4.37       |\n",
      "|    reward             | -0.18599574 |\n",
      "|    std                | 1.68        |\n",
      "|    value_loss         | 1.05        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 79200     |\n",
      "|    time_elapsed       | 670       |\n",
      "|    total_timesteps    | 396000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.72     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 89199     |\n",
      "|    policy_loss        | 30.1      |\n",
      "|    reward             | 1.5296693 |\n",
      "|    std                | 1.67      |\n",
      "|    value_loss         | 36.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 590      |\n",
      "|    iterations         | 79300    |\n",
      "|    time_elapsed       | 671      |\n",
      "|    total_timesteps    | 396500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.71    |\n",
      "|    explained_variance | 0.0307   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 89299    |\n",
      "|    policy_loss        | 3.54     |\n",
      "|    reward             | 0.322759 |\n",
      "|    std                | 1.67     |\n",
      "|    value_loss         | 0.854    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 79400     |\n",
      "|    time_elapsed       | 672       |\n",
      "|    total_timesteps    | 397000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.7      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 89399     |\n",
      "|    policy_loss        | -54.9     |\n",
      "|    reward             | 3.9081326 |\n",
      "|    std                | 1.66      |\n",
      "|    value_loss         | 118       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 79500     |\n",
      "|    time_elapsed       | 673       |\n",
      "|    total_timesteps    | 397500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.7      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 89499     |\n",
      "|    policy_loss        | -3.68     |\n",
      "|    reward             | 1.2043847 |\n",
      "|    std                | 1.66      |\n",
      "|    value_loss         | 0.581     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 79600      |\n",
      "|    time_elapsed       | 674        |\n",
      "|    total_timesteps    | 398000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.68      |\n",
      "|    explained_variance | 6.53e-05   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 89599      |\n",
      "|    policy_loss        | 7.13       |\n",
      "|    reward             | -1.5898976 |\n",
      "|    std                | 1.65       |\n",
      "|    value_loss         | 4.13       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 79700      |\n",
      "|    time_elapsed       | 674        |\n",
      "|    total_timesteps    | 398500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.71      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 89699      |\n",
      "|    policy_loss        | -12        |\n",
      "|    reward             | 0.47006217 |\n",
      "|    std                | 1.66       |\n",
      "|    value_loss         | 11.9       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 590         |\n",
      "|    iterations         | 79800       |\n",
      "|    time_elapsed       | 675         |\n",
      "|    total_timesteps    | 399000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.72       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 89799       |\n",
      "|    policy_loss        | 30          |\n",
      "|    reward             | -0.93134224 |\n",
      "|    std                | 1.67        |\n",
      "|    value_loss         | 41          |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 79900     |\n",
      "|    time_elapsed       | 676       |\n",
      "|    total_timesteps    | 399500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.7      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 89899     |\n",
      "|    policy_loss        | 5.09      |\n",
      "|    reward             | 0.8466609 |\n",
      "|    std                | 1.66      |\n",
      "|    value_loss         | 1.52      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 80000      |\n",
      "|    time_elapsed       | 677        |\n",
      "|    total_timesteps    | 400000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.71      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 89999      |\n",
      "|    policy_loss        | -15.9      |\n",
      "|    reward             | 0.93466276 |\n",
      "|    std                | 1.66       |\n",
      "|    value_loss         | 9.69       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 80100     |\n",
      "|    time_elapsed       | 678       |\n",
      "|    total_timesteps    | 400500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.7      |\n",
      "|    explained_variance | 5.87e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 90099     |\n",
      "|    policy_loss        | 11.3      |\n",
      "|    reward             | 2.3918576 |\n",
      "|    std                | 1.66      |\n",
      "|    value_loss         | 4.81      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 80200      |\n",
      "|    time_elapsed       | 679        |\n",
      "|    total_timesteps    | 401000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.7       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 90199      |\n",
      "|    policy_loss        | -11.5      |\n",
      "|    reward             | -1.0243162 |\n",
      "|    std                | 1.65       |\n",
      "|    value_loss         | 5.07       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 80300     |\n",
      "|    time_elapsed       | 680       |\n",
      "|    total_timesteps    | 401500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.69     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 90299     |\n",
      "|    policy_loss        | -3.64     |\n",
      "|    reward             | 4.9429827 |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 1.75      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 80400      |\n",
      "|    time_elapsed       | 680        |\n",
      "|    total_timesteps    | 402000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.67      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 90399      |\n",
      "|    policy_loss        | 20.6       |\n",
      "|    reward             | -4.3720274 |\n",
      "|    std                | 1.64       |\n",
      "|    value_loss         | 11.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 80500     |\n",
      "|    time_elapsed       | 681       |\n",
      "|    total_timesteps    | 402500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.68     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 90499     |\n",
      "|    policy_loss        | -0.885    |\n",
      "|    reward             | 1.3063031 |\n",
      "|    std                | 1.64      |\n",
      "|    value_loss         | 0.799     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 80600      |\n",
      "|    time_elapsed       | 682        |\n",
      "|    total_timesteps    | 403000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.68      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 90599      |\n",
      "|    policy_loss        | -8.1       |\n",
      "|    reward             | 0.11741416 |\n",
      "|    std                | 1.64       |\n",
      "|    value_loss         | 3.29       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 80700     |\n",
      "|    time_elapsed       | 683       |\n",
      "|    total_timesteps    | 403500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.69     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 90699     |\n",
      "|    policy_loss        | -23.2     |\n",
      "|    reward             | 1.1589998 |\n",
      "|    std                | 1.64      |\n",
      "|    value_loss         | 13.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 80800      |\n",
      "|    time_elapsed       | 684        |\n",
      "|    total_timesteps    | 404000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.68      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 90799      |\n",
      "|    policy_loss        | -6.7       |\n",
      "|    reward             | -2.6437268 |\n",
      "|    std                | 1.64       |\n",
      "|    value_loss         | 2.16       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 80900      |\n",
      "|    time_elapsed       | 685        |\n",
      "|    total_timesteps    | 404500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.67      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 90899      |\n",
      "|    policy_loss        | -11.5      |\n",
      "|    reward             | -1.3477421 |\n",
      "|    std                | 1.64       |\n",
      "|    value_loss         | 6.13       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 81000     |\n",
      "|    time_elapsed       | 685       |\n",
      "|    total_timesteps    | 405000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.69     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 90999     |\n",
      "|    policy_loss        | 19        |\n",
      "|    reward             | 4.0244493 |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 16.8      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 590         |\n",
      "|    iterations         | 81100       |\n",
      "|    time_elapsed       | 686         |\n",
      "|    total_timesteps    | 405500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.69       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 91099       |\n",
      "|    policy_loss        | 5.37        |\n",
      "|    reward             | -0.76636297 |\n",
      "|    std                | 1.65        |\n",
      "|    value_loss         | 1.73        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 81200     |\n",
      "|    time_elapsed       | 687       |\n",
      "|    total_timesteps    | 406000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.69     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 91199     |\n",
      "|    policy_loss        | -21.8     |\n",
      "|    reward             | 3.5910845 |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 21.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 81300      |\n",
      "|    time_elapsed       | 688        |\n",
      "|    total_timesteps    | 406500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.69      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 91299      |\n",
      "|    policy_loss        | 10.4       |\n",
      "|    reward             | -2.5206554 |\n",
      "|    std                | 1.64       |\n",
      "|    value_loss         | 3.51       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 81400     |\n",
      "|    time_elapsed       | 689       |\n",
      "|    total_timesteps    | 407000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.71     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 91399     |\n",
      "|    policy_loss        | -12.5     |\n",
      "|    reward             | 1.4126698 |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 4.36      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 81500     |\n",
      "|    time_elapsed       | 689       |\n",
      "|    total_timesteps    | 407500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.71     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 91499     |\n",
      "|    policy_loss        | -26.4     |\n",
      "|    reward             | 7.4636073 |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 70.3      |\n",
      "-------------------------------------\n",
      "day: 2892, episode: 160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4147273.16\n",
      "total_reward: 3147273.16\n",
      "total_cost: 1027.91\n",
      "total_trades: 5910\n",
      "Sharpe: 0.712\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 590         |\n",
      "|    iterations         | 81600       |\n",
      "|    time_elapsed       | 690         |\n",
      "|    total_timesteps    | 408000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.7        |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 91599       |\n",
      "|    policy_loss        | 5.9         |\n",
      "|    reward             | -0.47622964 |\n",
      "|    std                | 1.65        |\n",
      "|    value_loss         | 1.36        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 590        |\n",
      "|    iterations         | 81700      |\n",
      "|    time_elapsed       | 691        |\n",
      "|    total_timesteps    | 408500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.72      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 91699      |\n",
      "|    policy_loss        | 11.8       |\n",
      "|    reward             | 0.76030207 |\n",
      "|    std                | 1.66       |\n",
      "|    value_loss         | 5.36       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 81800     |\n",
      "|    time_elapsed       | 692       |\n",
      "|    total_timesteps    | 409000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.72     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 91799     |\n",
      "|    policy_loss        | -33.9     |\n",
      "|    reward             | 3.4656975 |\n",
      "|    std                | 1.66      |\n",
      "|    value_loss         | 119       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 590      |\n",
      "|    iterations         | 81900    |\n",
      "|    time_elapsed       | 693      |\n",
      "|    total_timesteps    | 409500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.71    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 91899    |\n",
      "|    policy_loss        | -18.3    |\n",
      "|    reward             | 5.33252  |\n",
      "|    std                | 1.65     |\n",
      "|    value_loss         | 8.32     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 82000     |\n",
      "|    time_elapsed       | 693       |\n",
      "|    total_timesteps    | 410000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.7      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 91999     |\n",
      "|    policy_loss        | -14.2     |\n",
      "|    reward             | -8.403894 |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 8.21      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 590         |\n",
      "|    iterations         | 82100       |\n",
      "|    time_elapsed       | 694         |\n",
      "|    total_timesteps    | 410500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.7        |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 92099       |\n",
      "|    policy_loss        | 1.96        |\n",
      "|    reward             | -0.32002845 |\n",
      "|    std                | 1.65        |\n",
      "|    value_loss         | 0.601       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 590       |\n",
      "|    iterations         | 82200     |\n",
      "|    time_elapsed       | 695       |\n",
      "|    total_timesteps    | 411000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.7      |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 92199     |\n",
      "|    policy_loss        | -9.13     |\n",
      "|    reward             | 2.7977085 |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 3.41      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 590      |\n",
      "|    iterations         | 82300    |\n",
      "|    time_elapsed       | 696      |\n",
      "|    total_timesteps    | 411500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.69    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 92299    |\n",
      "|    policy_loss        | 21.8     |\n",
      "|    reward             | 2.118794 |\n",
      "|    std                | 1.64     |\n",
      "|    value_loss         | 25.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 82400     |\n",
      "|    time_elapsed       | 697       |\n",
      "|    total_timesteps    | 412000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.69     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 92399     |\n",
      "|    policy_loss        | -18.5     |\n",
      "|    reward             | 1.3927205 |\n",
      "|    std                | 1.64      |\n",
      "|    value_loss         | 12.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 82500     |\n",
      "|    time_elapsed       | 697       |\n",
      "|    total_timesteps    | 412500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.7      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 92499     |\n",
      "|    policy_loss        | -18.6     |\n",
      "|    reward             | 0.9559394 |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 13.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 82600     |\n",
      "|    time_elapsed       | 698       |\n",
      "|    total_timesteps    | 413000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.69     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 92599     |\n",
      "|    policy_loss        | 14.5      |\n",
      "|    reward             | 0.7986704 |\n",
      "|    std                | 1.64      |\n",
      "|    value_loss         | 10.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 82700     |\n",
      "|    time_elapsed       | 699       |\n",
      "|    total_timesteps    | 413500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.7      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 92699     |\n",
      "|    policy_loss        | 15.5      |\n",
      "|    reward             | 1.1497368 |\n",
      "|    std                | 1.65      |\n",
      "|    value_loss         | 33.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 82800     |\n",
      "|    time_elapsed       | 700       |\n",
      "|    total_timesteps    | 414000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.69     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 92799     |\n",
      "|    policy_loss        | -8.23     |\n",
      "|    reward             | 0.7696554 |\n",
      "|    std                | 1.64      |\n",
      "|    value_loss         | 1.84      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 591      |\n",
      "|    iterations         | 82900    |\n",
      "|    time_elapsed       | 701      |\n",
      "|    total_timesteps    | 414500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.68    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 92899    |\n",
      "|    policy_loss        | 2.09     |\n",
      "|    reward             | 1.911599 |\n",
      "|    std                | 1.64     |\n",
      "|    value_loss         | 0.344    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 591      |\n",
      "|    iterations         | 83000    |\n",
      "|    time_elapsed       | 701      |\n",
      "|    total_timesteps    | 415000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.7     |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 92999    |\n",
      "|    policy_loss        | 6.99     |\n",
      "|    reward             | 0.48543  |\n",
      "|    std                | 1.65     |\n",
      "|    value_loss         | 1.83     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 83100     |\n",
      "|    time_elapsed       | 702       |\n",
      "|    total_timesteps    | 415500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.71     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 93099     |\n",
      "|    policy_loss        | 6.28      |\n",
      "|    reward             | 5.2738347 |\n",
      "|    std                | 1.66      |\n",
      "|    value_loss         | 20        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 83200     |\n",
      "|    time_elapsed       | 703       |\n",
      "|    total_timesteps    | 416000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.72     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 93199     |\n",
      "|    policy_loss        | 55.2      |\n",
      "|    reward             | 5.5312533 |\n",
      "|    std                | 1.66      |\n",
      "|    value_loss         | 136       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 83300      |\n",
      "|    time_elapsed       | 704        |\n",
      "|    total_timesteps    | 416500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.71      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 93299      |\n",
      "|    policy_loss        | 7.84       |\n",
      "|    reward             | -3.7376945 |\n",
      "|    std                | 1.66       |\n",
      "|    value_loss         | 17.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 83400      |\n",
      "|    time_elapsed       | 705        |\n",
      "|    total_timesteps    | 417000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.73      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 93399      |\n",
      "|    policy_loss        | -1.12      |\n",
      "|    reward             | 0.93588674 |\n",
      "|    std                | 1.67       |\n",
      "|    value_loss         | 0.264      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 591         |\n",
      "|    iterations         | 83500       |\n",
      "|    time_elapsed       | 706         |\n",
      "|    total_timesteps    | 417500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.71       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 93499       |\n",
      "|    policy_loss        | -8.76       |\n",
      "|    reward             | -0.11029927 |\n",
      "|    std                | 1.66        |\n",
      "|    value_loss         | 4.5         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 591         |\n",
      "|    iterations         | 83600       |\n",
      "|    time_elapsed       | 707         |\n",
      "|    total_timesteps    | 418000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.72       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 93599       |\n",
      "|    policy_loss        | -26.8       |\n",
      "|    reward             | -0.09525273 |\n",
      "|    std                | 1.67        |\n",
      "|    value_loss         | 22.6        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 83700      |\n",
      "|    time_elapsed       | 707        |\n",
      "|    total_timesteps    | 418500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.73      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 93699      |\n",
      "|    policy_loss        | 16.1       |\n",
      "|    reward             | -0.6333179 |\n",
      "|    std                | 1.67       |\n",
      "|    value_loss         | 23.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 83800      |\n",
      "|    time_elapsed       | 708        |\n",
      "|    total_timesteps    | 419000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.73      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 93799      |\n",
      "|    policy_loss        | 15.9       |\n",
      "|    reward             | -6.3131976 |\n",
      "|    std                | 1.67       |\n",
      "|    value_loss         | 9.22       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 83900      |\n",
      "|    time_elapsed       | 709        |\n",
      "|    total_timesteps    | 419500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.71      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 93899      |\n",
      "|    policy_loss        | -0.686     |\n",
      "|    reward             | 0.22477162 |\n",
      "|    std                | 1.66       |\n",
      "|    value_loss         | 0.0283     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 84000     |\n",
      "|    time_elapsed       | 710       |\n",
      "|    total_timesteps    | 420000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.72     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 93999     |\n",
      "|    policy_loss        | -7.51     |\n",
      "|    reward             | 2.7717013 |\n",
      "|    std                | 1.66      |\n",
      "|    value_loss         | 2.26      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 84100     |\n",
      "|    time_elapsed       | 710       |\n",
      "|    total_timesteps    | 420500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.73     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 94099     |\n",
      "|    policy_loss        | -14.1     |\n",
      "|    reward             | 0.6227473 |\n",
      "|    std                | 1.67      |\n",
      "|    value_loss         | 7.98      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 591         |\n",
      "|    iterations         | 84200       |\n",
      "|    time_elapsed       | 711         |\n",
      "|    total_timesteps    | 421000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.73       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 94199       |\n",
      "|    policy_loss        | -7.2        |\n",
      "|    reward             | -0.49886927 |\n",
      "|    std                | 1.67        |\n",
      "|    value_loss         | 5.99        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 84300      |\n",
      "|    time_elapsed       | 712        |\n",
      "|    total_timesteps    | 421500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.73      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 94299      |\n",
      "|    policy_loss        | -5.15      |\n",
      "|    reward             | 0.71877015 |\n",
      "|    std                | 1.67       |\n",
      "|    value_loss         | 1.24       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 84400     |\n",
      "|    time_elapsed       | 713       |\n",
      "|    total_timesteps    | 422000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.73     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 94399     |\n",
      "|    policy_loss        | -103      |\n",
      "|    reward             | 3.5867882 |\n",
      "|    std                | 1.67      |\n",
      "|    value_loss         | 369       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 84500      |\n",
      "|    time_elapsed       | 714        |\n",
      "|    total_timesteps    | 422500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.75      |\n",
      "|    explained_variance | 0.651      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 94499      |\n",
      "|    policy_loss        | -9.33      |\n",
      "|    reward             | 0.56031775 |\n",
      "|    std                | 1.68       |\n",
      "|    value_loss         | 3.02       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 591         |\n",
      "|    iterations         | 84600       |\n",
      "|    time_elapsed       | 715         |\n",
      "|    total_timesteps    | 423000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.73       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 94599       |\n",
      "|    policy_loss        | -11         |\n",
      "|    reward             | -0.56220585 |\n",
      "|    std                | 1.67        |\n",
      "|    value_loss         | 4.38        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 84700      |\n",
      "|    time_elapsed       | 715        |\n",
      "|    total_timesteps    | 423500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.74      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 94699      |\n",
      "|    policy_loss        | -16.1      |\n",
      "|    reward             | -2.7920992 |\n",
      "|    std                | 1.67       |\n",
      "|    value_loss         | 10.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 84800      |\n",
      "|    time_elapsed       | 716        |\n",
      "|    total_timesteps    | 424000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.73      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 94799      |\n",
      "|    policy_loss        | -28.8      |\n",
      "|    reward             | -1.5733061 |\n",
      "|    std                | 1.67       |\n",
      "|    value_loss         | 29.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 84900      |\n",
      "|    time_elapsed       | 717        |\n",
      "|    total_timesteps    | 424500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.73      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 94899      |\n",
      "|    policy_loss        | 4.2        |\n",
      "|    reward             | -0.1291947 |\n",
      "|    std                | 1.67       |\n",
      "|    value_loss         | 1.18       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 85000     |\n",
      "|    time_elapsed       | 718       |\n",
      "|    total_timesteps    | 425000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.75     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 94999     |\n",
      "|    policy_loss        | -49.4     |\n",
      "|    reward             | 5.2149057 |\n",
      "|    std                | 1.68      |\n",
      "|    value_loss         | 69.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 85100      |\n",
      "|    time_elapsed       | 718        |\n",
      "|    total_timesteps    | 425500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.75      |\n",
      "|    explained_variance | -0.35      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 95099      |\n",
      "|    policy_loss        | -7.94      |\n",
      "|    reward             | 0.74604887 |\n",
      "|    std                | 1.68       |\n",
      "|    value_loss         | 2.26       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 85200      |\n",
      "|    time_elapsed       | 719        |\n",
      "|    total_timesteps    | 426000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.76      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 95199      |\n",
      "|    policy_loss        | 12.9       |\n",
      "|    reward             | -0.4733933 |\n",
      "|    std                | 1.69       |\n",
      "|    value_loss         | 9.65       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 85300      |\n",
      "|    time_elapsed       | 720        |\n",
      "|    total_timesteps    | 426500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.76      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 95299      |\n",
      "|    policy_loss        | 9.92       |\n",
      "|    reward             | 0.26505348 |\n",
      "|    std                | 1.69       |\n",
      "|    value_loss         | 5.95       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 85400      |\n",
      "|    time_elapsed       | 721        |\n",
      "|    total_timesteps    | 427000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.76      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 95399      |\n",
      "|    policy_loss        | 4.03       |\n",
      "|    reward             | -1.9045514 |\n",
      "|    std                | 1.69       |\n",
      "|    value_loss         | 2.8        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 85500      |\n",
      "|    time_elapsed       | 722        |\n",
      "|    total_timesteps    | 427500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.78      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 95499      |\n",
      "|    policy_loss        | 13         |\n",
      "|    reward             | 0.74573874 |\n",
      "|    std                | 1.7        |\n",
      "|    value_loss         | 28.9       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 591         |\n",
      "|    iterations         | 85600       |\n",
      "|    time_elapsed       | 723         |\n",
      "|    total_timesteps    | 428000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.78       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 95599       |\n",
      "|    policy_loss        | 35.7        |\n",
      "|    reward             | 0.027207954 |\n",
      "|    std                | 1.7         |\n",
      "|    value_loss         | 58.3        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 591        |\n",
      "|    iterations         | 85700      |\n",
      "|    time_elapsed       | 723        |\n",
      "|    total_timesteps    | 428500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.81      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 95699      |\n",
      "|    policy_loss        | -0.825     |\n",
      "|    reward             | -0.8333705 |\n",
      "|    std                | 1.72       |\n",
      "|    value_loss         | 0.488      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 85800     |\n",
      "|    time_elapsed       | 724       |\n",
      "|    total_timesteps    | 429000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.82     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 95799     |\n",
      "|    policy_loss        | -7.59     |\n",
      "|    reward             | 0.8542322 |\n",
      "|    std                | 1.72      |\n",
      "|    value_loss         | 8.32      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 591         |\n",
      "|    iterations         | 85900       |\n",
      "|    time_elapsed       | 725         |\n",
      "|    total_timesteps    | 429500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.84       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 95899       |\n",
      "|    policy_loss        | -32.8       |\n",
      "|    reward             | -0.44040465 |\n",
      "|    std                | 1.73        |\n",
      "|    value_loss         | 28.7        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 86000      |\n",
      "|    time_elapsed       | 726        |\n",
      "|    total_timesteps    | 430000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.84      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 95999      |\n",
      "|    policy_loss        | 13.5       |\n",
      "|    reward             | 0.84938025 |\n",
      "|    std                | 1.73       |\n",
      "|    value_loss         | 5.96       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 86100     |\n",
      "|    time_elapsed       | 727       |\n",
      "|    total_timesteps    | 430500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.83     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 96099     |\n",
      "|    policy_loss        | 3.69      |\n",
      "|    reward             | 2.6773016 |\n",
      "|    std                | 1.73      |\n",
      "|    value_loss         | 15.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 86200     |\n",
      "|    time_elapsed       | 727       |\n",
      "|    total_timesteps    | 431000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.81     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 96199     |\n",
      "|    policy_loss        | -4.6      |\n",
      "|    reward             | 2.4074225 |\n",
      "|    std                | 1.71      |\n",
      "|    value_loss         | 70.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 86300      |\n",
      "|    time_elapsed       | 728        |\n",
      "|    total_timesteps    | 431500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.81      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 96299      |\n",
      "|    policy_loss        | 4.86       |\n",
      "|    reward             | 0.24075511 |\n",
      "|    std                | 1.71       |\n",
      "|    value_loss         | 1.73       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 86400     |\n",
      "|    time_elapsed       | 729       |\n",
      "|    total_timesteps    | 432000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.81     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 96399     |\n",
      "|    policy_loss        | -7        |\n",
      "|    reward             | 0.7744433 |\n",
      "|    std                | 1.71      |\n",
      "|    value_loss         | 1.43      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 86500     |\n",
      "|    time_elapsed       | 730       |\n",
      "|    total_timesteps    | 432500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.81     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 96499     |\n",
      "|    policy_loss        | 13.6      |\n",
      "|    reward             | 1.4044042 |\n",
      "|    std                | 1.72      |\n",
      "|    value_loss         | 4.62      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 86600     |\n",
      "|    time_elapsed       | 731       |\n",
      "|    total_timesteps    | 433000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.8      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 96599     |\n",
      "|    policy_loss        | -27.8     |\n",
      "|    reward             | 2.3374538 |\n",
      "|    std                | 1.71      |\n",
      "|    value_loss         | 34.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 86700      |\n",
      "|    time_elapsed       | 731        |\n",
      "|    total_timesteps    | 433500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.8       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 96699      |\n",
      "|    policy_loss        | -8.18      |\n",
      "|    reward             | -2.1927085 |\n",
      "|    std                | 1.71       |\n",
      "|    value_loss         | 10.7       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 86800     |\n",
      "|    time_elapsed       | 732       |\n",
      "|    total_timesteps    | 434000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.83     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 96799     |\n",
      "|    policy_loss        | 1.49      |\n",
      "|    reward             | 0.7420296 |\n",
      "|    std                | 1.73      |\n",
      "|    value_loss         | 0.553     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 86900      |\n",
      "|    time_elapsed       | 733        |\n",
      "|    total_timesteps    | 434500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.82      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 96899      |\n",
      "|    policy_loss        | 9.27       |\n",
      "|    reward             | -3.7178025 |\n",
      "|    std                | 1.72       |\n",
      "|    value_loss         | 2.88       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 87000      |\n",
      "|    time_elapsed       | 734        |\n",
      "|    total_timesteps    | 435000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.81      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 96999      |\n",
      "|    policy_loss        | 4.59       |\n",
      "|    reward             | 0.94130415 |\n",
      "|    std                | 1.72       |\n",
      "|    value_loss         | 3.41       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 87100       |\n",
      "|    time_elapsed       | 735         |\n",
      "|    total_timesteps    | 435500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.84       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 97099       |\n",
      "|    policy_loss        | 12.9        |\n",
      "|    reward             | -0.31768137 |\n",
      "|    std                | 1.73        |\n",
      "|    value_loss         | 4.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 87200       |\n",
      "|    time_elapsed       | 735         |\n",
      "|    total_timesteps    | 436000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.82       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 97199       |\n",
      "|    policy_loss        | 10.1        |\n",
      "|    reward             | -0.28670883 |\n",
      "|    std                | 1.72        |\n",
      "|    value_loss         | 6.96        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 592      |\n",
      "|    iterations         | 87300    |\n",
      "|    time_elapsed       | 736      |\n",
      "|    total_timesteps    | 436500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.82    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 97299    |\n",
      "|    policy_loss        | 25.2     |\n",
      "|    reward             | 3.053184 |\n",
      "|    std                | 1.72     |\n",
      "|    value_loss         | 21.5     |\n",
      "------------------------------------\n",
      "day: 2892, episode: 170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4277834.30\n",
      "total_reward: 3277834.30\n",
      "total_cost: 1308.13\n",
      "total_trades: 7881\n",
      "Sharpe: 0.726\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 87400     |\n",
      "|    time_elapsed       | 737       |\n",
      "|    total_timesteps    | 437000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.83     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 97399     |\n",
      "|    policy_loss        | -9.74     |\n",
      "|    reward             | 1.1544496 |\n",
      "|    std                | 1.73      |\n",
      "|    value_loss         | 2.74      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 592      |\n",
      "|    iterations         | 87500    |\n",
      "|    time_elapsed       | 738      |\n",
      "|    total_timesteps    | 437500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.82    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 97499    |\n",
      "|    policy_loss        | -47.7    |\n",
      "|    reward             | 4.62954  |\n",
      "|    std                | 1.72     |\n",
      "|    value_loss         | 84.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 87600     |\n",
      "|    time_elapsed       | 739       |\n",
      "|    total_timesteps    | 438000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.83     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 97599     |\n",
      "|    policy_loss        | -5.24     |\n",
      "|    reward             | 0.4762628 |\n",
      "|    std                | 1.73      |\n",
      "|    value_loss         | 1.43      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 87700       |\n",
      "|    time_elapsed       | 740         |\n",
      "|    total_timesteps    | 438500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.86       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 97699       |\n",
      "|    policy_loss        | -9.36       |\n",
      "|    reward             | -0.06330743 |\n",
      "|    std                | 1.74        |\n",
      "|    value_loss         | 9.2         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 87800      |\n",
      "|    time_elapsed       | 740        |\n",
      "|    total_timesteps    | 439000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.85      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 97799      |\n",
      "|    policy_loss        | -22.8      |\n",
      "|    reward             | -0.9188203 |\n",
      "|    std                | 1.74       |\n",
      "|    value_loss         | 22.8       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 87900       |\n",
      "|    time_elapsed       | 741         |\n",
      "|    total_timesteps    | 439500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.87       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 97899       |\n",
      "|    policy_loss        | 28          |\n",
      "|    reward             | -0.34633604 |\n",
      "|    std                | 1.75        |\n",
      "|    value_loss         | 24.8        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 88000     |\n",
      "|    time_elapsed       | 742       |\n",
      "|    total_timesteps    | 440000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.88     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 97999     |\n",
      "|    policy_loss        | -2.63     |\n",
      "|    reward             | -1.654096 |\n",
      "|    std                | 1.75      |\n",
      "|    value_loss         | 0.639     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 88100       |\n",
      "|    time_elapsed       | 743         |\n",
      "|    total_timesteps    | 440500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.88       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 98099       |\n",
      "|    policy_loss        | -6.27       |\n",
      "|    reward             | -0.87207454 |\n",
      "|    std                | 1.76        |\n",
      "|    value_loss         | 2.52        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 88200     |\n",
      "|    time_elapsed       | 743       |\n",
      "|    total_timesteps    | 441000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.87     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 98199     |\n",
      "|    policy_loss        | -2.49     |\n",
      "|    reward             | 0.5054795 |\n",
      "|    std                | 1.75      |\n",
      "|    value_loss         | 0.777     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 88300      |\n",
      "|    time_elapsed       | 744        |\n",
      "|    total_timesteps    | 441500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.86      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 98299      |\n",
      "|    policy_loss        | 18         |\n",
      "|    reward             | -1.8562007 |\n",
      "|    std                | 1.74       |\n",
      "|    value_loss         | 9.65       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 88400      |\n",
      "|    time_elapsed       | 745        |\n",
      "|    total_timesteps    | 442000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.85      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 98399      |\n",
      "|    policy_loss        | -15.9      |\n",
      "|    reward             | -0.8631059 |\n",
      "|    std                | 1.74       |\n",
      "|    value_loss         | 7.1        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 88500     |\n",
      "|    time_elapsed       | 746       |\n",
      "|    total_timesteps    | 442500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.85     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 98499     |\n",
      "|    policy_loss        | 0.838     |\n",
      "|    reward             | 1.4074895 |\n",
      "|    std                | 1.73      |\n",
      "|    value_loss         | 2.41      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 88600      |\n",
      "|    time_elapsed       | 747        |\n",
      "|    total_timesteps    | 443000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.85      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 98599      |\n",
      "|    policy_loss        | 8.87       |\n",
      "|    reward             | -1.9102888 |\n",
      "|    std                | 1.74       |\n",
      "|    value_loss         | 4.47       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 88700       |\n",
      "|    time_elapsed       | 748         |\n",
      "|    total_timesteps    | 443500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.84       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 98699       |\n",
      "|    policy_loss        | -2.74       |\n",
      "|    reward             | -0.88509077 |\n",
      "|    std                | 1.73        |\n",
      "|    value_loss         | 7.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 88800       |\n",
      "|    time_elapsed       | 749         |\n",
      "|    total_timesteps    | 444000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.85       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 98799       |\n",
      "|    policy_loss        | 4.32        |\n",
      "|    reward             | 0.083741836 |\n",
      "|    std                | 1.74        |\n",
      "|    value_loss         | 1.81        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 88900     |\n",
      "|    time_elapsed       | 749       |\n",
      "|    total_timesteps    | 444500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.86     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 98899     |\n",
      "|    policy_loss        | 2.17      |\n",
      "|    reward             | -1.011821 |\n",
      "|    std                | 1.74      |\n",
      "|    value_loss         | 0.938     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 89000     |\n",
      "|    time_elapsed       | 750       |\n",
      "|    total_timesteps    | 445000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.88     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 98999     |\n",
      "|    policy_loss        | -22.1     |\n",
      "|    reward             | 1.2706994 |\n",
      "|    std                | 1.76      |\n",
      "|    value_loss         | 16.6      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 89100       |\n",
      "|    time_elapsed       | 751         |\n",
      "|    total_timesteps    | 445500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.87       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99099       |\n",
      "|    policy_loss        | -15.3       |\n",
      "|    reward             | -0.47270775 |\n",
      "|    std                | 1.75        |\n",
      "|    value_loss         | 15.2        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 89200     |\n",
      "|    time_elapsed       | 752       |\n",
      "|    total_timesteps    | 446000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.87     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99199     |\n",
      "|    policy_loss        | -19.5     |\n",
      "|    reward             | 2.4491832 |\n",
      "|    std                | 1.75      |\n",
      "|    value_loss         | 13        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 89300      |\n",
      "|    time_elapsed       | 753        |\n",
      "|    total_timesteps    | 446500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.88      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99299      |\n",
      "|    policy_loss        | -26.6      |\n",
      "|    reward             | -1.0112013 |\n",
      "|    std                | 1.76       |\n",
      "|    value_loss         | 24.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 89400     |\n",
      "|    time_elapsed       | 754       |\n",
      "|    total_timesteps    | 447000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.87     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99399     |\n",
      "|    policy_loss        | 4.86      |\n",
      "|    reward             | 1.1973711 |\n",
      "|    std                | 1.75      |\n",
      "|    value_loss         | 1.13      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 89500     |\n",
      "|    time_elapsed       | 755       |\n",
      "|    total_timesteps    | 447500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.88     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99499     |\n",
      "|    policy_loss        | -11.9     |\n",
      "|    reward             | -0.720429 |\n",
      "|    std                | 1.75      |\n",
      "|    value_loss         | 4.37      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 592      |\n",
      "|    iterations         | 89600    |\n",
      "|    time_elapsed       | 755      |\n",
      "|    total_timesteps    | 448000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.9     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99599    |\n",
      "|    policy_loss        | -69.6    |\n",
      "|    reward             | 6.35764  |\n",
      "|    std                | 1.77     |\n",
      "|    value_loss         | 192      |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 89700       |\n",
      "|    time_elapsed       | 756         |\n",
      "|    total_timesteps    | 448500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.9        |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99699       |\n",
      "|    policy_loss        | 7.99        |\n",
      "|    reward             | -0.33007684 |\n",
      "|    std                | 1.77        |\n",
      "|    value_loss         | 1.86        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 89800      |\n",
      "|    time_elapsed       | 757        |\n",
      "|    total_timesteps    | 449000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.9       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99799      |\n",
      "|    policy_loss        | 11.1       |\n",
      "|    reward             | -0.9978364 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 4.42       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 89900     |\n",
      "|    time_elapsed       | 758       |\n",
      "|    total_timesteps    | 449500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99899     |\n",
      "|    policy_loss        | -91.7     |\n",
      "|    reward             | 0.1429261 |\n",
      "|    std                | 1.78      |\n",
      "|    value_loss         | 265       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 90000     |\n",
      "|    time_elapsed       | 759       |\n",
      "|    total_timesteps    | 450000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99999     |\n",
      "|    policy_loss        | 11.6      |\n",
      "|    reward             | 1.4104913 |\n",
      "|    std                | 1.78      |\n",
      "|    value_loss         | 3.91      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 90100     |\n",
      "|    time_elapsed       | 759       |\n",
      "|    total_timesteps    | 450500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.9      |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 100099    |\n",
      "|    policy_loss        | -12.4     |\n",
      "|    reward             | 2.1899161 |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 4.58      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 90200      |\n",
      "|    time_elapsed       | 760        |\n",
      "|    total_timesteps    | 451000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.92      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 100199     |\n",
      "|    policy_loss        | 6.98       |\n",
      "|    reward             | 0.98359424 |\n",
      "|    std                | 1.78       |\n",
      "|    value_loss         | 8.85       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 90300     |\n",
      "|    time_elapsed       | 761       |\n",
      "|    total_timesteps    | 451500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.89     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 100299    |\n",
      "|    policy_loss        | -5.42     |\n",
      "|    reward             | 1.1334168 |\n",
      "|    std                | 1.76      |\n",
      "|    value_loss         | 1.69      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 90400      |\n",
      "|    time_elapsed       | 762        |\n",
      "|    total_timesteps    | 452000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.9       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 100399     |\n",
      "|    policy_loss        | -29.7      |\n",
      "|    reward             | -4.2161546 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 28.5       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 90500      |\n",
      "|    time_elapsed       | 763        |\n",
      "|    total_timesteps    | 452500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.91      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 100499     |\n",
      "|    policy_loss        | -20.4      |\n",
      "|    reward             | -2.2219706 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 12.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 90600      |\n",
      "|    time_elapsed       | 764        |\n",
      "|    total_timesteps    | 453000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.91      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 100599     |\n",
      "|    policy_loss        | 13.6       |\n",
      "|    reward             | -0.7357066 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 8.07       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 90700       |\n",
      "|    time_elapsed       | 764         |\n",
      "|    total_timesteps    | 453500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.9        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 100699      |\n",
      "|    policy_loss        | 14.2        |\n",
      "|    reward             | -0.46758205 |\n",
      "|    std                | 1.77        |\n",
      "|    value_loss         | 5.99        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 90800       |\n",
      "|    time_elapsed       | 765         |\n",
      "|    total_timesteps    | 454000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.89       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 100799      |\n",
      "|    policy_loss        | 34.7        |\n",
      "|    reward             | -0.22834693 |\n",
      "|    std                | 1.76        |\n",
      "|    value_loss         | 48.4        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 90900      |\n",
      "|    time_elapsed       | 766        |\n",
      "|    total_timesteps    | 454500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.91      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 100899     |\n",
      "|    policy_loss        | -2.99      |\n",
      "|    reward             | 0.37377024 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 1.09       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 91000      |\n",
      "|    time_elapsed       | 767        |\n",
      "|    total_timesteps    | 455000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.91      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 100999     |\n",
      "|    policy_loss        | 9.11       |\n",
      "|    reward             | -3.1382842 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 5.2        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 91100     |\n",
      "|    time_elapsed       | 768       |\n",
      "|    total_timesteps    | 455500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 101099    |\n",
      "|    policy_loss        | -3.74     |\n",
      "|    reward             | 2.6643956 |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 0.662     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 91200      |\n",
      "|    time_elapsed       | 769        |\n",
      "|    total_timesteps    | 456000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.91      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 101199     |\n",
      "|    policy_loss        | 62.1       |\n",
      "|    reward             | -3.3106318 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 111        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 91300      |\n",
      "|    time_elapsed       | 769        |\n",
      "|    total_timesteps    | 456500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.93      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 101299     |\n",
      "|    policy_loss        | 2.76       |\n",
      "|    reward             | -2.8351614 |\n",
      "|    std                | 1.78       |\n",
      "|    value_loss         | 26.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 91400     |\n",
      "|    time_elapsed       | 770       |\n",
      "|    total_timesteps    | 457000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.93     |\n",
      "|    explained_variance | -3.58e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 101399    |\n",
      "|    policy_loss        | 89.4      |\n",
      "|    reward             | 3.0023615 |\n",
      "|    std                | 1.78      |\n",
      "|    value_loss         | 279       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 593         |\n",
      "|    iterations         | 91500       |\n",
      "|    time_elapsed       | 771         |\n",
      "|    total_timesteps    | 457500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.94       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 101499      |\n",
      "|    policy_loss        | -3.23       |\n",
      "|    reward             | -0.45082587 |\n",
      "|    std                | 1.78        |\n",
      "|    value_loss         | 0.967       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 91600     |\n",
      "|    time_elapsed       | 772       |\n",
      "|    total_timesteps    | 458000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 101599    |\n",
      "|    policy_loss        | 10.3      |\n",
      "|    reward             | 1.3432081 |\n",
      "|    std                | 1.78      |\n",
      "|    value_loss         | 8.35      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 91700      |\n",
      "|    time_elapsed       | 773        |\n",
      "|    total_timesteps    | 458500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.93      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 101699     |\n",
      "|    policy_loss        | -7.82      |\n",
      "|    reward             | -2.5855117 |\n",
      "|    std                | 1.78       |\n",
      "|    value_loss         | 1.55       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 592          |\n",
      "|    iterations         | 91800        |\n",
      "|    time_elapsed       | 774          |\n",
      "|    total_timesteps    | 459000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.93        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 101799       |\n",
      "|    policy_loss        | 22           |\n",
      "|    reward             | -0.104508005 |\n",
      "|    std                | 1.78         |\n",
      "|    value_loss         | 18.8         |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 593      |\n",
      "|    iterations         | 91900    |\n",
      "|    time_elapsed       | 774      |\n",
      "|    total_timesteps    | 459500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.95    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 101899   |\n",
      "|    policy_loss        | -2.15    |\n",
      "|    reward             | 4.468169 |\n",
      "|    std                | 1.78     |\n",
      "|    value_loss         | 3.41     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 92000     |\n",
      "|    time_elapsed       | 775       |\n",
      "|    total_timesteps    | 460000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.95     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 101999    |\n",
      "|    policy_loss        | -1.86     |\n",
      "|    reward             | -0.316706 |\n",
      "|    std                | 1.79      |\n",
      "|    value_loss         | 0.12      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 92100     |\n",
      "|    time_elapsed       | 776       |\n",
      "|    total_timesteps    | 460500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 102099    |\n",
      "|    policy_loss        | 1.91      |\n",
      "|    reward             | 1.0944039 |\n",
      "|    std                | 1.78      |\n",
      "|    value_loss         | 0.715     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 92200     |\n",
      "|    time_elapsed       | 777       |\n",
      "|    total_timesteps    | 461000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.92     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 102199    |\n",
      "|    policy_loss        | 0.725     |\n",
      "|    reward             | 1.7678173 |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 5.53      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 92300       |\n",
      "|    time_elapsed       | 778         |\n",
      "|    total_timesteps    | 461500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.93       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 102299      |\n",
      "|    policy_loss        | -17.4       |\n",
      "|    reward             | -0.19889253 |\n",
      "|    std                | 1.77        |\n",
      "|    value_loss         | 10          |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 92400      |\n",
      "|    time_elapsed       | 779        |\n",
      "|    total_timesteps    | 462000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 102399     |\n",
      "|    policy_loss        | 0.0665     |\n",
      "|    reward             | -1.5645821 |\n",
      "|    std                | 1.78       |\n",
      "|    value_loss         | 0.566      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 92500     |\n",
      "|    time_elapsed       | 780       |\n",
      "|    total_timesteps    | 462500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 102499    |\n",
      "|    policy_loss        | -45.6     |\n",
      "|    reward             | 3.3119793 |\n",
      "|    std                | 1.78      |\n",
      "|    value_loss         | 74.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 92600     |\n",
      "|    time_elapsed       | 780       |\n",
      "|    total_timesteps    | 463000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.93     |\n",
      "|    explained_variance | 0.28      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 102599    |\n",
      "|    policy_loss        | -5.82     |\n",
      "|    reward             | 1.5899769 |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 1.2       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 92700      |\n",
      "|    time_elapsed       | 781        |\n",
      "|    total_timesteps    | 463500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.93      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 102699     |\n",
      "|    policy_loss        | -7.27      |\n",
      "|    reward             | 0.71568495 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 1.83       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 92800     |\n",
      "|    time_elapsed       | 782       |\n",
      "|    total_timesteps    | 464000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.92     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 102799    |\n",
      "|    policy_loss        | -4.29     |\n",
      "|    reward             | 1.4278095 |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 5.76      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 592         |\n",
      "|    iterations         | 92900       |\n",
      "|    time_elapsed       | 783         |\n",
      "|    total_timesteps    | 464500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.94       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 102899      |\n",
      "|    policy_loss        | -17.2       |\n",
      "|    reward             | -0.33747736 |\n",
      "|    std                | 1.78        |\n",
      "|    value_loss         | 9.59        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 93000     |\n",
      "|    time_elapsed       | 784       |\n",
      "|    total_timesteps    | 465000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.93     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 102999    |\n",
      "|    policy_loss        | 2.65      |\n",
      "|    reward             | 0.2734533 |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 0.893     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 93100      |\n",
      "|    time_elapsed       | 785        |\n",
      "|    total_timesteps    | 465500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.93      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 103099     |\n",
      "|    policy_loss        | -30.6      |\n",
      "|    reward             | -3.8165119 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 22.7       |\n",
      "--------------------------------------\n",
      "day: 2892, episode: 180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4125156.71\n",
      "total_reward: 3125156.71\n",
      "total_cost: 1006.99\n",
      "total_trades: 5810\n",
      "Sharpe: 0.710\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 592       |\n",
      "|    iterations         | 93200     |\n",
      "|    time_elapsed       | 785       |\n",
      "|    total_timesteps    | 466000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.93     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 103199    |\n",
      "|    policy_loss        | 5.04      |\n",
      "|    reward             | -0.655184 |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 1.34      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 592        |\n",
      "|    iterations         | 93300      |\n",
      "|    time_elapsed       | 786        |\n",
      "|    total_timesteps    | 466500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.93      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 103299     |\n",
      "|    policy_loss        | 11.3       |\n",
      "|    reward             | -0.6811851 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 8.16       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 93400      |\n",
      "|    time_elapsed       | 787        |\n",
      "|    total_timesteps    | 467000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 103399     |\n",
      "|    policy_loss        | 13         |\n",
      "|    reward             | 0.63983214 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 5.82       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 593         |\n",
      "|    iterations         | 93500       |\n",
      "|    time_elapsed       | 788         |\n",
      "|    total_timesteps    | 467500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.92       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 103499      |\n",
      "|    policy_loss        | 7.07        |\n",
      "|    reward             | -0.23926465 |\n",
      "|    std                | 1.77        |\n",
      "|    value_loss         | 3.7         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 93600      |\n",
      "|    time_elapsed       | 789        |\n",
      "|    total_timesteps    | 468000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.93      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 103599     |\n",
      "|    policy_loss        | 20.7       |\n",
      "|    reward             | -0.2935019 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 25.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 93700     |\n",
      "|    time_elapsed       | 789       |\n",
      "|    total_timesteps    | 468500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.92     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 103699    |\n",
      "|    policy_loss        | 26.8      |\n",
      "|    reward             | 2.4094553 |\n",
      "|    std                | 1.76      |\n",
      "|    value_loss         | 28.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 93800     |\n",
      "|    time_elapsed       | 790       |\n",
      "|    total_timesteps    | 469000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.93     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 103799    |\n",
      "|    policy_loss        | 0.356     |\n",
      "|    reward             | 0.8328723 |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 1.01      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 593      |\n",
      "|    iterations         | 93900    |\n",
      "|    time_elapsed       | 791      |\n",
      "|    total_timesteps    | 469500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.94    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 103899   |\n",
      "|    policy_loss        | -25.2    |\n",
      "|    reward             | 3.323605 |\n",
      "|    std                | 1.77     |\n",
      "|    value_loss         | 16       |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 94000      |\n",
      "|    time_elapsed       | 792        |\n",
      "|    total_timesteps    | 470000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.93      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 103999     |\n",
      "|    policy_loss        | 4.48       |\n",
      "|    reward             | -0.7272983 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 2.49       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 593      |\n",
      "|    iterations         | 94100    |\n",
      "|    time_elapsed       | 793      |\n",
      "|    total_timesteps    | 470500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.93    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 104099   |\n",
      "|    policy_loss        | -8.45    |\n",
      "|    reward             | 1.772587 |\n",
      "|    std                | 1.77     |\n",
      "|    value_loss         | 5.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 593      |\n",
      "|    iterations         | 94200    |\n",
      "|    time_elapsed       | 794      |\n",
      "|    total_timesteps    | 471000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.93    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 104199   |\n",
      "|    policy_loss        | 24.3     |\n",
      "|    reward             | 4.982748 |\n",
      "|    std                | 1.77     |\n",
      "|    value_loss         | 30.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 94300     |\n",
      "|    time_elapsed       | 794       |\n",
      "|    total_timesteps    | 471500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.92     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 104299    |\n",
      "|    policy_loss        | 50.8      |\n",
      "|    reward             | -2.275513 |\n",
      "|    std                | 1.76      |\n",
      "|    value_loss         | 184       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 593         |\n",
      "|    iterations         | 94400       |\n",
      "|    time_elapsed       | 795         |\n",
      "|    total_timesteps    | 472000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.92       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 104399      |\n",
      "|    policy_loss        | 6.96        |\n",
      "|    reward             | -0.82535875 |\n",
      "|    std                | 1.76        |\n",
      "|    value_loss         | 2           |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 94500      |\n",
      "|    time_elapsed       | 796        |\n",
      "|    total_timesteps    | 472500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.91      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 104499     |\n",
      "|    policy_loss        | -1.84      |\n",
      "|    reward             | -1.0840108 |\n",
      "|    std                | 1.76       |\n",
      "|    value_loss         | 1.27       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 94600     |\n",
      "|    time_elapsed       | 797       |\n",
      "|    total_timesteps    | 473000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 104599    |\n",
      "|    policy_loss        | 1.07      |\n",
      "|    reward             | 1.2354064 |\n",
      "|    std                | 1.76      |\n",
      "|    value_loss         | 0.346     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 94700     |\n",
      "|    time_elapsed       | 798       |\n",
      "|    total_timesteps    | 473500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 104699    |\n",
      "|    policy_loss        | -9.97     |\n",
      "|    reward             | 0.5742753 |\n",
      "|    std                | 1.75      |\n",
      "|    value_loss         | 10        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 94800     |\n",
      "|    time_elapsed       | 799       |\n",
      "|    total_timesteps    | 474000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.89     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 104799    |\n",
      "|    policy_loss        | -35.7     |\n",
      "|    reward             | 4.0263333 |\n",
      "|    std                | 1.74      |\n",
      "|    value_loss         | 18.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 94900      |\n",
      "|    time_elapsed       | 800        |\n",
      "|    total_timesteps    | 474500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.89      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 104899     |\n",
      "|    policy_loss        | -5.81      |\n",
      "|    reward             | -0.1400185 |\n",
      "|    std                | 1.75       |\n",
      "|    value_loss         | 1.55       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 95000     |\n",
      "|    time_elapsed       | 800       |\n",
      "|    total_timesteps    | 475000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.88     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 104999    |\n",
      "|    policy_loss        | -12       |\n",
      "|    reward             | 2.1574388 |\n",
      "|    std                | 1.74      |\n",
      "|    value_loss         | 4.71      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 95100     |\n",
      "|    time_elapsed       | 801       |\n",
      "|    total_timesteps    | 475500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.89     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 105099    |\n",
      "|    policy_loss        | -6.79     |\n",
      "|    reward             | 1.3816112 |\n",
      "|    std                | 1.75      |\n",
      "|    value_loss         | 3.1       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 95200     |\n",
      "|    time_elapsed       | 802       |\n",
      "|    total_timesteps    | 476000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.9      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 105199    |\n",
      "|    policy_loss        | 13.5      |\n",
      "|    reward             | 0.7030274 |\n",
      "|    std                | 1.75      |\n",
      "|    value_loss         | 8.21      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 95300     |\n",
      "|    time_elapsed       | 803       |\n",
      "|    total_timesteps    | 476500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.9      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 105299    |\n",
      "|    policy_loss        | 20.2      |\n",
      "|    reward             | 0.6892752 |\n",
      "|    std                | 1.75      |\n",
      "|    value_loss         | 12.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 95400     |\n",
      "|    time_elapsed       | 804       |\n",
      "|    total_timesteps    | 477000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.87     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 105399    |\n",
      "|    policy_loss        | -6.83     |\n",
      "|    reward             | 0.6366623 |\n",
      "|    std                | 1.74      |\n",
      "|    value_loss         | 3.28      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 95500     |\n",
      "|    time_elapsed       | 805       |\n",
      "|    total_timesteps    | 477500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.88     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 105499    |\n",
      "|    policy_loss        | 2.65      |\n",
      "|    reward             | -0.740017 |\n",
      "|    std                | 1.74      |\n",
      "|    value_loss         | 0.894     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 593      |\n",
      "|    iterations         | 95600    |\n",
      "|    time_elapsed       | 805      |\n",
      "|    total_timesteps    | 478000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.91    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 105599   |\n",
      "|    policy_loss        | -27.7    |\n",
      "|    reward             | 4.879873 |\n",
      "|    std                | 1.76     |\n",
      "|    value_loss         | 19.3     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 95700      |\n",
      "|    time_elapsed       | 806        |\n",
      "|    total_timesteps    | 478500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.91      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 105699     |\n",
      "|    policy_loss        | -3.48      |\n",
      "|    reward             | -4.0812807 |\n",
      "|    std                | 1.76       |\n",
      "|    value_loss         | 0.77       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 95800     |\n",
      "|    time_elapsed       | 807       |\n",
      "|    total_timesteps    | 479000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 105799    |\n",
      "|    policy_loss        | -40.2     |\n",
      "|    reward             | 0.7819324 |\n",
      "|    std                | 1.76      |\n",
      "|    value_loss         | 80.6      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 593         |\n",
      "|    iterations         | 95900       |\n",
      "|    time_elapsed       | 808         |\n",
      "|    total_timesteps    | 479500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.91       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 105899      |\n",
      "|    policy_loss        | -29.8       |\n",
      "|    reward             | -0.99280834 |\n",
      "|    std                | 1.76        |\n",
      "|    value_loss         | 26.1        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 96000     |\n",
      "|    time_elapsed       | 809       |\n",
      "|    total_timesteps    | 480000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 105999    |\n",
      "|    policy_loss        | 5.75      |\n",
      "|    reward             | 1.6796885 |\n",
      "|    std                | 1.76      |\n",
      "|    value_loss         | 6.44      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 96100     |\n",
      "|    time_elapsed       | 810       |\n",
      "|    total_timesteps    | 480500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 106099    |\n",
      "|    policy_loss        | -11.4     |\n",
      "|    reward             | 2.1690996 |\n",
      "|    std                | 1.76      |\n",
      "|    value_loss         | 4.99      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 96200      |\n",
      "|    time_elapsed       | 810        |\n",
      "|    total_timesteps    | 481000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.92      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 106199     |\n",
      "|    policy_loss        | 8.37       |\n",
      "|    reward             | 0.71516573 |\n",
      "|    std                | 1.76       |\n",
      "|    value_loss         | 3.04       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 96300      |\n",
      "|    time_elapsed       | 811        |\n",
      "|    total_timesteps    | 481500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.91      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 106299     |\n",
      "|    policy_loss        | 16.2       |\n",
      "|    reward             | -2.2729313 |\n",
      "|    std                | 1.76       |\n",
      "|    value_loss         | 8.55       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 96400      |\n",
      "|    time_elapsed       | 812        |\n",
      "|    total_timesteps    | 482000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.89      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 106399     |\n",
      "|    policy_loss        | 7.3        |\n",
      "|    reward             | -2.3658621 |\n",
      "|    std                | 1.75       |\n",
      "|    value_loss         | 5.99       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 96500     |\n",
      "|    time_elapsed       | 813       |\n",
      "|    total_timesteps    | 482500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.9      |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 106499    |\n",
      "|    policy_loss        | -6.73     |\n",
      "|    reward             | 0.6829218 |\n",
      "|    std                | 1.75      |\n",
      "|    value_loss         | 3.47      |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 593          |\n",
      "|    iterations         | 96600        |\n",
      "|    time_elapsed       | 814          |\n",
      "|    total_timesteps    | 483000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.87        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 106599       |\n",
      "|    policy_loss        | 18.1         |\n",
      "|    reward             | -0.047350522 |\n",
      "|    std                | 1.74         |\n",
      "|    value_loss         | 13           |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 96700      |\n",
      "|    time_elapsed       | 815        |\n",
      "|    total_timesteps    | 483500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.89      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 106699     |\n",
      "|    policy_loss        | 20.6       |\n",
      "|    reward             | -1.3020796 |\n",
      "|    std                | 1.75       |\n",
      "|    value_loss         | 17.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 96800     |\n",
      "|    time_elapsed       | 815       |\n",
      "|    total_timesteps    | 484000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.88     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 106799    |\n",
      "|    policy_loss        | 19.5      |\n",
      "|    reward             | 1.9425244 |\n",
      "|    std                | 1.74      |\n",
      "|    value_loss         | 15.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 96900      |\n",
      "|    time_elapsed       | 816        |\n",
      "|    total_timesteps    | 484500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.87      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 106899     |\n",
      "|    policy_loss        | 8.93       |\n",
      "|    reward             | -1.2319022 |\n",
      "|    std                | 1.74       |\n",
      "|    value_loss         | 3.05       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 97000     |\n",
      "|    time_elapsed       | 817       |\n",
      "|    total_timesteps    | 485000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.88     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 106999    |\n",
      "|    policy_loss        | 21.3      |\n",
      "|    reward             | 0.5718086 |\n",
      "|    std                | 1.74      |\n",
      "|    value_loss         | 27.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 97100     |\n",
      "|    time_elapsed       | 818       |\n",
      "|    total_timesteps    | 485500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.9      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 107099    |\n",
      "|    policy_loss        | 0.29      |\n",
      "|    reward             | 2.6115031 |\n",
      "|    std                | 1.75      |\n",
      "|    value_loss         | 1.22      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 97200      |\n",
      "|    time_elapsed       | 819        |\n",
      "|    total_timesteps    | 486000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.9       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 107199     |\n",
      "|    policy_loss        | 35.3       |\n",
      "|    reward             | -1.6943358 |\n",
      "|    std                | 1.75       |\n",
      "|    value_loss         | 67.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 97300      |\n",
      "|    time_elapsed       | 820        |\n",
      "|    total_timesteps    | 486500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.9       |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 107299     |\n",
      "|    policy_loss        | -13.5      |\n",
      "|    reward             | 0.32857502 |\n",
      "|    std                | 1.75       |\n",
      "|    value_loss         | 8.53       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 97400      |\n",
      "|    time_elapsed       | 821        |\n",
      "|    total_timesteps    | 487000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.9       |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 107399     |\n",
      "|    policy_loss        | -18.9      |\n",
      "|    reward             | 0.88787407 |\n",
      "|    std                | 1.75       |\n",
      "|    value_loss         | 13.6       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 97500     |\n",
      "|    time_elapsed       | 821       |\n",
      "|    total_timesteps    | 487500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 107499    |\n",
      "|    policy_loss        | -10.5     |\n",
      "|    reward             | -1.419413 |\n",
      "|    std                | 1.76      |\n",
      "|    value_loss         | 3.33      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 593      |\n",
      "|    iterations         | 97600    |\n",
      "|    time_elapsed       | 822      |\n",
      "|    total_timesteps    | 488000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.93    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 107599   |\n",
      "|    policy_loss        | 6.9      |\n",
      "|    reward             | 4.642913 |\n",
      "|    std                | 1.77     |\n",
      "|    value_loss         | 1.75     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 97700     |\n",
      "|    time_elapsed       | 823       |\n",
      "|    total_timesteps    | 488500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.93     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 107699    |\n",
      "|    policy_loss        | -22.2     |\n",
      "|    reward             | 1.0959715 |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 23.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 97800      |\n",
      "|    time_elapsed       | 824        |\n",
      "|    total_timesteps    | 489000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 107799     |\n",
      "|    policy_loss        | -0.964     |\n",
      "|    reward             | 0.71181875 |\n",
      "|    std                | 1.78       |\n",
      "|    value_loss         | 0.152      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 97900     |\n",
      "|    time_elapsed       | 825       |\n",
      "|    total_timesteps    | 489500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 107899    |\n",
      "|    policy_loss        | -1.95     |\n",
      "|    reward             | 1.7928663 |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 0.46      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 98000     |\n",
      "|    time_elapsed       | 826       |\n",
      "|    total_timesteps    | 490000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 107999    |\n",
      "|    policy_loss        | -15       |\n",
      "|    reward             | 1.1267631 |\n",
      "|    std                | 1.77      |\n",
      "|    value_loss         | 7.66      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 98100     |\n",
      "|    time_elapsed       | 826       |\n",
      "|    total_timesteps    | 490500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 108099    |\n",
      "|    policy_loss        | -0.372    |\n",
      "|    reward             | 6.4148035 |\n",
      "|    std                | 1.78      |\n",
      "|    value_loss         | 0.102     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 593         |\n",
      "|    iterations         | 98200       |\n",
      "|    time_elapsed       | 827         |\n",
      "|    total_timesteps    | 491000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.95       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 108199      |\n",
      "|    policy_loss        | -9.32       |\n",
      "|    reward             | -0.14380254 |\n",
      "|    std                | 1.78        |\n",
      "|    value_loss         | 3.32        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 98300      |\n",
      "|    time_elapsed       | 828        |\n",
      "|    total_timesteps    | 491500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.96      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 108299     |\n",
      "|    policy_loss        | 19.5       |\n",
      "|    reward             | -2.0894246 |\n",
      "|    std                | 1.78       |\n",
      "|    value_loss         | 17         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 98400      |\n",
      "|    time_elapsed       | 829        |\n",
      "|    total_timesteps    | 492000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.95      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 108399     |\n",
      "|    policy_loss        | -9.9       |\n",
      "|    reward             | 0.26702634 |\n",
      "|    std                | 1.78       |\n",
      "|    value_loss         | 3.14       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 593         |\n",
      "|    iterations         | 98500       |\n",
      "|    time_elapsed       | 830         |\n",
      "|    total_timesteps    | 492500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.94       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 108499      |\n",
      "|    policy_loss        | 2.72        |\n",
      "|    reward             | -0.22179851 |\n",
      "|    std                | 1.78        |\n",
      "|    value_loss         | 5.44        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 593         |\n",
      "|    iterations         | 98600       |\n",
      "|    time_elapsed       | 831         |\n",
      "|    total_timesteps    | 493000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.96       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 108599      |\n",
      "|    policy_loss        | 16.5        |\n",
      "|    reward             | -0.41057318 |\n",
      "|    std                | 1.79        |\n",
      "|    value_loss         | 6.41        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 98700     |\n",
      "|    time_elapsed       | 832       |\n",
      "|    total_timesteps    | 493500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.96     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 108699    |\n",
      "|    policy_loss        | -5.46     |\n",
      "|    reward             | 2.4610407 |\n",
      "|    std                | 1.78      |\n",
      "|    value_loss         | 3.24      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 98800      |\n",
      "|    time_elapsed       | 832        |\n",
      "|    total_timesteps    | 494000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.99      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 108799     |\n",
      "|    policy_loss        | -3.17      |\n",
      "|    reward             | -0.8558262 |\n",
      "|    std                | 1.8        |\n",
      "|    value_loss         | 0.563      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 98900      |\n",
      "|    time_elapsed       | 833        |\n",
      "|    total_timesteps    | 494500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.99      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 108899     |\n",
      "|    policy_loss        | 19.1       |\n",
      "|    reward             | -1.6586671 |\n",
      "|    std                | 1.8        |\n",
      "|    value_loss         | 18.7       |\n",
      "--------------------------------------\n",
      "day: 2892, episode: 190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3271178.95\n",
      "total_reward: 2271178.95\n",
      "total_cost: 1245.19\n",
      "total_trades: 6047\n",
      "Sharpe: 0.609\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 99000      |\n",
      "|    time_elapsed       | 834        |\n",
      "|    total_timesteps    | 495000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.99      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 108999     |\n",
      "|    policy_loss        | -7.43      |\n",
      "|    reward             | 0.22576833 |\n",
      "|    std                | 1.8        |\n",
      "|    value_loss         | 1.69       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 99100     |\n",
      "|    time_elapsed       | 835       |\n",
      "|    total_timesteps    | 495500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.98     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 109099    |\n",
      "|    policy_loss        | 17.1      |\n",
      "|    reward             | 0.9854156 |\n",
      "|    std                | 1.8       |\n",
      "|    value_loss         | 9.97      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 99200      |\n",
      "|    time_elapsed       | 836        |\n",
      "|    total_timesteps    | 496000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.98      |\n",
      "|    explained_variance | 0.00542    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 109199     |\n",
      "|    policy_loss        | -1.37      |\n",
      "|    reward             | 0.31071833 |\n",
      "|    std                | 1.79       |\n",
      "|    value_loss         | 0.599      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 99300      |\n",
      "|    time_elapsed       | 837        |\n",
      "|    total_timesteps    | 496500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.99      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 109299     |\n",
      "|    policy_loss        | 45.9       |\n",
      "|    reward             | 0.55810064 |\n",
      "|    std                | 1.81       |\n",
      "|    value_loss         | 50.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 99400      |\n",
      "|    time_elapsed       | 837        |\n",
      "|    total_timesteps    | 497000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.02      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 109399     |\n",
      "|    policy_loss        | -25.1      |\n",
      "|    reward             | -0.3823005 |\n",
      "|    std                | 1.82       |\n",
      "|    value_loss         | 52.5       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 99500      |\n",
      "|    time_elapsed       | 838        |\n",
      "|    total_timesteps    | 497500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.02      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 109499     |\n",
      "|    policy_loss        | 96.5       |\n",
      "|    reward             | -2.0884597 |\n",
      "|    std                | 1.82       |\n",
      "|    value_loss         | 470        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 99600      |\n",
      "|    time_elapsed       | 839        |\n",
      "|    total_timesteps    | 498000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6         |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 109599     |\n",
      "|    policy_loss        | 7.24       |\n",
      "|    reward             | -1.9335707 |\n",
      "|    std                | 1.81       |\n",
      "|    value_loss         | 2.22       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 593       |\n",
      "|    iterations         | 99700     |\n",
      "|    time_elapsed       | 840       |\n",
      "|    total_timesteps    | 498500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.02     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 109699    |\n",
      "|    policy_loss        | 23.8      |\n",
      "|    reward             | 4.1661496 |\n",
      "|    std                | 1.82      |\n",
      "|    value_loss         | 19        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 99800      |\n",
      "|    time_elapsed       | 841        |\n",
      "|    total_timesteps    | 499000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.01      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 109799     |\n",
      "|    policy_loss        | 2.65       |\n",
      "|    reward             | -2.6489031 |\n",
      "|    std                | 1.81       |\n",
      "|    value_loss         | 1.73       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 593         |\n",
      "|    iterations         | 99900       |\n",
      "|    time_elapsed       | 842         |\n",
      "|    total_timesteps    | 499500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.01       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 109899      |\n",
      "|    policy_loss        | 19.7        |\n",
      "|    reward             | -0.79048043 |\n",
      "|    std                | 1.81        |\n",
      "|    value_loss         | 12.7        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 593        |\n",
      "|    iterations         | 100000     |\n",
      "|    time_elapsed       | 843        |\n",
      "|    total_timesteps    | 500000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.99      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 109999     |\n",
      "|    policy_loss        | 8.76       |\n",
      "|    reward             | 0.80595475 |\n",
      "|    std                | 1.8        |\n",
      "|    value_loss         | 5.74       |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=500000) if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(model=trained_a2c, \n",
    "                        environment = e_train_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_account_value_a2c.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_actions_a2c[df_actions_a2c['inm'] >= 100 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aapl</th>\n",
       "      <th>ibm</th>\n",
       "      <th>msft</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01-02</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-05</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-06</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-07</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-08</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2892 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aapl  ibm  msft\n",
       "date                       \n",
       "2009-01-02     0  100   100\n",
       "2009-01-05     0  100   100\n",
       "2009-01-06     0  100   100\n",
       "2009-01-07     0  100   100\n",
       "2009-01-08     0  100   100\n",
       "...          ...  ...   ...\n",
       "2020-06-23     0    0     0\n",
       "2020-06-24     0    0     0\n",
       "2020-06-25     0    0     0\n",
       "2020-06-26     0    0     0\n",
       "2020-06-29     0    0     0\n",
       "\n",
       "[2892 rows x 3 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions_a2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "ex = ccxt.binance()\n",
    "\n",
    "df_rrw = ex.fetch_ohlcv('BTC/USDT', '1d', since=1496787634826, limit=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-17</th>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4485.39</td>\n",
       "      <td>4200.74</td>\n",
       "      <td>4285.08</td>\n",
       "      <td>795.150377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-18</th>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>4285.08</td>\n",
       "      <td>4371.52</td>\n",
       "      <td>3938.77</td>\n",
       "      <td>4108.37</td>\n",
       "      <td>1199.888264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-19</th>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>4108.37</td>\n",
       "      <td>4184.69</td>\n",
       "      <td>3850.00</td>\n",
       "      <td>4139.98</td>\n",
       "      <td>381.309763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-20</th>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>4120.98</td>\n",
       "      <td>4211.08</td>\n",
       "      <td>4032.62</td>\n",
       "      <td>4086.29</td>\n",
       "      <td>467.083022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-21</th>\n",
       "      <td>2017-08-21</td>\n",
       "      <td>4069.13</td>\n",
       "      <td>4119.62</td>\n",
       "      <td>3911.79</td>\n",
       "      <td>4016.00</td>\n",
       "      <td>691.743060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date     open     high      low    close       volume\n",
       "date                                                                  \n",
       "2017-08-17 2017-08-17  4261.48  4485.39  4200.74  4285.08   795.150377\n",
       "2017-08-18 2017-08-18  4285.08  4371.52  3938.77  4108.37  1199.888264\n",
       "2017-08-19 2017-08-19  4108.37  4184.69  3850.00  4139.98   381.309763\n",
       "2017-08-20 2017-08-20  4120.98  4211.08  4032.62  4086.29   467.083022\n",
       "2017-08-21 2017-08-21  4069.13  4119.62  3911.79  4016.00   691.743060"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(df_rrw, columns=['date', 'open', 'high', 'low', 'close', 'volume'])\n",
    "df['date'] = pd.to_datetime(df['date'], unit='ms')\n",
    "df.set_index(df['date'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_df = df.loc['2018-01-01':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='date'>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sliced_df['close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='date'>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Download data for US Federal Funds Rate\n",
    "fed_funds_data = yf.download(\"^IRX\", start=\"2018-01-01\", end=\"2020-06-05\")\n",
    "\n",
    "# Access closing prices (daily interest rates)\n",
    "daily_rates = fed_funds_data[\"Close\"]\n",
    "\n",
    "# Print the first few daily rates\n",
    "daily_rates.plot()\n",
    "df['close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_price = np.array(df['close']).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "preprocessor = MinMaxScaler()\n",
    "df['close_scaled'] = preprocessor.fit_transform(close_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='date'>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['close_scaled'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, open, high, low, close, volume]\n",
       "Index: []"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliced_df = df.loc['2018-01-01':]\n",
    "sliced_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='date'>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "daily_rates.plot()\n",
    "df['close_scaled'].plot( color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='api.example.com', port=443): Max retries exceeded with url: /ftse-global-digital-asset-index?index=FTSE_GLOBAL_DIGITAL_ASSET_50&start_date=2023-01-01&end_date=2023-12-31 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001712601E890>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    175\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\urllib3\\util\\connection.py:72\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m six\u001b[38;5;241m.\u001b[39mraise_from(\n\u001b[0;32m     69\u001b[0m         LocationParseError(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label empty or too long\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m host), \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     )\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     73\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:955\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    954\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 955\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    956\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\urllib3\\connectionpool.py:715\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 715\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\urllib3\\connectionpool.py:404\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 404\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\urllib3\\connectionpool.py:1058\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1058\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\urllib3\\connection.py:363\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\urllib3\\connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x000001712601E890>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\requests\\adapters.py:589\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 589\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\urllib3\\connectionpool.py:799\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    797\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 799\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    802\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api.example.com', port=443): Max retries exceeded with url: /ftse-global-digital-asset-index?index=FTSE_GLOBAL_DIGITAL_ASSET_50&start_date=2023-01-01&end_date=2023-12-31 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001712601E890>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[194], line 13\u001b[0m\n\u001b[0;32m      6\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFTSE_GLOBAL_DIGITAL_ASSET_50\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_date\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_date\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023-12-31\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     10\u001b[0m }\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Fetch the data\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Convert the data to a pandas DataFrame\u001b[39;00m\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32md:\\RL-Project\\Py310-venv\\lib\\site-packages\\requests\\adapters.py:622\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    619\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    620\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m--> 622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='api.example.com', port=443): Max retries exceeded with url: /ftse-global-digital-asset-index?index=FTSE_GLOBAL_DIGITAL_ASSET_50&start_date=2023-01-01&end_date=2023-12-31 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001712601E890>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Define the API endpoint and parameters\n",
    "api_url = \"https://api.example.com/ftse-global-digital-asset-index\"\n",
    "params = {\n",
    "    'index': 'FTSE_GLOBAL_DIGITAL_ASSET_50',\n",
    "    'start_date': '2023-01-01',\n",
    "    'end_date': '2023-12-31'\n",
    "}\n",
    "\n",
    "# Fetch the data\n",
    "response = requests.get(api_url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "# Convert the data to a pandas DataFrame\n",
    "df = pd.DataFrame(data['prices'])\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not parse JSON data!\n",
      "Reason: HTTPSConnectionPool(host='api.example.com', port=443): Max retries exceeded with url: /ftse-global-digital-asset-index (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000171279A9BA0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "try:\n",
    "  # Your code to fetch data (replace with your actual API call)\n",
    "  response = requests.get(\"https://api.example.com/ftse-global-digital-asset-index\")\n",
    "  data = response.json()  # This line might raise the JSONDecodeError\n",
    "\n",
    "  # Process the data here (assuming it's valid JSON)\n",
    "  print(data[\"key\"])  # Access data from the JSON object\n",
    "\n",
    "except Exception as e:\n",
    "  print(\"Error: Could not parse JSON data!\")\n",
    "  print(f\"Reason: {e}\")  # Print the error message for debugging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': {'timestamp': '2024-06-05T16:20:05.848Z', 'error_code': 1002, 'error_message': 'API key missing.', 'elapsed': 0, 'credit_count': 0}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from json import JSONDecodeError\n",
    "\n",
    "try:\n",
    "  response = requests.get(\"https://pro-api.coinmarketcap.com/v1/global-metrics/quotes/historical\")\n",
    "  data = response.json()  # This line might raise the JSONDecodeError or other exceptions\n",
    "\n",
    "  # Process the data here (assuming it's valid JSON)\n",
    "  print(data)  # Access data from the JSON object\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "  # Handle different request exceptions\n",
    "  if isinstance(e, requests.exceptions.ConnectionError):\n",
    "    print(\"Error: Could not connect to the API server!\")\n",
    "    print(f\"Reason: {e}\")  # Print the connection error details\n",
    "  elif isinstance(e, requests.exceptions.Timeout):\n",
    "    print(\"Error: API request timed out!\")\n",
    "  else:\n",
    "    print(f\"An error occurred while making the API request: {e}\")\n",
    "\n",
    "except JSONDecodeError as e:\n",
    "  print(\"Error: Could not parse JSON data!\")\n",
    "  print(f\"Reason: {e}\")  # Print the JSON parsing error for debugging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_var():\n",
    "    global new_var \n",
    "    new_var = 4; \n",
    "    return new_var \n",
    "\n",
    "# global_var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_var(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class variable: 10\n",
      "Class attribute: Global value\n",
      "Instance variable: 20\n",
      "Class variable: 10\n",
      "Class attribute: Global value\n",
      "Instance variable: 30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class MyClass:\n",
    "    class_var = 10  # Class variable (shared)\n",
    "\n",
    "    def __init__(self, value):\n",
    "        self.instance_var = value  # Instance variable\n",
    "\n",
    "    def some_method(self):\n",
    "        print(\"Class variable:\", MyClass.class_var)  # No `global` needed\n",
    "        print(\"Class attribute:\", MyClass.shared_data)  # No `global` needed\n",
    "        print(\"Instance variable:\", self.instance_var)\n",
    "\n",
    "# Set class-level attribute\n",
    "MyClass.shared_data = \"Global value\"\n",
    "\n",
    "obj1 = MyClass(20)\n",
    "obj2 = MyClass(30)\n",
    "\n",
    "obj1.some_method()\n",
    "obj2.some_method()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\RL-Project\\Py310-venv\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> \n",
       "\n",
       " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> \n",
       "\n",
       " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " flatten (\u001b[38;5;33mFlatten\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m12,416\u001b[0m \n",
       "\n",
       " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                    \u001b[38;5;34m16,512\u001b[0m \n",
       "\n",
       " dense_2 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                         \u001b[38;5;34m129\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,057</span> (113.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,057\u001b[0m (113.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,057</span> (113.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,057\u001b[0m (113.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer (flattening the input)\n",
    "model.add(Flatten(input_shape=(6, 16)))  # 6 time steps, 16 features per time step\n",
    "\n",
    "# Hidden layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Output layer (example with a single output, e.g., future price or action value)\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traditional_opportunity_cost(current_balance, initial_balance, max_steps, current_step):\n",
    "  \"\"\"\n",
    "  Calculates opportunity cost based on traditional definition.\n",
    "\n",
    "  Args:\n",
    "      current_balance (float): The current account balance.\n",
    "      initial_balance (float): The initial account balance.\n",
    "      max_steps (int): The maximum number of steps (e.g., investment period).\n",
    "      current_step (int): The current step in the investment period.\n",
    "\n",
    "  Returns:\n",
    "      float: The opportunity cost.\n",
    "  \"\"\"\n",
    "\n",
    "  # Check for zero initial balance to avoid division by zero\n",
    "  if initial_balance == 0:\n",
    "    return 0\n",
    "\n",
    "  # Calculate the potential return if invested elsewhere\n",
    "  potential_return = (max_steps - current_step) * (current_balance - initial_balance) / initial_balance\n",
    "\n",
    "  return potential_return\n",
    "\n",
    "\n",
    "\n",
    "def custom_opportunity_cost(current_balance, max_steps, current_step):\n",
    "  \"\"\"\n",
    "  Calculates opportunity cost based on the custom definition.\n",
    "\n",
    "  Args:\n",
    "      current_balance (float): The current account balance.\n",
    "      max_steps (int): The maximum number of steps (e.g., investment period).\n",
    "      current_step (int): The current step in the investment period.\n",
    "\n",
    "  Returns:\n",
    "      float: The opportunity cost.\n",
    "  \"\"\"\n",
    "\n",
    "  # Avoid division by zero\n",
    "  if current_step == 0:\n",
    "    return 0\n",
    "\n",
    "  return current_balance * current_step / max_steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            interest_rate\n",
      "date                     \n",
      "2018-01-01           1.33\n",
      "2018-01-02           1.42\n",
      "2018-01-03           1.42\n",
      "2018-01-04           1.42\n",
      "2018-01-05           1.42\n",
      "...                   ...\n",
      "2023-12-27           5.33\n",
      "2023-12-28           5.33\n",
      "2023-12-29           5.33\n",
      "2023-12-30           5.33\n",
      "2023-12-31           5.33\n",
      "\n",
      "[2191 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "# Function to fetch data from FRED API\n",
    "def fetch_interest_rate_data(api_key, series_id, start_date, end_date):\n",
    "    url = f\"https://api.stlouisfed.org/fred/series/observations\"\n",
    "    params = {\n",
    "        \"series_id\": series_id,\n",
    "        \"api_key\": api_key,\n",
    "        \"file_type\": \"json\",\n",
    "        \"observation_start\": start_date,\n",
    "        \"observation_end\": end_date,\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to fetch data: {response.status_code}\")\n",
    "    data = response.json()\n",
    "    if 'observations' not in data:\n",
    "        raise KeyError(\"'observations' not found in the API response\")\n",
    "    observations = data['observations']\n",
    "    dates = [obs['date'] for obs in observations]\n",
    "    values = [float(obs['value']) for obs in observations]\n",
    "    return pd.DataFrame({'date': dates, 'interest_rate': values})\n",
    "\n",
    "# Your FRED API key\n",
    "api_key = '8b04ec256d29b1e56af63386ba61ebe1'\n",
    "series_id = 'DFF'  # This is the FRED series ID for the Federal Funds Rate\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2023-12-31'\n",
    "\n",
    "try:\n",
    "    # Fetch the interest rate data\n",
    "    interest_rate_df = fetch_interest_rate_data(api_key, series_id, start_date, end_date)\n",
    "    interest_rate_df['date'] = pd.to_datetime(interest_rate_df['date'])\n",
    "    interest_rate_df.set_index('date', inplace=True)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "print(interest_rate_df)\n",
    "# Assume you already have your daily OHLC data in a DataFrame called ohlc_df\n",
    "# Example OHLC DataFrame structure\n",
    "ohlc_df = pd.DataFrame({\n",
    "    'date': pd.date_range(start='2018-01-01', end='2023-12-31', freq='B'),\n",
    "    'open': 100 + np.random.randn(1516).cumsum(),\n",
    "    'high': 100 + np.random.randn(1516).cumsum(),\n",
    "    'low': 100 + np.random.randn(1516).cumsum(),\n",
    "    'close': 100 + np.random.randn(1516).cumsum()\n",
    "})\n",
    "ohlc_df['date'] = pd.to_datetime(ohlc_df['date'])\n",
    "ohlc_df.set_index('date', inplace=True)\n",
    "\n",
    "if 'interest_rate_df' in locals():\n",
    "    # Merge and backfill the interest rate data to match the OHLC data frequency\n",
    "    merged_df = ohlc_df.merge(interest_rate_df, left_index=True, right_index=True, how='left')\n",
    "    merged_df['interest_rate'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "    # Display the merged DataFrame\n",
    "    print(merged_df.head(10))\n",
    "else:\n",
    "    print(\"Interest rate data was not successfully fetched.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            interest_rate\n",
      "date                     \n",
      "2018-01-01           1.33\n",
      "2018-01-02           1.42\n",
      "2018-01-03           1.42\n",
      "2018-01-04           1.42\n",
      "2018-01-05           1.42\n",
      "...                   ...\n",
      "2023-12-27           5.33\n",
      "2023-12-28           5.33\n",
      "2023-12-29           5.33\n",
      "2023-12-30           5.33\n",
      "2023-12-31           5.33\n",
      "\n",
      "[2191 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "# Function to fetch data from FRED API\n",
    "def fetch_interest_rate_data(api_key, series_id, start_date, end_date):\n",
    "    url = f\"https://api.stlouisfed.org/fred/series/observations\"\n",
    "    params = {\n",
    "        \"series_id\": series_id,\n",
    "        \"api_key\": api_key,\n",
    "        \"file_type\": \"json\",\n",
    "        \"observation_start\": start_date,\n",
    "        \"observation_end\": end_date,\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to fetch data: {response.status_code}\")\n",
    "    data = response.json()\n",
    "    if 'observations' not in data:\n",
    "        raise KeyError(\"'observations' not found in the API response\")\n",
    "    observations = data['observations']\n",
    "    dates = [obs['date'] for obs in observations]\n",
    "    values = [float(obs['value']) for obs in observations]\n",
    "    return pd.DataFrame({'date': dates, 'interest_rate': values})\n",
    "\n",
    "# Your FRED API key\n",
    "api_key = '8b04ec256d29b1e56af63386ba61ebe1'\n",
    "series_id = 'DFF'  # This is the FRED series ID for the Federal Funds Rate\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2023-12-31'\n",
    "\n",
    "try:\n",
    "    # Fetch the interest rate data\n",
    "    interest_rate_df = fetch_interest_rate_data(api_key, series_id, start_date, end_date)\n",
    "    interest_rate_df['date'] = pd.to_datetime(interest_rate_df['date'])\n",
    "    interest_rate_df.set_index('date', inplace=True)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "print(interest_rate_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x258eff93070>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interest_rate_df.plot(figsize=(20,4))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.axhline(y=interest_rate_df['interest_rate'].values.mean(), color='black', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def detect_dc_events(prices, threshold):\n",
    "    dc_events = []\n",
    "    peak = prices[0]\n",
    "    trough = prices[0]\n",
    "    last_dc = None\n",
    "    for i, price in enumerate(prices):\n",
    "        if price >= peak:\n",
    "            peak = price\n",
    "            if (peak - trough) / trough >= threshold:\n",
    "                dc_events.append(('Upturn', i, price))\n",
    "                last_dc = 'Upturn'\n",
    "                trough = peak\n",
    "        elif price <= trough:\n",
    "            trough = price\n",
    "            if (peak - trough) / peak >= threshold:\n",
    "                dc_events.append(('Downturn', i, price))\n",
    "                last_dc = 'Downturn'\n",
    "                peak = trough\n",
    "    return dc_events\n",
    "\n",
    "df = yf.download('AAPL', start='2020-01-01', end='2020-12-31')\n",
    "prices = df['Close'].values\n",
    "threshold = 0.15\n",
    "dc_events = detect_dc_events(prices, threshold)\n",
    "\n",
    "# Separate events into timestamps and prices\n",
    "event_dates = [df.index[event[1]] for event in dc_events]\n",
    "event_prices = [event[2] for event in dc_events]\n",
    "event_types = [event[0] for event in dc_events]\n",
    "\n",
    "# Plotting the close prices and DC events\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(df['Close'], label='Close Price')\n",
    "\n",
    "# Plotting upturns and downturns with different colors\n",
    "upturn_dates = [event_dates[i] for i in range(len(event_dates)) if event_types[i] == 'Upturn']\n",
    "upturn_prices = [event_prices[i] for i in range(len(event_prices)) if event_types[i] == 'Upturn']\n",
    "downturn_dates = [event_dates[i] for i in range(len(event_dates)) if event_types[i] == 'Downturn']\n",
    "downturn_prices = [event_prices[i] for i in range(len(event_prices)) if event_types[i] == 'Downturn']\n",
    "\n",
    "plt.scatter(upturn_dates, upturn_prices, color='green', marker='^', label='Upturn')\n",
    "plt.scatter(downturn_dates, downturn_prices, color='red', marker='v', label='Downturn')\n",
    "\n",
    "plt.title('Close Price with Directional Change (DC) Events')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'interest_rate_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ic(\u001b[43minterest_rate_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterest_rate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mmean())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'interest_rate_df' is not defined"
     ]
    }
   ],
   "source": [
    "ic(interest_rate_df['interest_rate'].values.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'foo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfoo\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m123\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'foo' is not defined"
     ]
    }
   ],
   "source": [
    "print(foo('123'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'foo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfoo(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m123\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mfoo\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m123\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'foo' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"foo('123')\", foo('123'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| foo(123): 456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "456"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from icecream import ic\n",
    "\n",
    "def foo(i):\n",
    "    return i + 333\n",
    "\n",
    "ic(foo(123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| d['key'][1]: 'one'\n",
      "ic| klass.attr: 'yep'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yep'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'key': {1: 'one'}}\n",
    "ic(d['key'][1])\n",
    "\n",
    "class klass():\n",
    "    attr = 'yep'\n",
    "ic(klass.attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'first' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     10\u001b[0m         third()\n\u001b[1;32m---> 12\u001b[0m \u001b[43mfoo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m, in \u001b[0;36mfoo\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfoo\u001b[39m():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mfirst\u001b[49m()\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m expression:\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'first' is not defined"
     ]
    }
   ],
   "source": [
    "def foo():\n",
    "    print(0)\n",
    "    first()\n",
    "\n",
    "    if expression:\n",
    "        print(1)\n",
    "        second()\n",
    "    else:\n",
    "        print(2)\n",
    "        third()\n",
    "\n",
    "foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84285542, 0.35887187],\n",
       "       [0.82439832, 0.49185069],\n",
       "       [0.42440946, 0.41856043],\n",
       "       [0.33268943, 0.62471114],\n",
       "       [0.2086117 , 0.50295085]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random([5,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import finrl \n",
    "from finrl import config \n",
    "from finrl.config_tickers import DOW_30_TICKER\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--optional_arg OPTIONAL_ARG] positional_arg\n",
      "ipykernel_launcher.py: error: the following arguments are required: positional_arg\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "# Create an ArgumentParser object\n",
    "parser = argparse.ArgumentParser(description=\"My Script Description\")\n",
    "\n",
    "# Add a positional argument (required)\n",
    "parser.add_argument(\"positional_arg\", help=\"This is a required argument\")\n",
    "\n",
    "# Add an optional argument with a default value\n",
    "parser.add_argument(\"--optional_arg\", default=\"default_value\", help=\"This is an optional argument\")\n",
    "\n",
    "# Parse the arguments from sys.argv\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Access the arguments\n",
    "print(\"Positional argument:\", args.positional_arg)\n",
    "print(\"Optional argument:\", args.optional_arg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-n', '--number'], dest='number', nargs=None, const=None, default=10, type=<class 'int'>, choices=None, help='An integer value', metavar=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument(\"-f\", \"--file\", type=str, required=True, help=\"Path to a file\")\n",
    "parser.add_argument(\"-n\", \"--number\", type=int, default=10, help=\"An integer value\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --symbol SYMBOL --start-date START_DATE\n",
      "                             --end-date END_DATE --strategy\n",
      "                             {mean_reversion,momentum} [--capital CAPITAL]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --symbol, --start-date, --end-date, --strategy\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Algorithmic Trading Script\")\n",
    "    \n",
    "    parser.add_argument('--symbol', type=str, required=True, help='Stock symbol to trade')\n",
    "    parser.add_argument('--start-date', type=str, required=True, help='Start date in YYYY-MM-DD format')\n",
    "    parser.add_argument('--end-date', type=str, required=True, help='End date in YYYY-MM-DD format')\n",
    "    parser.add_argument('--strategy', type=str, required=True, choices=['mean_reversion', 'momentum'], help='Trading strategy to use')\n",
    "    parser.add_argument('--capital', type=float, default=10000, help='Initial capital in USD')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Now you can use args.symbol, args.start_date, args.end_date, args.strategy, and args.capital in your trading logic\n",
    "    print(f\"Trading {args.symbol} from {args.start_date} to {args.end_date} using {args.strategy} strategy with ${args.capital} capital.\")\n",
    "    \n",
    "    # Example of using these arguments in trading logic\n",
    "    # perform_trading(symbol=args.symbol, start_date=args.start_date, end_date=args.end_date, strategy=args.strategy, capital=args.capital)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid parameter: name with value ahmed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-02</th>\n",
       "      <td>38.722500</td>\n",
       "      <td>39.712502</td>\n",
       "      <td>38.557499</td>\n",
       "      <td>39.480000</td>\n",
       "      <td>37.845047</td>\n",
       "      <td>148158800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>35.994999</td>\n",
       "      <td>36.430000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>35.547501</td>\n",
       "      <td>34.075397</td>\n",
       "      <td>365248800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>36.132500</td>\n",
       "      <td>37.137501</td>\n",
       "      <td>35.950001</td>\n",
       "      <td>37.064999</td>\n",
       "      <td>35.530052</td>\n",
       "      <td>234428400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close     Volume\n",
       "Date                                                                        \n",
       "2019-01-02  38.722500  39.712502  38.557499  39.480000  37.845047  148158800\n",
       "2019-01-03  35.994999  36.430000  35.500000  35.547501  34.075397  365248800\n",
       "2019-01-04  36.132500  37.137501  35.950001  37.064999  35.530052  234428400"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "def yahoo_downloader(symbol='AAPL', **kwargs):\n",
    "\n",
    "    recognize_params = ['start_date', 'end_date', 'interval']\n",
    "\n",
    "    start_date = kwargs.get('start_date', '2019-01-01')\n",
    "    end_date = kwargs.get('end_date', '2020-12-31')\n",
    "    interval = kwargs.get('interval', '1d')\n",
    "    \n",
    "    for key in kwargs:\n",
    "        if key not in recognize_params:\n",
    "            print(f\"Invalid parameter: {key} with value {kwargs[key]}\")\n",
    "\n",
    "    data = yf.download(symbol, start=start_date, end=end_date, interval=interval)\n",
    "    return data\n",
    "\n",
    "yahoo_downloader('AAPL', name='ahmed').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, yfinance as yf\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>0.067894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>-0.618992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>0.646289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>-1.170088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>0.827327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>1.268497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2920 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               value\n",
       "date                \n",
       "2016-01-01  0.067894\n",
       "2016-01-02       NaN\n",
       "2016-01-03       NaN\n",
       "2016-01-04 -0.618992\n",
       "2016-01-05  0.646289\n",
       "...              ...\n",
       "2023-12-27 -1.170088\n",
       "2023-12-28  0.827327\n",
       "2023-12-29  1.268497\n",
       "2023-12-30       NaN\n",
       "2023-12-31       NaN\n",
       "\n",
       "[2920 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pd.date_range(start='2016-01-01', end='2023-12-31', freq='B')\n",
    "val = np.random.randn(len(index))\n",
    "\n",
    "# Create the initial dataset with business days\n",
    "dataset = pd.DataFrame({\n",
    "    'date': index,\n",
    "    'value': val\n",
    "})\n",
    "\n",
    "# Generate a full date range for the entire year\n",
    "full_index = pd.date_range(start='2016-01-01', end='2023-12-31', freq='D')\n",
    "\n",
    "# Reindex the dataset to the full date range\n",
    "# dataset = dataset.set_index('date').reindex(full_index).rename_axis('date').reset_index()\n",
    "# dataset = dataset[~((dataset['date'].dt.month == 2) & (dataset['date'].dt.day == 29))]\n",
    "\n",
    "dataset = dataset.set_index('date').reindex(full_index).rename_axis('date')\n",
    "\n",
    "# Exclude the leap day (2020-02-29)\n",
    "dataset = dataset[~((dataset.index.month == 2) & (dataset.index.day == 29))]\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2920\n",
      "Year\n",
      "2016    365\n",
      "2017    365\n",
      "2018    365\n",
      "2019    365\n",
      "2020    365\n",
      "2021    365\n",
      "2022    365\n",
      "2023    365\n",
      "Name: count, dtype: int64\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "Year         0\n",
      "dtype: int64\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\razaa\\AppData\\Local\\Temp\\ipykernel_19920\\3769557020.py:5: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\razaa\\AppData\\Local\\Temp\\ipykernel_19920\\3769557020.py:6: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df = yf.download('BTC-USD', start='2016-01-01', end='2023-12-31', interval='1D')\n",
    "df.reset_index(inplace=True)\n",
    "full_index = pd.date_range(start='2016-01-01', end='2023-12-31', freq='D')\n",
    "df = df.set_index('Date').reindex(full_index).rename_axis('Date')\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "df = df[~((df.index.month == 2) & (df.index.day == 29))]\n",
    "df['Year'] = df.index.year\n",
    "print(len(df))\n",
    "print(df['Year'].value_counts())\n",
    "print(df.isna().sum())\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2085\n",
      "Year\n",
      "2020    262\n",
      "2018    261\n",
      "2019    261\n",
      "2021    261\n",
      "2016    260\n",
      "2017    260\n",
      "2022    260\n",
      "2023    260\n",
      "Name: count, dtype: int64\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "Year         0\n",
      "dtype: int64\n",
      "68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\razaa\\AppData\\Local\\Temp\\ipykernel_19920\\1887837775.py:5: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\razaa\\AppData\\Local\\Temp\\ipykernel_19920\\1887837775.py:6: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df = yf.download('AAPL', start='2016-01-01', end='2023-12-31', interval='1D')\n",
    "df.reset_index(inplace=True)\n",
    "full_index = pd.date_range(start='2016-01-01', end='2023-12-31', freq='B')\n",
    "df = df.set_index('Date').reindex(full_index).rename_axis('Date')\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "df = df[~((df.index.month == 2) & (df.index.day == 29))]\n",
    "df['Year'] = df.index.year\n",
    "print(len(df))\n",
    "print(df['Year'].value_counts())\n",
    "print(df.isna().sum())\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd, numpy as np, datetime as dt \n",
    "import talib as ta\n",
    "import time, timeit\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "C:\\Users\\razaa\\AppData\\Local\\Temp\\ipykernel_19920\\1173667104.py:22: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\razaa\\AppData\\Local\\Temp\\ipykernel_19920\\1173667104.py:23: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-02</th>\n",
       "      <td>38.722500</td>\n",
       "      <td>39.712502</td>\n",
       "      <td>38.557499</td>\n",
       "      <td>39.480000</td>\n",
       "      <td>37.845043</td>\n",
       "      <td>148158800.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>35.994999</td>\n",
       "      <td>36.430000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>35.547501</td>\n",
       "      <td>34.075394</td>\n",
       "      <td>365248800.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>36.132500</td>\n",
       "      <td>37.137501</td>\n",
       "      <td>35.950001</td>\n",
       "      <td>37.064999</td>\n",
       "      <td>35.530056</td>\n",
       "      <td>234428400.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-05</th>\n",
       "      <td>36.132500</td>\n",
       "      <td>37.137501</td>\n",
       "      <td>35.950001</td>\n",
       "      <td>37.064999</td>\n",
       "      <td>35.530056</td>\n",
       "      <td>234428400.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-06</th>\n",
       "      <td>36.132500</td>\n",
       "      <td>37.137501</td>\n",
       "      <td>35.950001</td>\n",
       "      <td>37.064999</td>\n",
       "      <td>35.530056</td>\n",
       "      <td>234428400.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close  \\\n",
       "Date                                                                \n",
       "2019-01-02  38.722500  39.712502  38.557499  39.480000  37.845043   \n",
       "2019-01-03  35.994999  36.430000  35.500000  35.547501  34.075394   \n",
       "2019-01-04  36.132500  37.137501  35.950001  37.064999  35.530056   \n",
       "2019-01-05  36.132500  37.137501  35.950001  37.064999  35.530056   \n",
       "2019-01-06  36.132500  37.137501  35.950001  37.064999  35.530056   \n",
       "\n",
       "                 Volume  Year  \n",
       "Date                           \n",
       "2019-01-02  148158800.0  2019  \n",
       "2019-01-03  365248800.0  2019  \n",
       "2019-01-04  234428400.0  2019  \n",
       "2019-01-05  234428400.0  2019  \n",
       "2019-01-06  234428400.0  2019  "
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def yahoo_downloader(symbol: str = 'AAPL', **kwargs):\n",
    "    \"\"\"\n",
    "    Downloads historical price data from Yahoo Finance for a given symbol.\n",
    "    \"\"\"\n",
    "    start_date = kwargs.get('start_date', '2015-01-01')\n",
    "    end_date = kwargs.get('end_date', '2023-12-31')\n",
    "    intervel = kwargs.get('interval', '1d')\n",
    "\n",
    "    data = yf.download(symbol, start=start_date, end=end_date, interval=intervel) \n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocessor(df: pd.DataFrame, **kwargs):\n",
    "    \"\"\"\n",
    "    Preprocesses the data by calculating technical indicators and filling missing values.\n",
    "    \"\"\"\n",
    "    # Calculate technical indicators\n",
    "    df = df.reset_index()\n",
    "    full_index = pd.date_range(start=df['Date'].min(), end=df['Date'].max(), freq='D')\n",
    "    df = df.set_index('Date').reindex(full_index).rename_axis('Date')\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    df.fillna(method='bfill', inplace=True)\n",
    "    df = df[~((df.index.month == 2) & (df.index.day == 29))]\n",
    "    df['Year'] = df.index.year\n",
    "    return df \n",
    "\n",
    "\n",
    "df1 = preprocessor(yahoo_downloader('AAPL', start_date='2019-01-01', end_date='2023-12-31', interval='1d'))\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year\n",
       "2019    364\n",
       "2020    365\n",
       "2021    365\n",
       "2022    365\n",
       "2023    363\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Year'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "def histogram_plot(df: pd.DataFrame,  **kwargs):\n",
    "    \"\"\"\n",
    "    Plots a histogram of the data.\n",
    "    \"\"\"\n",
    "    column = kwargs.get('column', 'Adj Close')\n",
    "    sns.histplot(df[column], bins=50, kde=True)\n",
    "\n",
    "\n",
    "histogram_plot(df1, column='Close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['return'] = df1['Adj Close'].pct_change()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "histogram_plot(df1, column='return')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Index' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[309], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturn\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Index' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "if 'return' in df1.columns:\n",
    "    print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calling column seclector from sklearn \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Define the scalers\n",
    "scaler1 = StandardScaler()\n",
    "scaler2 = MinMaxScaler()\n",
    "\n",
    "# Column transformer setup\n",
    "col_trans = ColumnTransformer([\n",
    "    ('StandardScaler', scaler1, ['return']),\n",
    "    ('MinMaxScaler', scaler2, ['Open', 'High', 'Low', 'Close', 'Volume'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Apply the transformation\n",
    "transfer_data = col_trans.fit_transform(df1)\n",
    "\n",
    "# Convert the result back to a DataFrame\n",
    "transformed_df = pd.DataFrame(transfer_data, columns=['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'return'])\n",
    "\n",
    "# Plot the transformed 'Close' column\n",
    "transformed_df['Open'].plot()\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Scaled Close')\n",
    "plt.title('Scaled Close Price')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016834</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.018932</td>\n",
       "      <td>0.024191</td>\n",
       "      <td>0.308378</td>\n",
       "      <td>37.845043</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.962870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.847784</td>\n",
       "      <td>34.075394</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.467907</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.004335</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.009335</td>\n",
       "      <td>0.522733</td>\n",
       "      <td>35.530056</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.061351</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.004335</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.009335</td>\n",
       "      <td>0.522733</td>\n",
       "      <td>35.530056</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.061351</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.004335</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.009335</td>\n",
       "      <td>0.522733</td>\n",
       "      <td>35.530056</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date      Open      High       Low     Close  Adj Close     Volume  \\\n",
       "0       NaN  0.016834  0.020115  0.018932  0.024191   0.308378  37.845043   \n",
       "1 -5.962870  0.000000  0.000000  0.000000  0.000000   0.847784  34.075394   \n",
       "2  2.467907  0.000849  0.004335  0.002786  0.009335   0.522733  35.530056   \n",
       "3 -0.061351  0.000849  0.004335  0.002786  0.009335   0.522733  35.530056   \n",
       "4 -0.061351  0.000849  0.004335  0.002786  0.009335   0.522733  35.530056   \n",
       "\n",
       "   return  \n",
       "0  2019.0  \n",
       "1  2019.0  \n",
       "2  2019.0  \n",
       "3  2019.0  \n",
       "4  2019.0  "
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaler(df: pd.DataFrame, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns a scaler object for the data.\n",
    "    \"\"\"\n",
    "    if 'return' in df.columns:\n",
    "        scaler = StandardScaler()\n",
    "        return scaler.fit(df['return'].values.reshape(-1, 1))\n",
    "\n",
    "    elif 'Close' in df.columns:\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "    column = kwargs.get('column', 'Adj Close')\n",
    "    scaler = MinMaxScaler()\n",
    "    return scaler.fit(df[column].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(dataset: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Returns descriptive statistics for the dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (pd.DataFrame): The dataset to analyze.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the calculated statistics:\n",
    "            - maxChangepercent\n",
    "            - year5Changepercent\n",
    "            - year2Changepercent\n",
    "            - year1Changepercent\n",
    "            - month6Changepercent\n",
    "            - month3Changepercent\n",
    "            - month1Changepercent\n",
    "            - day5Changepercent\n",
    "            - day30Changepercent\n",
    "    \"\"\"\n",
    "\n",
    "    if 'Adj Close' in dataset.columns:\n",
    "        dataset['return'] = dataset['Adj Close'].pct_change()\n",
    "    else:\n",
    "        dataset['return'] = dataset['Close'].pct_change()\n",
    "\n",
    "    # Get MaxChangepercent\n",
    "    maxChangepercent = dataset['return'].max()\n",
    "\n",
    "    # Define the time periods in days (approximations)\n",
    "    time_periods = {\n",
    "        'year5Changepercent': 252 * 5,\n",
    "        'year2Changepercent': 252 * 2,\n",
    "        'year1Changepercent': 252,\n",
    "        'month6Changepercent': 21 * 6,\n",
    "        'month3Changepercent': 21 * 3,\n",
    "        'month1Changepercent': 21,\n",
    "        'day30Changepercent': 30,\n",
    "        'day5Changepercent': 5\n",
    "    }\n",
    "\n",
    "    stats = {'maxChangepercent': maxChangepercent}\n",
    "\n",
    "    # Calculate rolling means for each time period if enough data is available\n",
    "    for key, period in time_periods.items():\n",
    "        if len(dataset) >= period:\n",
    "            value = dataset['return'].rolling(period).mean().iloc[-1]\n",
    "            print(value)\n",
    "            stats[key] = f\"{value * 100:.5f}%\"\n",
    "        else:\n",
    "            stats[key] = 'Not enough data points'\n",
    "\n",
    "    # Format maxChangepercent in percentage\n",
    "    stats['maxChangepercent'] = f\"{stats['maxChangepercent'] * 100:.3f}%\"\n",
    "\n",
    "    return stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0015055335364521645\n",
      "0.00033037619744483995\n",
      "0.0017868471589326115\n",
      "3.204306665016346e-05\n",
      "0.0019329472381183791\n",
      "0.0008256306184326283\n",
      "0.0008229790070471236\n",
      "-0.0022136487405562066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = yf.download('AAPL', start='2016-01-01', end='2023-12-31', interval='1D')\n",
    "df_keys = get_stats(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['maxChangepercent', 'year5Changepercent', 'year2Changepercent', 'year1Changepercent', 'month6Changepercent', 'month3Changepercent', 'month1Changepercent', 'day30Changepercent', 'day5Changepercent'])\n"
     ]
    }
   ],
   "source": [
    "print(df_keys.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'maxChangepercent': 74.73604120318032, 'year5Changepercent': 51.60739087382639, 'year2Changepercent': 51.60739087382639, 'year1Changepercent': 14.362663449915896, 'month6Changepercent': 9.371177808017398, 'month3Changepercent': 24.46732417190292, 'month1Changepercent': 13.636766691423006, 'day30Changepercent': 16.01441770069517, 'day5Changepercent': -1.9871708421700904}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def get_stock_stats(stock_data: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate percentage changes for different time periods.\n",
    "    \n",
    "    Parameters:\n",
    "    - stock_data: pd.DataFrame containing stock data with 'Adj Close' or 'Close' columns.\n",
    "    \n",
    "    Returns:\n",
    "    - changes: dict containing percentage changes for specified periods.\n",
    "    \"\"\"\n",
    "    \n",
    "    periods = {\n",
    "        'year5': 5 * 252,\n",
    "        'year2': 2 * 252,\n",
    "        'year1': 252,\n",
    "        'month6': 6 * 21,\n",
    "        'month3': 3 * 21,\n",
    "        'month1': 21,\n",
    "        'day30': 30,\n",
    "        'day5': 5\n",
    "    }\n",
    "\n",
    "    changes = {}\n",
    "    column_name = 'Adj Close' if 'Adj Close' in stock_data.columns else 'Close'\n",
    "    stock_data = stock_data[column_name]\n",
    "\n",
    "    # Calculate max change percentage\n",
    "    max_price = stock_data.max()\n",
    "    min_price = stock_data.min()\n",
    "    latest_close = stock_data.iloc[-1]\n",
    "\n",
    "    changes['maxChangepercent'] = ((max_price - min_price) / min_price) * 100\n",
    "\n",
    "    # Calculate change percentages for each period\n",
    "    for period_name, period_days in periods.items():\n",
    "        period_days = min(period_days, len(stock_data))  # Ensure we do not exceed available data\n",
    "        past_close = stock_data.iloc[-period_days] if period_days > 0 else latest_close\n",
    "        changes[f'{period_name}Changepercent'] = ((latest_close - past_close) / past_close) * 100\n",
    "\n",
    "    return changes\n",
    "\n",
    "# Example usage\n",
    "ticker = 'AAPL'  # Replace with your desired stock ticker\n",
    "stock_data = yf.download(ticker, period='2y')\n",
    "stock_changes = get_stock_stats(stock_data)\n",
    "print(stock_changes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  10 of 10 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>ADA-USD</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>DASH-USD</th>\n",
       "      <th>DOGE-USD</th>\n",
       "      <th>ETH-USD</th>\n",
       "      <th>LTC-USD</th>\n",
       "      <th>TRX-USD</th>\n",
       "      <th>XLM-USD</th>\n",
       "      <th>XMR-USD</th>\n",
       "      <th>XRP-USD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>434.334015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.50898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>433.437988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.50216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>430.010986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.48307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>433.091003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.49539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>431.959991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.46967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker      ADA-USD     BTC-USD  DASH-USD  DOGE-USD  ETH-USD  LTC-USD  \\\n",
       "Date                                                                    \n",
       "2016-01-01      NaN  434.334015       NaN       NaN      NaN  3.50898   \n",
       "2016-01-02      NaN  433.437988       NaN       NaN      NaN  3.50216   \n",
       "2016-01-03      NaN  430.010986       NaN       NaN      NaN  3.48307   \n",
       "2016-01-04      NaN  433.091003       NaN       NaN      NaN  3.49539   \n",
       "2016-01-05      NaN  431.959991       NaN       NaN      NaN  3.46967   \n",
       "\n",
       "Ticker      TRX-USD  XLM-USD  XMR-USD  XRP-USD  \n",
       "Date                                            \n",
       "2016-01-01      NaN      NaN      NaN      NaN  \n",
       "2016-01-02      NaN      NaN      NaN      NaN  \n",
       "2016-01-03      NaN      NaN      NaN      NaN  \n",
       "2016-01-04      NaN      NaN      NaN      NaN  \n",
       "2016-01-05      NaN      NaN      NaN      NaN  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of crypto tickers \n",
    "\n",
    "crypto = ['BTC-USD', 'ETH-USD', 'XRP-USD', 'LTC-USD', 'XLM-USD', 'ADA-USD', 'TRX-USD', 'XMR-USD', 'DOGE-USD', 'DASH-USD']\n",
    "\n",
    "df = yf.download(crypto, start='2016-01-01', end='2023-12-31', interval='1D')['Close']\n",
    "df1 = df.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>ADA-USD</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>DASH-USD</th>\n",
       "      <th>DOGE-USD</th>\n",
       "      <th>ETH-USD</th>\n",
       "      <th>LTC-USD</th>\n",
       "      <th>TRX-USD</th>\n",
       "      <th>XLM-USD</th>\n",
       "      <th>XMR-USD</th>\n",
       "      <th>XRP-USD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>0.032053</td>\n",
       "      <td>7143.580078</td>\n",
       "      <td>326.007996</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>320.884003</td>\n",
       "      <td>64.269699</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>0.039946</td>\n",
       "      <td>120.779999</td>\n",
       "      <td>0.217488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>0.027119</td>\n",
       "      <td>6618.140137</td>\n",
       "      <td>329.571014</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>299.252991</td>\n",
       "      <td>59.260101</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.033073</td>\n",
       "      <td>105.585999</td>\n",
       "      <td>0.206483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>0.027437</td>\n",
       "      <td>6357.600098</td>\n",
       "      <td>346.056000</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>314.681000</td>\n",
       "      <td>62.303299</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.033053</td>\n",
       "      <td>119.615997</td>\n",
       "      <td>0.210430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12</th>\n",
       "      <td>0.023977</td>\n",
       "      <td>5950.069824</td>\n",
       "      <td>536.116028</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>307.907990</td>\n",
       "      <td>59.005402</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.028182</td>\n",
       "      <td>123.856003</td>\n",
       "      <td>0.197339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>0.025808</td>\n",
       "      <td>6559.490234</td>\n",
       "      <td>427.372986</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>316.716003</td>\n",
       "      <td>61.396500</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>0.030656</td>\n",
       "      <td>123.402000</td>\n",
       "      <td>0.203442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker       ADA-USD      BTC-USD    DASH-USD  DOGE-USD     ETH-USD  \\\n",
       "Date                                                                  \n",
       "2017-11-09  0.032053  7143.580078  326.007996  0.001415  320.884003   \n",
       "2017-11-10  0.027119  6618.140137  329.571014  0.001163  299.252991   \n",
       "2017-11-11  0.027437  6357.600098  346.056000  0.001201  314.681000   \n",
       "2017-11-12  0.023977  5950.069824  536.116028  0.001038  307.907990   \n",
       "2017-11-13  0.025808  6559.490234  427.372986  0.001211  316.716003   \n",
       "\n",
       "Ticker        LTC-USD   TRX-USD   XLM-USD     XMR-USD   XRP-USD  \n",
       "Date                                                             \n",
       "2017-11-09  64.269699  0.002344  0.039946  120.779999  0.217488  \n",
       "2017-11-10  59.260101  0.002013  0.033073  105.585999  0.206483  \n",
       "2017-11-11  62.303299  0.002003  0.033053  119.615997  0.210430  \n",
       "2017-11-12  59.005402  0.001783  0.028182  123.856003  0.197339  \n",
       "2017-11-13  61.396500  0.002112  0.030656  123.402000  0.203442  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dropna(inplace=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_columns = ['index', 'Stock', 'Price', 'One year return']\n",
    "new_df = pd.DataFrame(columns=my_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "new_df['Stock'] = df1.columns\n",
    "\n",
    "for i in range(len(df1.columns)):\n",
    "    new_df.iloc[i, 0] = i\n",
    "    print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ticker\n",
       "ADA-USD         0.601964\n",
       "BTC-USD     42156.902344\n",
       "DASH-USD       32.946571\n",
       "DOGE-USD        0.090148\n",
       "ETH-USD      2292.065430\n",
       "LTC-USD        73.312737\n",
       "TRX-USD         0.105985\n",
       "XLM-USD         0.132611\n",
       "XMR-USD       165.771484\n",
       "XRP-USD         0.621844\n",
       "Name: 2023-12-30 00:00:00, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.601963996887207,\n",
       " 42156.90234375,\n",
       " 32.946571350097656,\n",
       " 0.09014800190925598,\n",
       " 2292.0654296875,\n",
       " 73.31273651123047,\n",
       " 0.10598500072956085,\n",
       " 0.1326110064983368,\n",
       " 165.771484375,\n",
       " 0.6218439936637878]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_list = []\n",
    "last_close = []\n",
    "for i in range(len(df1.columns)):\n",
    "    stock_list.append(df1.columns[i]), last_close.append(df1.iloc[-1, i])\n",
    "\n",
    "get_stock_stats(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assets</th>\n",
       "      <th>Last close</th>\n",
       "      <th>One year return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADA-USD</td>\n",
       "      <td>0.601964</td>\n",
       "      <td>54.746529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>42156.902344</td>\n",
       "      <td>52.790093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DASH-USD</td>\n",
       "      <td>32.946571</td>\n",
       "      <td>-34.366478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DOGE-USD</td>\n",
       "      <td>0.090148</td>\n",
       "      <td>14.371993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ETH-USD</td>\n",
       "      <td>2292.06543</td>\n",
       "      <td>23.092862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LTC-USD</td>\n",
       "      <td>73.312737</td>\n",
       "      <td>-15.632918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TRX-USD</td>\n",
       "      <td>0.105985</td>\n",
       "      <td>58.952871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XLM-USD</td>\n",
       "      <td>0.132611</td>\n",
       "      <td>40.220791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XMR-USD</td>\n",
       "      <td>165.771484</td>\n",
       "      <td>5.342547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XRP-USD</td>\n",
       "      <td>0.621844</td>\n",
       "      <td>33.725288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Assets    Last close One year return\n",
       "0   ADA-USD      0.601964       54.746529\n",
       "1   BTC-USD  42156.902344       52.790093\n",
       "2  DASH-USD     32.946571      -34.366478\n",
       "3  DOGE-USD      0.090148       14.371993\n",
       "4   ETH-USD    2292.06543       23.092862\n",
       "5   LTC-USD     73.312737      -15.632918\n",
       "6   TRX-USD      0.105985       58.952871\n",
       "7   XLM-USD      0.132611       40.220791\n",
       "8   XMR-USD    165.771484        5.342547\n",
       "9   XRP-USD      0.621844       33.725288"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_return(df: pd.DataFrame, years: int = 1):\n",
    "\n",
    "    timeperiod = 252 * years\n",
    "    if timeperiod <= len(df):\n",
    "        lastes_close = df.iloc[-1]\n",
    "        past_close = df.iloc[-timeperiod]\n",
    "    else:\n",
    "        print('Not enough data points : available data points = ' + str(len(df)/252))\n",
    "\n",
    "    stock_retun = (lastes_close - past_close) / past_close * 100\n",
    "\n",
    "    new_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    new_df.loc[0] = df.columns\n",
    "    new_df.loc[2] = df.iloc[-1]\n",
    "    new_df.loc[1] = stock_retun\n",
    "    new_df = new_df.T\n",
    "    new_df.columns = ['Assets', 'Last close', 'One year return']\n",
    "    new_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "return_hist = get_return(df1, 1)\n",
    "return_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_hist.sort_values('One year return', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assets</th>\n",
       "      <th>Last close</th>\n",
       "      <th>One year return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TRX-USD</td>\n",
       "      <td>0.105985</td>\n",
       "      <td>58.952871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADA-USD</td>\n",
       "      <td>0.601964</td>\n",
       "      <td>54.746529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>42156.902344</td>\n",
       "      <td>52.790093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XLM-USD</td>\n",
       "      <td>0.132611</td>\n",
       "      <td>40.220791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XRP-USD</td>\n",
       "      <td>0.621844</td>\n",
       "      <td>33.725288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ETH-USD</td>\n",
       "      <td>2292.06543</td>\n",
       "      <td>23.092862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DOGE-USD</td>\n",
       "      <td>0.090148</td>\n",
       "      <td>14.371993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XMR-USD</td>\n",
       "      <td>165.771484</td>\n",
       "      <td>5.342547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LTC-USD</td>\n",
       "      <td>73.312737</td>\n",
       "      <td>-15.632918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DASH-USD</td>\n",
       "      <td>32.946571</td>\n",
       "      <td>-34.366478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Assets    Last close One year return\n",
       "6   TRX-USD      0.105985       58.952871\n",
       "0   ADA-USD      0.601964       54.746529\n",
       "1   BTC-USD  42156.902344       52.790093\n",
       "7   XLM-USD      0.132611       40.220791\n",
       "9   XRP-USD      0.621844       33.725288\n",
       "4   ETH-USD    2292.06543       23.092862\n",
       "3  DOGE-USD      0.090148       14.371993\n",
       "8   XMR-USD    165.771484        5.342547\n",
       "5   LTC-USD     73.312737      -15.632918\n",
       "2  DASH-USD     32.946571      -34.366478"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_input():\n",
    "    portfolio_size = input(\"Enter the value of your portfolio:\")\n",
    "\n",
    "    try:\n",
    "        float(portfolio_size)\n",
    "    except ValueError:\n",
    "        print(\"That's not a number! \\n Try again:\")\n",
    "        portfolio_size = input(\"Enter the value of your portfolio:\")\n",
    "    return portfolio_size\n",
    "\n",
    "def position_size():\n",
    "    \n",
    "    position_size = float(portfolio_value) / len(df1.columns)\n",
    "    \n",
    "    return position_size\n",
    "\n",
    "portfolio_value = float(portfolio_input())\n",
    "position_size = position_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assets</th>\n",
       "      <th>Last close</th>\n",
       "      <th>One year return</th>\n",
       "      <th>Number of Share to buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TRX-USD</td>\n",
       "      <td>0.105985</td>\n",
       "      <td>58.952871</td>\n",
       "      <td>9435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADA-USD</td>\n",
       "      <td>0.601964</td>\n",
       "      <td>54.746529</td>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>42156.902344</td>\n",
       "      <td>52.790093</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XLM-USD</td>\n",
       "      <td>0.132611</td>\n",
       "      <td>40.220791</td>\n",
       "      <td>7540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XRP-USD</td>\n",
       "      <td>0.621844</td>\n",
       "      <td>33.725288</td>\n",
       "      <td>1608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ETH-USD</td>\n",
       "      <td>2292.06543</td>\n",
       "      <td>23.092862</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DOGE-USD</td>\n",
       "      <td>0.090148</td>\n",
       "      <td>14.371993</td>\n",
       "      <td>11092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XMR-USD</td>\n",
       "      <td>165.771484</td>\n",
       "      <td>5.342547</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LTC-USD</td>\n",
       "      <td>73.312737</td>\n",
       "      <td>-15.632918</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DASH-USD</td>\n",
       "      <td>32.946571</td>\n",
       "      <td>-34.366478</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Assets    Last close One year return  Number of Share to buy\n",
       "6   TRX-USD      0.105985       58.952871                    9435\n",
       "0   ADA-USD      0.601964       54.746529                    1661\n",
       "1   BTC-USD  42156.902344       52.790093                       0\n",
       "7   XLM-USD      0.132611       40.220791                    7540\n",
       "9   XRP-USD      0.621844       33.725288                    1608\n",
       "4   ETH-USD    2292.06543       23.092862                       0\n",
       "3  DOGE-USD      0.090148       14.371993                   11092\n",
       "8   XMR-USD    165.771484        5.342547                       6\n",
       "5   LTC-USD     73.312737      -15.632918                      13\n",
       "2  DASH-USD     32.946571      -34.366478                      30"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "return_hist['Number of Share to buy'] = (position_size // return_hist['Last close']).astype('int64')\n",
    "return_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assets</th>\n",
       "      <th>Last close</th>\n",
       "      <th>One year return</th>\n",
       "      <th>Number of Share to buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TRX-USD</td>\n",
       "      <td>0.105985</td>\n",
       "      <td>58.952871</td>\n",
       "      <td>9435.297383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADA-USD</td>\n",
       "      <td>0.601964</td>\n",
       "      <td>54.746529</td>\n",
       "      <td>1661.228919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>42156.902344</td>\n",
       "      <td>52.790093</td>\n",
       "      <td>0.023721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XLM-USD</td>\n",
       "      <td>0.132611</td>\n",
       "      <td>40.220791</td>\n",
       "      <td>7540.852199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XRP-USD</td>\n",
       "      <td>0.621844</td>\n",
       "      <td>33.725288</td>\n",
       "      <td>1608.120381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ETH-USD</td>\n",
       "      <td>2292.06543</td>\n",
       "      <td>23.092862</td>\n",
       "      <td>0.436288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DOGE-USD</td>\n",
       "      <td>0.090148</td>\n",
       "      <td>14.371993</td>\n",
       "      <td>11092.869269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XMR-USD</td>\n",
       "      <td>165.771484</td>\n",
       "      <td>5.342547</td>\n",
       "      <td>6.032401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LTC-USD</td>\n",
       "      <td>73.312737</td>\n",
       "      <td>-15.632918</td>\n",
       "      <td>13.640195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DASH-USD</td>\n",
       "      <td>32.946571</td>\n",
       "      <td>-34.366478</td>\n",
       "      <td>30.352172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Assets    Last close One year return Number of Share to buy\n",
       "6   TRX-USD      0.105985       58.952871            9435.297383\n",
       "0   ADA-USD      0.601964       54.746529            1661.228919\n",
       "1   BTC-USD  42156.902344       52.790093               0.023721\n",
       "7   XLM-USD      0.132611       40.220791            7540.852199\n",
       "9   XRP-USD      0.621844       33.725288            1608.120381\n",
       "4   ETH-USD    2292.06543       23.092862               0.436288\n",
       "3  DOGE-USD      0.090148       14.371993           11092.869269\n",
       "8   XMR-USD    165.771484        5.342547               6.032401\n",
       "5   LTC-USD     73.312737      -15.632918              13.640195\n",
       "2  DASH-USD     32.946571      -34.366478              30.352172"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_hist[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[249], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(new_df\u001b[38;5;241m.\u001b[39mindex)):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(new_df\u001b[38;5;241m.\u001b[39mloc[i ,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of Share to buy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m (\u001b[43mposition_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnew_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m))\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "for i in range(len(new_df.index)):\n",
    "    print(new_df.loc[i ,'Number of Share to buy'] == (position_size / new_df.iloc[i, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Price</th>\n",
       "      <th>One year return</th>\n",
       "      <th>Number of Share to buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ADA-USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>DASH-USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DOGE-USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ETH-USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>LTC-USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>TRX-USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>XLM-USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>XMR-USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>XRP-USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index     Stock  Price One year return  Number of Share to buy\n",
       "0     0   ADA-USD    NaN             NaN                       0\n",
       "1     1   BTC-USD    NaN             NaN                       0\n",
       "2     2  DASH-USD    NaN             NaN                       0\n",
       "3     3  DOGE-USD    NaN             NaN                       0\n",
       "4     4   ETH-USD    NaN             NaN                       0\n",
       "5     5   LTC-USD    NaN             NaN                       0\n",
       "6     6   TRX-USD    NaN             NaN                       0\n",
       "7     7   XLM-USD    NaN             NaN                       0\n",
       "8     8   XMR-USD    NaN             NaN                       0\n",
       "9     9   XRP-USD    NaN             NaN                       0"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>ADA-USD</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>DASH-USD</th>\n",
       "      <th>DOGE-USD</th>\n",
       "      <th>ETH-USD</th>\n",
       "      <th>LTC-USD</th>\n",
       "      <th>TRX-USD</th>\n",
       "      <th>XLM-USD</th>\n",
       "      <th>XMR-USD</th>\n",
       "      <th>XRP-USD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>0.032053</td>\n",
       "      <td>7143.580078</td>\n",
       "      <td>326.007996</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>320.884003</td>\n",
       "      <td>64.269699</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>0.039946</td>\n",
       "      <td>120.779999</td>\n",
       "      <td>0.217488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>0.027119</td>\n",
       "      <td>6618.140137</td>\n",
       "      <td>329.571014</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>299.252991</td>\n",
       "      <td>59.260101</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.033073</td>\n",
       "      <td>105.585999</td>\n",
       "      <td>0.206483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-11</th>\n",
       "      <td>0.027437</td>\n",
       "      <td>6357.600098</td>\n",
       "      <td>346.056000</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>314.681000</td>\n",
       "      <td>62.303299</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.033053</td>\n",
       "      <td>119.615997</td>\n",
       "      <td>0.210430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-12</th>\n",
       "      <td>0.023977</td>\n",
       "      <td>5950.069824</td>\n",
       "      <td>536.116028</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>307.907990</td>\n",
       "      <td>59.005402</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.028182</td>\n",
       "      <td>123.856003</td>\n",
       "      <td>0.197339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>0.025808</td>\n",
       "      <td>6559.490234</td>\n",
       "      <td>427.372986</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>316.716003</td>\n",
       "      <td>61.396500</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>0.030656</td>\n",
       "      <td>123.402000</td>\n",
       "      <td>0.203442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-26</th>\n",
       "      <td>0.608799</td>\n",
       "      <td>42520.402344</td>\n",
       "      <td>36.170387</td>\n",
       "      <td>0.091356</td>\n",
       "      <td>2231.465332</td>\n",
       "      <td>73.150520</td>\n",
       "      <td>0.103069</td>\n",
       "      <td>0.126002</td>\n",
       "      <td>174.092911</td>\n",
       "      <td>0.622369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>0.633535</td>\n",
       "      <td>43442.855469</td>\n",
       "      <td>38.391033</td>\n",
       "      <td>0.093579</td>\n",
       "      <td>2378.739990</td>\n",
       "      <td>75.850304</td>\n",
       "      <td>0.105409</td>\n",
       "      <td>0.130853</td>\n",
       "      <td>175.491974</td>\n",
       "      <td>0.634856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>0.617422</td>\n",
       "      <td>42627.855469</td>\n",
       "      <td>36.893234</td>\n",
       "      <td>0.091884</td>\n",
       "      <td>2347.566162</td>\n",
       "      <td>76.722328</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>0.132362</td>\n",
       "      <td>175.264069</td>\n",
       "      <td>0.634998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>0.608494</td>\n",
       "      <td>42099.402344</td>\n",
       "      <td>33.041344</td>\n",
       "      <td>0.091038</td>\n",
       "      <td>2300.690674</td>\n",
       "      <td>73.404144</td>\n",
       "      <td>0.105689</td>\n",
       "      <td>0.129619</td>\n",
       "      <td>166.700546</td>\n",
       "      <td>0.623402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30</th>\n",
       "      <td>0.601964</td>\n",
       "      <td>42156.902344</td>\n",
       "      <td>32.946571</td>\n",
       "      <td>0.090148</td>\n",
       "      <td>2292.065430</td>\n",
       "      <td>73.312737</td>\n",
       "      <td>0.105985</td>\n",
       "      <td>0.132611</td>\n",
       "      <td>165.771484</td>\n",
       "      <td>0.621844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2243 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker       ADA-USD       BTC-USD    DASH-USD  DOGE-USD      ETH-USD  \\\n",
       "Date                                                                    \n",
       "2017-11-09  0.032053   7143.580078  326.007996  0.001415   320.884003   \n",
       "2017-11-10  0.027119   6618.140137  329.571014  0.001163   299.252991   \n",
       "2017-11-11  0.027437   6357.600098  346.056000  0.001201   314.681000   \n",
       "2017-11-12  0.023977   5950.069824  536.116028  0.001038   307.907990   \n",
       "2017-11-13  0.025808   6559.490234  427.372986  0.001211   316.716003   \n",
       "...              ...           ...         ...       ...          ...   \n",
       "2023-12-26  0.608799  42520.402344   36.170387  0.091356  2231.465332   \n",
       "2023-12-27  0.633535  43442.855469   38.391033  0.093579  2378.739990   \n",
       "2023-12-28  0.617422  42627.855469   36.893234  0.091884  2347.566162   \n",
       "2023-12-29  0.608494  42099.402344   33.041344  0.091038  2300.690674   \n",
       "2023-12-30  0.601964  42156.902344   32.946571  0.090148  2292.065430   \n",
       "\n",
       "Ticker        LTC-USD   TRX-USD   XLM-USD     XMR-USD   XRP-USD  \n",
       "Date                                                             \n",
       "2017-11-09  64.269699  0.002344  0.039946  120.779999  0.217488  \n",
       "2017-11-10  59.260101  0.002013  0.033073  105.585999  0.206483  \n",
       "2017-11-11  62.303299  0.002003  0.033053  119.615997  0.210430  \n",
       "2017-11-12  59.005402  0.001783  0.028182  123.856003  0.197339  \n",
       "2017-11-13  61.396500  0.002112  0.030656  123.402000  0.203442  \n",
       "...               ...       ...       ...         ...       ...  \n",
       "2023-12-26  73.150520  0.103069  0.126002  174.092911  0.622369  \n",
       "2023-12-27  75.850304  0.105409  0.130853  175.491974  0.634856  \n",
       "2023-12-28  76.722328  0.105600  0.132362  175.264069  0.634998  \n",
       "2023-12-29  73.404144  0.105689  0.129619  166.700546  0.623402  \n",
       "2023-12-30  73.312737  0.105985  0.132611  165.771484  0.621844  \n",
       "\n",
       "[2243 rows x 10 columns]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  18 of 18 completed\n"
     ]
    }
   ],
   "source": [
    "ticker_list =  ['AAPL', 'MSFT', 'GOOG', 'AMZN', 'TSLA', 'JPM', 'BAC', 'V', 'MA', 'PG', 'KO', 'WMT', 'PEP', 'JNJ', 'UNH', 'PFE', 'ABBV', 'LLY']\n",
    "ticker_df = yf.download(ticker_list, start='2016-01-01', end='2023-12-31', interval='1D')['Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>BAC</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>JNJ</th>\n",
       "      <th>JPM</th>\n",
       "      <th>KO</th>\n",
       "      <th>LLY</th>\n",
       "      <th>MA</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>PEP</th>\n",
       "      <th>PFE</th>\n",
       "      <th>PG</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>UNH</th>\n",
       "      <th>V</th>\n",
       "      <th>WMT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>26.337500</td>\n",
       "      <td>57.610001</td>\n",
       "      <td>31.849501</td>\n",
       "      <td>16.430000</td>\n",
       "      <td>37.091999</td>\n",
       "      <td>100.480003</td>\n",
       "      <td>63.619999</td>\n",
       "      <td>42.400002</td>\n",
       "      <td>82.870003</td>\n",
       "      <td>94.809998</td>\n",
       "      <td>54.799999</td>\n",
       "      <td>98.769997</td>\n",
       "      <td>30.313093</td>\n",
       "      <td>78.370003</td>\n",
       "      <td>14.894000</td>\n",
       "      <td>116.459999</td>\n",
       "      <td>75.699997</td>\n",
       "      <td>20.486668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>25.677500</td>\n",
       "      <td>57.369999</td>\n",
       "      <td>31.689501</td>\n",
       "      <td>16.430000</td>\n",
       "      <td>37.129002</td>\n",
       "      <td>100.900002</td>\n",
       "      <td>63.730000</td>\n",
       "      <td>42.549999</td>\n",
       "      <td>84.110001</td>\n",
       "      <td>94.989998</td>\n",
       "      <td>55.049999</td>\n",
       "      <td>99.449997</td>\n",
       "      <td>30.531309</td>\n",
       "      <td>78.620003</td>\n",
       "      <td>14.895333</td>\n",
       "      <td>116.680000</td>\n",
       "      <td>76.269997</td>\n",
       "      <td>20.973333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>25.174999</td>\n",
       "      <td>57.380001</td>\n",
       "      <td>31.632500</td>\n",
       "      <td>16.080000</td>\n",
       "      <td>37.181000</td>\n",
       "      <td>100.389999</td>\n",
       "      <td>62.810001</td>\n",
       "      <td>42.320000</td>\n",
       "      <td>83.580002</td>\n",
       "      <td>93.349998</td>\n",
       "      <td>54.049999</td>\n",
       "      <td>99.480003</td>\n",
       "      <td>29.990513</td>\n",
       "      <td>77.860001</td>\n",
       "      <td>14.602667</td>\n",
       "      <td>115.489998</td>\n",
       "      <td>75.269997</td>\n",
       "      <td>21.183332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>24.112499</td>\n",
       "      <td>57.209999</td>\n",
       "      <td>30.396999</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>36.319500</td>\n",
       "      <td>99.220001</td>\n",
       "      <td>60.270000</td>\n",
       "      <td>41.619999</td>\n",
       "      <td>81.410004</td>\n",
       "      <td>91.639999</td>\n",
       "      <td>52.169998</td>\n",
       "      <td>97.570000</td>\n",
       "      <td>29.791271</td>\n",
       "      <td>77.180000</td>\n",
       "      <td>14.376667</td>\n",
       "      <td>112.089996</td>\n",
       "      <td>73.790001</td>\n",
       "      <td>21.676666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-08</th>\n",
       "      <td>24.240000</td>\n",
       "      <td>55.650002</td>\n",
       "      <td>30.352501</td>\n",
       "      <td>15.200000</td>\n",
       "      <td>35.723499</td>\n",
       "      <td>98.160004</td>\n",
       "      <td>58.919998</td>\n",
       "      <td>41.509998</td>\n",
       "      <td>81.250000</td>\n",
       "      <td>89.889999</td>\n",
       "      <td>52.330002</td>\n",
       "      <td>97.209999</td>\n",
       "      <td>29.411764</td>\n",
       "      <td>75.970001</td>\n",
       "      <td>14.066667</td>\n",
       "      <td>110.160004</td>\n",
       "      <td>72.879997</td>\n",
       "      <td>21.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-22</th>\n",
       "      <td>193.600006</td>\n",
       "      <td>154.940002</td>\n",
       "      <td>153.419998</td>\n",
       "      <td>33.430000</td>\n",
       "      <td>142.720001</td>\n",
       "      <td>155.460007</td>\n",
       "      <td>167.399994</td>\n",
       "      <td>58.320000</td>\n",
       "      <td>570.390015</td>\n",
       "      <td>424.100006</td>\n",
       "      <td>374.579987</td>\n",
       "      <td>167.679993</td>\n",
       "      <td>28.400000</td>\n",
       "      <td>145.279999</td>\n",
       "      <td>252.539993</td>\n",
       "      <td>520.309998</td>\n",
       "      <td>258.429993</td>\n",
       "      <td>52.216667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-26</th>\n",
       "      <td>193.050003</td>\n",
       "      <td>154.619995</td>\n",
       "      <td>153.410004</td>\n",
       "      <td>33.860001</td>\n",
       "      <td>142.820007</td>\n",
       "      <td>156.139999</td>\n",
       "      <td>168.389999</td>\n",
       "      <td>58.560001</td>\n",
       "      <td>570.669983</td>\n",
       "      <td>423.670013</td>\n",
       "      <td>374.660004</td>\n",
       "      <td>168.860001</td>\n",
       "      <td>28.410000</td>\n",
       "      <td>145.940002</td>\n",
       "      <td>256.609985</td>\n",
       "      <td>520.030029</td>\n",
       "      <td>259.160004</td>\n",
       "      <td>52.136665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>193.149994</td>\n",
       "      <td>154.880005</td>\n",
       "      <td>153.339996</td>\n",
       "      <td>33.840000</td>\n",
       "      <td>141.440002</td>\n",
       "      <td>156.350006</td>\n",
       "      <td>169.399994</td>\n",
       "      <td>58.709999</td>\n",
       "      <td>581.510010</td>\n",
       "      <td>424.359985</td>\n",
       "      <td>374.070007</td>\n",
       "      <td>169.399994</td>\n",
       "      <td>28.610001</td>\n",
       "      <td>146.059998</td>\n",
       "      <td>261.440002</td>\n",
       "      <td>522.789978</td>\n",
       "      <td>258.929993</td>\n",
       "      <td>52.626667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>193.580002</td>\n",
       "      <td>154.750000</td>\n",
       "      <td>153.380005</td>\n",
       "      <td>33.880001</td>\n",
       "      <td>141.279999</td>\n",
       "      <td>156.580002</td>\n",
       "      <td>170.300003</td>\n",
       "      <td>58.750000</td>\n",
       "      <td>580.849976</td>\n",
       "      <td>426.320007</td>\n",
       "      <td>375.279999</td>\n",
       "      <td>169.389999</td>\n",
       "      <td>28.790001</td>\n",
       "      <td>145.729996</td>\n",
       "      <td>253.179993</td>\n",
       "      <td>524.900024</td>\n",
       "      <td>260.399994</td>\n",
       "      <td>52.523335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>192.529999</td>\n",
       "      <td>154.970001</td>\n",
       "      <td>151.940002</td>\n",
       "      <td>33.669998</td>\n",
       "      <td>140.929993</td>\n",
       "      <td>156.740005</td>\n",
       "      <td>170.100006</td>\n",
       "      <td>58.930000</td>\n",
       "      <td>582.919983</td>\n",
       "      <td>426.510010</td>\n",
       "      <td>376.040009</td>\n",
       "      <td>169.839996</td>\n",
       "      <td>28.790001</td>\n",
       "      <td>146.539993</td>\n",
       "      <td>248.479996</td>\n",
       "      <td>526.469971</td>\n",
       "      <td>260.350006</td>\n",
       "      <td>52.549999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2012 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker            AAPL        ABBV        AMZN        BAC        GOOG  \\\n",
       "Date                                                                    \n",
       "2016-01-04   26.337500   57.610001   31.849501  16.430000   37.091999   \n",
       "2016-01-05   25.677500   57.369999   31.689501  16.430000   37.129002   \n",
       "2016-01-06   25.174999   57.380001   31.632500  16.080000   37.181000   \n",
       "2016-01-07   24.112499   57.209999   30.396999  15.500000   36.319500   \n",
       "2016-01-08   24.240000   55.650002   30.352501  15.200000   35.723499   \n",
       "...                ...         ...         ...        ...         ...   \n",
       "2023-12-22  193.600006  154.940002  153.419998  33.430000  142.720001   \n",
       "2023-12-26  193.050003  154.619995  153.410004  33.860001  142.820007   \n",
       "2023-12-27  193.149994  154.880005  153.339996  33.840000  141.440002   \n",
       "2023-12-28  193.580002  154.750000  153.380005  33.880001  141.279999   \n",
       "2023-12-29  192.529999  154.970001  151.940002  33.669998  140.929993   \n",
       "\n",
       "Ticker             JNJ         JPM         KO         LLY          MA  \\\n",
       "Date                                                                    \n",
       "2016-01-04  100.480003   63.619999  42.400002   82.870003   94.809998   \n",
       "2016-01-05  100.900002   63.730000  42.549999   84.110001   94.989998   \n",
       "2016-01-06  100.389999   62.810001  42.320000   83.580002   93.349998   \n",
       "2016-01-07   99.220001   60.270000  41.619999   81.410004   91.639999   \n",
       "2016-01-08   98.160004   58.919998  41.509998   81.250000   89.889999   \n",
       "...                ...         ...        ...         ...         ...   \n",
       "2023-12-22  155.460007  167.399994  58.320000  570.390015  424.100006   \n",
       "2023-12-26  156.139999  168.389999  58.560001  570.669983  423.670013   \n",
       "2023-12-27  156.350006  169.399994  58.709999  581.510010  424.359985   \n",
       "2023-12-28  156.580002  170.300003  58.750000  580.849976  426.320007   \n",
       "2023-12-29  156.740005  170.100006  58.930000  582.919983  426.510010   \n",
       "\n",
       "Ticker            MSFT         PEP        PFE          PG        TSLA  \\\n",
       "Date                                                                    \n",
       "2016-01-04   54.799999   98.769997  30.313093   78.370003   14.894000   \n",
       "2016-01-05   55.049999   99.449997  30.531309   78.620003   14.895333   \n",
       "2016-01-06   54.049999   99.480003  29.990513   77.860001   14.602667   \n",
       "2016-01-07   52.169998   97.570000  29.791271   77.180000   14.376667   \n",
       "2016-01-08   52.330002   97.209999  29.411764   75.970001   14.066667   \n",
       "...                ...         ...        ...         ...         ...   \n",
       "2023-12-22  374.579987  167.679993  28.400000  145.279999  252.539993   \n",
       "2023-12-26  374.660004  168.860001  28.410000  145.940002  256.609985   \n",
       "2023-12-27  374.070007  169.399994  28.610001  146.059998  261.440002   \n",
       "2023-12-28  375.279999  169.389999  28.790001  145.729996  253.179993   \n",
       "2023-12-29  376.040009  169.839996  28.790001  146.539993  248.479996   \n",
       "\n",
       "Ticker             UNH           V        WMT  \n",
       "Date                                           \n",
       "2016-01-04  116.459999   75.699997  20.486668  \n",
       "2016-01-05  116.680000   76.269997  20.973333  \n",
       "2016-01-06  115.489998   75.269997  21.183332  \n",
       "2016-01-07  112.089996   73.790001  21.676666  \n",
       "2016-01-08  110.160004   72.879997  21.180000  \n",
       "...                ...         ...        ...  \n",
       "2023-12-22  520.309998  258.429993  52.216667  \n",
       "2023-12-26  520.030029  259.160004  52.136665  \n",
       "2023-12-27  522.789978  258.929993  52.626667  \n",
       "2023-12-28  524.900024  260.399994  52.523335  \n",
       "2023-12-29  526.469971  260.350006  52.549999  \n",
       "\n",
       "[2012 rows x 18 columns]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(stock_data):\n",
    "\n",
    "    periods = {\n",
    "        'year5': 5 * 252,\n",
    "        'year2': 2 * 252,\n",
    "        'year1': 252,\n",
    "        'month6': 6 * 21,\n",
    "        'month3': 3 * 21,\n",
    "        'month1': 21,\n",
    "        'day30': 30,\n",
    "        'day5': 5\n",
    "    }\n",
    "        \n",
    "\n",
    "    changes = {}\n",
    "    # column_name = 'Adj Close' if 'Adj Close' in stock_data.columns else 'Close'\n",
    "    # column_name = stock_data.columns\n",
    "    # stock_data = stock_data[column_name]\n",
    "\n",
    "    # Calculate max change percentage\n",
    "    max_price = stock_data.max()\n",
    "    min_price = stock_data.min()\n",
    "    latest_close = stock_data.iloc[-1]\n",
    "\n",
    "    changes['maxChangepercent'] = ((max_price - min_price) / min_price) * 100\n",
    "\n",
    "    # Calculate change percentages for each period\n",
    "    for period_name, period_days in periods.items():\n",
    "        period_days = min(period_days, len(stock_data))  # Ensure we do not exceed available data\n",
    "        past_close = stock_data.iloc[-period_days] if period_days > 0 else latest_close\n",
    "        changes[f'{period_name}Changepercent'] = ((latest_close - past_close) / past_close) * 100\n",
    "\n",
    "    dataframe = pd.DataFrame.from_dict(changes)\n",
    "\n",
    "\n",
    "    return dataframe\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxChangepercent</th>\n",
       "      <th>year5Changepercent</th>\n",
       "      <th>year2Changepercent</th>\n",
       "      <th>year1Changepercent</th>\n",
       "      <th>month6Changepercent</th>\n",
       "      <th>month3Changepercent</th>\n",
       "      <th>month1Changepercent</th>\n",
       "      <th>day30Changepercent</th>\n",
       "      <th>day5Changepercent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>777.175154</td>\n",
       "      <td>392.939907</td>\n",
       "      <td>7.330803</td>\n",
       "      <td>48.545635</td>\n",
       "      <td>0.036367</td>\n",
       "      <td>10.808632</td>\n",
       "      <td>1.358253</td>\n",
       "      <td>1.486475</td>\n",
       "      <td>-0.552690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>241.852297</td>\n",
       "      <td>70.072428</td>\n",
       "      <td>14.487294</td>\n",
       "      <td>-4.669043</td>\n",
       "      <td>14.784096</td>\n",
       "      <td>4.532884</td>\n",
       "      <td>8.834891</td>\n",
       "      <td>12.069715</td>\n",
       "      <td>0.019362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>674.039010</td>\n",
       "      <td>105.599384</td>\n",
       "      <td>-10.201477</td>\n",
       "      <td>80.494181</td>\n",
       "      <td>16.679466</td>\n",
       "      <td>17.364433</td>\n",
       "      <td>4.004385</td>\n",
       "      <td>6.378212</td>\n",
       "      <td>-0.964669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAC</th>\n",
       "      <td>342.473134</td>\n",
       "      <td>38.048376</td>\n",
       "      <td>-24.557478</td>\n",
       "      <td>1.599272</td>\n",
       "      <td>15.308210</td>\n",
       "      <td>26.104858</td>\n",
       "      <td>10.429644</td>\n",
       "      <td>13.981033</td>\n",
       "      <td>0.717912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>351.049016</td>\n",
       "      <td>171.782297</td>\n",
       "      <td>-3.805008</td>\n",
       "      <td>58.437322</td>\n",
       "      <td>16.896148</td>\n",
       "      <td>4.261297</td>\n",
       "      <td>5.234464</td>\n",
       "      <td>1.607784</td>\n",
       "      <td>-1.254210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JNJ</th>\n",
       "      <td>94.266313</td>\n",
       "      <td>23.155504</td>\n",
       "      <td>-8.633050</td>\n",
       "      <td>-11.725610</td>\n",
       "      <td>-4.046526</td>\n",
       "      <td>1.024822</td>\n",
       "      <td>1.344887</td>\n",
       "      <td>4.423717</td>\n",
       "      <td>0.823362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPM</th>\n",
       "      <td>223.685698</td>\n",
       "      <td>75.668701</td>\n",
       "      <td>7.278008</td>\n",
       "      <td>27.683534</td>\n",
       "      <td>16.022103</td>\n",
       "      <td>18.313974</td>\n",
       "      <td>8.982576</td>\n",
       "      <td>12.314301</td>\n",
       "      <td>1.612911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KO</th>\n",
       "      <td>76.277946</td>\n",
       "      <td>24.851694</td>\n",
       "      <td>-0.033928</td>\n",
       "      <td>-7.849883</td>\n",
       "      <td>-2.723674</td>\n",
       "      <td>6.218459</td>\n",
       "      <td>0.838470</td>\n",
       "      <td>3.114608</td>\n",
       "      <td>1.045954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LLY</th>\n",
       "      <td>838.502340</td>\n",
       "      <td>410.437827</td>\n",
       "      <td>109.367127</td>\n",
       "      <td>58.825132</td>\n",
       "      <td>26.331751</td>\n",
       "      <td>8.291071</td>\n",
       "      <td>-1.373849</td>\n",
       "      <td>-0.990236</td>\n",
       "      <td>2.196737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA</th>\n",
       "      <td>428.840672</td>\n",
       "      <td>129.109369</td>\n",
       "      <td>18.051980</td>\n",
       "      <td>22.486436</td>\n",
       "      <td>8.262265</td>\n",
       "      <td>7.745359</td>\n",
       "      <td>3.064066</td>\n",
       "      <td>7.406196</td>\n",
       "      <td>0.568263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>690.212698</td>\n",
       "      <td>274.579152</td>\n",
       "      <td>9.969292</td>\n",
       "      <td>56.026728</td>\n",
       "      <td>11.257735</td>\n",
       "      <td>16.855197</td>\n",
       "      <td>-0.757435</td>\n",
       "      <td>-0.034560</td>\n",
       "      <td>0.389776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP</th>\n",
       "      <td>109.150050</td>\n",
       "      <td>53.896335</td>\n",
       "      <td>-1.809565</td>\n",
       "      <td>-6.671063</td>\n",
       "      <td>-8.491384</td>\n",
       "      <td>0.396050</td>\n",
       "      <td>0.921031</td>\n",
       "      <td>1.270043</td>\n",
       "      <td>1.288170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PFE</th>\n",
       "      <td>134.404906</td>\n",
       "      <td>-29.365316</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>-43.911943</td>\n",
       "      <td>-21.446113</td>\n",
       "      <td>-15.173830</td>\n",
       "      <td>-5.513615</td>\n",
       "      <td>-3.291903</td>\n",
       "      <td>1.373244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PG</th>\n",
       "      <td>131.477306</td>\n",
       "      <td>60.715061</td>\n",
       "      <td>-10.749747</td>\n",
       "      <td>-3.964875</td>\n",
       "      <td>-3.908201</td>\n",
       "      <td>0.929810</td>\n",
       "      <td>-4.546646</td>\n",
       "      <td>-4.115690</td>\n",
       "      <td>0.867287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>4180.329905</td>\n",
       "      <td>1016.362666</td>\n",
       "      <td>-31.371122</td>\n",
       "      <td>103.973072</td>\n",
       "      <td>-11.200061</td>\n",
       "      <td>-1.240068</td>\n",
       "      <td>3.498831</td>\n",
       "      <td>6.374417</td>\n",
       "      <td>-1.607665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNH</th>\n",
       "      <td>408.239501</td>\n",
       "      <td>113.803590</td>\n",
       "      <td>4.131885</td>\n",
       "      <td>-0.643548</td>\n",
       "      <td>10.167817</td>\n",
       "      <td>2.312603</td>\n",
       "      <td>-4.792304</td>\n",
       "      <td>-2.473053</td>\n",
       "      <td>1.183904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <td>287.162488</td>\n",
       "      <td>98.831527</td>\n",
       "      <td>19.333551</td>\n",
       "      <td>25.132178</td>\n",
       "      <td>9.404549</td>\n",
       "      <td>12.574048</td>\n",
       "      <td>1.429801</td>\n",
       "      <td>4.739107</td>\n",
       "      <td>0.742953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMT</th>\n",
       "      <td>179.059824</td>\n",
       "      <td>71.116903</td>\n",
       "      <td>10.468782</td>\n",
       "      <td>10.903978</td>\n",
       "      <td>-0.347663</td>\n",
       "      <td>-1.530299</td>\n",
       "      <td>1.258909</td>\n",
       "      <td>1.031787</td>\n",
       "      <td>0.638363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        maxChangepercent  year5Changepercent  year2Changepercent  \\\n",
       "Ticker                                                             \n",
       "AAPL          777.175154          392.939907            7.330803   \n",
       "ABBV          241.852297           70.072428           14.487294   \n",
       "AMZN          674.039010          105.599384          -10.201477   \n",
       "BAC           342.473134           38.048376          -24.557478   \n",
       "GOOG          351.049016          171.782297           -3.805008   \n",
       "JNJ            94.266313           23.155504           -8.633050   \n",
       "JPM           223.685698           75.668701            7.278008   \n",
       "KO             76.277946           24.851694           -0.033928   \n",
       "LLY           838.502340          410.437827          109.367127   \n",
       "MA            428.840672          129.109369           18.051980   \n",
       "MSFT          690.212698          274.579152            9.969292   \n",
       "PEP           109.150050           53.896335           -1.809565   \n",
       "PFE           134.404906          -29.365316          -50.000000   \n",
       "PG            131.477306           60.715061          -10.749747   \n",
       "TSLA         4180.329905         1016.362666          -31.371122   \n",
       "UNH           408.239501          113.803590            4.131885   \n",
       "V             287.162488           98.831527           19.333551   \n",
       "WMT           179.059824           71.116903           10.468782   \n",
       "\n",
       "        year1Changepercent  month6Changepercent  month3Changepercent  \\\n",
       "Ticker                                                                 \n",
       "AAPL             48.545635             0.036367            10.808632   \n",
       "ABBV             -4.669043            14.784096             4.532884   \n",
       "AMZN             80.494181            16.679466            17.364433   \n",
       "BAC               1.599272            15.308210            26.104858   \n",
       "GOOG             58.437322            16.896148             4.261297   \n",
       "JNJ             -11.725610            -4.046526             1.024822   \n",
       "JPM              27.683534            16.022103            18.313974   \n",
       "KO               -7.849883            -2.723674             6.218459   \n",
       "LLY              58.825132            26.331751             8.291071   \n",
       "MA               22.486436             8.262265             7.745359   \n",
       "MSFT             56.026728            11.257735            16.855197   \n",
       "PEP              -6.671063            -8.491384             0.396050   \n",
       "PFE             -43.911943           -21.446113           -15.173830   \n",
       "PG               -3.964875            -3.908201             0.929810   \n",
       "TSLA            103.973072           -11.200061            -1.240068   \n",
       "UNH              -0.643548            10.167817             2.312603   \n",
       "V                25.132178             9.404549            12.574048   \n",
       "WMT              10.903978            -0.347663            -1.530299   \n",
       "\n",
       "        month1Changepercent  day30Changepercent  day5Changepercent  \n",
       "Ticker                                                              \n",
       "AAPL               1.358253            1.486475          -0.552690  \n",
       "ABBV               8.834891           12.069715           0.019362  \n",
       "AMZN               4.004385            6.378212          -0.964669  \n",
       "BAC               10.429644           13.981033           0.717912  \n",
       "GOOG               5.234464            1.607784          -1.254210  \n",
       "JNJ                1.344887            4.423717           0.823362  \n",
       "JPM                8.982576           12.314301           1.612911  \n",
       "KO                 0.838470            3.114608           1.045954  \n",
       "LLY               -1.373849           -0.990236           2.196737  \n",
       "MA                 3.064066            7.406196           0.568263  \n",
       "MSFT              -0.757435           -0.034560           0.389776  \n",
       "PEP                0.921031            1.270043           1.288170  \n",
       "PFE               -5.513615           -3.291903           1.373244  \n",
       "PG                -4.546646           -4.115690           0.867287  \n",
       "TSLA               3.498831            6.374417          -1.607665  \n",
       "UNH               -4.792304           -2.473053           1.183904  \n",
       "V                  1.429801            4.739107           0.742953  \n",
       "WMT                1.258909            1.031787           0.638363  "
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stats(ticker_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_poistion():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ = get_stats(ticker_df).sort_values('month3Changepercent', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "hqm_df = pd.DataFrame.from_dict(get_stats(df1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Ticker'>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hqm_df['year1Changepercent'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  4 of 4 completed\n"
     ]
    }
   ],
   "source": [
    "tickers = yf.download(['AAPL', 'MSFT', 'GOOG', 'AMZN'], start='2020-01-01', end='2020-12-31')['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AAPL', 'AMZN', 'GOOG', 'MSFT'], dtype='object', name='Ticker')"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HQM:\n",
    "\n",
    "    def __init__(self, stock_data):\n",
    "        self.stock_data = stock_data\n",
    "\n",
    "    def get_stats(self):\n",
    "        periods = {\n",
    "        'year5': 5 * 252,\n",
    "        'year2': 2 * 252,\n",
    "        'year1': 252,\n",
    "        'month6': 6 * 21,\n",
    "        'month3': 3 * 21,\n",
    "        'month1': 21,\n",
    "        'day30': 30,\n",
    "        'day5': 5\n",
    "    }\n",
    "        \n",
    "\n",
    "        changes = {}\n",
    "        # stock_columns = self.stock_data.columns\n",
    "        # print(stock_columns)\n",
    "        # stock_data = stock_data[stock_columns]\n",
    "\n",
    "        # Calculate max change percentage\n",
    "        max_price = stock_data.max()\n",
    "        print(max_price)\n",
    "        min_price = stock_data.min()\n",
    "        latest_close = stock_data.iloc[-1]\n",
    "\n",
    "        changes['maxChangepercent'] = ((max_price - min_price) / min_price) * 100\n",
    "\n",
    "        # Calculate change percentages for each period\n",
    "        for period_name, period_days in periods.items():\n",
    "            period_days = min(period_days, len(stock_data))  # Ensure we do not exceed available data\n",
    "            past_close = stock_data.iloc[-period_days] if period_days > 0 else latest_close\n",
    "            changes[f'{period_name}Changepercent'] = ((latest_close - past_close) / past_close) * 100\n",
    "\n",
    "        dataframe = pd.DataFrame.from_dict(changes)\n",
    "\n",
    "        return dataframe\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open         2.175900e+02\n",
      "High         2.202000e+02\n",
      "Low          2.130000e+02\n",
      "Close        2.166700e+02\n",
      "Adj Close    2.166700e+02\n",
      "Volume       2.418051e+08\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxChangepercent</th>\n",
       "      <th>year5Changepercent</th>\n",
       "      <th>year2Changepercent</th>\n",
       "      <th>year1Changepercent</th>\n",
       "      <th>month6Changepercent</th>\n",
       "      <th>month3Changepercent</th>\n",
       "      <th>month1Changepercent</th>\n",
       "      <th>day30Changepercent</th>\n",
       "      <th>day5Changepercent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>72.676766</td>\n",
       "      <td>48.477491</td>\n",
       "      <td>48.477491</td>\n",
       "      <td>11.948261</td>\n",
       "      <td>5.925546</td>\n",
       "      <td>21.779910</td>\n",
       "      <td>8.765319</td>\n",
       "      <td>12.341811</td>\n",
       "      <td>-2.647980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High</th>\n",
       "      <td>72.340927</td>\n",
       "      <td>49.883723</td>\n",
       "      <td>49.883723</td>\n",
       "      <td>13.403711</td>\n",
       "      <td>7.925713</td>\n",
       "      <td>23.705940</td>\n",
       "      <td>11.361255</td>\n",
       "      <td>14.917068</td>\n",
       "      <td>-2.854533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low</th>\n",
       "      <td>71.539022</td>\n",
       "      <td>47.807105</td>\n",
       "      <td>47.807105</td>\n",
       "      <td>11.664236</td>\n",
       "      <td>6.764856</td>\n",
       "      <td>21.917970</td>\n",
       "      <td>10.694953</td>\n",
       "      <td>13.429963</td>\n",
       "      <td>-2.881725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close</th>\n",
       "      <td>73.308274</td>\n",
       "      <td>49.911330</td>\n",
       "      <td>49.911330</td>\n",
       "      <td>13.758519</td>\n",
       "      <td>9.083831</td>\n",
       "      <td>24.298734</td>\n",
       "      <td>13.636767</td>\n",
       "      <td>16.014418</td>\n",
       "      <td>-1.987171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj Close</th>\n",
       "      <td>74.736041</td>\n",
       "      <td>51.607391</td>\n",
       "      <td>51.607391</td>\n",
       "      <td>14.362663</td>\n",
       "      <td>9.371178</td>\n",
       "      <td>24.467324</td>\n",
       "      <td>13.636767</td>\n",
       "      <td>16.014418</td>\n",
       "      <td>-1.987171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>905.497686</td>\n",
       "      <td>-63.829567</td>\n",
       "      <td>-63.829567</td>\n",
       "      <td>-39.272123</td>\n",
       "      <td>-30.653618</td>\n",
       "      <td>-40.624532</td>\n",
       "      <td>-36.803523</td>\n",
       "      <td>-36.496750</td>\n",
       "      <td>-65.609179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           maxChangepercent  year5Changepercent  year2Changepercent  \\\n",
       "Open              72.676766           48.477491           48.477491   \n",
       "High              72.340927           49.883723           49.883723   \n",
       "Low               71.539022           47.807105           47.807105   \n",
       "Close             73.308274           49.911330           49.911330   \n",
       "Adj Close         74.736041           51.607391           51.607391   \n",
       "Volume           905.497686          -63.829567          -63.829567   \n",
       "\n",
       "           year1Changepercent  month6Changepercent  month3Changepercent  \\\n",
       "Open                11.948261             5.925546            21.779910   \n",
       "High                13.403711             7.925713            23.705940   \n",
       "Low                 11.664236             6.764856            21.917970   \n",
       "Close               13.758519             9.083831            24.298734   \n",
       "Adj Close           14.362663             9.371178            24.467324   \n",
       "Volume             -39.272123           -30.653618           -40.624532   \n",
       "\n",
       "           month1Changepercent  day30Changepercent  day5Changepercent  \n",
       "Open                  8.765319           12.341811          -2.647980  \n",
       "High                 11.361255           14.917068          -2.854533  \n",
       "Low                  10.694953           13.429963          -2.881725  \n",
       "Close                13.636767           16.014418          -1.987171  \n",
       "Adj Close            13.636767           16.014418          -1.987171  \n",
       "Volume              -36.803523          -36.496750         -65.609179  "
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clobj = HQM(ticker_df).get_stats()\n",
    "clobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
